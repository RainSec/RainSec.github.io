{"meta":{"title":"RainSec","subtitle":"","description":"致力于云原生安全和自动化渗透测试的研究与分享","author":"RainSec","url":"https://rainsec.cn","root":"/"},"pages":[{"title":"about","date":"2022-01-28T03:36:25.000Z","updated":"2022-01-28T03:36:25.402Z","comments":true,"path":"about/index.html","permalink":"https://rainsec.cn/about/index.html","excerpt":"","text":""},{"title":"categories","date":"2019-07-14T04:39:04.000Z","updated":"2022-07-20T05:27:57.522Z","comments":true,"path":"categories/index.html","permalink":"https://rainsec.cn/categories/index.html","excerpt":"","text":""},{"title":"links","date":"2022-01-28T03:37:00.000Z","updated":"2022-01-28T03:37:00.466Z","comments":true,"path":"links/index.html","permalink":"https://rainsec.cn/links/index.html","excerpt":"","text":""},{"title":"tags","date":"2014-12-22T04:39:04.000Z","updated":"2022-07-20T05:28:08.938Z","comments":true,"path":"tags/index.html","permalink":"https://rainsec.cn/tags/index.html","excerpt":"","text":""}],"posts":[{"title":"Ubuntu 20.04更新内核到指定版本","slug":"Ubuntu20.04 升级降级内核到指定版本","date":"2022-03-28T10:38:45.000Z","updated":"2022-07-20T07:30:14.668Z","comments":true,"path":"/post/Ubuntu20.04 升级降级内核到指定版本.html","link":"","permalink":"https://rainsec.cn/post/Ubuntu20.04%20%E5%8D%87%E7%BA%A7%E9%99%8D%E7%BA%A7%E5%86%85%E6%A0%B8%E5%88%B0%E6%8C%87%E5%AE%9A%E7%89%88%E6%9C%AC.html","excerpt":"记一次更新内核到5.8.0-33-generic","text":"记一次更新内核到5.8.0-33-generic 更新到指定版本查看当前版本$ uname -r 4.15.0-101-generic $ lsb_release -a No LSB modules are available. Distributor ID: Ubuntu Description: Ubuntu 20.04 LTS Release: 20.04 Codename: focal 查看当前已经安装的 Kernel Image$ dpkg --get-selections |grep linux-image linux-image-5.4.0-90-generic purge linux-image-5.8.0-33-generic install linux-image-generic install 查询当前软件仓库可以安装的 Kernel Image 版本，如果没有预期的版本，则需要额外配置仓库$ apt-cache search linux | grep linux-image 安装指定版本的 Kernel Image 和 Kernel Header$ sudo apt-get install linux-headers-5.8.0-33-generic linux-image-5.8.0-33-generic 查看当前的Kernel列表$ grep menuentry /boot/grub/grub.cfg if [ x\"${feature_menuentry_id}\" = xy ]; then menuentry_id_option=\"--id\" menuentry_id_option=\"\" export menuentry_id_option menuentry 'Ubuntu' --class ubuntu --class gnu-linux --class gnu --class os $menuentry_id_option 'gnulinux-simple-b986dc3b-6b82-44d5-acb8-6cbad5e357d5' { submenu 'Advanced options for Ubuntu' $menuentry_id_option 'gnulinux-advanced-b986dc3b-6b82-44d5-acb8-6cbad5e357d5' { menuentry 'Ubuntu, with Linux 5.8.0-33-generic' --class ubuntu --class gnu-linux --class gnu --class os $menuentry_id_option 'gnulinux-5.8.0-33-generic-advanced-b986dc3b-6b82-44d5-acb8-6cbad5e357d5' { menuentry 'Ubuntu, with Linux 5.8.0-33-generic (recovery mode)' --class ubuntu --class gnu-linux --class gnu --class os $menuentry_id_option 'gnulinux-5.8.0-33-generic-recovery-b986dc3b-6b82-44d5-acb8-6cbad5e357d5' { menuentry 'Ubuntu, with Linux 5.4.0-90-generic' --class ubuntu --class gnu-linux --class gnu --class os $menuentry_id_option 'gnulinux-5.4.0-90-generic-advanced-b986dc3b-6b82-44d5-acb8-6cbad5e357d5' { menuentry 'Ubuntu, with Linux 5.4.0-90-generic (recovery mode)' --class ubuntu --class gnu-linux --class gnu --class os $menuentry_id_option 'gnulinux-5.4.0-90-generic-recovery-b986dc3b-6b82-44d5-acb8-6cbad5e357d5' { 修改 Kernel 的启动顺序：如果安装的是最新的版本，那么默认就是首选的；如果安装的是旧版本，就需要修改 grub 配置$ sudo vim /etc/default/grub # GRUB_DEFAULT=0 GRUB_DEFAULT=\"Advanced options for Ubuntu&gt;Ubuntu, with Linux 5.8.0-33-generic\" 生效配置$ update-grub $ reboot 删除不需要的Kernel查询不包括当前内核版本的其它所有内核版本$ dpkg -l | tail -n +6| grep -E 'linux-image-[0-9]+'| grep -Fv $(uname -r) pi linux-image-5.4.0-90-generic 5.4.0-90.101 amd64 Signed kernel image generic Kernel 状态： rc：表示已经被移除 ii：表示符合移除条件（可移除） iU：已进入 apt 安装队列，但还未被安装（不可移除） 删除指定的Kerneldpkg --purge linux-image-5.4.0-90-generic","categories":[{"name":"Zitui","slug":"Zitui","permalink":"https://rainsec.cn/categories/Zitui/"},{"name":"Ubuntu","slug":"Zitui/Ubuntu","permalink":"https://rainsec.cn/categories/Zitui/Ubuntu/"}],"tags":[{"name":"Linux","slug":"Linux","permalink":"https://rainsec.cn/tags/Linux/"}],"author":"Zitui"},{"title":"Go-fuzz的解析与思考","slug":"Go-Fuzz解析与思考","date":"2022-03-25T10:48:45.000Z","updated":"2022-07-20T05:42:22.848Z","comments":true,"path":"/post/Go-Fuzz解析与思考.html","link":"","permalink":"https://rainsec.cn/post/Go-Fuzz%E8%A7%A3%E6%9E%90%E4%B8%8E%E6%80%9D%E8%80%83.html","excerpt":"","text":"Go-fuzz的解析与思考go-fuzz Go-fuzz的原理很多都是基于AFL，这里只分析了一些它独特的地方，收获很多，也希望可以和大家交流，如有分析错误还望交流指正。 ​ go-fuzz是google开源的一款go语言fuzz框架，它和AFL很大的一个不同是在于，AFL通常通过对未修改的文件的输入进行操作，而go-fuzz需要你编写一个Fuzz函数，go-fuzz通过不断的调用该函数来进行fuzz，前者通常会为每一个输入创建一个新的进程，后者则是不断的调用Fuzz函数因此不需要经常启动或者重启进程。 什么是覆盖引导型Fuzz​ 覆盖引导型Fuzz通过代码覆盖率信息来决定一个突变是否有效，如果代码覆盖率增长就保存该输入并对其进行持续变异，否则就丢弃该变异： 源码解析go-fuzz-build模块​ 该模块的主要作用在于将需要测试的包信息和测试用例信息打包方便进行测试。 利用PProf进行性能分析 加载选中的go语言包和github.com/dvyukov/go-fuzz/go-fuzz-dep这个fuzz材料包 遍历加载的go语言包里面所有的函数名查找所有的名为Fuzz的函数，同时进行签名认证，但是Fuzz函数的个数应该大于0同时小于等于255 获取环境变量，大多是和go有关的环境变量. 加载go语言标准库 忽略一些标准库中的包和github.com/dvyukov/go-fuzz/go-fuzz-dep这个包，因为没有理由进行fuzz测试，为了避免陷入循环（具体为啥我也不是很清楚） 在/tmp下创建临时文件夹保存需要使用的tools和包 接下来就是很高阶的语法树等的建立过程，这个过程中会使用gatherLiterals获取到你提供的初始材料 获取到需要fuzz的包的具体信息，进而可以生成go-fuzz的元数据 将存储信息的cover.exe和sonar.exe已经metadata打包生成zip文件夹 语法树插桩实现​ go语言不同于C语言可以as等汇编工具来较为方便的实现编译时插桩（具体可以参考AFL的插桩方式），为了实现go语言的编译时插桩，我们首先要了解go语言整体的编译流程： 词法与语法分析 类型检查 中间代码生成 机器码生成 那么其实大致就可以看出比较理想的地方就是词法与语法分析的时候对抽象语法书进行插桩了，同时go标准库也提供了scanner，ast和token等相关库来帮助很好的扫描，解析和创建相关抽象语法树，在整个插桩的过程中其实是把go的包一个个遍历插桩的，然后因为go-fuzz不允许导入main包，其实是因为它在插桩完成之后会自己加入相关的main函数。 ​ 在go-fuzz-build中实现了结构体File和结构体Sonar，这两个结构体都实现了自己的Visit()函数用来遍历相关的语法树： type File struct { fset *token.FileSet pkg string fullName string astFile *ast.File blocks *[]CoverBlock info *types.Info } type Sonar struct { fset *token.FileSet fullName string pkg string blocks *[]CoverBlock info *types.Info } 在整个的build的过程中也会生成coverBin和sonarBin两个文件分别对应上述两个结构体的语法树遍历函数执行结果。 File遍历​ 在生成coverBin的时候使用的是File结构体对应的Visit遍历函数，不过在开始遍历之前会通过自身实现的addImport来实现go-fuzz-dep包相关内容的导入： file.addImport(“go-fuzz-dep”, fuzzdepPkg, “CoverTab”) func (f *File) addImport(path, name, anyIdent string) { newImport := &amp;ast.ImportSpec{ Name: ast.NewIdent(name), Path: &amp;ast.BasicLit{ Kind: token.STRING, Value: fmt.Sprintf(\"%q\", path), }, } impDecl := &amp;ast.GenDecl{ Lparen: f.astFile.Name.End(), Tok: token.IMPORT, Specs: []ast.Spec{ newImport, }, Rparen: f.astFile.Name.End(), } // Make the new import the first Decl in the file. astFile := f.astFile astFile.Decls = append(astFile.Decls, nil) copy(astFile.Decls[1:], astFile.Decls[0:]) astFile.Decls[0] = impDecl astFile.Imports = append(astFile.Imports, newImport) // Now refer to the package, just in case it ends up unused. // That is, append to the end of the file the declaration // var _ = _cover_atomic_.AddUint32 reference := &amp;ast.GenDecl{ Tok: token.VAR, Specs: []ast.Spec{ &amp;ast.ValueSpec{ Names: []*ast.Ident{ ast.NewIdent(\"_\"), }, Values: []ast.Expr{ &amp;ast.SelectorExpr{ X: ast.NewIdent(name), Sel: ast.NewIdent(anyIdent), }, }, }, }, } astFile.Decls = append(astFile.Decls, reference) } 观察源码其实逻辑也很简单，首先创建了一个基本声明信息节点来将相关的包导入原本的语法树中，同时为了避免导入包但是未使用，所以导入简单的声明语句。导入完成之后使用ast.Walk()来遍历语法树，该函数会调用File结构体对应的Visit函数。 // 源码太长，只贴部分 func (f *File) Visit(node ast.Node) ast.Visitor { switch n := node.(type) { case *ast.FuncDecl: if n.Name.String() == \"init\" { // Don't instrument init functions. // They run regardless of what we do, so it is just noise. return nil } case *ast.GenDecl: if n.Tok != token.VAR { return nil // constants and types are not interesting } case *ast.BlockStmt: // {}中间的语句 // If it's a switch or select, the body is a list of case clauses; don't tag the block itself. if len(n.List) &gt; 0 { switch n.List[0].(type) { case *ast.CaseClause: // switch for _, n := range n.List { clause := n.(*ast.CaseClause) clause.Body = f.addCounters(clause.Pos(), clause.End(), clause.Body, false) } return f case *ast.CommClause: // select for _, n := range n.List { clause := n.(*ast.CommClause) clause.Body = f.addCounters(clause.Pos(), clause.End(), clause.Body, false) } return f } } n.List = f.addCounters(n.Lbrace, n.Rbrace+1, n.List, true) // +1 to step past closing brace. ...... } 可以看出在遍历语法树的过程中对节点的类型进行了判断，然后对{}中间的内容进行一个判断和插桩，具体的插桩函数如下： func (f *File) addCounters(pos, blockEnd token.Pos, list []ast.Stmt, extendToClosingBrace bool) []ast.Stmt { // Special case: make sure we add a counter to an empty block. Can't do this below // or we will add a counter to an empty statement list after, say, a return statement. if len(list) == 0 { return []ast.Stmt{f.newCounter(pos, blockEnd, 0)} } // We have a block (statement list), but it may have several basic blocks due to the // appearance of statements that affect the flow of control. var newList []ast.Stmt for { // Find first statement that affects flow of control (break, continue, if, etc.). // It will be the last statement of this basic block. var last int end := blockEnd for last = 0; last &lt; len(list); last++ { end = f.statementBoundary(list[last]) if f.endsBasicSourceBlock(list[last]) { extendToClosingBrace = false // Block is broken up now. last++ break } } if extendToClosingBrace { end = blockEnd } if pos != end { // Can have no source to cover if e.g. blocks abut. newList = append(newList, f.newCounter(pos, end, last)) // 在List里面增加counter计数器 } newList = append(newList, list[0:last]...) list = list[last:] if len(list) == 0 { break } pos = list[0].Pos() } return newList } 假设现在有一个switch的demo func main() { var n = 1 switch n { case 0: fmt.Println(\"this is 0\") case 1: fmt.Println(\"this is 1\") } } 这一步的具体操作就是把每一个case拿出来，然后将case相关的语法树的起始位置和结束位置还有body部分全部传入addCounters，addCounters的逻辑起始也非常简单，如果body为空就直接返回一个Counter的ast.Stmt声明语法树结构， Counter是作者自定义的一种插桩计数器，这种计数器主要包括两个部分: 对于每个包的File的结构体都维护了一个*[]CoverBlock，每次增加Counter都会在这个数组里面增加一个CoverBlock里面记录了插桩语法树的位置以及内部是否还包含多少其他声明。 一个是ast.IncDecStmt节点，这个是newCounter()函数的返回值 如果body不为空就找到所有影响控制流的声明，比如if，switch, break ,goto等都会开启或者中断一个新的控制流，找到边界声明之后判断其是否属于刚才的类型： func (f *File) endsBasicSourceBlock(s ast.Stmt) bool { switch s := s.(type) { case *ast.BlockStmt: // Treat blocks like basic blocks to avoid overlapping counters. return true case *ast.BranchStmt: return true case *ast.ForStmt: return true case *ast.IfStmt: return true case *ast.LabeledStmt: return f.endsBasicSourceBlock(s.Stmt) case *ast.RangeStmt: return true case *ast.SwitchStmt: return true case *ast.SelectStmt: return true case *ast.TypeSwitchStmt: return true case *ast.ExprStmt: // Calls to panic change the flow. // We really should verify that \"panic\" is the predefined function, // but without type checking we can't and the likelihood of it being // an actual problem is vanishingly small. if call, ok := s.X.(*ast.CallExpr); ok { if ident, ok := call.Fun.(*ast.Ident); ok &amp;&amp; ident.Name == \"panic\" &amp;&amp; len(call.Args) == 1 { return true } } } found, _ := hasFuncLiteral(s) return found } 其实就是大量的switch语句，如果是的话，就可以将直接边界作为end进行插桩，这一步的意义其实就是在于把{}里面的body不断的分割成一个个可以影响控制流的小块进行分别插桩。其实到这里我们就可以洞悉go-fuzz整个的插桩思想：在语法分析的时候就通过go-fuzz本身所包含的一个包的内容插桩到各个可以影响控制流的语句块中，那么接下来对应的工作就应该是如何对这些进行插桩语句块进行感知，这其实就是Sonar结构体的作用，这是go-fuzz发明的声呐系统。 Sonar遍历​ Sonar结构体同样实现了Visit方法来用于遍历语法树，部分源码如下： func (s *Sonar) Visit(n ast.Node) ast.Visitor { switch nn := n.(type) { case *ast.BinaryExpr: break ...... case *ast.SwitchStmt: if nn.Tag == nil || nn.Body == nil { return s // recurse } // Replace: // switch a := foo(); bar(a) { // case x: ... // case y: ... // } // with: // switch { // default: // a := foo() // __tmp := bar(a) // switch { // case __tmp == x: ... // case __tmp == y: ... // } // } // The == comparisons will be instrumented later when we recurse. sw := new(ast.SwitchStmt) *sw = *nn var stmts []ast.Stmt if sw.Init != nil { stmts = append(stmts, sw.Init) sw.Init = nil } const tmpvar = \"__go_fuzz_tmp\" tmp := ast.NewIdent(tmpvar) typ := s.info.Types[sw.Tag] s.info.Types[tmp] = typ stmts = append(stmts, &amp;ast.AssignStmt{Lhs: []ast.Expr{tmp}, Tok: token.DEFINE, Rhs: []ast.Expr{sw.Tag}}) stmts = append(stmts, &amp;ast.AssignStmt{Lhs: []ast.Expr{ast.NewIdent(\"_\")}, Tok: token.ASSIGN, Rhs: []ast.Expr{tmp}}) sw.Tag = nil stmts = append(stmts, sw) for _, cas1 := range sw.Body.List { cas := cas1.(*ast.CaseClause) for i, expr := range cas.List { tmp := &amp;ast.Ident{Name: tmpvar, NamePos: expr.Pos()} s.info.Types[tmp] = typ cas.List[i] = &amp;ast.BinaryExpr{X: tmp, Op: token.EQL, Y: expr} } } nn.Tag = nil nn.Init = nil nn.Body = &amp;ast.BlockStmt{List: []ast.Stmt{&amp;ast.CaseClause{Body: stmts}}} return s // recurse ...... } 第一步先根据节点类型找到Switch和For这种结构进行语法树级别的变化，整体的替换逻辑已经在注释里面体现出来了，其实就是类似把switch的条件都提出来放在body内部，然后再body里面建立一个新的switch结构，主要作用可能就是方便识别和统计，对于ast.BinaryExpr结构则是通过自定义的flag进行标注。 ​ 整体来看其实就是对包内代码各种语法树节点进行类型检查和过滤，因为一些代码是肯定顺序执行的，然后再需要的地方都插入一些标志，同时在结构体里面记录标志的总量，方便在fuzz执行的时候确定自己的代码位置从而更方便进行统计，具体的可以细看相关代码。 插桩总结​ 其实无论是File还是Sonar，个人认为都算是一种插桩，方便对代码覆盖率进行统计，在结束之后都通过createFuzzMain函数进行了封装，这个地方其实也是go-fuzz不支持fuzz的代码包含main函数的具体原因： func (c *Context) createFuzzMain() string { mainPkg := filepath.Join(c.fuzzpkg.PkgPath, \"go.fuzz.main\") path := filepath.Join(c.workdir, \"gopath\", \"src\", mainPkg) c.mkdirAll(path) c.writeFile(filepath.Join(path, \"main.go\"), c.funcMain()) return mainPkg } 其实就是将已经写好的main函数模板写入： var ainSrc = template.Must(template.New(\"main\").Parse(` package main import ( target \"{{.Pkg}}\" dep \"go-fuzz-dep\" ) func main() { fns := []func([]byte)int { {{range .AllFuncs}} target.{{.}}, {{end}} } dep.Main(fns) } `)) 主要作用还是调用包内的Fuzz代码。 go-fuzz 首先通过丢弃触发相同代码路径的的样本来最小化语料库。 开始改变输入并将数据传递给Fuzz函数，不失败（return 1），然后扩展代码覆盖率的突变会被保留和迭代形成新的样本。 当程序出现Crash的时候，会保存报告并重新启动程序。 Fuzz这块的具体原理其实都是参考的AFL，就不多说了，详细也可以参考AFL的Fuzz方式和源码。 测试用例​ 首先简单介绍一下go的Fuzz函数的基本信息： func Fuzz(data []byte) int { } 该函数以int作为返回值，因此当其返回值为0的时候说明Fuzz对于数据不敢影响，可能的原因是测试目标发生了无意义的错误，比如输入内容不合法等，返回值为1说明该数据已经被成功解析，简单来说就是Fuzz输入的data被目标所接受。 DNS解析器Fuzz首先第一步是创建初始语料库，其实就是通过拆解pcap数据包来创造数据： package main import ( \"crypto/rand\" \"encoding/hex\" \"log\" \"os\" \"strconv\" \"github.com/miekg/pcap\" ) func fatalIfErr(err error) { if err != nil { log.Fatal(err) } } func main() { handle, err := pcap.OpenOffline(os.Args[1]) fatalIfErr(err) b := make([]byte, 4) _, err = rand.Read(b) fatalIfErr(err) prefix := hex.EncodeToString(b) i := 0 for pkt := handle.Next(); pkt != nil; pkt = handle.Next() { pkt.Decode() f, err := os.Create(\"p_\" + prefix + \"_\" + strconv.Itoa(i)) fatalIfErr(err) _, err = f.Write(pkt.Payload) fatalIfErr(err) fatalIfErr(f.Close()) i++ } } 编写初步的Fuzz函数： func Fuzz(rawMsg []byte) int { msg := &amp;dns.Msg{} if unpackErr := msg.Unpack(rawMsg); unpackErr != nil { return 0 } if _, packErr = msg.Pack(); packErr != nil { println(\"failed to pack back a message\") spew.Dump(msg) panic(packErr) } return 1 } 作者在发现了越界： func unpackTxt(msg []byte, offset, rdend int) ([]string, int, error) { var err error var ss []string var s string for offset &lt; rdend &amp;&amp; err == nil { s, offset, err = unpackTxtString(msg, offset) if err == nil { ss = append(ss, s) } } return ss, offset, err } 但是因为这些越界使得程序经常崩溃，并且Fuzz变的缓慢，于是作者先进行了阶段性的修复工作，主要修复是使用len(msg)而不是使用保留的偏移量： func unpackTxt(msg []byte, off0 int) (ss []string, off int, err error) { off = off0 var s string for off &lt; len(msg) &amp;&amp; err == nil { s, off, err = unpackTxtString(msg, off) if err == nil { ss = append(ss, s) } } return } 之后修改好的Fuzz，主要的修改在于增加了ParseDNSPacketSafely，并抛弃了一些无意义的错误，也可能不断测试，不断排除已知的错误: func Fuzz(rawMsg []byte) int { var ( msg, msgOld = &amp;dns.Msg{}, &amp;old.Msg{} buf, bufOld = make([]byte, 100000), make([]byte, 100000) res, resOld []byte unpackErr, unpackErrOld error packErr, packErrOld error ) unpackErr = msg.Unpack(rawMsg) unpackErrOld = ParseDNSPacketSafely(rawMsg, msgOld) if unpackErr != nil &amp;&amp; unpackErrOld != nil { return 0 } if unpackErr != nil &amp;&amp; unpackErr.Error() == \"dns: out of order NSEC block\" { // 97b0a31 - rewrite NSEC bitmap [un]packing to account for out-of-order return 0 } if unpackErr != nil &amp;&amp; unpackErr.Error() == \"dns: bad rdlength\" { // 3157620 - unpackStructValue: drop rdlen, reslice msg instead return 0 } if unpackErr != nil &amp;&amp; unpackErr.Error() == \"dns: bad address family\" { // f37c7ea - Reject a bad EDNS0_SUBNET family on unpack (not only on pack) return 0 } if unpackErr != nil &amp;&amp; unpackErr.Error() == \"dns: bad netmask\" { // 6d5de0a - EDNS0_SUBNET: refactor netmask handling return 0 } if unpackErr != nil &amp;&amp; unpackErrOld == nil { println(\"new code fails to unpack valid packets\") panic(unpackErr) } res, packErr = msg.PackBuffer(buf) if packErr != nil { println(\"failed to pack back a message\") spew.Dump(msg) panic(packErr) } if unpackErrOld == nil { resOld, packErrOld = msgOld.PackBuffer(bufOld) if packErrOld == nil &amp;&amp; !bytes.Equal(res, resOld) { println(\"new code changed behavior of valid packets:\") println() println(hex.Dump(res)) println(hex.Dump(resOld)) os.Exit(1) } } return 1 } Tips： ​ 其实在Fuzz过程中也会遇到一些结构化的问题，毕竟大型项目都会存在大量的复杂结构体难以变异，这时候才为大家提供一个神器go-fuzz-header： https://adalogics.com/blog/structure-aware-go-fuzzing-complex-types 云原生下的Fuzz思考​ 云原生的很多新技术其实都是在老技术的交叉上形成的，其实可以类似go项目结构里面的不同的包，对于很多Fuzz目标来言，像以前那样直接从最根本处下手已经不太现实可行，比如容器Fuzz其实很难通过生成大量镜像或者docker client的命令来解决，恰恰相反深入程序内部针对不同函数来编写Fuzz或许更有价值。 ​ 但是缺点也很明显，首先必须和代码审计相结合，其次就是由于代码是否用户可达或者crash是否真的引发漏洞效果都有待评估，正如go-fuzz创始人所说：“go-fuzz其实更适合开发者来寻求自己项目中存在的bug”，但是漏洞挖掘技术也是在不断的进步之中，或许可以思考如何把找到的bug发展成漏洞，毕竟对于内存安全的高级语言来说直接谋求可利用漏洞相对困难。 ​ 其实在内存漏洞越来越少的现在，这种bug最终演变成漏洞的例子还是有的，就比如linux pkexec提权漏洞，过去几年大家都认为这是一个bug，但是等利用方式被真正发掘，就能变化成为严重的安全问题。 参考资料 https://github.com/dvyukov/go-fuzz","categories":[{"name":"Clock","slug":"Clock","permalink":"https://rainsec.cn/categories/Clock/"},{"name":"Golang","slug":"Clock/Golang","permalink":"https://rainsec.cn/categories/Clock/Golang/"}],"tags":[{"name":"Fuzz","slug":"Fuzz","permalink":"https://rainsec.cn/tags/Fuzz/"}],"author":"Clock"},{"title":"EventListener XSS","slug":"EventListener XSS","date":"2022-03-25T10:38:45.000Z","updated":"2022-07-20T05:45:32.313Z","comments":true,"path":"/post/EventListener XSS.html","link":"","permalink":"https://rainsec.cn/post/EventListener%20XSS.html","excerpt":"","text":"EventListener XSSXSS作为混”低保“的最佳漏洞，我们在日常测试中没少碰到，但是DOM型XSS就相对来说不容易被发现了，而本文要介绍的则是更难发现并利用的监听postMessage所导致漏洞。首先从事件监听器开始说起 事件监听器事件监控器可以为指定对象设置一个回调函数，当该对象的指定事件被触发时会被执行： &lt;table id=\"outside\"&gt; &lt;tr&gt;&lt;td id=\"t1\"&gt;one&lt;/td&gt;&lt;/tr&gt; &lt;tr&gt;&lt;td id=\"t2\"&gt;two&lt;/td&gt;&lt;/tr&gt; &lt;/table&gt; &lt;script&gt; function modifyText() { var t2 = document.getElementById(\"t2\"); if (t2.firstChild.nodeValue == \"three\") { t2.firstChild.nodeValue = \"two\"; } else { t2.firstChild.nodeValue = \"three\"; } } // 为table添加事件监听器 var el = document.getElementById(\"outside\"); el.addEventListener(\"click\", modifyText, false); &lt;/script&gt; 以上代码监听了table的click事件，当点击table时会触发modifyText,下面链接列出了所有的事件: https://developer.mozilla.org/en-US/docs/Web/Events#event_index 这里要说的是postMessage与其对应的事件监听器在不安全配置情况下导致的漏洞，首先看下postMessage的介绍： &gt; window.postMessage() 方法可以安全地实现跨源通信。通常，对于两个不同页面的脚本，只有当执行它们的页面位于具有相同的协议（通常为https），端口号（443为https的默认值），以及主机 (两个页面的模数 Document.domain设置为相同的值) 时，这两个脚本才能相互通信。window.postMessage() 方法提供了一种受控机制来规避此限制，只要正确的使用，这种方法就很安全。 https://developer.mozilla.org/zh-CN/docs/Web/API/Window/postMessage 它的用法也很简单： windows.postMessage(message, targetOrigin, [transfer]) windows是指一个窗口，可以是当前页面的window、window.open返回的窗口对象、iframe的contentWindow属性等 message是要发送的消息，可以是字符串，也可以是json格式 targetOrigin用来指定哪个窗口可以接收到消息，如果为*则表示任意窗口均可收到信息。而如果指定了特定的域名后要求发送消息的窗口其协议、端口、主机地址与指定域名匹配才可发送消息。 发送消息事件可以通过如下方式添加监听事件： window.addEventListener(\"message\", receiveMessage, false); function receiveMessage(event) { } 当发送信息时就会触发receiveMessage。其中event的属性比较重要的有： data 即postMessage发送的数据 origin 发送信息窗口的origin 漏洞触发比起原理，大家肯定对漏洞如何利用更感兴趣。看下面这段代码 &lt;html&gt; &lt;head&gt;&lt;title&gt;Toxic DOM&lt;/title&gt;&lt;/head&gt; &lt;body&gt; &lt;script&gt; var postMessageHandler = function(msg) { var content = msg.data; var msgObj = eval(content); if (msgObj.isActive) { document.write(\"PostMessage arrived!\"); } } window.addEventListener('message', postMessageHandler, false); &lt;/script&gt; &lt;/body&gt; &lt;/html&gt; &lt;!-- https://public-firing-range.appspot.com/dom/toxicdom/postMessage/eval --&gt; 很明显可以看出这个页面在监听到postMessage时会调用eval执行发送的信息，那我们就可以构造payload了 &lt;script&gt; function pocLink() { let win = window.open('https://public-firing-range.appspot.com/dom/toxicdom/postMessage/eval'); let msg = \"alert(1);\"; setTimeout(function(){ win.postMessage(msg, '*'); }, 5000); } &lt;/script&gt; &lt;a href=\"#\" onclick=\"pocLink();\"&gt;PoC link&lt;/a&gt; 或者是使用iframe &lt;script&gt; function pocFrame(win) { let msg = \"alert(1);\"; win.postMessage(msg, '*'); } &lt;/script&gt; &lt;iframe src=\"https://public-firing-range.appspot.com/dom/toxicdom/postMessage/eval\" onload=\"pocFrame(this.contentWindow)\"&gt;&lt;/iframe&gt; 也就是说我们需要在自己服务器上新建一个页面，用来打开一个新窗口或是加载一个iframe并获取其句柄，用来传递信息。当打开的窗口中存在有message监听，且其触发代码有可利用点时就可以触发漏洞。 工具检测纯手工发现漏洞不可取，Burp的DOM Invader就可以帮助发现此类问题 对于https://public-firing-range.appspot.com/dom/toxicdom/postMessage/eval 它可以直接检测出漏洞存在并一键生成POC 为了了解原理最好可以看看它的代码，但是其源码做了混淆，没办法了解它的原理，所以我们从它的平替postMessage-tracker入手进行分析。 其检测结果展示形式为 平平无奇的一个小框框，相较于DOM Invader的可利用性分析差了许多，不过仅仅了解下原理已然足够了。 它的目录结构非常简单，首先看下mainfest.json run_at表明注入在css之后，dom构建之前。关键代码在content_script.js当中： 这一段的主要作用就是在添加监听器前判断其类型是否时message，如果是则记录下来一些数据，比如此时的堆栈信息等。合理推测Burp在此之上加入了危险函数判断的操作，后续有空的话就给DOM Invader加一个类似的功能练练手吧，日常使用当然还是Burp的香啊~ 参考文章 https://github.com/fransr/postMessage-tracker https://portswigger.net/burp/documentation/desktop/tools/dom-invader","categories":[{"name":"Noel","slug":"Noel","permalink":"https://rainsec.cn/categories/Noel/"},{"name":"Web","slug":"Noel/Web","permalink":"https://rainsec.cn/categories/Noel/Web/"}],"tags":[{"name":"XSS","slug":"XSS","permalink":"https://rainsec.cn/tags/XSS/"}],"author":"Noel"},{"title":"PHP-Parser的基本使用","slug":"PHP-Parser","date":"2022-01-28T10:38:45.000Z","updated":"2022-07-20T07:32:50.521Z","comments":true,"path":"/post/PHP-Parser.html","link":"","permalink":"https://rainsec.cn/post/PHP-Parser.html","excerpt":"PHP-ParserPHP-Parser组件的基础使用，该组件为静态分析和反混淆常用的第三方依赖。","text":"PHP-ParserPHP-Parser组件的基础使用，该组件为静态分析和反混淆常用的第三方依赖。 What is PHP-ParserPHP-Parser是nikic用PHP编写的PHP5.2到PHP7.4解析器，其目的是简化静态代码分析和操作 PHP-Parser的基础使用这里先贴一下官方文档 PHP-Parser/doc at master · nikic/PHP-Parser (github.com) 最基本的是要理解其中Walking the AST的部分 初始化解析器首先创建实例 use PhpParser\\ParserFactory; $parser = (new ParserFactory)-&gt;create(ParserFactory::PREFER_PHP7); 这其中有以下参数 KindBehaviorParserFactory::PREFER_PHP7Try to parse code as PHP 7. If this fails, try to parse it as PHP 5.ParserFactory::PREFER_PHP5Try to parse code as PHP 5. If this fails, try to parse it as PHP 7.ParserFactory::ONLY_PHP7Parse code as PHP 7.ParserFactory::ONLY_PHP5Parse code as PHP 5. create还有一个参数Lexer，这里先不做讨论 在实例化之后我们就可以通过 $stmts = $parser-&gt;parse($code); 来将代码转换成AST 为了防止抛出异常，最好在try….catch中执行 生成更加直观的AST当我们var_dump上面的$stmt时，会得到一个比较乱的AST，可以使用NodeDump将其转化为更加直观的AST 这里需要使用NodeDump 对于代码 &lt;?php function printLine($msg) { echo $msg, \"\\n\"; } printLine('Hello World!!!'); 将其转换为AST &lt;?php use PhpParser\\NodeDumper; $nodeDumper = new NodeDumper;echo $nodeDumper-&gt;dump($stmts), \"\\n\"; 得到以下输出 array( 0: Stmt_Function( byRef: false name: Identifier( name: printLine ) params: array( 0: Param( type: null byRef: false variadic: false var: Expr_Variable( name: msg ) default: null ) ) returnType: null stmts: array( 0: Stmt_Echo( exprs: array( 0: Expr_Variable( name: msg ) 1: Scalar_String( value: ) ) ) ) ) 1: Stmt_Expression( expr: Expr_FuncCall( name: Name( parts: array( 0: printLine ) ) args: array( 0: Arg( value: Scalar_String( value: Hello World!!! ) byRef: false unpack: false ) ) ) ) ) Node tree structure上面我们可以看到生成了很多的Node类型 PHP是一个成熟的脚本语言，它大约有140个不同的节点。但是为了方便使用，将他们分为三类： PhpParser\\Node\\Stmts是语句节点，即不返回值且不能出现在表达式中的语言构造。例如，类定义是一个语句，它不返回值，你不能编写类似func(class {})的语句。 PhpParser\\Node\\expr是表达式节点，即返回值的语言构造，因此可以出现在其他表达式中。如：$var (PhpParser\\Node\\Expr\\Variable)和func() (PhpParser\\Node\\Expr\\FuncCall)。 PhpParser\\Node\\Scalars是表示标量值的节点，如\"string\" (PhpParser\\Node\\scalar\\string)、0 (PhpParser\\Node\\scalar\\LNumber) 或魔术常量，如”FILE“ (PhpParser\\Node\\scalar\\MagicConst\\FILE) 。所有PhpParser\\Node\\scalar都是延伸自PhpParser\\Node\\Expr，因为scalar也是表达式。 需要注意的是PhpParser\\Node\\Name和PhpParser\\Node\\Arg不在以上的节点之中 Pretty printerPrettyprinter用来将我们修改后的AST转换回PHP代码，使用如下 use PhpParser\\Error; use PhpParser\\ParserFactory; use PhpParser\\PrettyPrinter; $code = \"&lt;?php echo 'Hi ', hi\\\\getTarget();\"; $parser = (new ParserFactory)-&gt;create(ParserFactory::PREFER_PHP7);$prettyPrinter = new PrettyPrinter\\Standard; try { //生成AST $stmts = $parser-&gt;parse($code); //对节点进行操作 $stmts[0] // the echo statement -&gt;exprs // sub expressions [0] // the first of them (the string node) -&gt;value // it's value, i.e. 'Hi ' = 'Hello '; // change to 'Hello ' // pretty print $code = $prettyPrinter-&gt;prettyPrint($stmts); echo $code; } catch (Error $e) { echo 'Parse Error: ', $e-&gt;getMessage(); } 在反混淆中我们一般很少使用$stmts[0]这种方式，因为我们要考虑节点的各种类型 此外还有prettyPrintExpr()，它可以用来输出一个表达式类型的节点 例如当你需要提取全局变量时 &lt;?php $a = $_POST['a']; 他的语法树如下 0: Stmt_Expression( expr: Expr_Assign( var: Expr_Variable( name: a ) expr: Expr_ArrayDimFetch( var: Expr_Variable( name: _POST ) dim: Scalar_String( value: a ) ) ) ) 如果我想获取$_POST[‘a’],我就需要先判断节点类型是不是Expr_ArrayDimFetch 然后判断$node-&gt;var-&gt;name是不是全局变量 最后提取$node-&gt;var-&gt;name和$node-&gt;dim-&gt;value然后将它们拼接 当我的全局变量为$_POST[a]时，dim部分的AST也会变化，我们还需要考虑这种情况。 但是我们可以使用 /* 用来识别全局变量; 如果要获取全局变量格式无需考虑value的节点类型 expr: Expr_ArrayDimFetch( var: Expr_Variable( name: _POST ) ) */ if ($node instanceof Node\\Expr\\ArrayDimFetch &amp;&amp; $node-&gt;var instanceof Node\\Expr\\Variable &amp;&amp; (in_array($node-&gt;var-&gt;name ,GLOBAL_VAR))) { self::$globalname = $this-&gt;prettyPrinter-&gt;prettyPrintExpr($node); } 其中 $this-&gt;prettyPrinter-&gt;prettyPrintExpr($node); 就会返回该Expr节点的表达式，无论是$_POST['a']还是$_POST[a]都可以正常返回 PHP-Parser/Pretty_printing.markdown at master · nikic/PHP-Parser (github.com) Node traversation我们使用PHP-Parser对文件的节点进行修改，最关键的就是编写节点遍历操作 使用PhpParser\\NodeTraverser我们可以遍历每一个节点，举几个简单的例子：解析php中的所有字符串，并输出 &lt;?php use PhpParser\\Error; use PhpParser\\ParserFactory; use PhpParser\\NodeTraverser; use PhpParser\\NodeVisitorAbstract; use PhpParser\\Node; require 'vendor/autoload.php'; class MyVisitor extends NodeVisitorAbstract{ public function leaveNode(Node $node) { //判断如果是一个String_节点，就输出 if ($node instanceof Node\\Scalar\\String_) { echo $node -&gt; value,\"\\n\"; } } } $code = file_get_contents(\"./test.php\"); //实例化解释器 $parser = (new ParserFactory)-&gt;create(ParserFactory::PREFER_PHP7); $traverser = New NodeTraverser; //添加自己的Visitor $traverser-&gt;addVisitor(new MyVisitor); try { //转化AST $ast = $parser-&gt;parse($code); //开始遍历 $stmts = $traverser-&gt;traverse($ast); } catch (Error $error) { echo \"Parse error: {$error-&gt;getMessage()}\\n\"; return; } ?&gt; 替换php脚本中函数以及类的成员方法函数名为小写 class MyVisitor extends NodeVisitorAbstract{ public function leaveNode(Node $node) { if( $node instanceof Node\\Expr\\FuncCall) { $node-&gt;name-&gt;parts[0]=strtolower($node-&gt;name-&gt;parts[0]); }elseif($node instanceof Node\\Stmt\\ClassMethod){ $node-&gt;name-&gt;name=strtolower($node-&gt;name-&gt;name); }elseif ($node instanceof Node\\Stmt\\Function_){ $node-&gt;name-&gt;name=strtolower($node-&gt;name-&gt;name); }elseif($node instanceof Node\\Expr\\MethodCall){ $node-&gt;name-&gt;name=strtolower($node-&gt;name-&gt;name); } } } 需要注意的是所有的visitors都必须实现PhpParser\\NodeVisitor接口，该接口定义了如下4个方法： public function beforeTraverse(array $nodes); public function enterNode(\\PhpParser\\Node $node); public function leaveNode(\\PhpParser\\Node $node); public function afterTraverse(array $nodes); beforeTraverse方法在遍历开始之前调用一次，并将其传递给调用遍历器的节点。此方法可用于在遍历之前重置值或准备遍历树。 afterTraverse方法与beforeTraverse方法类似，唯一的区别是它只在遍历之后调用一次。 在每个节点上都调用enterNode和leaveNode方法，前者在它被输入时，即在它的子节点被遍历之前，后者在它被离开时。 这四个方法要么返回更改的节点，要么根本不返回(即null)，在这种情况下，当前节点不更改。 例子基于 AST（抽象语法树）解 PHP 混淆 | J0k3r’s Blog P.S.我们需要知道你需要什么样的Node，进行什么样的操作，Node下数据的格式会有哪几种情况，会不会因为代码不够严谨导致错误或者无限递归","categories":[{"name":"Zitui","slug":"Zitui","permalink":"https://rainsec.cn/categories/Zitui/"},{"name":"PHP","slug":"Zitui/PHP","permalink":"https://rainsec.cn/categories/Zitui/PHP/"}],"tags":[{"name":"PHP-Parser","slug":"PHP-Parser","permalink":"https://rainsec.cn/tags/PHP-Parser/"}],"author":"Zitui"}],"categories":[{"name":"Zitui","slug":"Zitui","permalink":"https://rainsec.cn/categories/Zitui/"},{"name":"Ubuntu","slug":"Zitui/Ubuntu","permalink":"https://rainsec.cn/categories/Zitui/Ubuntu/"},{"name":"Clock","slug":"Clock","permalink":"https://rainsec.cn/categories/Clock/"},{"name":"Golang","slug":"Clock/Golang","permalink":"https://rainsec.cn/categories/Clock/Golang/"},{"name":"Noel","slug":"Noel","permalink":"https://rainsec.cn/categories/Noel/"},{"name":"Web","slug":"Noel/Web","permalink":"https://rainsec.cn/categories/Noel/Web/"},{"name":"PHP","slug":"Zitui/PHP","permalink":"https://rainsec.cn/categories/Zitui/PHP/"}],"tags":[{"name":"Linux","slug":"Linux","permalink":"https://rainsec.cn/tags/Linux/"},{"name":"Fuzz","slug":"Fuzz","permalink":"https://rainsec.cn/tags/Fuzz/"},{"name":"XSS","slug":"XSS","permalink":"https://rainsec.cn/tags/XSS/"},{"name":"PHP-Parser","slug":"PHP-Parser","permalink":"https://rainsec.cn/tags/PHP-Parser/"}]}