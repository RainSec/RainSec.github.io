
<!DOCTYPE html>
<html lang="en" class="loading">
<head>
    <meta charset="UTF-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, minimum-scale=1.0, maximum-scale=1.0, user-scalable=no">
    <title>Fuzzing之Grammars - RainSec</title>
    <meta name="apple-mobile-web-app-capable" content="yes" />
    <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
    <meta name="google" content="notranslate" />
    <meta name="keywords" content="RainSec,"> 
    <meta name="description" content="致力于云原生安全和自动化渗透测试的研究与分享,Fuzzing之GrammarsFuzzing input​  Fuzzing的一大核心思想其实就是通过大量的Input去触发程序的各个分支逻辑，因此Fuzzing的成功与否和Input的生成关系密,"> 
    <meta name="author" content="RainSec"> 
    <link rel="alternative" href="atom.xml" title="RainSec" type="application/atom+xml"> 
    <link rel="icon" href="https://cdn.staticaly.com/gh/L2ksy0d/image-host@master/20220714/logo.jpg"> 
    
<link rel="stylesheet" href="//at.alicdn.com/t/font_1429596_nzgqgvnmkjb.css">

    
<link rel="stylesheet" href="//cdn.bootcss.com/animate.css/3.7.2/animate.min.css">

    
<link rel="stylesheet" href="//cdnjs.cloudflare.com/ajax/libs/social-share.js/1.0.16/css/share.min.css">

    
<link rel="stylesheet" href="//cdn.bootcss.com/codemirror/5.48.4/codemirror.min.css">

    
<link rel="stylesheet" href="//cdn.bootcss.com/codemirror/5.48.4/theme/dracula.css">

    
<link rel="stylesheet" href="/css/obsidian.css">

    
<link rel="stylesheet" href="/css/ball-atom.min.css">

    
    
<link rel="stylesheet" href="//cdn.jsdelivr.net/npm/font-awesome/css/font-awesome.min.css">

    
    <script>var musiclist = ""</script>
    
<script src="/js/loadaplayer.js"></script>

    <!-- 引用依赖 -->
    
<link rel="stylesheet" href="/aplayer/dist/APlayer.min.css">

    
<script src="/aplayer/dist/APlayer.min.js"></script>
<script src="/js/Meting.min.js"></script>

    
<meta name="generator" content="Hexo 6.0.0">
<style>.github-emoji { position: relative; display: inline-block; width: 1.2em; min-height: 1.2em; overflow: hidden; vertical-align: top; color: transparent; }  .github-emoji > span { position: relative; z-index: 10; }  .github-emoji img, .github-emoji .fancybox { margin: 0 !important; padding: 0 !important; border: none !important; outline: none !important; text-decoration: none !important; user-select: none !important; cursor: auto !important; }  .github-emoji img { height: 1.2em !important; width: 1.2em !important; position: absolute !important; left: 50% !important; top: 50% !important; transform: translate(-50%, -50%) !important; user-select: none !important; cursor: auto !important; } .github-emoji-fallback { color: inherit; } .github-emoji-fallback img { opacity: 0 !important; }</style>
</head>


<body class="loading">
    <div class="loader">
        <div class="la-ball-atom la-2x">
            <div></div>
            <div></div>
            <div></div>
            <div></div>
        </div>
    </div>
    <span id="config-title" style="display:none">RainSec</span>
    <div id="loader"></div>
    <div id="single">
    <div class="scrollbar gradient-bg-rev"></div>
<div id="top" style="display: block;">
    <div class="bar" style="width: 0;"></div>
    <div class="navigation animated fadeIn fast delay-1s">
        <img id="home-icon" class="icon-home" src="https://cdn.staticaly.com/gh/L2ksy0d/image-host@master/20220714/logo.jpg" alt="" data-url="https://rainsec.cn">
        <div id="play-icon" title="Play/Pause" class="iconfont icon-play"></div>
        <h3 class="subtitle">Fuzzing之Grammars</h3>
        <div class="social">
            <!--        <div class="like-icon">-->
            <!--            <a href="javascript:;" class="likeThis active"><span class="icon-like"></span><span class="count">76</span></a>-->
            <!--        </div>-->
            <div>
                <div class="share">
                    
                        <a href="javascript:;" class="iconfont icon-share1"></a>
                        <div class="share-component-cc" data-disabled="facebook,douban,linkedin,diandian,tencent,google"></div>
                    
                </div>
            </div>
        </div>
    </div>
</div>

    <div class="section">
        <div class=article-header-wrapper>
    <div class="article-header">
        <div class="article-cover animated fadeIn" style="
            animation-delay: 600ms;
            animation-duration: 1.2s;
            background-image: 
                radial-gradient(ellipse closest-side, rgba(0, 0, 0, 0.65), #100e17),
                url('https://cdn.staticaly.com/gh/L2ksy0d/image-host@master/20220731/fuzzinggrammar.jpeg') ">
        </div>
        <div class="else">
            <p class="animated fadeInDown">
                
                <a href="/categories/漏洞挖掘"><b>「
                    </b>漏洞挖掘<b> 」</b></a>
                
                July 31, 2022
            </p>
            <h3 class="post-title animated fadeInDown"><a href="/post/Fuzzing%E4%B9%8BGrammers.html" title="Fuzzing之Grammars" class="">Fuzzing之Grammars</a>
            </h3>
            
            <p class="post-count animated fadeInDown">
                
                <span>
                    <b class="iconfont icon-text2"></b> <i>Words count</i>
                    39k
                </span>
                
                
                <span>
                    <b class="iconfont icon-timer__s"></b> <i>Reading time</i>
                    35 mins.
                </span>
                
                
                
                <span id="busuanzi_container_page_pv">
                    <b class="iconfont icon-read"></b> <i>Read count</i>
                    <span id="busuanzi_value_page_pv">0</span>
                </span>
                
            </p>
            
            
            <ul class="animated fadeInDown post-tags-list" itemprop="keywords"><li class="animated fadeInDown post-tags-list-item"><a class="animated fadeInDown post-tags-list-link" href="/tags/Fuzz/" rel="tag">Fuzz</a></li></ul>
            
        </div>
    </div>
</div>

<div class="screen-gradient-after">
    <div class="screen-gradient-content">
        <div class="screen-gradient-content-inside">
            <div class="bold-underline-links screen-gradient-sponsor">
                <p>
                    <span class="animated fadeIn delay-1s"></span>
                </p>
            </div>
        </div>
    </div>
</div>

<div class="article">
    <div class='main'>
        <div class="content markdown animated fadeIn">
            <h1 id="Fuzzing之Grammars"><a href="#Fuzzing之Grammars" class="headerlink" title="Fuzzing之Grammars"></a>Fuzzing之Grammars</h1><h2 id="Fuzzing-input"><a href="#Fuzzing-input" class="headerlink" title="Fuzzing input"></a>Fuzzing input</h2><p>​  Fuzzing的一大核心思想其实就是通过大量的Input去触发程序的各个分支逻辑，因此Fuzzing的成功与否和Input的生成关系密切。Input的格式多种多样，可以是文件，代码，json数据等等。但是各种各样的数据都有自己的格式，程序的输入也是如此，那么在生成Input的过程中，格式化非常关键，程序无法接受的输入对于Fuzzing来说是毫无意义的。</p>
<p>​  为了很好的描述一个程序的输入，一个很有必要的事情是为输入制定一些语法规范。比如编译器的输入：python解释器规定了符合python语法的程序才能得以执行，gcc规定了符合C语言语法的程序才能被完成编译进而生成二进制文件。Fuzzing也是如此，为了很好的达到Fuzzing的效果，为程序定义一种输入的语法规范往往是一种不错的选择。</p>
<p>​  一般而言，对于Fuzzing简单的程序来说，正则表达式往往是一个不错的选择，它所具备的有限状态机属性使得它易于推理进而获得一个满意的Input。但是如果面临的Fuzzing目标需要非常复杂的输入，那么它就会表现的捉襟见肘。</p>
<p>​  我曾见过为了更好的实现某些功能而专门设计一些语言，从计算机理论的角度这显然是非常有用的，一些特殊功能在特殊语言的加持之下表现出超高的质量，但是对于Fuzzing而言这确实是成本过高了，Grammars其实就是正则表达式和专业语言之间的一个中间地带。它易于理解，并且能很好的完成Fuzzing对它的期望–生成大量合法输入，因为通过Grammars可以规定Inputs的大量属性，完美的表达一个复杂输入的语法结构。</p>
<h2 id="Grammars初探"><a href="#Grammars初探" class="headerlink" title="Grammars初探"></a>Grammars初探</h2><p>​  Grammar一般由符号和一组表达式组成，例如<code>A = 10 | 9 | 0 |1</code>，符号化使得递归成为可能，假设<code>B = A | AB</code>，这无疑就使得符号所代表的范围倍增。根据这种思想我们可以制作一个算数表达式：</p>
<pre><code>&lt;start&gt;   ::= &lt;expr&gt;
&lt;expr&gt;    ::= &lt;term&gt; + &lt;expr&gt; | &lt;term&gt; - &lt;expr&gt; | &lt;term&gt;
&lt;term&gt;    ::= &lt;term&gt; * &lt;factor&gt; | &lt;term&gt; / &lt;factor&gt; | &lt;factor&gt;
&lt;factor&gt;  ::= +&lt;factor&gt; | -&lt;factor&gt; | (&lt;expr&gt;) | &lt;integer&gt; | &lt;integer&gt;.&lt;integer&gt;
&lt;integer&gt; ::= &lt;digit&gt;&lt;integer&gt; | &lt;digit&gt;
&lt;digit&gt;   ::= 0 | 1 | 2 | 3 | 4 | 5 | 6 | 7 | 8 | 9
</code></pre>
<p>那么通过对<code>&lt;start&gt;</code>的内部的符号进行逐一扩展，并对过程进行随机化处理，最终就可以得到大量的合法算数表达式。和大多数语法一样，Grammar也应该有自己的Type，以便对其合法性进行校验，以Python 为例子可以对上述的Grammar进行定义：</p>
<pre><code class="python">    Option = Dict[str, Any]
    Expansion = Union[str, Tuple[str, Option]]
    Grammar = Dict[str, List[Expansion]]
    EXPR_GRAMMAR: Grammar = {
        "&lt;start&gt;":
            ["&lt;expr&gt;"],

        "&lt;expr&gt;":
            ["&lt;term&gt; + &lt;expr&gt;", "&lt;term&gt; - &lt;expr&gt;", "&lt;term&gt;"],

        "&lt;term&gt;":
            ["&lt;factor&gt; * &lt;term&gt;", "&lt;factor&gt; / &lt;term&gt;", "&lt;factor&gt;"],

        "&lt;factor&gt;":
            ["+&lt;factor&gt;",
            "-&lt;factor&gt;",
            "(&lt;expr&gt;)",
            "&lt;integer&gt;.&lt;integer&gt;",
            "&lt;integer&gt;"],

        "&lt;integer&gt;":
            ["&lt;digit&gt;&lt;integer&gt;", "&lt;digit&gt;"],

        "&lt;digit&gt;":
            ["0", "1", "2", "3", "4", "5", "6", "7", "8", "9"]
    }
</code></pre>
<p>前三行代码定义了一个Grammar应该如何在Python中构成。通过代码中的<code>EXPR_GRAMMAR["&lt;digit&gt;"]</code>可以访问当前Grammar的各个组成部分并对其进行操作。</p>
<h3 id="Sample-Grammar-Fuzz"><a href="#Sample-Grammar-Fuzz" class="headerlink" title="Sample Grammar Fuzz"></a>Sample Grammar Fuzz</h3><p>​  那么该如何对Grammar语法进行解析呢？一种最简单的方式就是通过字符串替换，因为在Grammar中<code>:</code>的左右两侧本身就是一种映射关系，因此利用字符串替换不断迭代是一种最为直观的选择。</p>
<p>实例代码：</p>
<pre><code class="python">START_SYMBOL = "&lt;start&gt;"
# 一个简单的gramar fuzzer
def simple_grammar_fuzzer(grammar: Grammar, 
                          start_symbol: str = START_SYMBOL,
                          max_nonterminals: int = 10,
                          max_expansion_trials: int = 100,
                          log: bool = False) -&gt; str:
    """Produce a string from `grammar`.
       `start_symbol`: use a start symbol other than `&lt;start&gt;` (default).
       `max_nonterminals`: the maximum number of nonterminals 
         still left for expansion
       `max_expansion_trials`: maximum # of attempts to produce a string
       `log`: print expansion progress if True"""

    term = start_symbol
    expansion_trials = 0

    while len(nonterminals(term)) &gt; 0: # 判断字符串中是否存在&lt;&gt;，并返回所有被&lt;&gt;包裹的项，注意如果是&lt;dsad&lt;abc&gt;&gt;则返回&lt;abc&gt;
        symbol_to_expand = random.choice(nonterminals(term))
        expansions = grammar[symbol_to_expand]
        expansion = random.choice(expansions)
        # In later chapters, we allow expansions to be tuples,
        # with the expansion being the first element
        if isinstance(expansion, tuple):
            expansion = expansion[0]

        new_term = term.replace(symbol_to_expand, expansion, 1) # 解析下一个符号

        if len(nonterminals(new_term)) &lt; max_nonterminals: # 每次的可解析符号，必须少于最大单次解析量
            term = new_term
            if log:
                print("%-40s" % (symbol_to_expand + " -&gt; " + expansion), term)
            expansion_trials = 0
        else:
            expansion_trials += 1
            if expansion_trials &gt;= max_expansion_trials: # 总的解析次数也存在限制
                raise ExpansionError("Cannot expand " + repr(term))

    return term
</code></pre>
<p>利用上面的表达式Grammar可以制作一个简单的grammar fuzz，Fuzz的编写过程其实面临着很多的取舍，便利和速度或者各种各样的可行性之间的考虑，以上面的Grammar为例子，我们肯定不希望其陷入类似无限递归或者大量符号解析的情况，而是会限制对字段的提取次数和对符号的解析次数。</p>
<p>​  但是此类Grammar Fuzz都面临几个问题就是大量的字符串搜索和替换操作导致效率低下，而且可以看出存在Input生成失败的情况（ExpansionError），而且这是一个典型的上下文无关的Fuzz。不过，依赖于上述功能，我们只要编写Grammar就可以很好的对一些Inputs进行大量生成。</p>
<p>比如URL生成：</p>
<pre><code class="python">URL_GRAMMAR: Grammar = {
    "&lt;start&gt;":
        ["&lt;url&gt;"],
    "&lt;url&gt;":
        ["&lt;scheme&gt;://&lt;authority&gt;&lt;path&gt;&lt;query&gt;"],
    "&lt;scheme&gt;":
        ["http", "https", "ftp", "ftps"],
    "&lt;authority&gt;":
        ["&lt;host&gt;", "&lt;host&gt;:&lt;port&gt;", "&lt;userinfo&gt;@&lt;host&gt;", "&lt;userinfo&gt;@&lt;host&gt;:&lt;port&gt;"],
    "&lt;host&gt;":  # 大部分情况下其实可以指定一个URL
        ["cispa.saarland", "www.google.com", "fuzzingbook.com"],
    "&lt;port&gt;":
        ["80", "8080", "&lt;nat&gt;"],
    "&lt;nat&gt;":
        ["&lt;digit&gt;", "&lt;digit&gt;&lt;digit&gt;"],
    "&lt;digit&gt;":
        ["0", "1", "2", "3", "4", "5", "6", "7", "8", "9"],
    "&lt;userinfo&gt;":  # Just one
        ["user:password"],
    "&lt;path&gt;":  # Just a few
        ["", "/", "/&lt;id&gt;"],
    "&lt;id&gt;":  # Just a few
        ["abc", "def", "x&lt;digit&gt;&lt;digit&gt;"],
    "&lt;query&gt;":
        ["", "?&lt;params&gt;"],
    "&lt;params&gt;":
        ["&lt;param&gt;", "&lt;param&gt;&amp;&lt;params&gt;"],
    "&lt;param&gt;":  # Just a few
        ["&lt;id&gt;=&lt;id&gt;", "&lt;id&gt;=&lt;nat&gt;"],
}
</code></pre>
<p>或者类似HTTP协议的（但是这个不是为上述Fuzz准备的，只是拿来做个参考）：</p>
<pre><code class="python">{
    "&lt;A&gt;": [["&lt;START_LINE&gt;", "\r\n", "&lt;HEADERS&gt;", "&lt;BODY&gt;", "\r\n\r\n"]],
    
    "&lt;START_LINE&gt;": [["&lt;METHOD&gt;", " ", "&lt;URI&gt;", " ", "&lt;VERSION&gt;"]],
    
    "&lt;METHOD&gt;": [["GET"], ["HEAD"], ["POST"], ["PUT"], ["DELETE"], ["CONNECT"], ["OPTIONS"], ["TRACE"], ["PATCH"], ["ACL"], ["BASELINE-CONTROL"], ["BIND"], ["CHECKIN"], ["CHECKOUT"], ["COPY"], ["LABEL"], ["LINK"], ["LOCK"], ["MERGE"], ["MKACTIVITY"], ["MKCALENDAR"], ["MKCOL"], ["MKREDIRECTREF"], ["MKWORKSPACE"], ["MOVE"], ["ORDERPATCH"], ["PRI"], ["PROPFIND"], ["PROPPATCH"], ["REBIND"], ["REPORT"], ["SEARCH"], ["UNBIND"], ["UNCHECKOUT"], ["UNLINK"], ["UNLOCK"], ["UPDATE"], ["UPDATEREDIRECTREF"], ["VERSION-CONTROL"]],
    
    "&lt;URI&gt;": [["&lt;SCHEME&gt;" , ":", "&lt;HIER&gt;", "&lt;QUERY&gt;", "&lt;FRAGMENT&gt;"]],
    
    "&lt;SCHEME&gt;": [["http"], ["https"], ["shttp"], ["dav"], ["about"], ["attachment"], ["cid"], ["data"], ["file"], ["ftp"], ["ssh"], ["sip"]],
    
    "&lt;HIER&gt;": [["//", "&lt;AUTHORITY&gt;", "&lt;PATH&gt;"]],
    
    "&lt;AUTHORITY&gt;": [["&lt;USERINFO&gt;", "&lt;HOST&gt;"]],

    "&lt;PATH&gt;": [["/", "&lt;DIR&gt;"]],

    "&lt;DIR&gt;": [[], ["&lt;CHAR&gt;", "/", "&lt;DIR&gt;"]],
    
    "&lt;USERINFO&gt;": [[], ["&lt;CHAR&gt;", ":", "&lt;CHAR&gt;", "@"]],
    
    "&lt;HOST&gt;": [["127.0.0.1:8080"]],
    
    "&lt;QUERY&gt;": [[], ["?", "&lt;CHAR&gt;" , "=", "&lt;CHAR&gt;"]],
    
    "&lt;FRAGMENT&gt;": [[], ["#", "&lt;CHAR&gt;"]],

    "&lt;VERSION&gt;": [["HTTP/0.9"], ["HTTP/1.0"], ["HTTP/1.1"], ["HTTP/2.0"], ["HTTP/3.0"]],
    
    "&lt;HEADERS&gt;": [[], ["&lt;HEADER&gt;", "\r\n", "&lt;HEADERS&gt;"]],
    
    "&lt;HEADER&gt;": [["&lt;HEADER_FIELD&gt;", ": ", "&lt;ANY&gt;"]],
    
    "&lt;HEADER_FIELD&gt;": [["A-IM"], ["Accept"], ["Accept-Charset"], ["Accept-Datetime"], ["Accept-Encoding"], ["Accept-Language"], ["Access-Control-Request-Method"], ["Access-Control-Request-Headers"], ["Authorization"], ["Cache-Control"], ["Connection"], ["Content-Encoding"], ["Content-Length"], ["Content-MD5"], ["Content-Type"], ["Cookie"], ["Date"], ["Expect"], ["Forwarded"], ["From"], ["Host"], ["HTTP2-Settings"], ["If-Match"], ["If-Modified-Since"], ["If-None-Match"], ["If-Range"], ["If-Unmodified-Since"], ["Max-Forwards"], ["Origin"], ["Pragma"], ["Proxy-Authorization"], ["Range"], ["Referer"], ["TE"], ["Trailer"], ["Transfer-Encoding"], ["User-Agent"], ["Upgrade"], ["Via"], ["Warning"]],
    
    "&lt;BODY&gt;": [[], ["&lt;CHAR&gt;"]],
    
    "&lt;ANY&gt;": [[], ["&lt;DATE&gt;"], ["&lt;CHAR&gt;"], ["&lt;HOST&gt;"], ["&lt;URI&gt;"]],
    
    "&lt;DATE&gt;": [["Sat, 29 Oct 1994 19:43:31 GMT"]],
    
    "&lt;CHAR&gt;": [["0"], ["1"], ["2"], ["3"], ["4"], ["5"], ["6"], ["7"], ["8"], ["9"], ["a"], ["b"], ["c"], ["d"], ["e"], ["f"], ["g"], ["h"], ["i"], ["j"], ["k"], ["l"], ["m"], ["n"], ["o"], ["p"], ["q"], ["r"], ["s"], ["t"], ["u"], ["v"], ["w"], ["x"], ["y"], ["z"], ["A"], ["B"], ["C"], ["D"], ["E"], ["F"], ["G"], ["H"], ["I"], ["J"], ["K"], ["L"], ["M"], ["N"], ["O"], ["P"], ["Q"], ["R"], ["S"], ["T"], ["U"], ["V"], ["W"], ["X"], ["Y"], ["Z"]]
}
</code></pre>
<p>到此，我们理解了Grammar对于Fuzzing的重要性，一个杰出的Grammar能够有效的生成大量合法输入，不过这只是从输入组成（句法）来看，这毕竟是一个庞大的范围，虽然有时候满足程序的输入格式，但是未必真的对Fuzzing起作用，这种情况非常常见。再一次以编译器为例子，你的程序在满足语言语法的同时更应该具备正确的语义。但是语义很难再以Grammar的形式表达。以URL生成Grammar为例，简单通过Grammar很难定义端口的范围。面对这样的问题，最简单的解决办法其实就是在Fuzz里面而不是在Grammar里面进行限制。以URL Grammar为例，通过Grammar生成的URL在真正的被作为Input给予目标之前，应该在Fuzz系统里面经过URL“合法性”判断，这里的判断可以由作者根据自己的需求来进行限制。</p>
<h3 id="Grammar-Toolbox"><a href="#Grammar-Toolbox" class="headerlink" title="Grammar Toolbox"></a>Grammar Toolbox</h3><p>​  在Fuzzing项目中对于Grammar的需求并不是一成不变的，因此Grammar的一大需求就是具备可扩展性。以一个简单的Gramar为例：</p>
<pre><code class="python">simple_nonterminal_grammar: Grammar = {
    "&lt;start&gt;": ["&lt;nonterminal&gt;"],
    "&lt;nonterminal&gt;": ["&lt;left-angle&gt;&lt;identifier&gt;&lt;right-angle&gt;"],
    "&lt;left-angle&gt;": ["&lt;"],
    "&lt;right-angle&gt;": ["&gt;"],
    "&lt;identifier&gt;": ["id"]  # for now
}
</code></pre>
<p>有时候我们希望拓展其功能，但是不希望原来的Grammar受到影响（类比编程中的继承）,就是一个很简单的如下操作。</p>
<pre><code class="python">nonterminal_grammar = copy.deepcopy(simple_nonterminal_grammar)
nonterminal_grammar["&lt;identifier&gt;"] = ["&lt;idchar&gt;", "&lt;identifier&gt;&lt;idchar&gt;"]
nonterminal_grammar["&lt;idchar&gt;"] = ['a', 'b', 'c', 'd']  # for now
</code></pre>
<p>总结为一个函数如下，非常简单就不多解释：</p>
<pre><code class="python">def set_opts(grammar: Grammar, symbol: str, expansion: Expansion, 
             opts: Option = {}) -&gt; None:
    """Set the options of the given expansion of grammar[symbol] to opts"""
    expansions = grammar[symbol]
    for i, exp in enumerate(expansions):
        if exp_string(exp) != exp_string(expansion):
            continue

        new_opts = exp_opts(exp)
        if opts == {} or new_opts == {}:
            new_opts = opts
        else:
            for key in opts:
                new_opts[key] = opts[key]

        if new_opts == {}:
            grammar[symbol][i] = exp_string(exp)
        else:
            grammar[symbol][i] = (exp_string(exp), new_opts)

        return

    raise KeyError(
        "no expansion " +
        repr(symbol) +
        " -&gt; " +
        repr(
            exp_string(expansion)))
</code></pre>
<p>同时，在写Fuzz的时候肯定不希望不断地写大量的符号和值的对应，因此我们需要一些语法来帮助，这里提供了ENBF的解析方法：</p>
<pre><code class="python"># 解析 ebnf 语法
def new_symbol(grammar: Grammar, symbol_name: str = "&lt;symbol&gt;") -&gt; str:
    """Return a new symbol for `grammar` based on `symbol_name`"""
    if symbol_name not in grammar:
        return symbol_name

    count = 1
    while True:
        tentative_symbol_name = symbol_name[:-1] + "-" + repr(count) + "&gt;"
        if tentative_symbol_name not in grammar:
            return tentative_symbol_name
        count += 1

# 提取表达式中符合EBNF语法的部分，? , * , + , ()
def parenthesized_expressions(expansion: Expansion) -&gt; List[str]:
    RE_PARENTHESIZED_EXPR = re.compile(r'\([^()]*\)[?+*]')
    # In later chapters, we allow expansions to be tuples,
    # with the expansion being the first element
    if isinstance(expansion, tuple):
        expansion = expansion[0]

    return re.findall(RE_PARENTHESIZED_EXPR, expansion)

# 对Grammar中的EBNF语法括号进行解析
def convert_ebnf_parentheses(ebnf_grammar: Grammar) -&gt; Grammar:
    """Convert a grammar in extended BNF to BNF"""
    grammar = extend_grammar(ebnf_grammar)
    for nonterminal in ebnf_grammar:
        expansions = ebnf_grammar[nonterminal]

        for i in range(len(expansions)):
            expansion = expansions[i]
            if not isinstance(expansion, str):
                expansion = expansion[0]

            while True:
                parenthesized_exprs = parenthesized_expressions(expansion)
                if len(parenthesized_exprs) == 0:
                    break

                for expr in parenthesized_exprs:
                    operator = expr[-1:]
                    contents = expr[1:-2]

                    new_sym = new_symbol(grammar)

                    exp = grammar[nonterminal][i]
                    opts = None
                    if isinstance(exp, tuple):
                        (exp, opts) = exp
                    assert isinstance(exp, str)

                    expansion = exp.replace(expr, new_sym + operator, 1)
                    if opts:
                        grammar[nonterminal][i] = (expansion, opts)
                    else:
                        grammar[nonterminal][i] = expansion

                    grammar[new_sym] = [contents]

    return grammar

# ENBF符号扩展
def extended_nonterminals(expansion: Expansion) -&gt; List[str]:
    RE_EXTENDED_NONTERMINAL = re.compile(r'(&lt;[^&lt;&gt; ]*&gt;[?+*])')
    # In later chapters, we allow expansions to be tuples,
    # with the expansion being the first element
    if isinstance(expansion, tuple):
        expansion = expansion[0]

    return re.findall(RE_EXTENDED_NONTERMINAL, expansion)

# ENBF符号扩展
def convert_ebnf_operators(ebnf_grammar: Grammar) -&gt; Grammar:
    """Convert a grammar in extended BNF to BNF"""
    grammar = extend_grammar(ebnf_grammar)
    for nonterminal in ebnf_grammar:
        expansions = ebnf_grammar[nonterminal]

        for i in range(len(expansions)):
            expansion = expansions[i]
            extended_symbols = extended_nonterminals(expansion)

            for extended_symbol in extended_symbols:
                operator = extended_symbol[-1:]
                original_symbol = extended_symbol[:-1]
                assert original_symbol in ebnf_grammar, \
                    f"{original_symbol} is not defined in grammar"

                new_sym = new_symbol(grammar, original_symbol)

                exp = grammar[nonterminal][i]
                opts = None
                if isinstance(exp, tuple):
                    (exp, opts) = exp
                assert isinstance(exp, str)

                new_exp = exp.replace(extended_symbol, new_sym, 1)
                if opts:
                    grammar[nonterminal][i] = (new_exp, opts)
                else:
                    grammar[nonterminal][i] = new_exp

                if operator == '?':
                    grammar[new_sym] = ["", original_symbol]
                elif operator == '*':
                    grammar[new_sym] = ["", original_symbol + new_sym]
                elif operator == '+':
                    grammar[new_sym] = [
                        original_symbol, original_symbol + new_sym]

    return grammar

def convert_ebnf_grammar(ebnf_grammar: Grammar) -&gt; Grammar:
    return convert_ebnf_operators(convert_ebnf_parentheses(ebnf_grammar))
</code></pre>
<p>对于Grammar来言，我们必须要确定它的一个合法性，不然在使用中必然会遇到各种错误问题，因此语法检查是很必要的，就如同编译器的语法检查很重要一样：</p>
<pre><code class="python"># 搜索Grammar中的定义的noterminal
def def_used_nonterminals(grammar: Grammar, start_symbol: 
                          str = START_SYMBOL) -&gt; Tuple[Optional[Set[str]], 
                                                       Optional[Set[str]]]:
    """Return a pair (`defined_nonterminals`, `used_nonterminals`) in `grammar`.
    In case of error, return (`None`, `None`)."""

    defined_nonterminals = set()
    used_nonterminals = {start_symbol}

    for defined_nonterminal in grammar:
        defined_nonterminals.add(defined_nonterminal)
        expansions = grammar[defined_nonterminal]
        if not isinstance(expansions, list):
            print(repr(defined_nonterminal) + ": expansion is not a list",
                  file=sys.stderr)
            return None, None

        if len(expansions) == 0:
            print(repr(defined_nonterminal) + ": expansion list empty",
                  file=sys.stderr)
            return None, None

        for expansion in expansions:
            if isinstance(expansion, tuple):
                expansion = expansion[0]
            if not isinstance(expansion, str):
                print(repr(defined_nonterminal) + ": "
                      + repr(expansion) + ": not a string",
                      file=sys.stderr)
                return None, None

            for used_nonterminal in nonterminals(expansion):
                used_nonterminals.add(used_nonterminal)

    return defined_nonterminals, used_nonterminals

def reachable_nonterminals(grammar: Grammar,
                           start_symbol: str = START_SYMBOL) -&gt; Set[str]:
    reachable = set()

    def _find_reachable_nonterminals(grammar, symbol):
        nonlocal reachable
        reachable.add(symbol)
        for expansion in grammar.get(symbol, []):
            for nonterminal in nonterminals(expansion):
                if nonterminal not in reachable:
                    _find_reachable_nonterminals(grammar, nonterminal)

    _find_reachable_nonterminals(grammar, start_symbol)
    return reachable

def unreachable_nonterminals(grammar: Grammar,
                             start_symbol=START_SYMBOL) -&gt; Set[str]:
    return grammar.keys() - reachable_nonterminals(grammar, start_symbol)

def opts_used(grammar: Grammar) -&gt; Set[str]:
    used_opts = set()
    for symbol in grammar:
        for expansion in grammar[symbol]:
            used_opts |= set(exp_opts(expansion).keys())
    return used_opts

# Grammar的合法性判断，类似于编译器里面的语法检查
def is_valid_grammar(grammar: Grammar,
                     start_symbol: str = START_SYMBOL, 
                     supported_opts: Set[str] = set()) -&gt; bool:
    """Check if the given `grammar` is valid.
       `start_symbol`: optional start symbol (default: `&lt;start&gt;`)
       `supported_opts`: options supported (default: none)"""

    defined_nonterminals, used_nonterminals = \
        def_used_nonterminals(grammar, start_symbol)
    if defined_nonterminals is None or used_nonterminals is None:
        return False

    # Do not complain about '&lt;start&gt;' being not used,
    # even if start_symbol is different
    if START_SYMBOL in grammar:
        used_nonterminals.add(START_SYMBOL)

    for unused_nonterminal in defined_nonterminals - used_nonterminals:
        print(repr(unused_nonterminal) + ": defined, but not used",
              file=sys.stderr)
    for undefined_nonterminal in used_nonterminals - defined_nonterminals:
        print(repr(undefined_nonterminal) + ": used, but not defined",
              file=sys.stderr)

    # Symbols must be reachable either from &lt;start&gt; or given start symbol
    unreachable = unreachable_nonterminals(grammar, start_symbol)
    msg_start_symbol = start_symbol

    if START_SYMBOL in grammar:
        unreachable = unreachable - \
            reachable_nonterminals(grammar, START_SYMBOL)
        if start_symbol != START_SYMBOL:
            msg_start_symbol += " or " + START_SYMBOL

    for unreachable_nonterminal in unreachable:
        print(repr(unreachable_nonterminal) + ": unreachable from " + msg_start_symbol,
              file=sys.stderr)

    used_but_not_supported_opts = set()
    if len(supported_opts) &gt; 0:
        used_but_not_supported_opts = opts_used(
            grammar).difference(supported_opts)
        for opt in used_but_not_supported_opts:
            print(
                "warning: option " +
                repr(opt) +
                " is not supported",
                file=sys.stderr)

    return used_nonterminals == defined_nonterminals and len(unreachable) == 0
</code></pre>
<p>以上列举的是常用的Tools，在Fuzz的编写过程中，要根据实际问题针对性的编写各式各样的工具。</p>
<h2 id="高效Grammars-Fuzz"><a href="#高效Grammars-Fuzz" class="headerlink" title="高效Grammars Fuzz"></a>高效Grammars Fuzz</h2><p>​  前面提供的simple_grammar_fuzzer其实存在大量的问题，比如性能低下，对于符号的解析次数受限，容易引起报错等，因此需要更加高明的算法。这里选择的是派生树，因为树形结构易于追踪而且易于添加和删除其中分支。关于Fuzz的编写其实就是不断的对派生树进行分析和对子节点的不断扩展。</p>
<h3 id="派生树算法"><a href="#派生树算法" class="headerlink" title="派生树算法"></a>派生树算法</h3><p>​  从上述的简单算法可以看出，整个的Grammar Fuzz的核心其实就是通过大量的符号扩展形成对应的数据结构，那么用来存储或者拓展符号的数据结构其实尤为重要。派生树的树状结构其实完美的符合了我们的要求，树形结构自上而下的扩展正好和符号的扩展相对应。而且<code>派生树使得我们可以掌控整个扩展过程的状态</code>，比如那些节点已经被扩展，或者某个节点是否需要扩展等，同时，在扩展过程中增加新节点的速度远超把一个符号替换为一个值的过程，因此使用这种数据结构也带来了一定的性能增益。</p>
<p>​  让我们以下面的Grammar为例子：</p>
<pre><code class="python"># URL Grammar
URL_GRAMMAR: Grammar = {
    "&lt;start&gt;":
        ["&lt;url&gt;"],
    "&lt;url&gt;":
        ["&lt;scheme&gt;://&lt;authority&gt;&lt;path&gt;&lt;query&gt;"],
    "&lt;scheme&gt;":
        ["http", "https", "ftp", "ftps"],
    "&lt;authority&gt;":
        ["&lt;host&gt;", "&lt;host&gt;:&lt;port&gt;", "&lt;userinfo&gt;@&lt;host&gt;", "&lt;userinfo&gt;@&lt;host&gt;:&lt;port&gt;"],
    "&lt;host&gt;":  # 大部分情况下其实可以指定一个URL
        ["cispa.saarland", "www.google.com", "fuzzingbook.com"],
    "&lt;port&gt;":
        ["80", "8080", "&lt;nat&gt;"],
    "&lt;nat&gt;":
        ["&lt;digit&gt;", "&lt;digit&gt;&lt;digit&gt;"],
    "&lt;digit&gt;":
        ["0", "1", "2", "3", "4", "5", "6", "7", "8", "9"],
    "&lt;userinfo&gt;":  # Just one
        ["user:password"],
    "&lt;path&gt;":  # Just a few
        ["", "/", "/&lt;id&gt;"],
    "&lt;id&gt;":  # Just a few
        ["abc", "def", "x&lt;digit&gt;&lt;digit&gt;"],
    "&lt;query&gt;":
        ["", "?&lt;params&gt;"],
    "&lt;params&gt;":
        ["&lt;param&gt;", "&lt;param&gt;&amp;&lt;params&gt;"],
    "&lt;param&gt;":  # Just a few
        ["&lt;id&gt;=&lt;id&gt;", "&lt;id&gt;=&lt;nat&gt;"],
}
</code></pre>
<p>以派生树算法来看，首先以<code>&lt;start&gt;</code>为初始节点，然后在Grammar中发现其存在对应的表达，所以就会选择<code>&lt;url&gt;</code>作为它的子节点，循环往复知道一个节点不再出现对应的子节点，然后整个的树形结构完成解析，输出对应的结构化数据。</p>
<p>​  对应的数据表示如下：</p>
<pre><code class="python">(SYMBOL_NAME, CHILDREN)
DerivationTree = Tuple[str, Optional[List[Any]]]
derivation_tree: DerivationTree = ("&lt;start&gt;",
                   [("&lt;expr&gt;",
                     [("&lt;expr&gt;", None),
                      (" + ", []),
                         ("&lt;term&gt;", None)]
                     )])
</code></pre>
<p><code>SYMBOL_NAME</code>代表的就是符号，CHILDREN代表子节点，表示为具体的数据结构就是：<code>DerivationTree = Tuple[str, Optional[List[Any]]]</code>。其中CHILDREN主要有两种表示：</p>
<ol>
<li>None代表当前节点可以继续向下扩展，其含义就是现在节点存在可扩展的符号。</li>
<li>[]代表的就是没有子节点了</li>
</ol>
<p>整个算法都围绕上面的基本原理展开</p>
<pre><code class="python">def g_rammar_fuzzer():
    f = GrammarFuzzer(URL_GRAMMAR)
    f.fuzz()
</code></pre>
<h3 id="ProbabilisticGrammarFuzzer"><a href="#ProbabilisticGrammarFuzzer" class="headerlink" title="ProbabilisticGrammarFuzzer"></a>ProbabilisticGrammarFuzzer</h3><p>​  有时候完全随机的进行表达式展开其实会白白浪费大量的时间和资源，因此可以对表达式附加概率值，这一块涉及到大量的概率学问题，有部分数据来源于世界的统计规律，比如下面给出的<code>leaddigit</code>符号对应的概率，这些就不在深入分析。</p>
<pre><code class="python">PROBABILISTIC_EXPR_GRAMMAR: Grammar = {
    "&lt;start&gt;":
        ["&lt;expr&gt;"],

    "&lt;expr&gt;":
        [("&lt;term&gt; + &lt;expr&gt;", opts(prob=0.1)),
         ("&lt;term&gt; - &lt;expr&gt;", opts(prob=0.2)),
         "&lt;term&gt;"],

    "&lt;term&gt;":
        [("&lt;factor&gt; * &lt;term&gt;", opts(prob=0.1)),
         ("&lt;factor&gt; / &lt;term&gt;", opts(prob=0.1)),
         "&lt;factor&gt;"
         ],

    "&lt;factor&gt;":
        ["+&lt;factor&gt;", "-&lt;factor&gt;", "(&lt;expr&gt;)",
            "&lt;leadinteger&gt;", "&lt;leadinteger&gt;.&lt;integer&gt;"],

    "&lt;leadinteger&gt;":
        ["&lt;leaddigit&gt;&lt;integer&gt;", "&lt;leaddigit&gt;"],

    # Benford's law: frequency distribution of leading digits
    "&lt;leaddigit&gt;":
        [("1", opts(prob=0.301)),
         ("2", opts(prob=0.176)),
         ("3", opts(prob=0.125)),
         ("4", opts(prob=0.097)),
         ("5", opts(prob=0.079)),
         ("6", opts(prob=0.067)),
         ("7", opts(prob=0.058)),
         ("8", opts(prob=0.051)),
         ("9", opts(prob=0.046)),
         ],

    # Remaining digits are equally distributed
    "&lt;integer&gt;":
        ["&lt;digit&gt;&lt;integer&gt;", "&lt;digit&gt;"],

    "&lt;digit&gt;":
        ["0", "1", "2", "3", "4", "5", "6", "7", "8", "9"],
}
</code></pre>
<p>跟之前的Grammar有很大不同的地方在于，现在的Grammar可以通过增加注释的方式为列表中的值添加随机概率，使得作者可以通过逆向获取其它渠道得到的信息可以在Fuzz中获得利用。那现在问题就显而易见了，如何确定概率？</p>
<p>​  当Fuzz的作者没办法直接给出一个符号对应的所有项具体的概率的时候，可以遵循的最直接的规则就是下面三个公式：</p>
<p><img src="https://cdn.staticaly.com/gh/L2ksy0d/image-host@master/20220731/image-20220727074801193.2ln12v05bx40.png"></p>
<p><img src="https://cdn.staticaly.com/gh/L2ksy0d/image-host@master/20220731/image-20220727074816609.10867094x8k0.png"></p>
<p><img src="https://cdn.staticaly.com/gh/L2ksy0d/image-host@master/20220731/image-20220727074824325.1vqo9xj0oiw0.png"></p>
<p>大致含义也很好理解，就是a代表的是已知概率的项，而u代表的未知概率的项目，已知概率自然可以通过<code>opts</code>的方法给对应项附加概率，未知概率的项则按照概率平分的原则来赋予概率。之后自然是要在Fuzz里面引入概率，使得在生成种子的时候可以对符号解析的选择赋予权重，进而提高Fuzz效率。</p>
<p>​  就Fuzz的具体实现而言，其实相比于上述的Grammar Fuzz只是增加了一个对于opts注释的访问，以便在随机解析的时候可以附加概率值权重。但是这样带来的优势是很明显的，甚至可以通过控制输入Fuzz目标指定的Func等。但是还有一种情况，我第一次解析Grammar symbol的时候希望它的概率为0.3，但是我第二次解析Grammar symbol的时候希望其概率为0.5，为了实现这一点其实可以利用上下文，在不同的上下文中复制希望赋予其不同概率的symbol，以IP Grammar为例子：</p>
<pre><code class="python">IP_ADDRESS_GRAMMAR: Grammar = {
    "&lt;start&gt;": ["&lt;address&gt;"],
    "&lt;address&gt;": ["&lt;octet&gt;.&lt;octet&gt;.&lt;octet&gt;.&lt;octet&gt;"],
    # ["0", "1", "2", ..., "255"]
    "&lt;octet&gt;": decrange(0, 256) # 其实代表的就是0-256
}
</code></pre>
<p>为了使得每次解析<code>&lt;octet&gt;</code>的时候都使用不同的概率，可以对其扩展，形成下面的语法：</p>
<pre><code class="python">IP_ADDRESS_GRAMMAR: Grammar = {
    "&lt;start&gt;": ["&lt;address&gt;"],
    "&lt;address&gt;": ["&lt;octet-1&gt;.&lt;octet-2&gt;.&lt;octet-3&gt;.&lt;octet-4&gt;"],
    # ["0", "1", "2", ..., "255"]
    "&lt;octet-1&gt;": decrange(0, 256) # 其实代表的就是0-256
    "&lt;octet-2&gt;": decrange(0, 256) # 其实代表的就是0-256
    "&lt;octet-3&gt;": decrange(0, 256) # 其实代表的就是0-256
    "&lt;octet-4&gt;": decrange(0, 256) # 其实代表的就是0-256
}
</code></pre>
<p>这样在进行解析的时候就完全可以对每次解析附加不同的概率。下面是帮助实现的函数：</p>
<pre><code class="python">def _duplicate_context(grammar: Grammar,
                       orig_grammar: Grammar,
                       symbol: str,
                       expansion: Optional[Expansion],
                       depth: Union[float, int],
                       seen: Dict[str, str]) -&gt; None:
    """Helper function for `duplicate_context()`"""

    for i in range(len(grammar[symbol])):
        if expansion is None or grammar[symbol][i] == expansion:
            new_expansion = ""
            for (s, c) in expansion_to_children(grammar[symbol][i]):
                if s in seen:                 # Duplicated already
                    new_expansion += seen[s]
                elif c == [] or depth == 0:   # Terminal symbol or end of recursion
                    new_expansion += s
                else:                         # Nonterminal symbol - duplicate
                    # Add new symbol with copy of rule
                    new_s = new_symbol(grammar, s)
                    grammar[new_s] = copy.deepcopy(orig_grammar[s])

                    # Duplicate its expansions recursively
                    # {**seen, **{s: new_s}} is seen + {s: new_s}
                    _duplicate_context(grammar, orig_grammar, new_s, expansion=None,
                                       depth=depth - 1, seen={**seen, **{s: new_s}})
                    new_expansion += new_s

            grammar[symbol][i] = new_expansion

def duplicate_context(grammar: Grammar, 
                      symbol: str,
                      expansion: Optional[Expansion] = None, 
                      depth: Union[float, int] = float('inf')):
    """Duplicate an expansion within a grammar.

    In the given grammar, take the given expansion of the given `symbol`
    (if `expansion` is omitted: all symbols), and replace it with a
    new expansion referring to a duplicate of all originally referenced rules.

    If `depth` is given, limit duplication to `depth` references
    (default: unlimited)
    """
    orig_grammar = extend_grammar(grammar)
    _duplicate_context(grammar, orig_grammar, symbol,
                       expansion, depth, seen={})

    # After duplication, we may have unreachable rules; delete them
    for nonterminal in unreachable_nonterminals(grammar):
        del grammar[nonterminal]
</code></pre>
<p>在完成上下文复制之后就可以通过类似下面的操作得到我们想要的结果：</p>
<pre><code class="python">set_prob(probabilistic_ip_address_grammar, "&lt;octet-1&gt;", "127", 1.0)
set_prob(probabilistic_ip_address_grammar, "&lt;octet-2&gt;", "0", 1.0)
</code></pre>
<p>不过这就又引入一个问题，概率在赋予给symbol之后一成不变真的合适吗？在真实世界的Fuzz中随着我们对于目标的不断了解，或者一些其它情况比如长时间未出现想要的结果等，及时改变策略也是非常必要的，但是如果Fuzz可以智能的自己调节调整不同symbol的概率值的话，会减轻很多的负担并获得更好的软件测试效果。一个比较好的办法是让Fuzz通过最开始被给予Inputs种子来学习应该赋予某些symbol多大的一个概率值，这种方法在某些场景下非常有用：</p>
<ol>
<li>测试常用功能，因为很多软件测试更希望常用的功能确保安全，但是对于漏洞挖掘研究人员来说可能目标不在于此。</li>
<li>测试不常用功能，通过规避Inputs中解析到的symbol，Fuzz就会更偏向于测试一些不常用的功能。</li>
<li>专注于指定的Inputs，一些漏洞挖掘可能希望专注于已有的非常有价值的poc inputs，通过专注于这些inputs，Fuzz可以测试软件的一些薄弱环节从而达到很好的效果。</li>
</ol>
<p>​  理论已经存在，那么如何实现呢？第一步肯定是需要将已经存在的Inputs种子恢复成为派生树，然后对派生树种每个Symbol对应的值有多少来计算将来的概率值。</p>
<p><img src="https://cdn.staticaly.com/gh/L2ksy0d/image-host@master/20220731/image-20220727103008425.4agknyqe2ly0.png"></p>
<p>如上图，假设我给与一个<code>127.0.0.1</code>的种子，那么被解析之后，0在<code>&lt;octet&gt;</code>中的概率值就会被限制为<code>50%</code>，127和1分别为<code>25%</code>，那么在Fuzz运行的时候相关的概率值就可以赋予给<code>&lt;octet&gt;</code>。那么如果测试一些不常用功能该怎么办呢？其实就是通过原来测常用功能的Inputs得到相关概率，然后进行概率翻转就行了，比如常用功能的Inputs概率如下：</p>
<pre><code>[('http', {'prob': 0.2222222222222222}),
 ('https', {'prob': 0.6666666666666666}),
 ('ftp', {'prob': 0.0}),
 ('ftps', {'prob': 0.1111111111111111})]
</code></pre>
<p>那么经过翻转之后就是：</p>
<pre><code>[('http', {'prob': 0.1111111111111111}),
 ('https', {'prob': 0.0}),
 ('ftp', {'prob': 0.6666666666666666}),
 ('ftps', {'prob': 0.2222222222222222})]
</code></pre>
<p>上述就是之前讲到的专注测试常用功能或者非常用功能的基本思路，从此处引出的另一个比较关键的是通过Inputs帮我们专注于目标的特定功能，它和测试常用功能的区别就是首先要找到一批特殊的Inputs，通过这些Inputs作为seeds就可以对语法解析的过程进行概率分析和限制，使得后续的变异可以一直有较高的目标命中率。</p>
<h3 id="Generator-With-Pre-or-Post-or-order-Func"><a href="#Generator-With-Pre-or-Post-or-order-Func" class="headerlink" title="Generator With Pre or Post or order Func"></a>Generator With Pre or Post or order Func</h3><p>​  在某些Inputs在生成的时候，Fuzz作者可能希望对他们进行一些限制调整，获取其它的操作，这些都可以通过<code>pre func</code>完成。这类似于hook，那么对于func触发的时机一般就分为两种，在Inputs的生成之前或者是生成之后，在语法里面的表示就是：</p>
<pre><code class="python">CHARGE_GRAMMAR: Grammar = {
    "&lt;start&gt;": ["Charge &lt;amount&gt; to my credit card &lt;credit-card-number&gt;"],
    "&lt;amount&gt;": ["$&lt;float&gt;"],
    "&lt;float&gt;": ["&lt;integer&gt;.&lt;digit&gt;&lt;digit&gt;"],
    "&lt;integer&gt;": ["&lt;digit&gt;", "&lt;integer&gt;&lt;digit&gt;"],
    "&lt;digit&gt;": crange('0', '9'),

    "&lt;credit-card-number&gt;": ["&lt;digits&gt;"],
    "&lt;digits&gt;": ["&lt;digit-block&gt;&lt;digit-block&gt;&lt;digit-block&gt;&lt;digit-block&gt;"],
    "&lt;digit-block&gt;": ["&lt;digit&gt;&lt;digit&gt;&lt;digit&gt;&lt;digit&gt;"],
}

CHARGE_GRAMMAR.update({
    "&lt;float&gt;": [("&lt;integer&gt;.&lt;digit&gt;&lt;digit&gt;", opts(pre=high_charge))], # high_charge是函数名称
})

CHARGE_GRAMMAR.update({
    "&lt;float&gt;": [("&lt;integer&gt;.&lt;digit&gt;&lt;digit&gt;",
                 opts(pre=lambda: random.randint(10000000, 90000000) / 100.0))] # 或者选择使用lambda表达式
})
</code></pre>
<p>另一种就是在Seeds的生成之后了：</p>
<pre><code class="python">CHARGE_GRAMMAR.update({
    "&lt;credit-card-number&gt;": [("&lt;digits&gt;", opts(post=lambda digits: fix_credit_card(digits)))]
})
</code></pre>
<p>比如生成的digits不能满足Fuzz的需求，我们就可以通过这种方式来进行及时的修正，以提高Fuzz的效率。</p>
<h3 id="Greybox-Fuzzing-with-Grammars"><a href="#Greybox-Fuzzing-with-Grammars" class="headerlink" title="Greybox Fuzzing with Grammars"></a>Greybox Fuzzing with Grammars</h3><p>​  除了Fuzzing性能类的问题之外的另一个问题就是变异的导向问题，在Grammars Fuzz生成Input的过程中对于Grammar的内部解析是随机的，但是对于Fuzz目标来说，大量的Input可能会触发相同的分支进而导致代码覆盖率难以达到理想的值。对于AFL类似的覆盖引导型Fuzz来说，因为白盒Fuzz的源代码插桩缘故可以统计代码覆盖率来进行不错的引导，但是还存在很多情况，比如黑盒，甚至是以一种WebServer为目标的Fuzz，统计代码覆盖率并不是一件简单的事情，这时候采取的措施应该是不断的增加Inputs生成的多样性，比如在上述的派生树的子节点的扩展过程进行统计，使其在生成Input语料的时候偏向于还没扩展过的节点。这时候就会面临新的问题，如何快速提升代码覆盖率？</p>
<p>​  在进行Fuzz的时候，有时候一些输入的部分会被识别为关键字，比如C语言里面的int等，如果告诉Fuzz这些关键字就可以在短时间内极大的提升代码覆盖率，但是就长远来看整体的代码覆盖率还是要差于不使用关键字字典的情况。下面是使用关键字字典的变异Inputs生成器。</p>
<pre><code class="python">class DictMutator(Mutator):
    """Mutate strings using keywords from a dictionary"""

    def __init__(self, dictionary: List[str]) -&gt; None:
        """Constructor. `dictionary` is the list of keywords to use."""
        super().__init__()
        self.dictionary = dictionary
        self.mutators.append(self.insert_from_dictionary)

    def insert_from_dictionary(self, s: str) -&gt; str:
        """Returns s with a keyword from the dictionary inserted"""
        pos = random.randint(0, len(s))
        random_keyword = random.choice(self.dictionary)
        return s[:pos] + random_keyword + s[pos:]
</code></pre>
<p>但是问题在于关键字通过字典随机引入的方式很可能破坏了Input本来的正确输入结构进而引发不必要的损耗。解决的方法其实也很简单：<code>Fuzzing with Input Fragments</code>.</p>
<ol>
<li>对原有的Input进行Parse，形成派生树。</li>
<li>对派生树进行节点互换或者节点替换等操作。</li>
<li>对派生树进行还原，形成新的Input。</li>
</ol>
<p>以上的所有操作都在派生树上进行。为了更方便的进行编译操作，可以建立一个派生树的碎片池，每个碎片都由子树组成，子树包括符号和对应的Node节点和其子节点。不过对于派生树的parse其实是非常耗时的，因此可以设置一些时间限制来防止速度过低。不过以Fragments为基础的变异虽然可以很好的符合Inputs合法性的要求但是在代码覆盖率提升方面并不亮眼。而且以此为基础的<code>LangFuzz</code>其实在Inputs生成的速度上也远低于平常的结构化黑盒Fuzz。下面是两组对比数据：</p>
<pre><code>LangFuzz
From the 300 generated inputs, 152 (50.67%) can be parsed.In total, 91 statements are covered.

BlackFuzz
From the 300 generated inputs, 36 (12.00%) can be parsed.In total, 161 statements are covered.
</code></pre>
<p>可以看出以Fragments为基础的变异的优势在于它可以很好的生成符合结构化语法的变异。那么现在的疑问就是如何在保证输入语法正确性的前提下提升代码覆盖率？</p>
<p>​  一种方法是利用类似AFL的覆盖引导方式，利用代码覆盖率不断作为变异的反馈，以此来不断的增添提高代码覆盖率的种子，同时提供<code>structural mutations</code>和<code>32 byte-level mutations</code>两种变异方式，如下：</p>
<pre><code class="python">class GreyboxGrammarFuzzer(GreyboxFuzzer):
    """Greybox fuzzer using grammars."""

    def __init__(self, seeds: List[str],
                 byte_mutator: Mutator, tree_mutator: FragmentMutator,
                 schedule: PowerSchedule) -&gt; None:
        """Constructor.
        `seeds` - set of inputs to mutate.
        `byte_mutator` - a byte-level mutator.
        `tree_mutator` = a tree-level mutator.
        `schedule` - a power schedule.
        """
        super().__init__(seeds, byte_mutator, schedule)
        self.tree_mutator = tree_mutator

    def create_candidate(self) -&gt; str:
        """Returns an input generated by structural mutation 
           of a seed in the population"""
        seed = cast(SeedWithStructure, self.schedule.choose(self.population))

        # Structural mutation
        trials = random.randint(0, 4)
        for i in range(trials):
            seed = self.tree_mutator.mutate(seed)

        # Byte-level mutation
        candidate = seed.data
        if trials == 0 or not seed.has_structure or random.randint(0, 1) == 1:
            dumb_trials = min(len(seed.data), 1 &lt;&lt; random.randint(1, 5))
            for i in range(dumb_trials):
                candidate = self.mutator.mutate(candidate)

        return candidate
</code></pre>
<p>想通的种子和变异次数的条件下，测试结果如下：</p>
<pre><code class="python">From the 300 generated inputs, 1 (0.33%) can be parsed.
In total, 180 statements are covered.
</code></pre>
<p>同时，在Inputs生成的速度方面极大提升，较高的代码覆盖率，但是在Inputs的合法性方面表现是最差的。那这个问题该如何解决呢？答案就是<code>Fuzzing with Input Regions</code>，这种Fuzz的变异方法不再使用派生树节点拆分重组等方式，而是通过将合法种子的不同区域直接进行拆分重组的方式，这里的区域指的是可以和派生树符号对应的连续的字节序列，这样的好处其实在于它操作的对象可能比Fragments更大或者更小，以此种方式进行变异在和上述变异条件相同的情况下测试结构如下：</p>
<pre><code>It took the structural greybox fuzzer with region mutator
        11.35 seconds to generate and execute 300 inputs.

From the 300 generated inputs, 4 (1.33%) can be parsed.
In total, 168 statements are covered.
On average, 9.1% of a seed in the population can be successfully parsed.
</code></pre>
<p>可以看到存在较高的代码覆盖率，在速度方面虽然优于Fragments Fuzz但是还是弱于普通的黑盒Fuzz，在代码覆盖率方面高于Fragments Fuzz并和GreyboxGrammarFuzzer维持在相差无几的水平。不过核心原因还是在于，通过的合法Inputs其实占比很低。那么如何解决这个问题？首先要让Fuzzer可以聚焦合法的Inputs。这一点其实前面已经讨论过了，只需要利用<code>schedule</code>给合法Inputs的相关结构赋予更多的权重。测试结果如下：</p>
<pre><code>It took AFLSmart 20.75 seconds to generate and execute 300 inputs.

From the 300 generated inputs, 46 (15.33%) can be parsed.
In total, 162 statements are covered.
On average, 23.7% of a seed in the population can be successfully parsed.
</code></pre>
<p>可以看出在代码覆盖率保持较高水平的情况下，Inputs的合法性也得到了大幅度的提升，但是在Inputs的生成速度上来看，还是远弱于普通的GrammarFuzz。</p>
<p>​  从上面可以看出，在选择Fuzz的时候本身就是一个取舍的问题，通过二次开发或者针对不同场景的选择才能更好的达到我们想要的结果。</p>
<h3 id="Parser-input"><a href="#Parser-input" class="headerlink" title="Parser input"></a>Parser input</h3><p>​  假设你在做一个模糊测试，无论是Grammar Fuzz 或者其他的Fuzz也好，如果没有合适的种子那么通过不断变异形成合适的Inputs是非常困难的，当然AFL的作者展示了通过简单的输入不断向目标进化的可能性，但是这毕竟十分浪费时间和性能，效果在很多场景下估计也是不尽人意的。</p>
<p>​  因此在进行模糊测试的时候如果可以获取一些poc，或者其它较好种子，比如在Fuzz js解释器的一个比较经常的做法就是将一些公开的poc，如下：</p>
<pre><code class="js">var haystack = "foo";
var re_text = "^foo";
haystack += "x";
re_text += "(x)";
var re = new RegExp(re_text);
re.test(haystack);
RegExp.input = Number();
print(RegExp.$1);
</code></pre>
<p>作为seeds进行变异，将生成的Inputs用来Fuzz解释器。表现出来不错的结果。</p>
<blockquote>
<p>Tips:如何判断对面的代码覆盖率，一般黑盒情况下可以试时间，如果一个Input在对面耗费了更多的时间来运行，那么可以猜测其走过了更多的代码分支。</p>
</blockquote>
<h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>​  在面对Fuzz的目标的时候最重要的是选择合适的变异方式以及较好的初始种子，根据目标和测试目的不断地进行取舍和针对性开发才能得到比较理想的结果。</p>
<h2 id="参考链接"><a href="#参考链接" class="headerlink" title="参考链接"></a>参考链接</h2><blockquote>
<p><a target="_blank" rel="noopener" href="https://www.fuzzingbook.org/">https://www.fuzzingbook.org</a></p>
<p>文中数据测试来源大多为Fuzzingbook，因为根据电脑不同，其实具体数值结果会有一定偏差，但是结论都是一样的，因此就展示了书中的测试数据。</p>
</blockquote>

            <!--[if lt IE 9]><script>document.createElement('audio');</script><![endif]-->
            <audio id="audio" loop="1" preload="auto" controls="controls"
                data-autoplay="false">
                <source type="audio/mpeg" src="">
            </audio>
            
            <ul id="audio-list" style="display:none">
                
                
                <li title='0' data-url='/statics/chengdu.mp3'></li>
                
                    
            </ul>
            
                        
            
            
    <div id='gitalk-container' class="comment link"
        data-ae='false'
        data-ci=''
        data-cs=''
        data-r=''
        data-o=''
        data-a=''
        data-d=''
        data-p='https://cors-anywhere.azm.workers.dev/https://github.com/login/oauth/access_token'
    >Comments</div>


            
            
        </div>
        <div class="sidebar">
            <div class="box animated fadeInRight">
                <div class="subbox">
                    <img src="https://cdn.staticaly.com/gh/L2ksy0d/image-host@master/20220720/clocklogo.jpg" height=300 width=300></img>
                    <p>Clock</p>
                    <span>Love pwn and exploit,Passionate about vulnerability mining and security research.</span>
                    <dl>
                        
                        
                            
                                <dd>
                                    <link rel="stylesheet" type="text/css" href="">
                                    <a href="function link() { [native code] }" target="_blank"><span
                                    class=" iconfont "></span></a>
                                </dd>
                            
                            
                            
                        
                    </dl>
                </div>
                <ul>
                    <li><a href="/">21 <p>Articles</p></a></li>
                    <li><a href="/categories">9 <p>Categories</p></a></li>
                    <li><a href="/tags">11 <p>Tags</p></a></li>
                </ul>
            </div>
            
            
            
            <div class="box sticky animated fadeInRight faster">
                <div id="toc" class="subbox">
                    <h4>Contents</h4>
                    <ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#Fuzzing%E4%B9%8BGrammars"><span class="toc-number">1.</span> <span class="toc-text">Fuzzing之Grammars</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#Fuzzing-input"><span class="toc-number">1.1.</span> <span class="toc-text">Fuzzing input</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Grammars%E5%88%9D%E6%8E%A2"><span class="toc-number">1.2.</span> <span class="toc-text">Grammars初探</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#Sample-Grammar-Fuzz"><span class="toc-number">1.2.1.</span> <span class="toc-text">Sample Grammar Fuzz</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Grammar-Toolbox"><span class="toc-number">1.2.2.</span> <span class="toc-text">Grammar Toolbox</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E9%AB%98%E6%95%88Grammars-Fuzz"><span class="toc-number">1.3.</span> <span class="toc-text">高效Grammars Fuzz</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%B4%BE%E7%94%9F%E6%A0%91%E7%AE%97%E6%B3%95"><span class="toc-number">1.3.1.</span> <span class="toc-text">派生树算法</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#ProbabilisticGrammarFuzzer"><span class="toc-number">1.3.2.</span> <span class="toc-text">ProbabilisticGrammarFuzzer</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Generator-With-Pre-or-Post-or-order-Func"><span class="toc-number">1.3.3.</span> <span class="toc-text">Generator With Pre or Post or order Func</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Greybox-Fuzzing-with-Grammars"><span class="toc-number">1.3.4.</span> <span class="toc-text">Greybox Fuzzing with Grammars</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Parser-input"><span class="toc-number">1.3.5.</span> <span class="toc-text">Parser input</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%80%BB%E7%BB%93"><span class="toc-number">1.4.</span> <span class="toc-text">总结</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%8F%82%E8%80%83%E9%93%BE%E6%8E%A5"><span class="toc-number">1.5.</span> <span class="toc-text">参考链接</span></a></li></ol></li></ol>
                </div>
            </div>
            
            
        </div>
    </div>
</div>

    </div>
</div>
    <div id="back-to-top" class="animated fadeIn faster">
        <div class="flow"></div>
        <span class="percentage animated fadeIn faster">0%</span>
        <span class="iconfont icon-top02 animated fadeIn faster"></span>
    </div>
</body>
<footer>
    <p class="copyright" id="copyright">
        &copy; 2023
        <span class="gradient-text">
            RainSec
        </span>.
        Powered by <a href="http://hexo.io/" title="Hexo" target="_blank" rel="noopener">Hexo</a>
        Theme
        <span class="gradient-text">
            <a href="https://github.com/TriDiamond/hexo-theme-obsidian" title="Obsidian" target="_blank" rel="noopener">Obsidian</a>
        </span>
        <small><a href="https://github.com/TriDiamond/hexo-theme-obsidian/blob/master/CHANGELOG.md" title="v1.4.9.3" target="_blank" rel="noopener">v1.4.9.3</a></small>
        
        
    </p>
</footer>

<script type="text/javascript" src="https://cdn.bootcss.com/mathjax/2.7.6/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
</script>
<script>
  MathJax.Hub.Config({
    "HTML-CSS": {
      preferredFont: "TeX",
      availableFonts: ["STIX", "TeX"],
      linebreaks: {
        automatic: true
      },
      EqnChunk: (MathJax.Hub.Browser.isMobile ? 10 : 50)
    },
    tex2jax: {
      inlineMath: [
        ["$", "$"],
        ["\\(", "\\)"]
      ],
      processEscapes: true,
      ignoreClass: "tex2jax_ignore|dno",
      skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
    },
    TeX: {
      noUndefined: {
        attributes: {
          mathcolor: "red",
          mathbackground: "#FFEEEE",
          mathsize: "90%"
        }
      },
      Macros: {
        href: "{}"
      }
    },
    messageStyle: "none"
  });
</script>
<script>
  function initialMathJax() {
    MathJax.Hub.Queue(function () {
      var all = MathJax.Hub.getAllJax(),
        i;
      // console.log(all);
      for (i = 0; i < all.length; i += 1) {
        console.log(all[i].SourceElement().parentNode)
        all[i].SourceElement().parentNode.className += ' has-jax';
      }
    });
  }

  function reprocessMathJax() {
    if (typeof MathJax !== 'undefined') {
      MathJax.Hub.Queue(["Typeset", MathJax.Hub]);
    }
  }
</script>


 
<link rel="stylesheet" href="//cdn.bootcss.com/gitalk/1.5.0/gitalk.min.css">
 
<script src="//cdn.bootcss.com/gitalk/1.5.0/gitalk.min.js"></script>
  
<script src="//cdnjs.cloudflare.com/ajax/libs/jquery/3.4.1/jquery.min.js"></script>
<script src="/js/plugin.js"></script>
<script src="/js/obsidian.js"></script>
<script src="/js/jquery.truncate.js"></script>
<script src="/js/search.js"></script>
 
<script src="//cdn.bootcss.com/typed.js/2.0.10/typed.min.js"></script>
 
<script src="//cdn.bootcss.com/blueimp-md5/2.12.0/js/md5.min.js"></script>
 
<script src="//cdnjs.cloudflare.com/ajax/libs/social-share.js/1.0.16/js/social-share.min.js"></script>


<script src="https://cdn.bootcss.com/codemirror/5.48.4/codemirror.min.js"></script>
 
<script src="//cdn.bootcss.com/codemirror/5.48.4/mode/javascript/javascript.min.js"></script>
  
<script src="//cdn.bootcss.com/codemirror/5.48.4/mode/css/css.min.js"></script>
  
<script src="//cdn.bootcss.com/codemirror/5.48.4/mode/xml/xml.min.js"></script>
  
<script src="//cdn.bootcss.com/codemirror/5.48.4/mode/htmlmixed/htmlmixed.min.js"></script>
  
<script src="//cdn.bootcss.com/codemirror/5.48.4/mode/clike/clike.min.js"></script>
  
<script src="//cdn.bootcss.com/codemirror/5.48.4/mode/php/php.min.js"></script>
  
<script src="//cdn.bootcss.com/codemirror/5.48.4/mode/shell/shell.min.js"></script>
  
<script src="//cdn.bootcss.com/codemirror/5.48.4/mode/python/python.min.js"></script>
  
<script src="//cdn.bootcss.com/codemirror/5.48.4/mode/java/java.min.js"></script>
  
<script src="//cdn.bootcss.com/codemirror/5.48.4/mode/go/go.min.js"></script>
   
<script src="/js/busuanzi.min.js"></script>

<script>
  $(document).ready(function () {
    if ($('span[id^="busuanzi_"]').length) {
      initialBusuanzi();
    }
  });
</script>
 
<link rel="stylesheet" href="//cdn.bootcss.com/photoswipe/4.1.3/photoswipe.min.css">
<link rel="stylesheet" href="//cdn.bootcss.com/photoswipe/4.1.3/default-skin/default-skin.min.css">


<script src="//cdn.bootcss.com/photoswipe/4.1.3/photoswipe.min.js"></script>
<script src="//cdn.bootcss.com/photoswipe/4.1.3/photoswipe-ui-default.min.js"></script>


<!-- Root element of PhotoSwipe. Must have class pswp. -->
<div class="pswp" tabindex="-1" role="dialog" aria-hidden="true">
    <!-- Background of PhotoSwipe. 
         It's a separate element as animating opacity is faster than rgba(). -->
    <div class="pswp__bg"></div>
    <!-- Slides wrapper with overflow:hidden. -->
    <div class="pswp__scroll-wrap">
        <!-- Container that holds slides. 
            PhotoSwipe keeps only 3 of them in the DOM to save memory.
            Don't modify these 3 pswp__item elements, data is added later on. -->
        <div class="pswp__container">
            <div class="pswp__item"></div>
            <div class="pswp__item"></div>
            <div class="pswp__item"></div>
        </div>
        <!-- Default (PhotoSwipeUI_Default) interface on top of sliding area. Can be changed. -->
        <div class="pswp__ui pswp__ui--hidden">
            <div class="pswp__top-bar">
                <!--  Controls are self-explanatory. Order can be changed. -->
                <div class="pswp__counter"></div>
                <button class="pswp__button pswp__button--close" title="Close (Esc)"></button>
                <button class="pswp__button pswp__button--share" title="Share"></button>
                <button class="pswp__button pswp__button--fs" title="Toggle fullscreen"></button>
                <button class="pswp__button pswp__button--zoom" title="Zoom in/out"></button>
                <!-- Preloader demo http://codepen.io/dimsemenov/pen/yyBWoR -->
                <!-- element will get class pswp__preloader--active when preloader is running -->
                <div class="pswp__preloader">
                    <div class="pswp__preloader__icn">
                      <div class="pswp__preloader__cut">
                        <div class="pswp__preloader__donut"></div>
                      </div>
                    </div>
                </div>
            </div>
            <div class="pswp__share-modal pswp__share-modal--hidden pswp__single-tap">
                <div class="pswp__share-tooltip"></div> 
            </div>
            <button class="pswp__button pswp__button--arrow--left" title="Previous (arrow left)">
            </button>
            <button class="pswp__button pswp__button--arrow--right" title="Next (arrow right)">
            </button>
            <div class="pswp__caption">
                <div class="pswp__caption__center"></div>
            </div>
        </div>
    </div>
</div>
  

<script>
  function initialTyped() {
    var typedTextEl = $('.typed-text');
    if (typedTextEl && typedTextEl.length > 0) {
      var typed = new Typed('.typed-text', {
        strings: ['艺术家思维去思考问题，工匠创造精神去开发|', '致力于自动化渗透测试和漏洞挖掘'],
        typeSpeed: 90,
        loop: true,
        loopCount: Infinity,
        backSpeed: 20,
      });
    }
  }

  if ($('.article-header') && $('.article-header').length) {
    $(document).ready(function () {
      initialTyped();
    });
  }
</script>




<!-- 引用依赖 -->
<script>document.write(aplayerconf)</script>




</html>
